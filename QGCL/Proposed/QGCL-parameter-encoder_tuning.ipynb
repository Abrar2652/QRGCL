{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5165eef4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:21:44.057511Z",
     "iopub.status.busy": "2024-10-15T09:21:44.057126Z",
     "iopub.status.idle": "2024-10-15T09:27:50.073721Z",
     "shell.execute_reply": "2024-10-15T09:27:50.072600Z"
    },
    "id": "-LvCO-zQ2nmU",
    "papermill": {
     "duration": 366.036238,
     "end_time": "2024-10-15T09:27:50.075972",
     "exception": false,
     "start_time": "2024-10-15T09:21:44.039734",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "!pip install torch==2.2.0\n",
    "!pip install torch_geometric\n",
    "!pip install particle\n",
    "!pip install pennylane\n",
    "!pip install pennylane-lightning\n",
    "!pip install pennylane-torch\n",
    "!pip install torchdata==0.7.1\n",
    "!pip install torchvision==0.17.0\n",
    "!pip install qiskit==0.46.0\n",
    "!pip install torchquantum\n",
    "!pip install qiskit-ibm-runtime==0.18.0\n",
    "!pip install qiskit-aer==0.13.2\n",
    "!pip install dgl -f https://data.dgl.ai/wheels/cu121/repo.html\n",
    "!pip install dglgo -f https://data.dgl.ai/wheels-test/repo.html\n",
    "!pip install energyflow\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a9288b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:27:50.109023Z",
     "iopub.status.busy": "2024-10-15T09:27:50.108686Z",
     "iopub.status.idle": "2024-10-15T09:27:53.137512Z",
     "shell.execute_reply": "2024-10-15T09:27:53.136393Z"
    },
    "id": "gt_ntIZ7S00B",
    "outputId": "1564d571-3f70-46b2-a6f1-a90c31740161",
    "papermill": {
     "duration": 3.047927,
     "end_time": "2024-10-15T09:27:53.139987",
     "exception": false,
     "start_time": "2024-10-15T09:27:50.092060",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                                  Version            Editable project location\r\n",
      "---------------------------------------- ------------------ -------------------------\r\n",
      "absl-py                                  1.4.0\r\n",
      "accelerate                               0.34.2\r\n",
      "aiobotocore                              2.15.1\r\n",
      "aiofiles                                 22.1.0\r\n",
      "aiohttp                                  3.9.5\r\n",
      "aioitertools                             0.12.0\r\n",
      "aiosignal                                1.3.1\r\n",
      "aiosqlite                                0.20.0\r\n",
      "alabaster                                1.0.0\r\n",
      "albucore                                 0.0.17\r\n",
      "albumentations                           1.4.17\r\n",
      "alembic                                  1.13.3\r\n",
      "altair                                   5.4.1\r\n",
      "annotated-types                          0.7.0\r\n",
      "annoy                                    1.17.3\r\n",
      "ansicolors                               1.1.8\r\n",
      "anyio                                    4.4.0\r\n",
      "apache-beam                              2.46.0\r\n",
      "appdirs                                  1.4.4\r\n",
      "archspec                                 0.2.3\r\n",
      "argon2-cffi                              23.1.0\r\n",
      "argon2-cffi-bindings                     21.2.0\r\n",
      "array_record                             0.5.1\r\n",
      "arrow                                    1.3.0\r\n",
      "arviz                                    0.20.0\r\n",
      "astroid                                  3.3.4\r\n",
      "asttokens                                2.4.1\r\n",
      "astunparse                               1.6.3\r\n",
      "async-lru                                2.0.4\r\n",
      "async-timeout                            4.0.3\r\n",
      "atpublic                                 4.1.0\r\n",
      "attrs                                    23.2.0\r\n",
      "audioread                                3.0.1\r\n",
      "autograd                                 1.7.0\r\n",
      "autopep8                                 2.0.4\r\n",
      "autoray                                  0.6.12\r\n",
      "Babel                                    2.15.0\r\n",
      "backports.tarfile                        1.2.0\r\n",
      "bayesian-optimization                    1.5.1\r\n",
      "beatrix_jupyterlab                       2024.66.154055\r\n",
      "beautifulsoup4                           4.12.3\r\n",
      "bidict                                   0.23.1\r\n",
      "bigframes                                0.22.0\r\n",
      "bleach                                   6.1.0\r\n",
      "blessed                                  1.20.0\r\n",
      "blinker                                  1.8.2\r\n",
      "blis                                     0.7.10\r\n",
      "blosc2                                   2.7.1\r\n",
      "bokeh                                    3.5.2\r\n",
      "boltons                                  24.0.0\r\n",
      "Boruta                                   0.4.3\r\n",
      "boto3                                    1.26.100\r\n",
      "botocore                                 1.35.23\r\n",
      "bq_helper                                0.4.1              /root/src/BigQuery_Helper\r\n",
      "bqplot                                   0.12.43\r\n",
      "branca                                   0.8.0\r\n",
      "Brotli                                   1.1.0\r\n",
      "brotlipy                                 0.7.0\r\n",
      "cached-property                          1.5.2\r\n",
      "cachetools                               4.2.4\r\n",
      "Cartopy                                  0.23.0\r\n",
      "catalogue                                2.0.10\r\n",
      "catboost                                 1.2.7\r\n",
      "category-encoders                        2.6.4\r\n",
      "certifi                                  2024.8.30\r\n",
      "cesium                                   0.12.3\r\n",
      "cffi                                     1.16.0\r\n",
      "charset-normalizer                       3.3.2\r\n",
      "chex                                     0.1.86\r\n",
      "click                                    8.1.7\r\n",
      "click-plugins                            1.1.1\r\n",
      "cligj                                    0.7.2\r\n",
      "cloud-tpu-client                         0.10\r\n",
      "cloud-tpu-profiler                       2.4.0\r\n",
      "cloudpathlib                             0.19.0\r\n",
      "cloudpickle                              3.0.0\r\n",
      "cmdstanpy                                1.2.4\r\n",
      "colorama                                 0.4.6\r\n",
      "colorcet                                 3.1.0\r\n",
      "colorful                                 0.5.6\r\n",
      "colorlog                                 6.8.2\r\n",
      "colorlover                               0.3.0\r\n",
      "comm                                     0.2.2\r\n",
      "commonmark                               0.9.1\r\n",
      "conda                                    24.9.0\r\n",
      "conda-content-trust                      0+unknown\r\n",
      "conda-libmamba-solver                    23.12.0\r\n",
      "conda-package-handling                   2.3.0\r\n",
      "conda_package_streaming                  0.10.0\r\n",
      "confection                               0.1.4\r\n",
      "contourpy                                1.2.1\r\n",
      "crcmod                                   1.7\r\n",
      "cryptography                             42.0.8\r\n",
      "cuda-python                              12.6.0\r\n",
      "cudf                                     24.8.3\r\n",
      "cufflinks                                0.17.3\r\n",
      "cuml                                     24.8.0\r\n",
      "cupy                                     13.3.0\r\n",
      "CVXcanon                                 0.1.2\r\n",
      "cycler                                   0.12.1\r\n",
      "cymem                                    2.0.8\r\n",
      "Cython                                   3.0.10\r\n",
      "cytoolz                                  0.12.3\r\n",
      "daal                                     2024.7.0\r\n",
      "daal4py                                  2024.7.0\r\n",
      "dacite                                   1.8.1\r\n",
      "dask                                     2024.9.1\r\n",
      "dask-cuda                                24.8.2\r\n",
      "dask-cudf                                24.8.3\r\n",
      "dask-expr                                1.1.15\r\n",
      "dataclasses-json                         0.6.7\r\n",
      "dataproc_jupyter_plugin                  0.1.79\r\n",
      "datasets                                 3.0.1\r\n",
      "datashader                               0.16.3\r\n",
      "datatile                                 1.0.3\r\n",
      "db-dtypes                                1.2.0\r\n",
      "deap                                     1.4.1\r\n",
      "debugpy                                  1.8.1\r\n",
      "decorator                                5.1.1\r\n",
      "deepdiff                                 8.0.1\r\n",
      "defusedxml                               0.7.1\r\n",
      "Deprecated                               1.2.14\r\n",
      "dgl                                      2.1.0+cu121\r\n",
      "dglgo                                    0.0.2\r\n",
      "dill                                     0.3.4\r\n",
      "dipy                                     1.9.0\r\n",
      "distlib                                  0.3.8\r\n",
      "distributed                              2024.7.1\r\n",
      "distributed-ucxx                         0.39.1\r\n",
      "distro                                   1.9.0\r\n",
      "dm-tree                                  0.1.8\r\n",
      "dnspython                                2.6.1\r\n",
      "docker                                   7.1.0\r\n",
      "docker-pycreds                           0.4.0\r\n",
      "docopt                                   0.6.2\r\n",
      "docstring_parser                         0.16\r\n",
      "docstring-to-markdown                    0.15\r\n",
      "docutils                                 0.21.2\r\n",
      "earthengine-api                          1.1.2\r\n",
      "easyocr                                  1.7.2\r\n",
      "ecos                                     2.0.14\r\n",
      "eli5                                     0.13.0\r\n",
      "email_validator                          2.1.1\r\n",
      "emoji                                    2.13.2\r\n",
      "en-core-web-lg                           3.7.1\r\n",
      "en-core-web-sm                           3.7.1\r\n",
      "EnergyFlow                               1.3.2\r\n",
      "entrypoints                              0.4\r\n",
      "et-xmlfile                               1.1.0\r\n",
      "etils                                    1.7.0\r\n",
      "eval_type_backport                       0.2.0\r\n",
      "exceptiongroup                           1.2.0\r\n",
      "execnb                                   0.1.6\r\n",
      "executing                                2.0.1\r\n",
      "explainable-ai-sdk                       1.3.3\r\n",
      "Farama-Notifications                     0.0.4\r\n",
      "fastai                                   2.7.17\r\n",
      "fastapi                                  0.111.0\r\n",
      "fastapi-cli                              0.0.4\r\n",
      "fastavro                                 1.9.4\r\n",
      "fastcore                                 1.7.10\r\n",
      "fastdownload                             0.0.7\r\n",
      "fasteners                                0.19\r\n",
      "fastjsonschema                           2.19.1\r\n",
      "fastprogress                             1.0.3\r\n",
      "fastrlock                                0.8.2\r\n",
      "fasttext                                 0.9.3\r\n",
      "featuretools                             1.31.0\r\n",
      "filelock                                 3.15.1\r\n",
      "fiona                                    1.9.6\r\n",
      "flake8                                   7.1.1\r\n",
      "Flask                                    3.0.3\r\n",
      "flatbuffers                              24.3.25\r\n",
      "flax                                     0.8.4\r\n",
      "folium                                   0.17.0\r\n",
      "fonttools                                4.53.0\r\n",
      "fqdn                                     1.5.1\r\n",
      "frozendict                               2.4.4\r\n",
      "frozenlist                               1.4.1\r\n",
      "fsspec                                   2024.6.1\r\n",
      "funcy                                    2.0\r\n",
      "fury                                     0.11.0\r\n",
      "future                                   1.0.0\r\n",
      "fuzzywuzzy                               0.18.0\r\n",
      "gast                                     0.5.4\r\n",
      "gatspy                                   0.3\r\n",
      "gcsfs                                    2024.6.1\r\n",
      "gensim                                   4.3.3\r\n",
      "geographiclib                            2.0\r\n",
      "geojson                                  3.1.0\r\n",
      "geopandas                                0.14.4\r\n",
      "geopy                                    2.4.1\r\n",
      "ghapi                                    1.0.6\r\n",
      "gitdb                                    4.0.11\r\n",
      "GitPython                                3.1.43\r\n",
      "google-ai-generativelanguage             0.6.10\r\n",
      "google-api-core                          2.11.1\r\n",
      "google-api-python-client                 2.147.0\r\n",
      "google-apitools                          0.5.31\r\n",
      "google-auth                              2.30.0\r\n",
      "google-auth-httplib2                     0.2.0\r\n",
      "google-auth-oauthlib                     1.2.0\r\n",
      "google-cloud-aiplatform                  0.6.0a1\r\n",
      "google-cloud-artifact-registry           1.11.3\r\n",
      "google-cloud-automl                      1.0.1\r\n",
      "google-cloud-bigquery                    2.34.4\r\n",
      "google-cloud-bigquery-connection         1.15.3\r\n",
      "google-cloud-bigtable                    1.7.3\r\n",
      "google-cloud-core                        2.4.1\r\n",
      "google-cloud-datastore                   2.20.1\r\n",
      "google-cloud-dlp                         3.18.0\r\n",
      "google-cloud-functions                   1.16.3\r\n",
      "google-cloud-iam                         2.15.0\r\n",
      "google-cloud-jupyter-config              0.0.10\r\n",
      "google-cloud-language                    2.14.0\r\n",
      "google-cloud-monitoring                  2.21.0\r\n",
      "google-cloud-pubsub                      2.21.3\r\n",
      "google-cloud-pubsublite                  1.10.0\r\n",
      "google-cloud-recommendations-ai          0.7.1\r\n",
      "google-cloud-resource-manager            1.12.3\r\n",
      "google-cloud-spanner                     3.47.0\r\n",
      "google-cloud-storage                     1.44.0\r\n",
      "google-cloud-translate                   3.12.1\r\n",
      "google-cloud-videointelligence           2.13.5\r\n",
      "google-cloud-vision                      2.8.0\r\n",
      "google-crc32c                            1.5.0\r\n",
      "google-generativeai                      0.8.2\r\n",
      "google-pasta                             0.2.0\r\n",
      "google-resumable-media                   2.7.1\r\n",
      "googleapis-common-protos                 1.63.1\r\n",
      "gpustat                                  1.0.0\r\n",
      "gpxpy                                    1.6.2\r\n",
      "graphviz                                 0.20.3\r\n",
      "greenlet                                 3.0.3\r\n",
      "grpc-google-iam-v1                       0.12.7\r\n",
      "grpc-interceptor                         0.15.4\r\n",
      "grpcio                                   1.62.2\r\n",
      "grpcio-status                            1.48.0\r\n",
      "gviz-api                                 1.10.0\r\n",
      "gym                                      0.26.2\r\n",
      "gym-notices                              0.0.8\r\n",
      "gymnasium                                0.29.0\r\n",
      "h11                                      0.14.0\r\n",
      "h2o                                      3.46.0.5\r\n",
      "h5netcdf                                 1.3.0\r\n",
      "h5py                                     3.11.0\r\n",
      "haversine                                2.8.1\r\n",
      "hdfs                                     2.7.3\r\n",
      "hep-ml                                   0.7.2\r\n",
      "hepunits                                 2.3.5\r\n",
      "holidays                                 0.57\r\n",
      "holoviews                                1.19.1\r\n",
      "html5lib                                 1.1\r\n",
      "htmlmin                                  0.1.12\r\n",
      "httpcore                                 1.0.5\r\n",
      "httplib2                                 0.21.0\r\n",
      "httptools                                0.6.1\r\n",
      "httpx                                    0.27.0\r\n",
      "huggingface-hub                          0.25.1\r\n",
      "humanize                                 4.9.0\r\n",
      "hyperopt                                 0.2.7\r\n",
      "ibis-framework                           7.1.0\r\n",
      "ibm-cloud-sdk-core                       3.21.0\r\n",
      "ibm-platform-services                    0.57.1\r\n",
      "idna                                     3.7\r\n",
      "igraph                                   0.11.6\r\n",
      "ImageHash                                4.3.1\r\n",
      "imageio                                  2.34.1\r\n",
      "imagesize                                1.4.1\r\n",
      "imbalanced-learn                         0.12.3\r\n",
      "imgaug                                   0.4.0\r\n",
      "immutabledict                            4.2.0\r\n",
      "importlib-metadata                       7.0.0\r\n",
      "importlib_resources                      6.4.0\r\n",
      "iniconfig                                2.0.0\r\n",
      "ipykernel                                6.29.4\r\n",
      "ipympl                                   0.7.0\r\n",
      "ipython                                  8.21.0\r\n",
      "ipython-genutils                         0.2.0\r\n",
      "ipython-sql                              0.5.0\r\n",
      "ipywidgets                               7.7.1\r\n",
      "isoduration                              20.11.0\r\n",
      "isort                                    5.13.2\r\n",
      "isoweek                                  1.3.3\r\n",
      "itsdangerous                             2.2.0\r\n",
      "Janome                                   0.5.0\r\n",
      "jaraco.classes                           3.4.0\r\n",
      "jaraco.context                           5.3.0\r\n",
      "jaraco.functools                         4.0.1\r\n",
      "jax                                      0.4.26\r\n",
      "jax-jumpy                                1.0.0\r\n",
      "jaxlib                                   0.4.26.dev20240620\r\n",
      "jedi                                     0.19.1\r\n",
      "jeepney                                  0.8.0\r\n",
      "jieba                                    0.42.1\r\n",
      "Jinja2                                   3.1.4\r\n",
      "jmespath                                 1.0.1\r\n",
      "joblib                                   1.4.2\r\n",
      "json5                                    0.9.25\r\n",
      "jsonpatch                                1.33\r\n",
      "jsonpointer                              2.4\r\n",
      "jsonschema                               4.22.0\r\n",
      "jsonschema-specifications                2023.12.1\r\n",
      "jupyter_client                           7.4.9\r\n",
      "jupyter-console                          6.6.3\r\n",
      "jupyter_core                             5.7.2\r\n",
      "jupyter-events                           0.10.0\r\n",
      "jupyter-http-over-ws                     0.0.8\r\n",
      "jupyter-lsp                              1.5.1\r\n",
      "jupyter_server                           2.12.5\r\n",
      "jupyter_server_fileid                    0.9.2\r\n",
      "jupyter-server-mathjax                   0.2.6\r\n",
      "jupyter_server_proxy                     4.2.0\r\n",
      "jupyter_server_terminals                 0.5.3\r\n",
      "jupyter_server_ydoc                      0.8.0\r\n",
      "jupyter-ydoc                             0.2.5\r\n",
      "jupyterlab                               4.2.5\r\n",
      "jupyterlab_git                           0.44.0\r\n",
      "jupyterlab-lsp                           5.1.0\r\n",
      "jupyterlab_pygments                      0.3.0\r\n",
      "jupyterlab_server                        2.27.2\r\n",
      "jupyterlab_widgets                       3.0.11\r\n",
      "jupytext                                 1.16.2\r\n",
      "kaggle                                   1.6.17\r\n",
      "kaggle-environments                      1.14.15\r\n",
      "kagglehub                                0.3.1\r\n",
      "keras                                    3.3.3\r\n",
      "keras-core                               0.1.7\r\n",
      "keras-cv                                 0.9.0\r\n",
      "keras-nlp                                0.15.1\r\n",
      "keras-tuner                              1.4.7\r\n",
      "kernels-mixer                            0.0.13\r\n",
      "keyring                                  25.2.1\r\n",
      "keyrings.google-artifactregistry-auth    1.1.2\r\n",
      "kfp                                      2.5.0\r\n",
      "kfp-pipeline-spec                        0.2.2\r\n",
      "kfp-server-api                           2.0.5\r\n",
      "kiwisolver                               1.4.5\r\n",
      "kornia                                   0.7.3\r\n",
      "kornia_rs                                0.1.5\r\n",
      "kt-legacy                                1.0.5\r\n",
      "kubernetes                               26.1.0\r\n",
      "langcodes                                3.4.1\r\n",
      "langid                                   1.1.6\r\n",
      "language_data                            1.2.0\r\n",
      "lazy_loader                              0.4\r\n",
      "learntools                               0.3.4\r\n",
      "leven                                    1.0.4\r\n",
      "libclang                                 18.1.1\r\n",
      "libmambapy                               1.5.10\r\n",
      "libpysal                                 4.9.2\r\n",
      "librosa                                  0.10.2.post1\r\n",
      "lightgbm                                 4.2.0\r\n",
      "lightning-utilities                      0.11.7\r\n",
      "lime                                     0.2.0.1\r\n",
      "line_profiler                            4.1.3\r\n",
      "linkify-it-py                            2.0.3\r\n",
      "littleutils                              0.2.4\r\n",
      "llvmlite                                 0.43.0\r\n",
      "lml                                      0.1.0\r\n",
      "locket                                   1.0.0\r\n",
      "loguru                                   0.7.2\r\n",
      "lxml                                     5.3.0\r\n",
      "lz4                                      4.3.3\r\n",
      "Mako                                     1.3.5\r\n",
      "mamba                                    1.5.10\r\n",
      "marisa-trie                              1.1.0\r\n",
      "Markdown                                 3.6\r\n",
      "markdown-it-py                           3.0.0\r\n",
      "MarkupSafe                               2.1.5\r\n",
      "marshmallow                              3.22.0\r\n",
      "matplotlib                               3.7.5\r\n",
      "matplotlib-inline                        0.1.7\r\n",
      "matplotlib-venn                          1.1.1\r\n",
      "mccabe                                   0.7.0\r\n",
      "mdit-py-plugins                          0.4.1\r\n",
      "mdurl                                    0.1.2\r\n",
      "memory-profiler                          0.61.0\r\n",
      "memray                                   1.12.0\r\n",
      "menuinst                                 2.1.1\r\n",
      "missingno                                0.5.2\r\n",
      "mistune                                  0.8.4\r\n",
      "mizani                                   0.11.4\r\n",
      "ml-dtypes                                0.3.2\r\n",
      "mlcrate                                  0.2.0\r\n",
      "mlxtend                                  0.23.1\r\n",
      "mne                                      1.8.0\r\n",
      "more-itertools                           10.3.0\r\n",
      "mpld3                                    0.5.10\r\n",
      "mpmath                                   1.3.0\r\n",
      "msgpack                                  1.0.8\r\n",
      "msgpack-numpy                            0.4.8\r\n",
      "multidict                                6.0.5\r\n",
      "multimethod                              1.11.2\r\n",
      "multipledispatch                         1.0.0\r\n",
      "multiprocess                             0.70.12.2\r\n",
      "munkres                                  1.1.4\r\n",
      "murmurhash                               1.0.10\r\n",
      "mypy-extensions                          1.0.0\r\n",
      "namex                                    0.0.8\r\n",
      "narwhals                                 1.9.0\r\n",
      "nb_conda                                 2.2.1\r\n",
      "nb_conda_kernels                         2.5.1\r\n",
      "nbclassic                                1.1.0\r\n",
      "nbclient                                 0.5.13\r\n",
      "nbconvert                                6.4.5\r\n",
      "nbdev                                    2.3.31\r\n",
      "nbdime                                   3.2.0\r\n",
      "nbformat                                 5.10.4\r\n",
      "nbsphinx                                 0.9.5\r\n",
      "ndindex                                  1.9.2\r\n",
      "nest-asyncio                             1.6.0\r\n",
      "networkx                                 3.3\r\n",
      "nibabel                                  5.2.1\r\n",
      "nilearn                                  0.10.4\r\n",
      "ninja                                    1.11.1.1\r\n",
      "nltk                                     3.2.4\r\n",
      "nose                                     1.3.7\r\n",
      "notebook                                 6.5.7\r\n",
      "notebook_executor                        0.2\r\n",
      "notebook_shim                            0.2.4\r\n",
      "numba                                    0.60.0\r\n",
      "numexpr                                  2.10.1\r\n",
      "numpy                                    1.26.4\r\n",
      "numpydoc                                 1.8.0\r\n",
      "nvidia-cublas-cu12                       12.1.3.1\r\n",
      "nvidia-cuda-cupti-cu12                   12.1.105\r\n",
      "nvidia-cuda-nvrtc-cu12                   12.1.105\r\n",
      "nvidia-cuda-runtime-cu12                 12.1.105\r\n",
      "nvidia-cudnn-cu12                        8.9.2.26\r\n",
      "nvidia-cufft-cu12                        11.0.2.54\r\n",
      "nvidia-curand-cu12                       10.3.2.106\r\n",
      "nvidia-cusolver-cu12                     11.4.5.107\r\n",
      "nvidia-cusparse-cu12                     12.1.0.106\r\n",
      "nvidia-ml-py                             11.495.46\r\n",
      "nvidia-nccl-cu12                         2.19.3\r\n",
      "nvidia-nvjitlink-cu12                    12.6.77\r\n",
      "nvidia-nvtx-cu12                         12.1.105\r\n",
      "nvtx                                     0.2.10\r\n",
      "oauth2client                             4.1.3\r\n",
      "oauthlib                                 3.2.2\r\n",
      "objsize                                  0.6.1\r\n",
      "odfpy                                    1.4.1\r\n",
      "ogb                                      1.3.6\r\n",
      "olefile                                  0.47\r\n",
      "onnx                                     1.17.0\r\n",
      "opencensus                               0.11.4\r\n",
      "opencensus-context                       0.1.3\r\n",
      "opencv-contrib-python                    4.10.0.84\r\n",
      "opencv-python                            4.10.0.84\r\n",
      "opencv-python-headless                   4.10.0.84\r\n",
      "openpyxl                                 3.1.5\r\n",
      "openslide-python                         1.3.1\r\n",
      "opentelemetry-api                        1.25.0\r\n",
      "opentelemetry-exporter-otlp              1.25.0\r\n",
      "opentelemetry-exporter-otlp-proto-common 1.25.0\r\n",
      "opentelemetry-exporter-otlp-proto-grpc   1.25.0\r\n",
      "opentelemetry-exporter-otlp-proto-http   1.25.0\r\n",
      "opentelemetry-proto                      1.25.0\r\n",
      "opentelemetry-sdk                        1.25.0\r\n",
      "opentelemetry-semantic-conventions       0.46b0\r\n",
      "opt-einsum                               3.3.0\r\n",
      "optax                                    0.2.2\r\n",
      "optree                                   0.11.0\r\n",
      "optuna                                   4.0.0\r\n",
      "orbax-checkpoint                         0.6.4\r\n",
      "orderly-set                              5.2.2\r\n",
      "orjson                                   3.10.4\r\n",
      "outdated                                 0.2.2\r\n",
      "overrides                                7.7.0\r\n",
      "packaging                                24.1\r\n",
      "pandas                                   2.2.2\r\n",
      "pandas-datareader                        0.10.0\r\n",
      "pandas-profiling                         3.6.6\r\n",
      "pandas-summary                           0.2.0\r\n",
      "pandasql                                 0.7.3\r\n",
      "pandocfilters                            1.5.0\r\n",
      "panel                                    1.5.1\r\n",
      "papermill                                2.6.0\r\n",
      "param                                    2.1.1\r\n",
      "parso                                    0.8.4\r\n",
      "parsy                                    2.1\r\n",
      "partd                                    1.4.2\r\n",
      "particle                                 0.25.2\r\n",
      "path                                     17.0.0\r\n",
      "path.py                                  12.5.0\r\n",
      "pathos                                   0.2.8\r\n",
      "patsy                                    0.5.6\r\n",
      "pbr                                      6.1.0\r\n",
      "pdf2image                                1.17.0\r\n",
      "pendulum                                 3.0.0\r\n",
      "PennyLane                                0.38.0\r\n",
      "PennyLane_Lightning                      0.38.0\r\n",
      "pettingzoo                               1.24.0\r\n",
      "pexpect                                  4.9.0\r\n",
      "phik                                     0.12.4\r\n",
      "pickleshare                              0.7.5\r\n",
      "pillow                                   10.3.0\r\n",
      "pins                                     0.8.6\r\n",
      "pip                                      24.0\r\n",
      "pkgutil_resolve_name                     1.3.10\r\n",
      "platformdirs                             3.11.0\r\n",
      "plotly                                   5.22.0\r\n",
      "plotly-express                           0.4.1\r\n",
      "plotnine                                 0.13.6\r\n",
      "pluggy                                   1.5.0\r\n",
      "ply                                      3.11\r\n",
      "polars                                   1.9.0\r\n",
      "pooch                                    1.8.2\r\n",
      "pox                                      0.3.5\r\n",
      "ppft                                     1.7.6.9\r\n",
      "preprocessing                            0.1.13\r\n",
      "preshed                                  3.0.9\r\n",
      "prettytable                              3.10.0\r\n",
      "prometheus_client                        0.20.0\r\n",
      "promise                                  2.3\r\n",
      "prompt_toolkit                           3.0.47\r\n",
      "prophet                                  1.1.5\r\n",
      "proto-plus                               1.23.0\r\n",
      "protobuf                                 3.20.3\r\n",
      "psutil                                   5.9.3\r\n",
      "ptyprocess                               0.7.0\r\n",
      "pudb                                     2024.1.2\r\n",
      "pure-eval                                0.2.2\r\n",
      "py-cpuinfo                               9.0.0\r\n",
      "py-spy                                   0.3.14\r\n",
      "py4j                                     0.10.9.7\r\n",
      "pyaml                                    24.9.0\r\n",
      "PyArabic                                 0.6.15\r\n",
      "pyarrow                                  16.1.0\r\n",
      "pyarrow-hotfix                           0.6\r\n",
      "pyasn1                                   0.6.0\r\n",
      "pyasn1_modules                           0.4.0\r\n",
      "pybind11                                 2.13.6\r\n",
      "pyclipper                                1.3.0.post5\r\n",
      "pycodestyle                              2.12.1\r\n",
      "pycosat                                  0.6.6\r\n",
      "pycparser                                2.22\r\n",
      "pycryptodome                             3.20.0\r\n",
      "pyct                                     0.5.0\r\n",
      "pycuda                                   2024.1.2\r\n",
      "pydantic                                 2.9.2\r\n",
      "pydantic_core                            2.23.4\r\n",
      "pydata-google-auth                       1.8.2\r\n",
      "pydegensac                               0.1.2\r\n",
      "pydicom                                  3.0.1\r\n",
      "pydocstyle                               6.3.0\r\n",
      "pydot                                    1.4.2\r\n",
      "pydub                                    0.25.1\r\n",
      "pyemd                                    1.0.0\r\n",
      "pyexcel-io                               0.6.6\r\n",
      "pyexcel-ods                              0.6.0\r\n",
      "pyflakes                                 3.2.0\r\n",
      "pygltflib                                1.16.2\r\n",
      "Pygments                                 2.18.0\r\n",
      "PyJWT                                    2.8.0\r\n",
      "pylatexenc                               2.10\r\n",
      "pyLDAvis                                 3.4.1\r\n",
      "pylibraft                                24.8.1\r\n",
      "pylint                                   3.3.1\r\n",
      "pymc3                                    3.11.4\r\n",
      "pymongo                                  3.13.0\r\n",
      "Pympler                                  1.1\r\n",
      "pynvjitlink-cu12                         0.3.0\r\n",
      "pynvml                                   11.4.1\r\n",
      "pynvrtc                                  9.2\r\n",
      "pyOpenSSL                                24.0.0\r\n",
      "pyparsing                                3.1.2\r\n",
      "pypdf                                    5.0.1\r\n",
      "pyproj                                   3.6.1\r\n",
      "pyscf                                    2.7.0\r\n",
      "pyshp                                    2.3.1\r\n",
      "PySocks                                  1.7.1\r\n",
      "pyspnego                                 0.11.1\r\n",
      "pytesseract                              0.3.13\r\n",
      "pytest                                   8.3.3\r\n",
      "python-bidi                              0.6.0\r\n",
      "python-dateutil                          2.9.0.post0\r\n",
      "python-dotenv                            1.0.1\r\n",
      "python-json-logger                       2.0.7\r\n",
      "python-louvain                           0.16\r\n",
      "python-lsp-jsonrpc                       1.1.2\r\n",
      "python-lsp-server                        1.12.0\r\n",
      "python-multipart                         0.0.9\r\n",
      "python-slugify                           8.0.4\r\n",
      "pytoolconfig                             1.3.1\r\n",
      "pytools                                  2024.1.14\r\n",
      "pytorch-ignite                           0.5.1\r\n",
      "pytorch-lightning                        2.4.0\r\n",
      "pytz                                     2024.1\r\n",
      "pyu2f                                    0.1.5\r\n",
      "PyUpSet                                  0.1.1.post7\r\n",
      "pyviz_comms                              3.0.3\r\n",
      "PyWavelets                               1.6.0\r\n",
      "PyYAML                                   6.0.2\r\n",
      "pyzmq                                    26.0.3\r\n",
      "qgrid                                    1.3.1\r\n",
      "qiskit                                   0.46.0\r\n",
      "qiskit-aer                               0.13.2\r\n",
      "qiskit-ibm-provider                      0.11.0\r\n",
      "qiskit-ibm-runtime                       0.18.0\r\n",
      "qiskit-terra                             0.46.0\r\n",
      "qtconsole                                5.6.0\r\n",
      "QtPy                                     2.4.1\r\n",
      "raft-dask                                24.8.1\r\n",
      "rapids-dask-dependency                   24.8.0a0\r\n",
      "ray                                      2.24.0\r\n",
      "ray-cpp                                  2.24.0\r\n",
      "rdkit-pypi                               2022.9.5\r\n",
      "recommonmark                             0.7.1\r\n",
      "referencing                              0.35.1\r\n",
      "regex                                    2024.5.15\r\n",
      "requests                                 2.32.3\r\n",
      "requests_ntlm                            1.3.0\r\n",
      "requests-oauthlib                        2.0.0\r\n",
      "requests-toolbelt                        0.10.1\r\n",
      "retrying                                 1.3.3\r\n",
      "rfc3339-validator                        0.1.4\r\n",
      "rfc3986-validator                        0.1.1\r\n",
      "rgf-python                               3.12.0\r\n",
      "rich                                     13.7.1\r\n",
      "rmm                                      24.8.2\r\n",
      "rope                                     1.13.0\r\n",
      "rpds-py                                  0.18.1\r\n",
      "rsa                                      4.9\r\n",
      "Rtree                                    1.3.0\r\n",
      "ruamel.yaml                              0.18.6\r\n",
      "ruamel.yaml.clib                         0.2.8\r\n",
      "ruamel-yaml-conda                        0.15.100\r\n",
      "rustworkx                                0.15.1\r\n",
      "s3fs                                     2024.6.1\r\n",
      "s3transfer                               0.6.2\r\n",
      "safetensors                              0.4.5\r\n",
      "scikit-image                             0.23.2\r\n",
      "scikit-learn                             1.2.2\r\n",
      "scikit-learn-intelex                     2024.7.0\r\n",
      "scikit-multilearn                        0.2.0\r\n",
      "scikit-optimize                          0.10.2\r\n",
      "scikit-plot                              0.3.7\r\n",
      "scikit-surprise                          1.1.4\r\n",
      "scipy                                    1.14.1\r\n",
      "seaborn                                  0.12.2\r\n",
      "SecretStorage                            3.3.3\r\n",
      "segment_anything                         1.0\r\n",
      "semver                                   3.0.2\r\n",
      "Send2Trash                               1.8.3\r\n",
      "sentencepiece                            0.2.0\r\n",
      "sentry-sdk                               2.15.0\r\n",
      "setproctitle                             1.3.3\r\n",
      "setuptools                               70.0.0\r\n",
      "setuptools-scm                           8.1.0\r\n",
      "shap                                     0.44.1\r\n",
      "Shapely                                  1.8.5.post1\r\n",
      "shellingham                              1.5.4\r\n",
      "Shimmy                                   1.3.0\r\n",
      "simpervisor                              1.0.0\r\n",
      "simple_parsing                           0.1.5\r\n",
      "SimpleITK                                2.4.0\r\n",
      "six                                      1.16.0\r\n",
      "sklearn-pandas                           2.2.0\r\n",
      "slicer                                   0.0.7\r\n",
      "smart_open                               7.0.4\r\n",
      "smmap                                    5.0.1\r\n",
      "sniffio                                  1.3.1\r\n",
      "snowballstemmer                          2.2.0\r\n",
      "sortedcontainers                         2.4.0\r\n",
      "soundfile                                0.12.1\r\n",
      "soupsieve                                2.5\r\n",
      "soxr                                     0.5.0.post1\r\n",
      "spacy                                    3.7.6\r\n",
      "spacy-legacy                             3.0.12\r\n",
      "spacy-loggers                            1.0.5\r\n",
      "Sphinx                                   8.1.3\r\n",
      "sphinx-rtd-theme                         0.2.4\r\n",
      "sphinxcontrib-applehelp                  2.0.0\r\n",
      "sphinxcontrib-devhelp                    2.0.0\r\n",
      "sphinxcontrib-htmlhelp                   2.1.0\r\n",
      "sphinxcontrib-jsmath                     1.0.1\r\n",
      "sphinxcontrib-qthelp                     2.0.0\r\n",
      "sphinxcontrib-serializinghtml            2.0.0\r\n",
      "SQLAlchemy                               2.0.30\r\n",
      "sqlglot                                  19.9.0\r\n",
      "sqlparse                                 0.5.0\r\n",
      "squarify                                 0.4.4\r\n",
      "srsly                                    2.4.8\r\n",
      "stable-baselines3                        2.1.0\r\n",
      "stack-data                               0.6.2\r\n",
      "stanio                                   0.5.1\r\n",
      "starlette                                0.37.2\r\n",
      "statsmodels                              0.14.2\r\n",
      "stevedore                                5.3.0\r\n",
      "stopit                                   1.1.2\r\n",
      "stumpy                                   1.13.0\r\n",
      "symengine                                0.13.0\r\n",
      "sympy                                    1.13.3\r\n",
      "tables                                   3.10.1\r\n",
      "tabulate                                 0.9.0\r\n",
      "tangled-up-in-unicode                    0.2.0\r\n",
      "tbb                                      2021.13.1\r\n",
      "tblib                                    3.0.0\r\n",
      "tenacity                                 8.3.0\r\n",
      "tensorboard                              2.16.2\r\n",
      "tensorboard-data-server                  0.7.2\r\n",
      "tensorboard_plugin_profile               2.15.1\r\n",
      "tensorboardX                             2.6.2.2\r\n",
      "tensorflow                               2.16.1\r\n",
      "tensorflow-cloud                         0.1.16\r\n",
      "tensorflow-datasets                      4.9.6\r\n",
      "tensorflow_decision_forests              1.9.1\r\n",
      "tensorflow-estimator                     2.15.0\r\n",
      "tensorflow-hub                           0.16.1\r\n",
      "tensorflow-io                            0.37.0\r\n",
      "tensorflow-io-gcs-filesystem             0.37.0\r\n",
      "tensorflow-metadata                      0.14.0\r\n",
      "tensorflow-probability                   0.24.0\r\n",
      "tensorflow-serving-api                   2.16.1\r\n",
      "tensorflow-text                          2.16.1\r\n",
      "tensorflow-transform                     0.14.0\r\n",
      "tensorpack                               0.11\r\n",
      "tensorstore                              0.1.66\r\n",
      "termcolor                                2.4.0\r\n",
      "terminado                                0.18.1\r\n",
      "testpath                                 0.6.0\r\n",
      "text-unidecode                           1.3\r\n",
      "textblob                                 0.18.0.post0\r\n",
      "texttable                                1.7.0\r\n",
      "textual                                  0.67.1\r\n",
      "tf_keras                                 2.16.0\r\n",
      "Theano                                   1.0.5\r\n",
      "Theano-PyMC                              1.1.2\r\n",
      "thinc                                    8.2.5\r\n",
      "threadpoolctl                            3.5.0\r\n",
      "tifffile                                 2024.5.22\r\n",
      "time-machine                             2.14.1\r\n",
      "timm                                     1.0.9\r\n",
      "tinycss2                                 1.3.0\r\n",
      "tokenizers                               0.20.0\r\n",
      "toml                                     0.10.2\r\n",
      "tomli                                    2.0.1\r\n",
      "tomlkit                                  0.13.2\r\n",
      "toolz                                    0.12.1\r\n",
      "torch                                    2.2.0\r\n",
      "torch-geometric                          2.6.1\r\n",
      "torchaudio                               2.4.0\r\n",
      "torchdata                                0.7.1\r\n",
      "torchdiffeq                              0.2.4\r\n",
      "torchinfo                                1.8.0\r\n",
      "torchmetrics                             1.4.2\r\n",
      "torchpack                                0.3.1\r\n",
      "torchquantum                             0.1.8\r\n",
      "torchvision                              0.17.0\r\n",
      "tornado                                  6.4.1\r\n",
      "TPOT                                     0.12.1\r\n",
      "tqdm                                     4.66.4\r\n",
      "traceml                                  1.0.8\r\n",
      "traitlets                                5.14.3\r\n",
      "traittypes                               0.2.1\r\n",
      "transformers                             4.45.1\r\n",
      "treelite                                 4.3.0\r\n",
      "triton                                   2.2.0\r\n",
      "truststore                               0.8.0\r\n",
      "trx-python                               0.3\r\n",
      "tsfresh                                  0.20.3\r\n",
      "typeguard                                4.3.0\r\n",
      "typer                                    0.12.3\r\n",
      "typer-slim                               0.12.5\r\n",
      "types-python-dateutil                    2.9.0.20240316\r\n",
      "typing_extensions                        4.12.2\r\n",
      "typing-inspect                           0.9.0\r\n",
      "typing-utils                             0.1.0\r\n",
      "tzdata                                   2024.1\r\n",
      "uc-micro-py                              1.0.3\r\n",
      "ucx-py                                   0.39.2\r\n",
      "ucxx                                     0.39.1\r\n",
      "ujson                                    5.10.0\r\n",
      "unicodedata2                             15.1.0\r\n",
      "update-checker                           0.18.0\r\n",
      "uri-template                             1.3.0\r\n",
      "uritemplate                              3.0.1\r\n",
      "urllib3                                  2.2.1\r\n",
      "urwid                                    2.6.15\r\n",
      "urwid_readline                           0.15.1\r\n",
      "uvicorn                                  0.30.1\r\n",
      "uvloop                                   0.19.0\r\n",
      "vec_noise                                1.1.4\r\n",
      "virtualenv                               20.21.0\r\n",
      "visions                                  0.7.5\r\n",
      "vtk                                      9.3.1\r\n",
      "Wand                                     0.6.13\r\n",
      "wandb                                    0.18.3\r\n",
      "wasabi                                   1.1.2\r\n",
      "wasserstein                              1.1.0\r\n",
      "watchdog                                 5.0.3\r\n",
      "watchfiles                               0.22.0\r\n",
      "wavio                                    0.0.9\r\n",
      "wcwidth                                  0.2.13\r\n",
      "weasel                                   0.4.1\r\n",
      "webcolors                                24.6.0\r\n",
      "webencodings                             0.5.1\r\n",
      "websocket-client                         1.8.0\r\n",
      "websockets                               12.0\r\n",
      "Werkzeug                                 3.0.4\r\n",
      "whatthepatch                             1.0.6\r\n",
      "wheel                                    0.43.0\r\n",
      "widgetsnbextension                       3.6.9\r\n",
      "witwidget                                1.8.1\r\n",
      "woodwork                                 0.31.0\r\n",
      "wordcloud                                1.9.3\r\n",
      "wrapt                                    1.16.0\r\n",
      "wurlitzer                                3.1.1\r\n",
      "xarray                                   2024.9.0\r\n",
      "xarray-einstats                          0.8.0\r\n",
      "xgboost                                  2.0.3\r\n",
      "xvfbwrapper                              0.2.9\r\n",
      "xxhash                                   3.4.1\r\n",
      "xyzservices                              2024.9.0\r\n",
      "y-py                                     0.6.2\r\n",
      "yapf                                     0.40.2\r\n",
      "yarl                                     1.9.4\r\n",
      "ydata-profiling                          4.10.0\r\n",
      "ydf                                      0.8.0\r\n",
      "yellowbrick                              1.5\r\n",
      "ypy-websocket                            0.8.4\r\n",
      "zict                                     3.0.0\r\n",
      "zipp                                     3.19.2\r\n",
      "zstandard                                0.23.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7f04375",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:27:53.175420Z",
     "iopub.status.busy": "2024-10-15T09:27:53.175028Z",
     "iopub.status.idle": "2024-10-15T09:27:53.179527Z",
     "shell.execute_reply": "2024-10-15T09:27:53.178657Z"
    },
    "papermill": {
     "duration": 0.024318,
     "end_time": "2024-10-15T09:27:53.181350",
     "exception": false,
     "start_time": "2024-10-15T09:27:53.157032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nodes_per_graph = nodes_per_graph_original = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec14b2ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:27:53.215179Z",
     "iopub.status.busy": "2024-10-15T09:27:53.214889Z",
     "iopub.status.idle": "2024-10-15T09:28:07.805993Z",
     "shell.execute_reply": "2024-10-15T09:28:07.805147Z"
    },
    "id": "kDgEhsePTK1h",
    "outputId": "946393cf-588a-4c73-c976-a0f8c89b6d2d",
    "papermill": {
     "duration": 14.610853,
     "end_time": "2024-10-15T09:28:07.808324",
     "exception": false,
     "start_time": "2024-10-15T09:27:53.197471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchdata\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchquantum as tq\n",
    "from torchquantum.layer.entanglement.op2_layer import Op2QAllLayer\n",
    "from torchquantum.layer.layers.layers import Op1QAllLayer, Op2QAllLayer\n",
    "from torchquantum.measurement import measure\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import scipy\n",
    "import warnings\n",
    "import dgl\n",
    "from dgl.data import DGLDataset\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import scipy.sparse as sp\n",
    "import csv\n",
    "import time\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "import pickle\n",
    "import multiprocessing\n",
    "import joblib\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.utils import add_self_loops, degree, softmax\n",
    "import torch.optim as optim\n",
    "\n",
    "from copy import deepcopy\n",
    "import gc\n",
    "\n",
    "from particle import Particle\n",
    "import pennylane as qml\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00f634a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:28:07.844467Z",
     "iopub.status.busy": "2024-10-15T09:28:07.843712Z",
     "iopub.status.idle": "2024-10-15T09:29:17.674638Z",
     "shell.execute_reply": "2024-10-15T09:29:17.673775Z"
    },
    "id": "aCmapYGUTWG4",
    "outputId": "57892645-64e3-4d15-9624-0202191aeb2b",
    "papermill": {
     "duration": 69.851576,
     "end_time": "2024-10-15T09:29:17.677139",
     "exception": false,
     "start_time": "2024-10-15T09:28:07.825563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading QG_jets.npz from https://www.dropbox.com/s/fclsl7pukcpobsb/QG_jets.npz?dl=1 to /content//energyflow/datasets\n",
      "URL fetch failure on https://www.dropbox.com/s/fclsl7pukcpobsb/QG_jets.npz?dl=1: None -- Bad Request\n",
      "Failed to download QG_jets.npz from source 'dropbox', trying next source...\n",
      "Downloading QG_jets.npz from https://zenodo.org/record/3164691/files/QG_jets.npz?download=1 to /content//energyflow/datasets\n"
     ]
    }
   ],
   "source": [
    "## Download the jets along with storing them in a folder for future use, eliminating the need to download them again\n",
    "main_dir = '/content/'\n",
    "\n",
    "import energyflow\n",
    "data = energyflow.qg_jets.load(num_data=20000, pad=True, ncol=4, generator='pythia',\n",
    "                        with_bc=False, cache_dir=main_dir+'/energyflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "def376fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:29:17.713023Z",
     "iopub.status.busy": "2024-10-15T09:29:17.712108Z",
     "iopub.status.idle": "2024-10-15T09:29:17.718562Z",
     "shell.execute_reply": "2024-10-15T09:29:17.717698Z"
    },
    "id": "IZJZuPAvUJ-c",
    "papermill": {
     "duration": 0.026402,
     "end_time": "2024-10-15T09:29:17.720636",
     "exception": false,
     "start_time": "2024-10-15T09:29:17.694234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "jet_file_path = '/content/energyflow/datasets/QG_jets.npz'\n",
    "data = np.load(jet_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "157b368a",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2024-10-15T09:29:17.758894Z",
     "iopub.status.busy": "2024-10-15T09:29:17.758530Z",
     "iopub.status.idle": "2024-10-15T09:29:17.784991Z",
     "shell.execute_reply": "2024-10-15T09:29:17.784187Z"
    },
    "id": "lhY05LBQUeYY",
    "papermill": {
     "duration": 0.048256,
     "end_time": "2024-10-15T09:29:17.786854",
     "exception": false,
     "start_time": "2024-10-15T09:29:17.738598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "### Reference - https://github.com/ML4SCI/QMLHEP/blob/main/Quantum_GNN_for_HEP_Roy_Forestano/utils/preprocess.py\n",
    "\n",
    "def preprocess_fixed_nodes(x_data,y_data,nodes_per_graph=10): #,masses):\n",
    "    print('--- Finding All Unique Particles ---')\n",
    "    unique_particles = np.unique(x_data[:,:,3])\n",
    "    x_data = torch.tensor(x_data)\n",
    "    y_data = torch.tensor(y_data)\n",
    "    print()\n",
    "    print('--- Inserting Masses ---')\n",
    "    masses = torch.zeros((x_data.shape[0],x_data.shape[1]))\n",
    "    for i,particle in tqdm(enumerate(unique_particles)):\n",
    "        if particle!=0:\n",
    "            mass = Particle.from_pdgid(particle).mass/1000\n",
    "            inds = torch.where(particle==x_data[:,:,3])\n",
    "            masses[inds]=mass # GeV\n",
    "    print()\n",
    "    print('--- Calculating Momenta and Energies ---')\n",
    "    #theta = torch.arctan(torch.exp(-X[:,:,1]))*2 # polar angle\n",
    "    pt        = x_data[:,:,0]     # transverse momentum\n",
    "    rapidity  = x_data[:,:,1]     # rapidity\n",
    "    phi       = x_data[:,:,2]     # azimuthal angle\n",
    "\n",
    "    mt        = (pt**2+masses**2).sqrt() # Transverse mass\n",
    "    energy    = mt*torch.cosh(rapidity) # Energy per multiplicity bin\n",
    "    e_per_jet = energy.sum(axis=1)  # total energy per jet summed across multiplicity bins\n",
    "\n",
    "    px = pt*torch.cos(phi)  # momentum in x\n",
    "    py = pt*torch.sin(phi)  # momentum in y\n",
    "    pz = mt*torch.sinh(rapidity)  # momentum in z\n",
    "\n",
    "    # three momentum\n",
    "    p  = torch.cat(( px[:,:,None],\n",
    "                     py[:,:,None],\n",
    "                     pz[:,:,None]), dim=2 )\n",
    "\n",
    "    p_per_jet        = (p).sum(axis=1)  # total componet momentum per jet\n",
    "    pt_per_Mbin      = (p_per_jet[:,:2]**2).sum(axis=1).sqrt()  # transverse momentum per jet\n",
    "    mass_per_jet     = (e_per_jet**2-(p_per_jet**2).sum(axis=1)).sqrt() # mass per jet\n",
    "    rapidity_per_jet = torch.log( (e_per_jet+p_per_jet[:,2])/(e_per_jet-p_per_jet[:,2]) )/2  # rapidity per jet from analytical formula\n",
    "    end_multiplicity_indx_per_jet = (pt!=0).sum(axis=1).int() # see where the jet (graph) ends\n",
    "\n",
    "    x_data = torch.cat( ( x_data[:,:,:3],\n",
    "                          x_data[:,:,4:],\n",
    "                          masses[:,:,None],\n",
    "                          energy[:,:,None],\n",
    "                          p), dim=2)\n",
    "\n",
    "    x_data_max = (x_data.max(dim=1).values).max(dim=0).values\n",
    "    x_data = x_data/x_data_max\n",
    "\n",
    "    print()\n",
    "    print('--- Calculating Edge Tensors ---')\n",
    "    N = x_data[:,0,3].shape[0]  # number of jets (graphs)\n",
    "    M = nodes_per_graph #x_data[0,:,3].shape[0]  # number of max multiplicty\n",
    "    connections = nodes_per_graph\n",
    "    edge_tensor = torch.zeros((N,M,M))\n",
    "    edge_indx_tensor = torch.zeros((N,2,connections*(connections-1) )) # M*(connections-1) is the max number of edges we allow per jet\n",
    "    edge_attr_matrix = torch.zeros((N,connections*(connections-1),1))\n",
    "#     fixed_edges_list = torch.tensor([ [i,j] for i in range(connections) for j in range(connections) if i!=j]).reshape(2,90)\n",
    "\n",
    "    for jet in tqdm(range(N)):\n",
    "        stop_indx = end_multiplicity_indx_per_jet[jet] #connections # stop finding edges once we hit zeros -> when we hit 10\n",
    "        if end_multiplicity_indx_per_jet[jet]>=connections:\n",
    "            for m in range(connections):\n",
    "#                 inds_edge = np.argsort((energy[jet,m]+energy[jet,:stop_indx])**2-torch.sum((p[jet,m,:stop_indx]+p[jet,:stop_indx,:])**2,axis=1))[:connections]\n",
    "#                 edge_tensor[jet,m,:] = (energy[jet,m]+energy[jet,:connections])**2-torch.sum((p[jet,m,:]+p[jet,:connections,:])**2,axis=1)\n",
    "#                 edge_tensor[jet,m,m] = 0.\n",
    "#                 edge_tensor[jet,m,m]=((energy[jet,m]+energy[jet,m])**2-torch.sum((p[jet,m,:]+p[jet,m,:])**2,axis=0))\n",
    "                # inds_edge = torch.sqrt( (phi[jet,m]-phi[jet,:])**2 + (rapidity[jet,m]-rapidity[jet,:])**2 ).argsort()[:connections]\n",
    "                # edge_tensor[jet,m,:] = torch.sqrt( (phi[jet,m]-phi[jet,inds_edge])**2 + (rapidity[jet,m]-rapidity[jet,inds_edge])**2 )\n",
    "                edge_tensor[jet,m,:] = torch.sqrt( (phi[jet,m]-phi[jet,:connections])**2 + (rapidity[jet,m]-rapidity[jet,:connections])**2 )\n",
    "#                 inds_edge = np.argsort( (energy[jet,m]+energy[jet,:stop_indx])**2-torch.sum((p[jet,m,:stop_indx]+p[jet,:stop_indx,:])**2,axis=1) )[:connections]\n",
    "#                 edge_tensor[jet,m,inds_edge] = (energy[jet,m]+energy[jet,inds_edge])**2-torch.sum((p[jet,m,:]+p[jet,inds_edge,:])**2,axis=1)\n",
    "            edges_exist_at = torch.where(edge_tensor[jet,:,:].abs()>0)\n",
    "\n",
    "#             edge_indx_tensor[jet,:,:(edge_tensor[jet,:,:].abs()>0).sum()] = fixed_edges_list\n",
    "            edge_indx_tensor[jet,:,:(edge_tensor[jet,:,:].abs()>0).sum()] = torch.cat((edges_exist_at[0][None,:],edges_exist_at[1][None,:]),dim=0).reshape((2,edges_exist_at[0].shape[0]))\n",
    "            edge_attr_matrix[jet,:(edge_tensor[jet,:,:].abs()>0).sum(),0]  =  edge_tensor[jet,edges_exist_at[0],edges_exist_at[1]].flatten()\n",
    "\n",
    "    end_edges_indx_per_jet = (edge_attr_matrix!=0).sum(axis=1).int()\n",
    "    keep_inds =  torch.where(end_edges_indx_per_jet>=connections)[0]\n",
    "\n",
    "    edge_tensor = edge_tensor/edge_tensor.max()\n",
    "    edge_attr_matrix = edge_attr_matrix/edge_attr_matrix.max()\n",
    "\n",
    "    graph_help = torch.cat( ( (energy.max(axis=1).values/e_per_jet).reshape(x_data[:,0,3].shape[0],1),\n",
    "                              (mass_per_jet).reshape(x_data[:,0,3].shape[0],1),\n",
    "                              (end_multiplicity_indx_per_jet).reshape(x_data[:,0,3].shape[0],1).int(),\n",
    "                              (end_edges_indx_per_jet).reshape(x_data[:,0,3].shape[0],1).int() ), dim=1)\n",
    "\n",
    "    return x_data[keep_inds,:nodes_per_graph], y_data[keep_inds].long(), edge_tensor[keep_inds], edge_indx_tensor[keep_inds].long(), edge_attr_matrix[keep_inds], graph_help[keep_inds], masses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5211a086",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2024-10-15T09:29:17.862517Z",
     "iopub.status.busy": "2024-10-15T09:29:17.862107Z",
     "iopub.status.idle": "2024-10-15T09:29:17.876637Z",
     "shell.execute_reply": "2024-10-15T09:29:17.875616Z"
    },
    "id": "-uyS1h4zU4XB",
    "papermill": {
     "duration": 0.034575,
     "end_time": "2024-10-15T09:29:17.878713",
     "exception": false,
     "start_time": "2024-10-15T09:29:17.844138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "### Reference - https://github.com/bmdillon/JetCLR/blob/main/scripts/modules/jet_augs.py\n",
    "\n",
    "def distort_jets( batch, strength=0.1, pT_clip_min=0.1 ):\n",
    "    '''\n",
    "    Input: batch of jets, shape (batchsize, 3, n_constit)\n",
    "    dim 1 ordering: (pT, eta, phi)\n",
    "    Output: batch of jets with each constituents position shifted independently, shifts drawn from normal with mean 0, std strength/pT, same shape as input\n",
    "    '''\n",
    "    pT = batch[:,0]   # (batchsize, n_constit)\n",
    "    shift_eta = np.nan_to_num( strength * np.random.randn(batch.shape[0], batch.shape[2]) / pT.clip(min=pT_clip_min), posinf = 0.0, neginf = 0.0 )# * mask\n",
    "    shift_phi = np.nan_to_num( strength * np.random.randn(batch.shape[0], batch.shape[2]) / pT.clip(min=pT_clip_min), posinf = 0.0, neginf = 0.0 )# * mask\n",
    "    shift = np.stack( [ np.zeros( (batch.shape[0], batch.shape[2]) ), shift_eta, shift_phi ], 1)\n",
    "    return batch + shift\n",
    "\n",
    "def collinear_fill_jets( batch ):\n",
    "    '''\n",
    "    Input: batch of jets, shape (batchsize, 3, n_constit)\n",
    "    dim 1 ordering: (pT, eta, phi)\n",
    "    Output: batch of jets with collinear splittings, the function attempts to fill as many of the zero-padded args.nconstit\n",
    "    entries with collinear splittings of the constituents by splitting each constituent at most once, same shape as input\n",
    "    '''\n",
    "    batchb = batch.copy()\n",
    "    nc = batch.shape[2]\n",
    "    nzs = np.array( [ np.where( batch[:,0,:][i]>0.0)[0].shape[0] for i in range(len(batch)) ] )\n",
    "\n",
    "    for k in range(len(batch)):\n",
    "        nzs1 = np.max( [ nzs[k], int(nc/2) ] )\n",
    "        zs1 = int(nc-nzs1)\n",
    "        els = np.random.choice( np.linspace(0,nzs1-1,nzs1), size=zs1, replace=False )\n",
    "        rs = np.random.uniform( size=zs1 )\n",
    "        for j in range(zs1):\n",
    "            batchb[k,0,int(els[j])] = rs[j]*batch[k,0,int(els[j])]\n",
    "            batchb[k,0,int(nzs[k]+j)] = (1-rs[j])*batch[k,0,int(els[j])]\n",
    "            batchb[k,1,int(nzs[k]+j)] = batch[k,1,int(els[j])]\n",
    "            batchb[k,2,int(nzs[k]+j)] = batch[k,2,int(els[j])]\n",
    "\n",
    "    return batchb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c85998f",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2024-10-15T09:29:17.913318Z",
     "iopub.status.busy": "2024-10-15T09:29:17.912990Z",
     "iopub.status.idle": "2024-10-15T09:29:17.947807Z",
     "shell.execute_reply": "2024-10-15T09:29:17.946963Z"
    },
    "id": "Ym9AH6-SVLr-",
    "papermill": {
     "duration": 0.054577,
     "end_time": "2024-10-15T09:29:17.949705",
     "exception": false,
     "start_time": "2024-10-15T09:29:17.895128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "class QuarkGluonGraphDataset(dgl.data.dgl_dataset.DGLDataset):\n",
    "\n",
    "  def __init__(self, dataset_name, raw_dir, save_dir, data_folder_name, datafile_name, labelsfile_name, datatype='particles', dataset_size=12500,\n",
    "               nodes_per_graph = 5, spectral_augmentation=False, irc_safety_aug=False, url=None, hash_key=..., force_reload=False, verbose=False, transform=None,\n",
    "              device='cpu'):\n",
    "    self.data_folder = data_folder_name\n",
    "    self.datafile_name = datafile_name\n",
    "    self.labelsfile_name = labelsfile_name\n",
    "    self.datatype = datatype\n",
    "    self.nodes_per_graph = nodes_per_graph\n",
    "    self.spectral_augmentation = spectral_augmentation\n",
    "    self.drop_ra_nodes = False\n",
    "    self.drop_cp_nodes = False\n",
    "    self.aug_ratio = None\n",
    "    self.irc_safety_aug = irc_safety_aug\n",
    "    self.device = device\n",
    "    self.dataset_size = dataset_size\n",
    "    self.augment = False\n",
    "    self.nodes_per_aug_graph = None\n",
    "    super().__init__(dataset_name, url, raw_dir, save_dir, hash_key, force_reload, verbose, transform)\n",
    "\n",
    "  @property\n",
    "  def data_folder_name(self):\n",
    "    return self.data_folder\n",
    "\n",
    "  @property\n",
    "  def raw_path(self):\n",
    "    return os.path.join(self.raw_dir, self.data_folder_name)\n",
    "\n",
    "  @property\n",
    "  def save_path(self):\n",
    "    return os.path.join(self.save_dir, self.data_folder_name)\n",
    "\n",
    "  @property\n",
    "  def graph_path(self):\n",
    "    return os.path.join(self.save_path, 'graphs_and_labels')\n",
    "\n",
    "  @property\n",
    "  def info_path(self):\n",
    "    return os.path.join(self.save_path, 'graphs_and_labels')\n",
    "\n",
    "  def load(self):\n",
    "    graphs, label_dict = dgl.load_graphs(str(self.graph_path))\n",
    "    info_dict = dgl.data.utils.load_info(str(self.info_path))\n",
    "\n",
    "    self.graph_lists = graphs\n",
    "    self.graph_labels = label_dict[\"labels\"]\n",
    "    self.max_num_node = info_dict[\"max_num_node\"]\n",
    "    self.num_labels = info_dict[\"num_labels\"]\n",
    "\n",
    "  # def save(self,):\n",
    "  #   label_dict = {\"labels\": self.graph_labels}\n",
    "  #   info_dict = {\n",
    "  #           \"max_num_node\": self.max_num_node,\n",
    "  #           \"num_labels\": self.num_labels,\n",
    "  #       }\n",
    "  #   dgl.save_graphs(str(self.graph_path), self.graph_lists, label_dict)\n",
    "  #   dgl.data.utils.save_info(str(self.info_path), info_dict)\n",
    "\n",
    "  def process(self,):\n",
    "    data = np.load(os.path.join(self.raw_path, self.datafile_name))\n",
    "    X = data['X']\n",
    "    y = data['y']\n",
    "    X_l, y_l = [], []\n",
    "    i = 0\n",
    "\n",
    "    while len(X_l)!=self.dataset_size:\n",
    "        if np.unique(X[i].sum(axis=1).nonzero()).shape[0] >= self.nodes_per_graph:\n",
    "            sorted_inds = np.argsort(X[i,:,0])[::-1]\n",
    "            x = X[i][sorted_inds]\n",
    "            X_l.append(x[:self.nodes_per_graph, :])\n",
    "            y_l.append(y[i])\n",
    "        i += 1\n",
    "    X = np.array(X_l)\n",
    "    y = np.array(y_l)\n",
    "\n",
    "\n",
    "    if self.datatype == 'particles':\n",
    "      self.graph_lists = []\n",
    "      self.rationale_augmented_graph_lists_1 = []\n",
    "      self.rationale_augmented_graph_lists_2 = []\n",
    "      self.complement_augmented_graph_lists = []\n",
    "      x_data_proc, y_data_proc, edge_tensor, edge_indx_tensor, edge_attr_matrix, graph_help, masses = preprocess_fixed_nodes(X,y,nodes_per_graph = self.nodes_per_graph) #,masses[:N])\n",
    "      self.max_num_node = x_data_proc.shape[1]\n",
    "      self.graph_labels = y_data_proc\n",
    "      self.num_labels = y_data_proc.shape[0]\n",
    "\n",
    "      print('--- Creating graphs ---')\n",
    "      for i in tqdm(range(x_data_proc.shape[0])):\n",
    "        g = dgl.graph((edge_indx_tensor[i][0], edge_indx_tensor[i][1]))\n",
    "        g.ndata['node_attr'] = x_data_proc[i]\n",
    "        g.ndata['node_indices'] = torch.arange(x_data_proc[i].shape[0]).reshape(-1,1)\n",
    "        g.ndata['node_mass'] = masses[i][:self.nodes_per_graph]\n",
    "        g.edata['edge_attr'] = edge_attr_matrix[i].view(-1,)\n",
    "        g.to(self.device)\n",
    "        self.graph_lists.append(g)\n",
    "        self.rationale_augmented_graph_lists_1.append(g)\n",
    "        self.rationale_augmented_graph_lists_2.append(g)\n",
    "        self.complement_augmented_graph_lists.append(g)\n",
    "\n",
    "      if self.spectral_augmentation:\n",
    "        self.spectral_graph_lists = []\n",
    "        print('--- Creating spectral graphs ---')\n",
    "        for i in tqdm(range(x_data_proc.shape[0])):\n",
    "          g = SpectralGraph((edge_indx_tensor[i][0], edge_indx_tensor[i][1]), theta=0.1, delta_origin=0.05, edge_weights_matrix=edge_tensor[i])\n",
    "          g.ndata['node_attr'] = x_data_proc[i]\n",
    "          g.edata['edge_attr'] = edge_attr_matrix[i].view(-1,)\n",
    "          self.spectral_graph_lists.append(g)\n",
    "        # print(self.graph_lists)\n",
    "\n",
    "      if self.irc_safety_aug:\n",
    "        for idx in range(len(self.graph_lists)):\n",
    "          g = self.graph_lists[idx]\n",
    "          g.ndata['node_attr_irc'] = g.ndata['node_attr'].clone()\n",
    "          if self.device=='cuda':\n",
    "            g.ndata['node_attr_irc'][:,:3] = torch.Tensor(distort_jets(collinear_fill_jets(g.ndata['node_attr'][:,:3].T.unsqueeze(0).cpu().numpy()))).squeeze(0).T.cuda()\n",
    "          else:\n",
    "            g.ndata['node_attr_irc'][:,:3] = torch.Tensor(distort_jets(collinear_fill_jets(g.ndata['node_attr'][:,:3].T.unsqueeze(0).numpy()))).squeeze(0).T\n",
    "          pt, rapidity, phi = g.ndata['node_attr_irc'][:, 0], g.ndata['node_attr_irc'][:, 1], g.ndata['node_attr_irc'][:, 2]\n",
    "          mt = (pt**2+g.ndata['node_mass']**2).sqrt()\n",
    "          energy = mt*torch.cosh(rapidity)\n",
    "          px, py, pz = pt*torch.cos(phi), pt*torch.sin(phi), mt*torch.sinh(rapidity)\n",
    "          g.ndata['node_attr_irc'][:,3] =  mt\n",
    "          g.ndata['node_attr_irc'][:,4] = energy\n",
    "          g.ndata['node_attr_irc'][:,5] = px\n",
    "          g.ndata['node_attr_irc'][:,6] = py\n",
    "          g.ndata['node_attr_irc'][:,7] = pz\n",
    "\n",
    "  def has_cache(self):\n",
    "    if os.path.exists(self.graph_path) and os.path.exists(self.info_path):\n",
    "      return True\n",
    "    return False\n",
    "\n",
    "  def __len__(self,):\n",
    "    return len(self.graph_lists)\n",
    "\n",
    "  def augment_dataset(self, type, batched_graph, batch_size):\n",
    "    self.augment = True\n",
    "\n",
    "    if type == 'rationale':\n",
    "      return drop_nodes_prob_batch(batched_graph, batch_size), drop_nodes_prob_batch(batched_graph, batch_size)\n",
    "\n",
    "    if type == 'complement':\n",
    "      return drop_nodes_cp_batch(batched_graph, batch_size)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    if self.spectral_augmentation:\n",
    "      g1 = self.graph_lists[idx]\n",
    "      g2 = self.spectral_graph_lists[idx]\n",
    "      if self._transform is not None:\n",
    "        g1 = self._transform(g1)\n",
    "        g2 = self._transform(g2)\n",
    "      return g1, g2, self.graph_labels[idx]\n",
    "\n",
    "    else:\n",
    "      g = self.graph_lists[idx]\n",
    "      if self._transform is not None:\n",
    "        g = self._transform(g)\n",
    "      return g, self.graph_labels[idx]\n",
    "\n",
    "  @property\n",
    "  def num_classes(self):\n",
    "    return int(self.num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13eb103e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:29:17.985054Z",
     "iopub.status.busy": "2024-10-15T09:29:17.984721Z",
     "iopub.status.idle": "2024-10-15T09:29:40.195310Z",
     "shell.execute_reply": "2024-10-15T09:29:40.194357Z"
    },
    "id": "lTcJqvhaVYQU",
    "outputId": "6e310eb6-e215-43bb-daa0-969b82adf3e9",
    "papermill": {
     "duration": 22.231389,
     "end_time": "2024-10-15T09:29:40.197923",
     "exception": false,
     "start_time": "2024-10-15T09:29:17.966534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Finding All Unique Particles ---\n",
      "\n",
      "--- Inserting Masses ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:00, 1673.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calculating Momenta and Energies ---\n",
      "\n",
      "--- Calculating Edge Tensors ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10000/10000 [00:07<00:00, 1326.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating graphs ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10000/10000 [00:04<00:00, 2072.42it/s]\n"
     ]
    }
   ],
   "source": [
    "main_dir = '/content/'\n",
    "jet_folder_path = '/content/energyflow/'\n",
    "\n",
    "qg_dataset = QuarkGluonGraphDataset(dataset_name='Quark Gluon', raw_dir=main_dir, save_dir='/content',\n",
    "                                    data_folder_name=jet_folder_path, datafile_name=jet_file_path, labelsfile_name=jet_file_path,\n",
    "                                    datatype='particles', dataset_size=10000, nodes_per_graph=nodes_per_graph, spectral_augmentation=False, irc_safety_aug=True,\n",
    "                                   device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fbcdfcb",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2024-10-15T09:29:40.253637Z",
     "iopub.status.busy": "2024-10-15T09:29:40.253212Z",
     "iopub.status.idle": "2024-10-15T09:29:40.272533Z",
     "shell.execute_reply": "2024-10-15T09:29:40.271616Z"
    },
    "id": "iwFoIOb2XdjG",
    "papermill": {
     "duration": 0.049185,
     "end_time": "2024-10-15T09:29:40.274497",
     "exception": false,
     "start_time": "2024-10-15T09:29:40.225312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "class GNN_imp_estimator(torch.nn.Module):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        num_layer (int): the number of GNN layers\n",
    "        emb_dim (int): dimensionality of embeddings\n",
    "        JK (str): last, concat, max or sum.\n",
    "        max_pool_layer (int): the layer from which we use max pool rather than add pool for neighbor aggregation\n",
    "        drop_ratio (float): dropout rate\n",
    "        gnn_type: gin, gcn, graphsage, gat\n",
    "\n",
    "    Output:\n",
    "        node representations\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_layer, emb_dim, in_dim, JK=\"last\", drop_ratio=0):\n",
    "        super(GNN_imp_estimator, self).__init__()\n",
    "        self.num_layer = num_layer\n",
    "        self.drop_ratio = drop_ratio\n",
    "        self.JK = JK\n",
    "\n",
    "        if self.num_layer < 2:\n",
    "            raise ValueError(\"Number of GNN layers must be greater than 1.\")\n",
    "\n",
    "\n",
    "        ###List of MLPs\n",
    "        self.gnns = torch.nn.ModuleList()\n",
    "        # self.gnns.append(torch_geometric.nn.conv.GCNConv(in_dim, 32))\n",
    "        # self.gnns.append(torch_geometric.nn.conv.GCNConv(32, 16))\n",
    "        # self.gnns.append(torch_geometric.nn.conv.GCNConv(16, 8))\n",
    "\n",
    "        self.gnns.append(dgl.nn.GraphConv(in_dim, 32, weight=True, bias=True))\n",
    "        self.gnns.append(dgl.nn.GraphConv(32, 16, weight=True, bias=True))\n",
    "        self.gnns.append(dgl.nn.GraphConv(16, 8, weight=True, bias=True))\n",
    "\n",
    "        ###List of batchnorms\n",
    "        self.batch_norms = torch.nn.ModuleList()\n",
    "        self.batch_norms.append(torch.nn.BatchNorm1d(32))\n",
    "        self.batch_norms.append(torch.nn.BatchNorm1d(16))\n",
    "        self.batch_norms.append(torch.nn.BatchNorm1d(8))\n",
    "\n",
    "        self.linear = torch.nn.Linear(8, 1)\n",
    "\n",
    "    def forward(self, *argv):\n",
    "        if len(argv) == 4:\n",
    "            x, edge_index, edge_attr, batch = argv[0], argv[1], argv[2], argv[3]\n",
    "            # Ensure edge_index is a 2D tensor (shape: [2, num_edges])\n",
    "            if edge_index.dim() != 2 or edge_index.size(0) != 2:\n",
    "                raise ValueError(\"edge_index must be a 2D tensor with shape [2, num_edges].\")\n",
    "\n",
    "            # Create the graph using DGL\n",
    "            graph = dgl.graph((edge_index[0], edge_index[1]))  # Create the graph from edge indices\n",
    "            graph.ndata['node_attr'] = x   # Assign node features\n",
    "            graph.edata['edge_attr'] = edge_attr  # Assign edge attributes\n",
    "\n",
    "        elif len(argv) == 2:\n",
    "            graph, batch = argv[0], argv[1]\n",
    "            x, edge_index, edge_attr = graph.ndata['node_attr'], graph.edges(), graph.edata['edge_attr']\n",
    "        else:\n",
    "            raise ValueError(\"unmatched number of arguments.\")\n",
    "        \n",
    "        \n",
    "        # x = self.x_embedding1(x[:, 0]) + self.x_embedding2(x[:, 1])\n",
    "        \n",
    "        # h_list = [x]\n",
    "        # for layer in range(len(self.gnns)):\n",
    "        #     print('Layer : ',layer)\n",
    "        #     h = self.gnns[layer](graph, h_list[layer].float(), edge_weight=edge_attr)   #\n",
    "        #     h = self.batch_norms[layer](h)\n",
    "        #     if layer == len(self.gnns) - 1:\n",
    "        #         # remove relu for the last layer\n",
    "        #         h = F.dropout(h, self.drop_ratio, training=self.training)\n",
    "        #     else:\n",
    "        #         h = F.dropout(nn.ReLU()(h), self.drop_ratio, training=self.training)\n",
    "        #     h_list.append(h)\n",
    "\n",
    "        h0 = self.gnns[0](graph, x.float(), edge_weight=edge_attr) # self.gnns[layer](h, edge_index, edge_attr)\n",
    "        h0 = self.batch_norms[0](h0)\n",
    "        h0 = F.dropout(nn.ReLU()(h0), self.drop_ratio, training=self.training)\n",
    "        h1 = self.gnns[1](graph, h0, edge_weight=edge_attr)\n",
    "        h1 = self.batch_norms[1](h1)\n",
    "        h1 = F.dropout(nn.ReLU()(h1), self.drop_ratio, training=self.training)\n",
    "        h2 = self.gnns[2](graph, h1, edge_weight=edge_attr)\n",
    "        h2 = self.batch_norms[2](h2)\n",
    "        h2 = F.dropout(h2, self.drop_ratio, training=self.training)\n",
    "\n",
    "        node_representation = h2  #h_list[-1]\n",
    "        node_representation = self.linear(node_representation)\n",
    "        node_representation = softmax(node_representation, batch)\n",
    "\n",
    "        return node_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "399411d8",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2024-10-15T09:29:40.330537Z",
     "iopub.status.busy": "2024-10-15T09:29:40.329909Z",
     "iopub.status.idle": "2024-10-15T09:29:40.360889Z",
     "shell.execute_reply": "2024-10-15T09:29:40.359915Z"
    },
    "id": "zGuASKZx4Vxm",
    "papermill": {
     "duration": 0.062346,
     "end_time": "2024-10-15T09:29:40.363096",
     "exception": false,
     "start_time": "2024-10-15T09:29:40.300750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "class GNN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    Args:\n",
    "        num_layer (int): the number of GNN layers\n",
    "        emb_dim (int): dimensionality of embeddings\n",
    "        JK (str): last, concat, max or sum.\n",
    "        max_pool_layer (int): the layer from which we use max pool rather than add pool for neighbor aggregation\n",
    "        drop_ratio (float): dropout rate\n",
    "        gnn_type: gin, gcn, graphsage, gat\n",
    "\n",
    "    Output:\n",
    "        node representations\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layer, in_dim, emb_dim, inter_dim, JK = \"last\", drop_ratio=0, gnn_type = \"gin\"):\n",
    "        super(GNN, self).__init__()\n",
    "        self.num_layer = num_layer\n",
    "        self.drop_ratio = drop_ratio\n",
    "        self.JK = JK\n",
    "\n",
    "        if self.num_layer < 2:\n",
    "            raise ValueError(\"Number of GNN layers must be greater than 1.\")\n",
    "\n",
    "        ###List of MLPs\n",
    "        self.gnns = torch.nn.ModuleList()\n",
    "        self.batch_norms = torch.nn.ModuleList()\n",
    "        # self.gnns.append(torch_geometric.nn.conv.GCNConv(in_dim, emb_dim))\n",
    "        if gnn_type == \"gin\":\n",
    "            self.gnns.append(GINConv(in_dim, aggr=\"add\"))\n",
    "            self.batch_norms.append(torch.nn.BatchNorm1d(inter_dim))\n",
    "        elif gnn_type == \"gcn\":\n",
    "            self.gnns.append(torch_geometric.nn.conv.GCNConv(in_dim, inter_dim))\n",
    "            self.batch_norms.append(torch.nn.BatchNorm1d(inter_dim))\n",
    "        elif gnn_type == \"gat\":\n",
    "            self.gnns.append(torch_geometric.nn.conv.GATConv(in_dim, inter_dim, heads=3, concat=False))\n",
    "            self.batch_norms.append(torch.nn.BatchNorm1d(inter_dim))\n",
    "        elif gnn_type == \"graphsage\":\n",
    "            self.gnns.append(GraphSAGEConv(in_dim))\n",
    "            self.batch_norms.append(torch.nn.BatchNorm1d(inter_dim))\n",
    "\n",
    "        for layer in range(num_layer):\n",
    "            if gnn_type == \"gin\":\n",
    "                self.gnns.append(GINConv(inter_dim, aggr=\"add\"))\n",
    "                self.batch_norms.append(torch.nn.BatchNorm1d(inter_dim))\n",
    "            elif gnn_type == \"gcn\":\n",
    "                self.gnns.append(torch_geometric.nn.conv.GCNConv(inter_dim, inter_dim))\n",
    "                self.batch_norms.append(torch.nn.BatchNorm1d(inter_dim))\n",
    "            elif gnn_type == \"gat\":\n",
    "                self.gnns.append(torch_geometric.nn.conv.GATConv(inter_dim, inter_dim, heads=3, concat=False))\n",
    "                self.batch_norms.append(torch.nn.BatchNorm1d(inter_dim))\n",
    "            elif gnn_type == \"graphsage\":\n",
    "                self.gnns.append(GraphSAGEConv(inter_dim))\n",
    "                self.batch_norms.append(torch.nn.BatchNorm1d(inter_dim))\n",
    "\n",
    "        if gnn_type == \"gin\":\n",
    "            self.gnns.append(GINConv(emb_dim, aggr=\"add\"))\n",
    "            self.batch_norms.append(torch.nn.BatchNorm1d(emb_dim))\n",
    "        elif gnn_type == \"gcn\":\n",
    "            self.gnns.append(torch_geometric.nn.conv.GCNConv(inter_dim, emb_dim))\n",
    "            self.batch_norms.append(torch.nn.BatchNorm1d(emb_dim))\n",
    "        elif gnn_type == \"gat\":\n",
    "            self.gnns.append(torch_geometric.nn.conv.GATConv(inter_dim, emb_dim, heads=3, concat=False))\n",
    "            self.batch_norms.append(torch.nn.BatchNorm1d(emb_dim))\n",
    "        elif gnn_type == \"graphsage\":\n",
    "            self.gnns.append(GraphSAGEConv(emb_dim))\n",
    "            self.batch_norms.append(torch.nn.BatchNorm1d(emb_dim))\n",
    "\n",
    "\n",
    "    #def forward(self, x, edge_index, edge_attr):\n",
    "    def forward(self, *argv):\n",
    "        if len(argv) == 3:\n",
    "            x, edge_index, edge_attr = argv[0], argv[1], argv[2]\n",
    "        elif len(argv) == 1:\n",
    "            # data = argv[0]\n",
    "            # x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "            graph = argv[0]\n",
    "            x, edge_index, edge_attr = graph.ndata['node_attr'], graph.edges(), graph.edata['edge_attr']\n",
    "        else:\n",
    "            raise ValueError(\"unmatched number of arguments.\")\n",
    "\n",
    "        # print(x)\n",
    "        # h_list = [x]\n",
    "        h = x\n",
    "        for layer in range(self.num_layer+2):\n",
    "            h = self.gnns[layer](h, edge_index, edge_attr)   #h_list[layer]\n",
    "            h = self.batch_norms[layer](h)\n",
    "            #h = F.dropout(F.relu(h), self.drop_ratio, training = self.training)\n",
    "            if layer == self.num_layer+1:\n",
    "                #remove relu for the last layer\n",
    "                h = F.dropout(h, self.drop_ratio, training = self.training)\n",
    "            else:\n",
    "                h = F.dropout(F.relu(h), self.drop_ratio, training = self.training)\n",
    "            # h_list.append(h)\n",
    "\n",
    "        ### Different implementations of Jk-concat\n",
    "        if self.JK == \"concat\":\n",
    "            node_representation = torch.cat(h_list, dim = 1)\n",
    "        elif self.JK == \"last\":\n",
    "            node_representation = h   #h_list[-1]\n",
    "        elif self.JK == \"max\":\n",
    "            h_list = [h.unsqueeze(0) for h in h_list]\n",
    "            node_representation = torch.max(torch.cat(h_list, dim = 0), dim = 0)[0]\n",
    "        elif self.JK == \"sum\":\n",
    "            h_list = [h.unsqueeze(0) for h in h_list]\n",
    "            node_representation = torch.sum(torch.cat(h_list, dim = 0), dim = 0)[0]\n",
    "\n",
    "        return node_representation\n",
    "\n",
    "    def forward_gradc(self, *argv):\n",
    "        if len(argv) == 3:\n",
    "            x, edge_index, edge_attr = argv[0], argv[1], argv[2]\n",
    "        elif len(argv) == 1:\n",
    "            data = argv[0]\n",
    "            x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        else:\n",
    "            raise ValueError(\"unmatched number of arguments.\")\n",
    "\n",
    "        h_list = [x]\n",
    "        for layer in range(self.num_layer+2):\n",
    "            h = self.gnns[layer](h_list[layer], edge_index, edge_attr)\n",
    "            h = self.batch_norms[layer](h)\n",
    "            h = F.dropout(F.relu(h), self.drop_ratio, training = self.training)\n",
    "            if layer == self.num_layer - 1:\n",
    "                #remove relu for the last layer\n",
    "                h = F.dropout(h, self.drop_ratio, training = self.training)\n",
    "            else:\n",
    "                h = F.dropout(F.relu(h), self.drop_ratio, training = self.training)\n",
    "            h_list.append(h)\n",
    "\n",
    "        ### Different implementations of Jk-concat\n",
    "        if self.JK == \"concat\":\n",
    "            node_representation = torch.cat(h_list, dim = 1)\n",
    "        elif self.JK == \"last\":\n",
    "            node_representation = h_list[-1]\n",
    "        elif self.JK == \"max\":\n",
    "            h_list = [h.unsqueeze(0) for h in h_list]\n",
    "            node_representation = torch.max(torch.cat(h_list, dim = 0), dim = 0)[0]\n",
    "        elif self.JK == \"sum\":\n",
    "            h_list = [h.unsqueeze(0) for h in h_list]\n",
    "            node_representation = torch.sum(torch.cat(h_list, dim = 0), dim = 0)[0]\n",
    "\n",
    "        return node_representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80c2cea",
   "metadata": {
    "id": "EjdpTpoY4eel",
    "papermill": {
     "duration": 0.026144,
     "end_time": "2024-10-15T09:29:40.415541",
     "exception": false,
     "start_time": "2024-10-15T09:29:40.389397",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Quantum circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d0225a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:29:40.470816Z",
     "iopub.status.busy": "2024-10-15T09:29:40.470316Z",
     "iopub.status.idle": "2024-10-15T09:29:42.279403Z",
     "shell.execute_reply": "2024-10-15T09:29:42.278416Z"
    },
    "papermill": {
     "duration": 1.840054,
     "end_time": "2024-10-15T09:29:42.281735",
     "exception": false,
     "start_time": "2024-10-15T09:29:40.441681",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0211+0.0062j, -0.0136+0.0079j, -0.0190+0.0088j,  ...,\n",
      "          0.0068-0.0331j, -0.0180+0.0338j, -0.0026-0.0034j],\n",
      "        [-0.0211+0.0062j, -0.0136+0.0079j, -0.0190+0.0088j,  ...,\n",
      "          0.0068-0.0331j, -0.0180+0.0338j, -0.0026-0.0034j],\n",
      "        [-0.0211+0.0062j, -0.0136+0.0079j, -0.0190+0.0088j,  ...,\n",
      "          0.0068-0.0331j, -0.0180+0.0338j, -0.0026-0.0034j],\n",
      "        ...,\n",
      "        [-0.0211+0.0062j, -0.0136+0.0079j, -0.0190+0.0088j,  ...,\n",
      "          0.0068-0.0331j, -0.0180+0.0338j, -0.0026-0.0034j],\n",
      "        [-0.0211+0.0062j, -0.0136+0.0079j, -0.0190+0.0088j,  ...,\n",
      "          0.0068-0.0331j, -0.0180+0.0338j, -0.0026-0.0034j],\n",
      "        [-0.0211+0.0062j, -0.0136+0.0079j, -0.0190+0.0088j,  ...,\n",
      "          0.0068-0.0331j, -0.0180+0.0338j, -0.0026-0.0034j]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchquantum as tq\n",
    "import torchquantum.functional as tqf\n",
    "from itertools import combinations\n",
    "\n",
    "class IQPEmbedding(tq.QuantumModule):\n",
    "    def __init__(self, wires, n_repeats=1, pattern=None):\n",
    "        \"\"\"\n",
    "        Initialize the IQPEmbedding with specified number of qubits and repetitions.\n",
    "\n",
    "        Args:\n",
    "            wires (list[int]): List of qubits (wires) to apply the operations on.\n",
    "            n_repeats (int): Number of repetitions of the embedding circuit.\n",
    "            pattern (list[tuple]): Optional custom pattern for entanglement.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.wires = wires  # The number of qubits (wires)\n",
    "        self.n_repeats = n_repeats  # Number of repetitions for the embedding\n",
    "        if pattern is None:\n",
    "            # Default to an all-to-all entanglement pattern\n",
    "            self.pattern = list(combinations(wires, 2))\n",
    "        else:\n",
    "            self.pattern = pattern  # Custom entanglement pattern\n",
    "\n",
    "    def forward(self, q_device, features):\n",
    "        \"\"\"\n",
    "        Apply the IQPEmbedding on the quantum device.\n",
    "\n",
    "        Args:\n",
    "            q_device (tq.QuantumDevice): The quantum device (simulator).\n",
    "            features (torch.Tensor): Tensor of features to encode.\n",
    "                Shape: (batch_size, num_wires, feature_dim)\n",
    "        \"\"\"\n",
    "        batch_size = features.shape[0]\n",
    "        n_wires = len(self.wires)\n",
    "        n_features = features.shape[-1]\n",
    "\n",
    "        if n_wires != features.shape[1]:\n",
    "            raise ValueError(f\"Feature dimension ({features.shape[1]}) must match number of wires ({n_wires}).\")\n",
    "\n",
    "        for batch_idx in range(batch_size):\n",
    "            feature_batch = features[batch_idx]\n",
    "            # print(feature_batch.shape)\n",
    "            for _ in range(self.n_repeats):\n",
    "                # Apply Hadamard gates and RZ rotations for each wire\n",
    "                for i, wire in enumerate(self.wires):\n",
    "                    tqf.hadamard(q_device, wires=wire)\n",
    "                    # Ensure we pass a scalar for the RZ gate (e.g., the first feature in feature_batch)\n",
    "                    tqf.rz(q_device, wires=wire, params=feature_batch[i, 0])  # Pick the first feature value\n",
    "\n",
    "                # Apply ZZ entanglement according to the pattern\n",
    "                for (wire1, wire2) in self.pattern:\n",
    "                    # Multiply the selected feature scalars for the interaction\n",
    "                    tqf.multirz(q_device, n_wires=2, wires=[wire1, wire2],\n",
    "                                params=feature_batch[self.wires.index(wire1), 0] * feature_batch[self.wires.index(wire2), 0])\n",
    "\n",
    "                    \n",
    "# Example usage\n",
    "n_qubit = 10\n",
    "\n",
    "# Sample input data for embedding\n",
    "data = torch.rand((20, n_qubit, 8))  # Batch of size 2000, 4 wires, 8 features per wire\n",
    "\n",
    "# Instantiate the quantum device and the circuit\n",
    "qdev = tq.QuantumDevice(n_wires=n_qubit, bsz=data.shape[0], device='cpu')\n",
    "\n",
    "# Initialize the circuit\n",
    "encoder = IQPEmbedding(wires=range(n_qubit), n_repeats=3)\n",
    "\n",
    "# Apply the circuit to the quantum device\n",
    "encoder(qdev, data)\n",
    "\n",
    "# Get the quantum state\n",
    "quantum_state = qdev.get_states_1d()\n",
    "print(quantum_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3a25d19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:29:42.338186Z",
     "iopub.status.busy": "2024-10-15T09:29:42.337813Z",
     "iopub.status.idle": "2024-10-15T09:30:02.922498Z",
     "shell.execute_reply": "2024-10-15T09:30:02.921513Z"
    },
    "papermill": {
     "duration": 20.615422,
     "end_time": "2024-10-15T09:30:02.924738",
     "exception": false,
     "start_time": "2024-10-15T09:29:42.309316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0189-0.0008j, -0.0040-0.0056j, -0.0299+0.0079j,  ...,\n",
      "          0.0002-0.0009j, -0.0036-0.0024j, -0.0001-0.0016j],\n",
      "        [-0.0189-0.0008j, -0.0040-0.0056j, -0.0299+0.0079j,  ...,\n",
      "          0.0002-0.0009j, -0.0036-0.0024j, -0.0001-0.0016j],\n",
      "        [-0.0189-0.0008j, -0.0040-0.0056j, -0.0299+0.0079j,  ...,\n",
      "          0.0002-0.0009j, -0.0036-0.0024j, -0.0001-0.0016j],\n",
      "        ...,\n",
      "        [-0.0189-0.0008j, -0.0040-0.0056j, -0.0299+0.0079j,  ...,\n",
      "          0.0002-0.0009j, -0.0036-0.0024j, -0.0001-0.0016j],\n",
      "        [-0.0189-0.0008j, -0.0040-0.0056j, -0.0299+0.0079j,  ...,\n",
      "          0.0002-0.0009j, -0.0036-0.0024j, -0.0001-0.0016j],\n",
      "        [-0.0189-0.0008j, -0.0040-0.0056j, -0.0299+0.0079j,  ...,\n",
      "          0.0002-0.0009j, -0.0036-0.0024j, -0.0001-0.0016j]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchquantum as tq\n",
    "import torchquantum.functional as tqf\n",
    "\n",
    "class DisplacementEmbedding(tq.QuantumModule):\n",
    "    \"\"\"\n",
    "    Encodes features into the displacement amplitudes or phases of quantum states\n",
    "    in a way similar to PennyLane's DisplacementEmbedding but using TorchQuantum.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_features, wires, method=\"amplitude\", c=0.1):\n",
    "        super().__init__()\n",
    "        self.n_features = n_features\n",
    "        self.wires = wires\n",
    "        self.method = method\n",
    "        self.c = c\n",
    "\n",
    "        if self.method not in [\"amplitude\", \"phase\"]:\n",
    "            raise ValueError(f\"Method must be 'amplitude' or 'phase', but got {self.method}.\")\n",
    "\n",
    "    def forward(self, q_device, features):\n",
    "        \"\"\"\n",
    "        Process the input features and apply the displacement embedding to each wire of the quantum device.\n",
    "\n",
    "        Args:\n",
    "            q_device (tq.QuantumDevice): Quantum device (simulator).\n",
    "            features (torch.Tensor): Input features of shape (batch_size, num_wires, num_features).\n",
    "                                     For example, (20, 10, 8).\n",
    "        \"\"\"\n",
    "        batch_size, n_wires, n_features = features.shape\n",
    "\n",
    "        # Ensure that the number of wires matches the input dimension\n",
    "        if n_wires != len(self.wires):\n",
    "            raise ValueError(f\"Number of wires ({len(self.wires)}) does not match feature dimension ({n_wires}).\")\n",
    "        \n",
    "        for batch_idx in range(batch_size):\n",
    "            # Extract the features for this batch\n",
    "            feature_batch = features[batch_idx]\n",
    "            \n",
    "            for i, wire in enumerate(self.wires):\n",
    "                for j in range(n_features):\n",
    "                    if self.method == \"amplitude\":\n",
    "                        # Encode into displacement amplitudes using the j-th feature\n",
    "                        displacement_amp = feature_batch[i, j]\n",
    "                        displacement_phase = self.c\n",
    "                    elif self.method == \"phase\":\n",
    "                        # Encode into displacement phases using the j-th feature\n",
    "                        displacement_amp = self.c\n",
    "                        displacement_phase = feature_batch[i, j]\n",
    "\n",
    "                    # Apply the displacement operation on the quantum device\n",
    "                    # Assuming tqf.rx and tqf.rz simulate the behavior of displacement for this illustration\n",
    "                    tqf.rx(q_device, wires=wire, params=displacement_amp)\n",
    "                    tqf.rz(q_device, wires=wire, params=displacement_phase)\n",
    "\n",
    "# Usage Example:\n",
    "\n",
    "# Create a quantum device with the necessary wires\n",
    "n_wires = 10  # The number of wires must match the second dimension of the input data\n",
    "\n",
    "# Create features with shape (20, 10, 8) - 20 batches, 10 wires, and 8 features per wire\n",
    "features = torch.rand((256, n_wires, 8))\n",
    "\n",
    "q_device = tq.QuantumDevice(n_wires=n_wires, bsz=features.shape[0], device='cpu')\n",
    "# Initialize the DisplacementEmbedding\n",
    "embedding = DisplacementEmbedding(n_features=n_wires, wires=list(range(n_wires)), method=\"amplitude\") # \"amplitude\", \"phase\"\n",
    "\n",
    "# Apply the embedding\n",
    "embedding(q_device, features)\n",
    "\n",
    "# Print the quantum state to check the result\n",
    "print(q_device.get_states_1d())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "512aa724",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:30:02.980296Z",
     "iopub.status.busy": "2024-10-15T09:30:02.979931Z",
     "iopub.status.idle": "2024-10-15T09:30:02.989410Z",
     "shell.execute_reply": "2024-10-15T09:30:02.988527Z"
    },
    "id": "9LTkuQziJqtu",
    "outputId": "21725ff0-dfc4-4cfa-dcac-d502b1c7dcd7",
    "papermill": {
     "duration": 0.039764,
     "end_time": "2024-10-15T09:30:02.991332",
     "exception": false,
     "start_time": "2024-10-15T09:30:02.951568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def pad_or_truncate_to_power_of_two(data, pad_with=0):\n",
    "    \"\"\"\n",
    "    Convert input data into a size of 2^n by padding or truncating.\n",
    "\n",
    "    Parameters:\n",
    "    - data: torch.Tensor of shape (batch_size, input_size, features)\n",
    "    - pad_with: Value to pad with if the data needs to be padded.\n",
    "\n",
    "    Returns:\n",
    "    - padded_data: torch.Tensor of shape (batch_size, target_size, features)\n",
    "    \"\"\"\n",
    "    print(data.shape)\n",
    "    batch_size, input_size, features = data.shape\n",
    "\n",
    "    # Calculate the next power of 2 for the input_size\n",
    "    n = torch.ceil(torch.log2(torch.tensor(input_size, dtype=torch.float))).int().item()\n",
    "    target_size = 2 ** n\n",
    "\n",
    "    # If input size is less than target size, pad with `pad_with`\n",
    "    if input_size < target_size:\n",
    "        padded_data = F.pad(data, (0, 0, 0, target_size - input_size), mode='constant', value=pad_with)\n",
    "    # If input size is greater than target size, truncate the extra elements\n",
    "    else:\n",
    "        padded_data = data[:, :target_size, :]\n",
    "\n",
    "    return padded_data\n",
    "\n",
    "def normalize_data(data):\n",
    "    \"\"\"\n",
    "    Normalize input data such that the sum of squares of each sample is 1.\n",
    "\n",
    "    Parameters:\n",
    "    - data: torch.Tensor of shape (batch_size, N, features)\n",
    "\n",
    "    Returns:\n",
    "    - normalized_data: torch.Tensor of shape (batch_size, N, features)\n",
    "    \"\"\"\n",
    "    # Calculate the L2 norm (sum of squares) for each sample in the batch along the last two dimensions\n",
    "    norm = torch.sqrt(torch.sum(data ** 2, dim=(1, 2), keepdim=True))\n",
    "\n",
    "    # Normalize each sample by dividing by its norm\n",
    "    normalized_data = data / (norm + 1e-10)\n",
    "\n",
    "    return normalized_data\n",
    "\n",
    "# # Example usage:\n",
    "# # Sample input data of size (2000, 10, 8)\n",
    "# data = torch.rand((2000, 10, 8))\n",
    "\n",
    "# # Convert to a size that is a power of 2\n",
    "# converted_data = pad_or_truncate_to_power_of_two(data)\n",
    "\n",
    "# # Normalize the data\n",
    "# normalized_data = normalize_data(converted_data)\n",
    "\n",
    "# print(\"Converted Data Shape:\", converted_data.shape)\n",
    "# print(\"Normalized Data Shape:\", normalized_data.shape)\n",
    "\n",
    "# # Apply amplitude encoding (assuming `amplitude_encoder` is defined elsewhere)\n",
    "# # amplitude_encoder(qdev, normalized_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7967dbfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:30:03.045461Z",
     "iopub.status.busy": "2024-10-15T09:30:03.045133Z",
     "iopub.status.idle": "2024-10-15T09:30:03.186405Z",
     "shell.execute_reply": "2024-10-15T09:30:03.185623Z"
    },
    "id": "KMtqZdOeBxvp",
    "outputId": "cd1d1702-5239-4945-c2c3-aff6a100fe7c",
    "papermill": {
     "duration": 0.171022,
     "end_time": "2024-10-15T09:30:03.188449",
     "exception": false,
     "start_time": "2024-10-15T09:30:03.017427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 10, 8])\n",
      "tensor([[-2.5972e-06+0.j, -1.3089e-05+0.j, -3.0166e-05+0.j,  ...,\n",
      "         -4.1098e-05+0.j, -1.7832e-05+0.j, -3.5384e-06+0.j],\n",
      "        [-2.5972e-06+0.j, -1.3089e-05+0.j, -3.0166e-05+0.j,  ...,\n",
      "         -4.1098e-05+0.j, -1.7832e-05+0.j, -3.5384e-06+0.j],\n",
      "        [-2.5972e-06+0.j, -1.3089e-05+0.j, -3.0166e-05+0.j,  ...,\n",
      "         -4.1098e-05+0.j, -1.7832e-05+0.j, -3.5384e-06+0.j],\n",
      "        ...,\n",
      "        [-2.5972e-06+0.j, -1.3089e-05+0.j, -3.0166e-05+0.j,  ...,\n",
      "         -4.1098e-05+0.j, -1.7832e-05+0.j, -3.5384e-06+0.j],\n",
      "        [-2.5972e-06+0.j, -1.3089e-05+0.j, -3.0166e-05+0.j,  ...,\n",
      "         -4.1098e-05+0.j, -1.7832e-05+0.j, -3.5384e-06+0.j],\n",
      "        [-2.5972e-06+0.j, -1.3089e-05+0.j, -3.0166e-05+0.j,  ...,\n",
      "         -4.1098e-05+0.j, -1.7832e-05+0.j, -3.5384e-06+0.j]])\n"
     ]
    }
   ],
   "source": [
    "import torchquantum as tq\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "TOLERANCE = 1e-10\n",
    "\n",
    "class AmplitudeEmbedding(tq.QuantumModule):\n",
    "    def __init__(self, num_qubits, pad_with=None, normalize=True):\n",
    "        super(AmplitudeEmbedding, self).__init__()\n",
    "        self.num_qubits = num_qubits\n",
    "        self.pad_with = pad_with\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def forward(self, qdev, data):\n",
    "        \"\"\"Amplitude embedding using torchquantum basic gates.\"\"\"\n",
    "        # Calculate the required number of amplitudes\n",
    "        required_size = 2 ** self.num_qubits\n",
    "\n",
    "        # Reshape data to ensure proper dimensionality for padding\n",
    "        if data.ndim == 3:\n",
    "            batch_size, input_size, features = data.shape\n",
    "            # Flatten the features dimension\n",
    "            data = data.view(batch_size, input_size * features)\n",
    "        else:\n",
    "            raise ValueError(\"Input data must be of shape (batch_size, input_size, features).\")\n",
    "\n",
    "        # Pad the data if necessary\n",
    "        if data.shape[1] < required_size:\n",
    "            if self.pad_with is not None:\n",
    "                pad_size = required_size - data.shape[1]\n",
    "                data = F.pad(data, (0, pad_size), mode='constant', value=self.pad_with)\n",
    "            else:\n",
    "                raise ValueError(\"Input data must have a size of 2^n or provide pad_with value.\")\n",
    "\n",
    "        # Normalize the data if required\n",
    "        if self.normalize:\n",
    "            data = F.normalize(data, p=2, dim=1)\n",
    "\n",
    "        # Check if the data is properly normalized\n",
    "        norm = torch.sum(data ** 2, dim=1)\n",
    "        # print(\"Norm:\", norm)\n",
    "        # Check if the norm is close enough to 1 for all samples in the batch\n",
    "        if not torch.allclose(norm, torch.ones_like(norm), atol=TOLERANCE):\n",
    "            raise ValueError(\"Input data must be normalized such that the sum of squares is 1.\")\n",
    "\n",
    "        # Reset quantum device states before encoding (Pass the batch size)\n",
    "        qdev.reset_states(bsz=qdev.bsz)\n",
    "\n",
    "        # Amplitude encoding: Decompose the amplitude preparation into basic gates\n",
    "        self._apply_amplitude_encoding(qdev, data.view(-1, required_size))  # Ensure the data shape matches the encoding requirement\n",
    "\n",
    "    def _apply_amplitude_encoding(self, qdev, data):\n",
    "        \"\"\"Apply amplitude encoding using basic gates.\"\"\"\n",
    "        batch_size = data.shape[0]\n",
    "\n",
    "        # Thetas for RY gates are calculated from the data amplitudes\n",
    "        for i in range(self.num_qubits):\n",
    "            for b in range(batch_size):\n",
    "                theta = 2 * torch.acos(data[b, i])  # Ensure you are accessing the right element\n",
    "\n",
    "                # Wrap theta as a torch.nn.Parameter\n",
    "                theta_param = nn.Parameter(theta, requires_grad=False)\n",
    "\n",
    "                # Apply the RY gate for the ith qubit\n",
    "                tq.RY(has_params=True, trainable=False)(qdev, wires=i, params=theta_param)\n",
    "\n",
    "        # Apply CNOT gates for entanglement between qubits\n",
    "        for i in range(self.num_qubits - 1):\n",
    "            tq.CNOT()(qdev, wires=[i, i + 1])\n",
    "\n",
    "# Example usage:\n",
    "# Initialize a 2-qubit quantum device\n",
    "n_qubit = 10\n",
    "\n",
    "# Sample input data for amplitude embedding\n",
    "data = torch.rand((20, n_qubit, 8))  # Should be of size (2000, 10, 8)\n",
    "\n",
    "qdev = tq.QuantumDevice(n_wires=n_qubit, bsz=data.shape[0], device='cpu')\n",
    "\n",
    "# Convert to a size that is a power of 2\n",
    "converted_data = pad_or_truncate_to_power_of_two(data)  # You need to define this function\n",
    "\n",
    "# Normalize the data\n",
    "normalized_data = normalize_data(converted_data)  # You need to define this function\n",
    "\n",
    "# Initialize the amplitude embedding layer\n",
    "amplitude_encoder = AmplitudeEmbedding(num_qubits=n_qubit, normalize=True, pad_with=0.0)\n",
    "\n",
    "# Apply amplitude encoding\n",
    "amplitude_encoder(qdev, normalized_data)\n",
    "\n",
    "# Get the quantum state\n",
    "quantum_state = qdev.get_states_1d()\n",
    "print(quantum_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fccfaa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:30:03.246094Z",
     "iopub.status.busy": "2024-10-15T09:30:03.245201Z",
     "iopub.status.idle": "2024-10-15T09:30:03.274534Z",
     "shell.execute_reply": "2024-10-15T09:30:03.273731Z"
    },
    "id": "B0JvK_rRKGtR",
    "papermill": {
     "duration": 0.060858,
     "end_time": "2024-10-15T09:30:03.276639",
     "exception": false,
     "start_time": "2024-10-15T09:30:03.215781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchquantum as tq\n",
    "\n",
    "class BetterBetterTorchLayer(torch.nn.Module):\n",
    "    def __init__(self, nodes_per_graph, num_layers, input_dim, device, entanglement_type='CNOT', encoding_type='RY'):\n",
    "        super(BetterBetterTorchLayer, self).__init__()\n",
    "        self.device = device\n",
    "        self.num_qubits = nodes_per_graph\n",
    "        self.entanglement_type = entanglement_type\n",
    "        self.encoding_type = encoding_type  # Encoding type\n",
    "        inputs = []\n",
    "        self.node_attr_count = 0\n",
    "        self.amplitude_encoding = False\n",
    "        self.IQP_encoding = False\n",
    "        self.displacement_encoding = False\n",
    "        \n",
    "        # Choose the type of encoding\n",
    "        if self.encoding_type == 'AmplitudeEncoding':\n",
    "            self.amplitude_encoding = True\n",
    "        elif self.encoding_type == 'IQPEncoding':\n",
    "            self.IQP_encoding = True\n",
    "        elif self.encoding_type == 'DisplacementEncoding':\n",
    "            self.displacement_encoding = True\n",
    "        else:\n",
    "            self.amplitude_encoding = False\n",
    "            self.IQP_encoding = False\n",
    "            self.displacement_encoding = False\n",
    "\n",
    "        # Standard gate encoding for node attributes\n",
    "        q_control = 0  # Define the control qubit as the first qubit (you can modify this as needed)\n",
    "        q2 = 1  # Define a second qubit for gates like SWAP (you can modify this as well)\n",
    "        theta, phi, lambda_ = 0.5, 0.3, 0.1  # Example values for U3 gate parameters (adjustable)\n",
    "\n",
    "        if not self.amplitude_encoding and not self.IQP_encoding and not self.displacement_encoding:\n",
    "            for q in range(self.num_qubits):\n",
    "                for d in range(input_dim):\n",
    "                    if self.encoding_type == 'RY':\n",
    "                        # Y-axis rotation encoding\n",
    "                        inputs.append({'input_idx': self.node_attr_count, 'func': 'ry', 'wires': [q]})\n",
    "                    \n",
    "                    elif self.encoding_type == 'RZ':\n",
    "                        # Z-axis rotation encoding\n",
    "                        inputs.append({'input_idx': self.node_attr_count, 'func': 'rz', 'wires': [q]})\n",
    "                    \n",
    "                    elif self.encoding_type == 'RX':\n",
    "                        # X-axis rotation encoding\n",
    "                        inputs.append({'input_idx': self.node_attr_count, 'func': 'rx', 'wires': [q]})\n",
    "                    \n",
    "                    elif self.encoding_type == 'H':\n",
    "                        # Hadamard gate encoding for superposition\n",
    "                        inputs.append({'input_idx': self.node_attr_count, 'func': 'h', 'wires': [q]})\n",
    "                    \n",
    "                    elif self.encoding_type == 'Phase':\n",
    "                        # Phase gate encoding\n",
    "                        inputs.append({'input_idx': self.node_attr_count, 'func': 'p', 'wires': [q]})\n",
    "                    \n",
    "                    self.node_attr_count += 1\n",
    "\n",
    "            # Prepare edge inputs\n",
    "            self.edge_attr_count = self.node_attr_count + 1\n",
    "            for q in range(self.num_qubits):\n",
    "                for e in range(q + 1, self.num_qubits):\n",
    "                    inputs.append({'input_idx': self.edge_attr_count, 'func': 'crz', 'wires': [q, e]})\n",
    "                    self.edge_attr_count += 1\n",
    "            self.edge_attr_count -= self.node_attr_count\n",
    "\n",
    "        self.encoder = tq.GeneralEncoder(inputs)\n",
    "        self.q_layers = tq.QuantumModuleList()\n",
    "\n",
    "        # Build quantum layers with entanglement\n",
    "        for layer in range(num_layers):\n",
    "            self.q_layers.append(\n",
    "                tq.Op1QAllLayer(op=tq.RX, n_wires=self.num_qubits, has_params=True, trainable=True)\n",
    "            )\n",
    "            self.q_layers.append(\n",
    "                tq.Op1QAllLayer(op=tq.RY, n_wires=self.num_qubits, has_params=True, trainable=True)\n",
    "            )\n",
    "            self.q_layers.append(\n",
    "                tq.Op1QAllLayer(op=tq.RZ, n_wires=self.num_qubits, has_params=True, trainable=True)\n",
    "            )\n",
    "\n",
    "            # Apply entanglement layer based on selected type\n",
    "            if self.entanglement_type == 'CNOT':\n",
    "                self.q_layers.append(\n",
    "                    tq.Op2QAllLayer(op=tq.CNOT, n_wires=self.num_qubits, jump=(layer + 1) % (self.num_qubits - 1), circular=True)\n",
    "                )\n",
    "            elif self.entanglement_type == 'CZ':\n",
    "                self.q_layers.append(\n",
    "                    tq.Op2QAllLayer(op=tq.CZ, n_wires=self.num_qubits, jump=(layer + 1) % (self.num_qubits - 1), circular=True)\n",
    "                )\n",
    "            elif self.entanglement_type == 'SWAP':\n",
    "                self.q_layers.append(\n",
    "                    tq.Op2QAllLayer(op=tq.SWAP, n_wires=self.num_qubits, jump=(layer + 1) % (self.num_qubits - 1), circular=True)\n",
    "                )\n",
    "            elif self.entanglement_type == 'CNOTbutterfly':\n",
    "                self.q_layers.append(\n",
    "                    tq.Op2QButterflyLayer(op=tq.CNOT, n_wires=self.num_qubits, has_params=False, trainable=False, wire_reverse=False)\n",
    "                )\n",
    "            elif self.entanglement_type == 'CZbutterfly':\n",
    "                self.q_layers.append(\n",
    "                    tq.Op2QButterflyLayer(op=tq.CZ, n_wires=self.num_qubits, has_params=False, trainable=False, wire_reverse=False)\n",
    "                )\n",
    "            elif self.entanglement_type == 'SWAPbutterfly':\n",
    "                self.q_layers.append(\n",
    "                    tq.Op2QButterflyLayer(op=tq.SWAP, n_wires=self.num_qubits, has_params=False, trainable=False, wire_reverse=False)\n",
    "                )\n",
    "\n",
    "\n",
    "    def forward(self, node_inputs, node_indices, edge_inputs):\n",
    "        qdev = tq.QuantumDevice(n_wires=self.num_qubits, bsz=node_inputs.shape[0], device=self.device, record_op=True)\n",
    "\n",
    "        if self.amplitude_encoding:\n",
    "            # Convert to a size that is a power of 2\n",
    "            converted_data = pad_or_truncate_to_power_of_two(node_inputs)\n",
    "            # Normalize the data\n",
    "            normalized_data = normalize_data(converted_data)\n",
    "            # Initialize the amplitude embedding layer\n",
    "            amplitude_encoder = AmplitudeEmbedding(num_qubits=self.num_qubits, normalize=False, pad_with=0.0)\n",
    "            # Apply amplitude encoding\n",
    "            amplitude_encoder(qdev, normalized_data)\n",
    "\n",
    "        elif self.IQP_encoding:\n",
    "            # Initialize the circuit\n",
    "            encoder = IQPEmbedding(wires=range(self.num_qubits), n_repeats=3)\n",
    "            # Apply the circuit to the quantum device\n",
    "            encoder(qdev, node_inputs)\n",
    "\n",
    "        elif self.displacement_encoding:\n",
    "            # Initialize the circuit\n",
    "            encoder = DisplacementEmbedding(n_features=self.num_qubits, wires=list(range(self.num_qubits)), method=\"phase\") # \"amplitude\", \"phase\"\n",
    "            # Apply the circuit to the quantum device\n",
    "            encoder(qdev, node_inputs)\n",
    "\n",
    "        else:\n",
    "            # Default to gate encoding\n",
    "            self.encoder(qdev, torch.cat((node_inputs.reshape(node_inputs.shape[0], -1), edge_inputs.reshape(edge_inputs.shape[0], -1)), dim=1))\n",
    "\n",
    "        # Apply quantum layers\n",
    "        for l in range(len(self.q_layers)):\n",
    "            self.q_layers[l](qdev)\n",
    "\n",
    "        # Return the squared amplitude of the final quantum state\n",
    "        return torch.abs(qdev.get_states_1d()) ** 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "046ce266",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2024-10-15T09:30:03.333601Z",
     "iopub.status.busy": "2024-10-15T09:30:03.333220Z",
     "iopub.status.idle": "2024-10-15T09:30:03.343929Z",
     "shell.execute_reply": "2024-10-15T09:30:03.343053Z"
    },
    "id": "_Ky_BkEUXiYJ",
    "papermill": {
     "duration": 0.041256,
     "end_time": "2024-10-15T09:30:03.345936",
     "exception": false,
     "start_time": "2024-10-15T09:30:03.304680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "class QGNN_node_estimator(torch.nn.Module):\n",
    "  def __init__(self, nodes_per_graph, num_layers, input_dim=None, device='cpu', entanglement_type='CNOT', encoding_type='RY'):\n",
    "    super(QGNN_node_estimator, self).__init__()\n",
    "    self.device = device\n",
    "    self.nodes_per_graph = nodes_per_graph\n",
    "    self.num_layers = num_layers\n",
    "    self.input_dim = input_dim\n",
    "    self.entanglement_type = entanglement_type\n",
    "    self.encoding_type = encoding_type\n",
    "    self.quantum_nn = BetterBetterTorchLayer(self.nodes_per_graph, self.num_layers, self.input_dim, self.device, self.entanglement_type, self.encoding_type)\n",
    "\n",
    "\n",
    "  def edge_attr_relevant(self, edge_attr, edge_attr_r):\n",
    "    count=0\n",
    "    for n in range(edge_attr.shape[0]):\n",
    "        for e in range(n+1, edge_attr.shape[1]):\n",
    "          edge_attr_r[count] = edge_attr[n, e]\n",
    "          count += 1\n",
    "    return edge_attr_r\n",
    "\n",
    "  def forward(self, x, node_indices, edge_attr=None):\n",
    "    if edge_attr is not None:\n",
    "      edge_attr_r = torch.zeros((edge_attr.shape[0], int(edge_attr.shape[1]*edge_attr.shape[2]/2 + 1)), device=self.device)\n",
    "      edge_attr = torch.vmap(self.edge_attr_relevant)(edge_attr, edge_attr_r)\n",
    "    output = self.quantum_nn(x, node_indices, edge_attr)\n",
    "    output = output[:, [2**i for i in range(self.nodes_per_graph)]]\n",
    "    return torch.vmap(lambda out, ind: out[ind])(output, node_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ce7e3e",
   "metadata": {
    "id": "Lx1VcRhVX9tg",
    "papermill": {
     "duration": 0.026645,
     "end_time": "2024-10-15T09:30:03.399094",
     "exception": false,
     "start_time": "2024-10-15T09:30:03.372449",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Convolutional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "184864aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:30:03.455775Z",
     "iopub.status.busy": "2024-10-15T09:30:03.455367Z",
     "iopub.status.idle": "2024-10-15T09:30:03.508199Z",
     "shell.execute_reply": "2024-10-15T09:30:03.507243Z"
    },
    "id": "apm4c_MrZw0T",
    "papermill": {
     "duration": 0.08369,
     "end_time": "2024-10-15T09:30:03.510309",
     "exception": false,
     "start_time": "2024-10-15T09:30:03.426619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "### Reference - https://github.com/colizz/weaver-benchmark/blob/main/top_tagging/networks/particlenet_pf.py\n",
    "\n",
    "'''Based on https://github.com/WangYueFt/dgcnn/blob/master/pytorch/model.py.'''\n",
    "\n",
    "\n",
    "def knn(x, k):\n",
    "    inner = -2 * torch.matmul(x.transpose(2, 1), x)\n",
    "    xx = torch.sum(x ** 2, dim=1, keepdim=True)\n",
    "    pairwise_distance = -xx - inner - xx.transpose(2, 1)\n",
    "    idx = pairwise_distance.topk(k=k + 1, dim=-1)[1][:, :, 1:]  # (batch_size, num_points, k)\n",
    "    return idx\n",
    "\n",
    "\n",
    "# v1 is faster on GPU\n",
    "def get_graph_feature_v1(x, k, idx):\n",
    "    batch_size, num_dims, num_points = x.size()\n",
    "\n",
    "\n",
    "    idx_base = torch.arange(0, batch_size, device=x.device).view(-1, 1, 1) * num_points\n",
    "    idx = idx + idx_base\n",
    "    idx = idx.view(-1)\n",
    "\n",
    "    fts = x.transpose(2, 1).reshape(-1, num_dims)  # -> (batch_size, num_points, num_dims) -> (batch_size*num_points, num_dims)\n",
    "    fts = fts[idx, :].view(batch_size, num_points, k, num_dims)  # neighbors: -> (batch_size*num_points*k, num_dims) -> ...\n",
    "    fts = fts.permute(0, 3, 1, 2).contiguous()  # (batch_size, num_dims, num_points, k)\n",
    "    x = x.view(batch_size, num_dims, num_points, 1).repeat(1, 1, 1, k)\n",
    "    fts = torch.cat((x, fts - x), dim=1)  # ->(batch_size, 2*num_dims, num_points, k)\n",
    "    return fts\n",
    "\n",
    "\n",
    "# v2 is faster on CPU\n",
    "def get_graph_feature_v2(x, k, idx):\n",
    "    batch_size, num_dims, num_points = x.size()\n",
    "\n",
    "    idx_base = torch.arange(0, batch_size, device=x.device).view(-1, 1, 1) * num_points\n",
    "    idx = idx + idx_base\n",
    "    idx = idx.view(-1)\n",
    "\n",
    "    fts = x.transpose(0, 1).reshape(num_dims, -1)  # -> (num_dims, batch_size, num_points) -> (num_dims, batch_size*num_points)\n",
    "    fts = fts[:, idx].view(num_dims, batch_size, num_points, k)  # neighbors: -> (num_dims, batch_size*num_points*k) -> ...\n",
    "    fts = fts.transpose(1, 0).contiguous()  # (batch_size, num_dims, num_points, k)\n",
    "\n",
    "    x = x.view(batch_size, num_dims, num_points, 1).repeat(1, 1, 1, k)\n",
    "    fts = torch.cat((x, fts - x), dim=1)  # ->(batch_size, 2*num_dims, num_points, k)\n",
    "\n",
    "    return fts\n",
    "\n",
    "\n",
    "class EdgeConvBlock(nn.Module):\n",
    "    r\"\"\"EdgeConv layer.\n",
    "    Introduced in \"`Dynamic Graph CNN for Learning on Point Clouds\n",
    "    <https://arxiv.org/pdf/1801.07829>`__\".  Can be described as follows:\n",
    "    .. math::\n",
    "       x_i^{(l+1)} = \\max_{j \\in \\mathcal{N}(i)} \\mathrm{ReLU}(\n",
    "       \\Theta \\cdot (x_j^{(l)} - x_i^{(l)}) + \\Phi \\cdot x_i^{(l)})\n",
    "    where :math:`\\mathcal{N}(i)` is the neighbor of :math:`i`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_feat : int\n",
    "        Input feature size.\n",
    "    out_feat : int\n",
    "        Output feature size.\n",
    "    batch_norm : bool\n",
    "        Whether to include batch normalization on messages.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k, in_feat, out_feats, batch_norm=True, activation=True, cpu_mode=False):\n",
    "        super(EdgeConvBlock, self).__init__()\n",
    "        self.k = k\n",
    "        self.batch_norm = batch_norm\n",
    "        self.activation = activation\n",
    "        self.num_layers = len(out_feats)\n",
    "        self.get_graph_feature = get_graph_feature_v2 if cpu_mode else get_graph_feature_v1\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        for i in range(self.num_layers):\n",
    "            self.convs.append(nn.Conv2d(2 * in_feat if i == 0 else out_feats[i - 1], out_feats[i], kernel_size=1, bias=False if self.batch_norm else True))\n",
    "\n",
    "        if batch_norm:\n",
    "            self.bns = nn.ModuleList()\n",
    "            for i in range(self.num_layers):\n",
    "                self.bns.append(nn.BatchNorm2d(out_feats[i]))\n",
    "\n",
    "        if activation:\n",
    "            self.acts = nn.ModuleList()\n",
    "            for i in range(self.num_layers):\n",
    "                self.acts.append(nn.ReLU())\n",
    "\n",
    "        if in_feat == out_feats[-1]:\n",
    "            self.sc = None\n",
    "        else:\n",
    "            self.sc = nn.Conv1d(in_feat, out_feats[-1], kernel_size=1, bias=False)\n",
    "            self.sc_bn = nn.BatchNorm1d(out_feats[-1])\n",
    "\n",
    "        if activation:\n",
    "            self.sc_act = nn.ReLU()\n",
    "\n",
    "    def forward(self, points, features):\n",
    "\n",
    "        topk_indices = knn(points, self.k)\n",
    "        x = self.get_graph_feature(features, self.k, topk_indices)\n",
    "\n",
    "        for conv, bn, act in zip(self.convs, self.bns, self.acts):\n",
    "            x = conv(x)  # (N, C', P, K)\n",
    "            if bn:\n",
    "                x = bn(x)\n",
    "            if act:\n",
    "                x = act(x)\n",
    "\n",
    "        fts = x.mean(dim=-1)  # (N, C, P)\n",
    "\n",
    "        # shortcut\n",
    "        if self.sc:\n",
    "            sc = self.sc(features)  # (N, C_out, P)\n",
    "            sc = self.sc_bn(sc)\n",
    "        else:\n",
    "            sc = features\n",
    "\n",
    "        return self.sc_act(sc + fts)  # (N, C_out, P)\n",
    "\n",
    "\n",
    "class ParticleNet(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dims,\n",
    "                 num_classes,\n",
    "                 conv_params=[(7, (32, 32, 32)), (7, (64, 64, 64))],\n",
    "                 fc_params=[(128, 0.1)],\n",
    "                 use_fusion=True,\n",
    "                 use_fts_bn=True,\n",
    "                 use_counts=True,\n",
    "                 for_inference=False,\n",
    "                 for_segmentation=True,\n",
    "                 **kwargs):\n",
    "        super(ParticleNet, self).__init__(**kwargs)\n",
    "\n",
    "        self.use_fts_bn = use_fts_bn\n",
    "        if self.use_fts_bn:\n",
    "            self.bn_fts = nn.BatchNorm1d(input_dims)\n",
    "\n",
    "        self.use_counts = use_counts\n",
    "\n",
    "        self.edge_convs = nn.ModuleList()\n",
    "        for idx, layer_param in enumerate(conv_params):\n",
    "            k, channels = layer_param\n",
    "            in_feat = input_dims if idx == 0 else conv_params[idx - 1][1][-1]\n",
    "            self.edge_convs.append(EdgeConvBlock(k=k, in_feat=in_feat, out_feats=channels, cpu_mode=for_inference))\n",
    "\n",
    "        self.use_fusion = use_fusion\n",
    "        if self.use_fusion:\n",
    "            in_chn = sum(x[-1] for _, x in conv_params)\n",
    "            out_chn = np.clip((in_chn // 128) * 128, 128, 1024)\n",
    "            self.fusion_block = nn.Sequential(nn.Conv1d(in_chn, out_chn, kernel_size=1, bias=False), nn.BatchNorm1d(out_chn), nn.ReLU())\n",
    "\n",
    "        self.for_segmentation = for_segmentation\n",
    "\n",
    "        fcs = []\n",
    "        for idx, layer_param in enumerate(fc_params):\n",
    "            channels, drop_rate = layer_param\n",
    "            if idx == 0:\n",
    "                in_chn = out_chn if self.use_fusion else conv_params[-1][1][-1]\n",
    "            else:\n",
    "                in_chn = fc_params[idx - 1][0]\n",
    "            if self.for_segmentation:\n",
    "                fcs.append(nn.Sequential(nn.Conv1d(in_chn, channels, kernel_size=1, bias=False),\n",
    "                                         nn.BatchNorm1d(channels), nn.ReLU(), nn.Dropout(drop_rate)))\n",
    "            else:\n",
    "                fcs.append(nn.Sequential(nn.Linear(in_chn, channels), nn.ReLU(), nn.Dropout(drop_rate)))\n",
    "        # if self.for_segmentation:\n",
    "        #     fcs.append(nn.Conv1d(fc_params[-1][0], num_classes, kernel_size=1))\n",
    "        # else:\n",
    "        #     fcs.append(nn.Linear(fc_params[-1][0], num_classes))\n",
    "        self.fc = nn.Sequential(*fcs)\n",
    "\n",
    "        self.for_inference = for_inference\n",
    "\n",
    "    def forward(self, points, features, mask=None):\n",
    "#         print('points:\\n', points)\n",
    "#         print('features:\\n', features)\n",
    "        if mask is None:\n",
    "            mask = (features.abs().sum(dim=1, keepdim=True) != 0)  # (N, 1, P)\n",
    "            # print(mask)\n",
    "            # print(mask.shape)\n",
    "        points *= mask\n",
    "        features *= mask\n",
    "        coord_shift = (mask == 0) * 1e9\n",
    "        if self.use_counts:\n",
    "            counts = mask.float().sum(dim=-1)\n",
    "            counts = torch.max(counts, torch.ones_like(counts))  # >=1\n",
    "\n",
    "        if self.use_fts_bn:\n",
    "            fts = self.bn_fts(features) * mask\n",
    "        else:\n",
    "            fts = features\n",
    "        outputs = []\n",
    "        for idx, conv in enumerate(self.edge_convs):\n",
    "            pts = (points if idx == 0 else fts) + coord_shift\n",
    "            fts = conv(pts, fts) * mask\n",
    "            if self.use_fusion:\n",
    "                outputs.append(fts)\n",
    "        if self.use_fusion:\n",
    "            fts = self.fusion_block(torch.cat(outputs, dim=1)) * mask\n",
    "\n",
    "#         assert(((fts.abs().sum(dim=1, keepdim=True) != 0).float() - mask.float()).abs().sum().item() == 0)\n",
    "\n",
    "        if self.for_segmentation:\n",
    "            x = fts\n",
    "        else:\n",
    "            if self.use_counts:\n",
    "                x = fts.sum(dim=-1) / counts  # divide by the real counts\n",
    "            else:\n",
    "                x = fts.mean(dim=-1)\n",
    "\n",
    "        output =  self.fc(x)\n",
    "\n",
    "        if self.for_inference:\n",
    "            output = torch.softmax(output, dim=1)\n",
    "        # print('output:\\n', output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class FeatureConv(nn.Module):\n",
    "\n",
    "    def __init__(self, in_chn, out_chn, **kwargs):\n",
    "        super(FeatureConv, self).__init__(**kwargs)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.BatchNorm1d(in_chn),\n",
    "            nn.Conv1d(in_chn, out_chn, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm1d(out_chn),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class ParticleNetTagger1Path(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 pf_features_dims,\n",
    "                 num_classes,\n",
    "                 conv_params= [(6, (32, 32, 32)), (6, (64, 64, 64)), (6, (128, 128, 128))],   #[(7, (32, 32, 32)), (7, (64, 64, 64))],  #\n",
    "                 fc_params=[(128, 0.1)],\n",
    "                 use_fusion=False,\n",
    "                 use_fts_bn=False,\n",
    "                 use_counts=True,\n",
    "                 pf_input_dropout=None,\n",
    "                 for_inference=False,\n",
    "                 **kwargs):\n",
    "        super(ParticleNetTagger1Path, self).__init__(**kwargs)\n",
    "        self.pf_input_dropout = nn.Dropout(pf_input_dropout) if pf_input_dropout else None\n",
    "        # self.pf_conv = FeatureConv(pf_features_dims, 32)\n",
    "        self.gnn = ParticleNet(input_dims=pf_features_dims,\n",
    "                              num_classes=num_classes,\n",
    "                              conv_params=conv_params,\n",
    "                              fc_params=fc_params,\n",
    "                              use_fusion=use_fusion,\n",
    "                              use_fts_bn=use_fts_bn,\n",
    "                              use_counts=use_counts,\n",
    "                              for_inference=for_inference)\n",
    "\n",
    "    def forward(self, pf_points, pf_features, pf_mask):\n",
    "        if self.pf_input_dropout:\n",
    "            pf_mask = (self.pf_input_dropout(pf_mask) != 0).float()\n",
    "            pf_points *= pf_mask\n",
    "            pf_features *= pf_mask\n",
    "        # mod_feats = self.pf_conv(pf_features)   #* pf_mask , * pf_mask\n",
    "        return self.gnn(pf_points, pf_features, pf_mask)\n",
    "\n",
    "def get_model(data_config, **kwargs):\n",
    "    # conv_params = [\n",
    "    #     (16, (64, 64, 64)),\n",
    "    #     (16, (128, 128, 128)),\n",
    "    #     (16, (256, 256, 256)),\n",
    "    #     ]\n",
    "    ec_k = kwargs.get('ec_k', 16)\n",
    "    ec_c1 = kwargs.get('ec_c1', 64)\n",
    "    ec_c2 = kwargs.get('ec_c2', 128)\n",
    "    ec_c3 = kwargs.get('ec_c3', 256)\n",
    "    fc_c, fc_p = kwargs.get('fc_c', 256), kwargs.get('fc_p', 0.1)\n",
    "    conv_params = [\n",
    "        (ec_k, (ec_c1, ec_c1, ec_c1)),\n",
    "        (ec_k, (ec_c2, ec_c2, ec_c2)),\n",
    "        (ec_k, (ec_c3, ec_c3, ec_c3)),\n",
    "        ]\n",
    "    fc_params = [(fc_c, fc_p)]\n",
    "    use_fusion = True\n",
    "\n",
    "    pf_features_dims = len(data_config.input_dicts['pf_features'])\n",
    "    num_classes = len(data_config.label_value)\n",
    "    model = ParticleNetTagger1Path(pf_features_dims, num_classes,\n",
    "                                   conv_params, fc_params,\n",
    "                                   use_fusion=use_fusion,\n",
    "                                   use_fts_bn=kwargs.get('use_fts_bn', False),\n",
    "                                   use_counts=kwargs.get('use_counts', True),\n",
    "                                   pf_input_dropout=kwargs.get('pf_input_dropout', None),\n",
    "                                   for_inference=kwargs.get('for_inference', False)\n",
    "                                   )\n",
    "    model_info = {\n",
    "        'input_names':list(data_config.input_names),\n",
    "        'input_shapes':{k:((1,) + s[1:]) for k, s in data_config.input_shapes.items()},\n",
    "        'output_names':['softmax'],\n",
    "        'dynamic_axes':{**{k:{0:'N', 2:'n_' + k.split('_')[0]} for k in data_config.input_names}, **{'softmax':{0:'N'}}},\n",
    "        }\n",
    "\n",
    "    return model, model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d6d8bca",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2024-10-15T09:30:03.565313Z",
     "iopub.status.busy": "2024-10-15T09:30:03.564944Z",
     "iopub.status.idle": "2024-10-15T09:30:03.582093Z",
     "shell.execute_reply": "2024-10-15T09:30:03.581169Z"
    },
    "id": "poBXGx9yXlIL",
    "papermill": {
     "duration": 0.047142,
     "end_time": "2024-10-15T09:30:03.584118",
     "exception": false,
     "start_time": "2024-10-15T09:30:03.536976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "def drop_nodes_prob_batch(graph, batch_size):\n",
    "\n",
    "    node_num = graph.num_nodes()\n",
    "    edge_num = graph.num_edges()\n",
    "    node_num_sin = int(graph.num_nodes()/batch_size)\n",
    "    edge_num_sin = int(graph.num_edges()/batch_size)\n",
    "    drop_num_sin = int(node_num_sin * aug_ratio)\n",
    "    drop_num = batch_size*drop_num_sin\n",
    "    node_score = graph.ndata['node_score'].reshape(batch_size, -1)\n",
    "    node_prob = node_score.float()\n",
    "    node_prob += 0.001\n",
    "    node_prob = cp.array(node_prob)\n",
    "    node_prob /= node_prob.sum(axis=1)[:, None]\n",
    "    node_prob = node_prob.get()\n",
    "\n",
    "    idx_nondrop = np.zeros((batch_size, node_num_sin-drop_num_sin), dtype=np.int64)\n",
    "    idx_drop_set = []\n",
    "    idx_nondrop_e = np.zeros((batch_size, node_num_sin-drop_num_sin), dtype=np.int64)\n",
    "    for b in range(batch_size):\n",
    "      idx_nondrop[b] = np.random.choice(node_num_sin, node_num_sin-drop_num_sin, replace=False, p=node_prob[b])\n",
    "      idx_drop_set.append(set(np.setdiff1d(np.arange(node_num_sin), idx_nondrop[b]).tolist()))\n",
    "      idx_nondrop[b].sort()\n",
    "      idx_nondrop_e[b] += idx_nondrop[b] + b*node_num_sin\n",
    "\n",
    "    idx_nondrop_e = idx_nondrop_e.reshape(-1,)\n",
    "\n",
    "    idx_drop_set_e = set(np.setdiff1d(np.arange(node_num), idx_nondrop_e).tolist())\n",
    "\n",
    "    idx_dict = np.zeros((idx_nondrop_e[-1] + 1,), dtype=np.int64)\n",
    "    idx_dict[idx_nondrop_e] = np.arange(len(idx_nondrop_e), dtype=np.int64)\n",
    "\n",
    "    # edge_index = data.edge_index.numpy()\n",
    "    edge_index = np.array([graph.edges()[0].cpu().numpy(), graph.edges()[1].cpu().numpy()])\n",
    "\n",
    "    edge_mask = []\n",
    "    for n in range(edge_num):\n",
    "        if edge_index[0, n] not in idx_drop_set_e and edge_index[1, n] not in idx_drop_set_e:\n",
    "          edge_mask.append(n)\n",
    "    edge_mask = np.asarray(edge_mask, dtype=np.int64)\n",
    "    edge_index = idx_dict[edge_index[:, edge_mask]]\n",
    "\n",
    "    ng = dgl.graph([])\n",
    "    src = graph.edges()[0]\n",
    "    dst = graph.edges()[1]\n",
    "    nsrc = edge_index[0]\n",
    "    ndst = edge_index[1]\n",
    "    ng.add_edges(nsrc, ndst)\n",
    "    ng.to(device)\n",
    "    ng.ndata['node_attr'] = graph.ndata['node_attr'].clone().reshape(batch_size,node_num_sin,-1)[torch.arange(batch_size, device=device).unsqueeze(-1), idx_nondrop].reshape(node_num-drop_num,-1)\n",
    "    ng.ndata['node_attr_irc'] = graph.ndata['node_attr_irc'].clone().reshape(batch_size,node_num_sin,-1)[torch.arange(batch_size, device=device).unsqueeze(-1), idx_nondrop].reshape(node_num-drop_num,-1)\n",
    "    ng.ndata['node_indices'] = torch.Tensor(idx_nondrop, device=device).int().reshape(-1,1)\n",
    "    ng.edata['edge_attr'] = graph.edata['edge_attr'].clone()[edge_mask]\n",
    "    ng.edata['edge_indices'] = torch.Tensor(edge_mask, device=device).int()\n",
    "\n",
    "    return ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6261f4f",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2024-10-15T09:30:03.638267Z",
     "iopub.status.busy": "2024-10-15T09:30:03.637961Z",
     "iopub.status.idle": "2024-10-15T09:30:03.655436Z",
     "shell.execute_reply": "2024-10-15T09:30:03.654449Z"
    },
    "id": "9pqevFSEXptq",
    "papermill": {
     "duration": 0.046685,
     "end_time": "2024-10-15T09:30:03.657340",
     "exception": false,
     "start_time": "2024-10-15T09:30:03.610655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "def drop_nodes_cp_batch(graph, batch_size):\n",
    "\n",
    "    node_num = graph.num_nodes()\n",
    "    edge_num = graph.num_edges()\n",
    "    node_num_sin = int(graph.num_nodes()/batch_size)\n",
    "    edge_num_sin = int(graph.num_edges()/batch_size)\n",
    "    drop_num_sin = int(node_num_sin * aug_ratio)\n",
    "    drop_num = batch_size*drop_num_sin\n",
    "    node_score = graph.ndata['node_score'].reshape(batch_size, -1)\n",
    "    node_prob = torch.sub(torch.max(node_score, dim=1).values.reshape(-1,1), node_score)\n",
    "    node_prob += 0.001\n",
    "    node_prob = cp.array(node_prob)\n",
    "    node_prob /= node_prob.sum(axis=1)[:, None]\n",
    "    node_prob = node_prob.get()\n",
    "\n",
    "    idx_nondrop = np.zeros((batch_size, node_num_sin-drop_num_sin), dtype=np.int64)\n",
    "    idx_drop_set = []\n",
    "    idx_nondrop_e = np.zeros((batch_size, node_num_sin-drop_num_sin), dtype=np.int64)\n",
    "    for b in range(batch_size):\n",
    "      idx_nondrop[b] = np.random.choice(node_num_sin, node_num_sin-drop_num_sin, replace=False, p=node_prob[b])\n",
    "      idx_drop_set.append(set(np.setdiff1d(np.arange(node_num_sin), idx_nondrop[b]).tolist()))\n",
    "      idx_nondrop[b].sort()\n",
    "      idx_nondrop_e[b] += idx_nondrop[b] + b*node_num_sin\n",
    "\n",
    "    idx_nondrop_e = idx_nondrop_e.reshape(-1,)\n",
    "\n",
    "    idx_drop_set_e = set(np.setdiff1d(np.arange(node_num), idx_nondrop_e).tolist())\n",
    "\n",
    "    idx_dict = np.zeros((idx_nondrop_e[-1] + 1,), dtype=np.int64)\n",
    "    idx_dict[idx_nondrop_e] = np.arange(len(idx_nondrop_e), dtype=np.int64)\n",
    "\n",
    "    # edge_index = data.edge_index.numpy()\n",
    "    edge_index = np.array([graph.edges()[0].cpu().numpy(), graph.edges()[1].cpu().numpy()])\n",
    "\n",
    "    edge_mask = []\n",
    "    for n in range(edge_num):\n",
    "        if edge_index[0, n] not in idx_drop_set_e and edge_index[1, n] not in idx_drop_set_e:\n",
    "          edge_mask.append(n)\n",
    "    edge_mask = np.asarray(edge_mask, dtype=np.int64)\n",
    "    edge_index = idx_dict[edge_index[:, edge_mask]]\n",
    "\n",
    "    ng = dgl.graph([])\n",
    "    src = graph.edges()[0]\n",
    "    dst = graph.edges()[1]\n",
    "    nsrc = edge_index[0]\n",
    "    ndst = edge_index[1]\n",
    "    ng.add_edges(nsrc, ndst)\n",
    "    ng.to(device)\n",
    "    ng.ndata['node_attr'] = graph.ndata['node_attr'].clone().reshape(batch_size,node_num_sin,-1)[torch.arange(batch_size,  device=device).unsqueeze(-1), idx_nondrop].reshape(node_num-drop_num,-1)\n",
    "    ng.ndata['node_attr_irc'] = graph.ndata['node_attr_irc'].clone().reshape(batch_size,node_num_sin,-1)[torch.arange(batch_size, device=device).unsqueeze(-1), idx_nondrop].reshape(node_num-drop_num,-1)\n",
    "    ng.ndata['node_indices'] = torch.Tensor(idx_nondrop, device=device).int().reshape(-1,1)\n",
    "    ng.edata['edge_attr'] = graph.edata['edge_attr'].clone()[edge_mask]\n",
    "    ng.edata['edge_indices'] = torch.Tensor(edge_mask, device=device).int()\n",
    "\n",
    "    return ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "668cab64",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2024-10-15T09:30:03.713352Z",
     "iopub.status.busy": "2024-10-15T09:30:03.713029Z",
     "iopub.status.idle": "2024-10-15T09:30:03.760579Z",
     "shell.execute_reply": "2024-10-15T09:30:03.759656Z"
    },
    "id": "pR4PZBx2XsD8",
    "papermill": {
     "duration": 0.077673,
     "end_time": "2024-10-15T09:30:03.762417",
     "exception": false,
     "start_time": "2024-10-15T09:30:03.684744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "class graphcl(nn.Module):\n",
    "    def __init__(self, gnn, node_imp_estimator, emb_dim, out_dim):\n",
    "        super(graphcl, self).__init__()\n",
    "        self.gnn = gnn\n",
    "        self.node_imp_estimator = node_imp_estimator\n",
    "        self.pool = global_mean_pool\n",
    "        self.projection_head = nn.Sequential(nn.Linear(emb_dim, out_dim), nn.ReLU(inplace=True), nn.Linear(out_dim, out_dim))\n",
    "\n",
    "    def prepare_variables_rg(self, gr_n, g_n, n_i):\n",
    "      g_n[n_i] = gr_n\n",
    "      return g_n\n",
    "\n",
    "    def forward_cl(self, x, edge_index, edge_attr, batch, nodes_per_graph, g_batch=None, q_edge_attr=False, device='cpu', node_est='classical'):\n",
    "      if node_est == 'classical':\n",
    "          node_imp = self.node_imp_estimator(x, edge_index, edge_attr, batch)\n",
    "      if node_est == 'quantum':\n",
    "          # ############ Quantum Node Est.\n",
    "\n",
    "          g_n = g_batch.ndata['node_attr'].clone().reshape(3*batch_size, nodes_per_graph, -1)\n",
    "          n_i = g_batch.ndata['node_indices'].clone().reshape(3*batch_size, nodes_per_graph)\n",
    "          g_n_0 = torch.zeros((3*batch_size, nodes_per_graph_original, g_n.shape[2]), device=device)\n",
    "          g_n = torch.vmap(self.prepare_variables_rg)(g_n.float(), g_n_0, n_i.long())\n",
    "\n",
    "          e_n = g_batch.edata['edge_attr'].clone()\n",
    "          e_i = g_batch.edata['edge_indices'].clone()\n",
    "          e_n_0 = torch.zeros((3*batch_size*nodes_per_graph_original*(nodes_per_graph_original-1)), device=device)\n",
    "          e_n_0[e_i.long()]  = e_n\n",
    "          e_n = e_n_0.reshape(3*batch_size, nodes_per_graph_original, -1)\n",
    "\n",
    "          if q_edge_attr:\n",
    "            node_imp = self.node_imp_estimator(g_n, n_i, e_n)\n",
    "          else:\n",
    "            node_imp = self.node_imp_estimator(g_n, n_i)\n",
    "          node_imp = node_imp.reshape(-1,1)\n",
    "          ############\n",
    "\n",
    "      out = torch.max(node_imp.reshape(-1, nodes_per_graph), 1)[0]\n",
    "      out = out.reshape(-1, 1)\n",
    "      out = out[batch]\n",
    "      node_imp /= (out * 10)\n",
    "      node_imp += 0.9\n",
    "\n",
    "      pf_feats = x.reshape(3*batch_size, nodes_per_graph, -1)\n",
    "      points = pf_feats[:,:,1:3]\n",
    "\n",
    "      x = self.gnn(points.reshape(points.shape[0], points.shape[2], points.shape[1])\n",
    "                     , pf_feats.reshape(pf_feats.shape[0], pf_feats.shape[2], pf_feats.shape[1]), None)\n",
    "      x = x.reshape(x.shape[0], x.shape[2], x.shape[1])\n",
    "      x = x.reshape(x.shape[0]*x.shape[1], x.shape[2])\n",
    "\n",
    "      node_imp = node_imp.expand(-1, x.shape[1])\n",
    "      x = torch.mul(x, node_imp)\n",
    "      x = self.pool(x, batch)\n",
    "      x = self.projection_head(x.float())\n",
    "\n",
    "      return x\n",
    "\n",
    "    def loss_cl(self, x1, x2, temp):\n",
    "        T = temp\n",
    "        batch_size, _ = x1.size()\n",
    "        x1_abs = x1.norm(dim=1)\n",
    "        x2_abs = x2.norm(dim=1)\n",
    "\n",
    "        sim_matrix = torch.einsum('ik,jk->ij', x1, x2) / torch.einsum('i,j->ij', x1_abs, x2_abs)\n",
    "        sim_matrix = torch.exp(sim_matrix / T)\n",
    "        pos_sim = sim_matrix[range(batch_size), range(batch_size)]\n",
    "        loss = pos_sim / (sim_matrix.sum(dim=1) - pos_sim)\n",
    "        loss = - torch.log(loss).mean()\n",
    "        return loss\n",
    "\n",
    "    def loss_infonce(self, x1, x2, temp):\n",
    "        T = temp\n",
    "        batch_size, _ = x1.size()\n",
    "        x1_abs = x1.norm(dim=1)\n",
    "        x2_abs = x2.norm(dim=1)\n",
    "\n",
    "        sim_matrix = torch.einsum('ik,jk->ij', x1, x2) / torch.einsum('i,j->ij', x1_abs, x2_abs)\n",
    "        sim_matrix = torch.exp(sim_matrix / T)\n",
    "        pos_sim = sim_matrix[range(batch_size), range(batch_size)]\n",
    "        loss = pos_sim / sim_matrix.sum(dim=1)\n",
    "        loss = - torch.log(loss).mean()\n",
    "        return loss\n",
    "\n",
    "    def loss_ra(self, x1, x2, x3, temp, lamda):\n",
    "        batch_size, _ = x1.size()\n",
    "        x1_abs = x1.norm(dim=1)\n",
    "        x2_abs = x2.norm(dim=1)\n",
    "        x3_abs = x3.norm(dim=1)\n",
    "\n",
    "        cp_sim_matrix = torch.einsum('ik,jk->ij', x1, x3) / torch.einsum('i,j->ij', x1_abs, x3_abs)\n",
    "        cp_sim_matrix = torch.exp(cp_sim_matrix / temp)\n",
    "\n",
    "        sim_matrix = torch.einsum('ik,jk->ij', x1, x2) / torch.einsum('i,j->ij', x1_abs, x2_abs)\n",
    "        sim_matrix = torch.exp(sim_matrix / temp)\n",
    "\n",
    "        pos_sim = sim_matrix[range(batch_size), range(batch_size)]\n",
    "\n",
    "        ra_loss = pos_sim / (sim_matrix.sum(dim=1) - pos_sim)\n",
    "        ra_loss = - torch.log(ra_loss).mean()\n",
    "\n",
    "        cp_loss = pos_sim / (cp_sim_matrix.sum(dim=1) + pos_sim)\n",
    "        cp_loss = - torch.log(cp_loss).mean()\n",
    "\n",
    "        uni_loss_1 = self.lunif(torch.nn.functional.normalize(x1, dim=1))\n",
    "        uni_loss_2 = self.lunif(torch.nn.functional.normalize(x2, dim=1))\n",
    "        uni_loss = (uni_loss_1 + uni_loss_2) / 2\n",
    "        al_loss = self.lalign(torch.nn.functional.normalize(x1, dim=1), torch.nn.functional.normalize(x2, dim=1))\n",
    "\n",
    "        loss = ra_loss + lamda * cp_loss\n",
    "        # loss = 0.5*uni_loss + al_loss + lamda * cp_loss\n",
    "\n",
    "        return ra_loss, cp_loss, loss, uni_loss, al_loss\n",
    "\n",
    "    def lalign(self, x, y, alpha=2):\n",
    "      return (x - y).norm(dim=1).pow(alpha).mean()\n",
    "\n",
    "    def lunif(self, x, t=2):\n",
    "      sq_pdist = torch.pdist(x, p=2).pow(2)\n",
    "      return sq_pdist.mul(-t).exp().mean().log()\n",
    "\n",
    "def train(epoch, model, device, dataset, optimizer, batch_size, nodes_per_graph, aug_ratio, loss_temp, lamda, irc_safety, q_edge_attr=False, loader=None, node_est='classical'):\n",
    "\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    dataset.aug = \"none\"\n",
    "    imp_batch_size = batch_size\n",
    "    loader = GraphDataLoader(dataset, batch_size=imp_batch_size, shuffle=False, drop_last=False)\n",
    "    model.eval()\n",
    "    torch.set_grad_enabled(False)\n",
    "    node_imp_l = []\n",
    "    # loader.set_epoch(epoch)\n",
    "    for step, (g_batch, _) in enumerate(loader):\n",
    "\n",
    "        batch = torch.arange(0, g_batch.batch_size, device=device).reshape(-1,1).expand(g_batch.batch_size, nodes_per_graph).reshape(-1,)\n",
    "        if node_est == 'classical':\n",
    "          node_imp = model.node_imp_estimator(g_batch.ndata['node_attr'], torch.stack(g_batch.edges()), g_batch.edata['edge_attr'], batch).detach()\n",
    "        else:\n",
    "          ############ Quantum Node Est.\n",
    "          g_batch.to(device)\n",
    "          g_n = g_batch.ndata['node_attr'].clone().reshape(batch_size, nodes_per_graph, -1)\n",
    "          e_n = g_batch.edata['edge_attr'].clone().reshape(batch_size, nodes_per_graph, -1)\n",
    "          n_i = g_batch.ndata['node_indices'].clone().reshape(batch_size, nodes_per_graph)\n",
    "\n",
    "          if q_edge_attr:\n",
    "            node_imp = model.node_imp_estimator(g_n, n_i, e_n)\n",
    "          else:\n",
    "            node_imp = model.node_imp_estimator(g_n, n_i)\n",
    "          node_imp = node_imp.reshape(-1,1)\n",
    "\n",
    "          ############\n",
    "\n",
    "        node_imp_l.append(node_imp.squeeze())\n",
    "\n",
    "    for i, b in enumerate(node_imp_l):\n",
    "      n = b.reshape(-1,nodes_per_graph)\n",
    "      for g in range(len(n)):\n",
    "        dataset[i*len(n)+g][0].ndata['node_score'] = torch.Tensor(n[g])\n",
    "\n",
    "    dataset.nodes_per_aug_graph = dataset.nodes_per_graph-int(aug_ratio*dataset.nodes_per_graph)\n",
    "\n",
    "    torch.set_grad_enabled(True)\n",
    "    model.train()\n",
    "\n",
    "    train_loss_accum = 0\n",
    "    ra_loss_accum = 0\n",
    "    cp_loss_accum = 0\n",
    "    uni_loss_accum = 0\n",
    "    alignment_loss_accum = 0\n",
    "\n",
    "    for step, (g_batch, _) in enumerate(loader):\n",
    "        batch1, batch2 = dataset.augment_dataset('rationale', g_batch, batch_size)\n",
    "        batch3 = dataset.augment_dataset('complement', g_batch, batch_size)\n",
    "\n",
    "        batch1 = batch1.to(device)\n",
    "        batch2 = batch2.to(device)\n",
    "        batch3 = batch3.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        batch_1 = torch.arange(0, batch_size, device=device).reshape(-1,1).expand(batch_size, dataset.nodes_per_aug_graph).reshape(-1,)\n",
    "        batch_2 = torch.arange(0, batch_size, device=device).reshape(-1,1).expand(batch_size, dataset.nodes_per_aug_graph).reshape(-1,)\n",
    "        batch_3 = torch.arange(0, batch_size, device=device).reshape(-1,1).expand(batch_size, dataset.nodes_per_aug_graph).reshape(-1,)\n",
    "\n",
    "        node_attr_123 = torch.cat((batch1.ndata['node_attr'].float(), batch2.ndata['node_attr'].float(), batch3.ndata['node_attr'].float()), dim=0)\n",
    "        edges_123 = torch.stack(dgl.batch([batch1, batch2, batch3]).edges())\n",
    "        edge_attr_123 = torch.cat((batch1.edata['edge_attr'], batch2.edata['edge_attr'], batch3.edata['edge_attr']), dim=0)\n",
    "        overall_batch = torch.arange(0, batch_size*3).reshape(-1,1).expand(batch_size*3, dataset.nodes_per_aug_graph).reshape(-1,)\n",
    "        output = model.forward_cl(node_attr_123, edges_123, edge_attr_123, overall_batch, dataset.nodes_per_aug_graph, dgl.batch([batch1, batch2, batch3]), q_edge_attr, device=device, node_est=node_est)\n",
    "        x1, x2, x3 = torch.split(output, [batch_size, batch_size, batch_size], dim=0)\n",
    "\n",
    "        ra_loss, cp_loss, loss, uni_loss, al_loss = model.loss_ra(x1, x2, x3, loss_temp, lamda)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss_accum += float(loss.detach().cpu().item())\n",
    "        ra_loss_accum += float(ra_loss.detach().cpu().item())\n",
    "        cp_loss_accum += float(cp_loss.detach().cpu().item())\n",
    "        uni_loss_accum += float(uni_loss.detach().cpu().item())\n",
    "        alignment_loss_accum += float(al_loss.detach().cpu().item())\n",
    "\n",
    "    gc.collect()\n",
    "    return train_loss_accum/(step+1), ra_loss_accum/(step+1), cp_loss_accum/(step+1), uni_loss_accum/(step+1), alignment_loss_accum/(step+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ace102",
   "metadata": {
    "id": "pGOPXa_D4akV",
    "papermill": {
     "duration": 0.027465,
     "end_time": "2024-10-15T09:30:03.817954",
     "exception": false,
     "start_time": "2024-10-15T09:30:03.790489",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ce2077c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:30:03.877066Z",
     "iopub.status.busy": "2024-10-15T09:30:03.876681Z",
     "iopub.status.idle": "2024-10-15T09:30:37.967968Z",
     "shell.execute_reply": "2024-10-15T09:30:37.966827Z"
    },
    "id": "BeXbU8V9XzWk",
    "outputId": "72c18fbb-f886-4d70-923a-a73b09c1be61",
    "papermill": {
     "duration": 34.123441,
     "end_time": "2024-10-15T09:30:37.970344",
     "exception": false,
     "start_time": "2024-10-15T09:30:03.846903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/__init__.py:690: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Finding All Unique Particles ---\n",
      "\n",
      "--- Inserting Masses ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:00, 342.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calculating Momenta and Energies ---\n",
      "\n",
      "--- Calculating Edge Tensors ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10000/10000 [00:15<00:00, 636.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating graphs ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10000/10000 [00:05<00:00, 1913.66it/s]\n"
     ]
    }
   ],
   "source": [
    "#set up model\n",
    "device = 'cuda'\n",
    "# nodes_per_graph_original = 10\n",
    "num_layer_gnn = 2\n",
    "num_layer_gnn_est = 2\n",
    "qnn_layers = 3\n",
    "emb_dim = 128\n",
    "in_dim = 8\n",
    "inter_dim = 256\n",
    "out_dim = 128\n",
    "JK = 'last' # 'concat', 'last', 'max', 'sum'\n",
    "dropout_ratio = 0.1 \n",
    "gnn_type = 'gat'    # gat, gin, gcn, graphsage\n",
    "lr = 0.001 # 1e-4, 1e-2, 3e-3, 5e-3\n",
    "decay = 0\n",
    "aug_ratio = 0.1\n",
    "batch_size = 2000 # 2000\n",
    "loss_temp = 0.1\n",
    "lamda = 0.1\n",
    "node_est = 'quantum' # 'classical'\n",
    "entanglement_type='CNOTbutterfly' # Can be 'CNOT', 'CZ', 'SWAP', 'CNOTbutterfly', 'CZbutterfly', 'SWAPbutterfly'\n",
    "encoding_type='RY' # Can be 'AmplitudeEncoding', 'IQPEncoding', 'DisplacementEncoding', 'RY', 'RZ', 'RX', 'CRZ'\n",
    "\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "qg_dataset = QuarkGluonGraphDataset(dataset_name='Quark Gluon', raw_dir=main_dir, save_dir='/content',\n",
    "                                    data_folder_name=jet_folder_path, datafile_name=jet_file_path, labelsfile_name=jet_file_path,\n",
    "                                    datatype='particles', dataset_size=10000, nodes_per_graph=nodes_per_graph_original, spectral_augmentation=False, irc_safety_aug=True,\n",
    "                                    device='cuda') # dataset_size=10000\n",
    "\n",
    "# gnn = GNN(num_layer=num_layer_gnn, in_dim=in_dim, emb_dim=emb_dim, inter_dim=inter_dim, JK=JK, drop_ratio=dropout_ratio, gnn_type=gnn_type)\n",
    "gnn = ParticleNetTagger1Path(in_dim, 2)\n",
    "if node_est == 'classical':\n",
    "  node_imp_estimator = GNN_imp_estimator(num_layer=num_layer_gnn_est, emb_dim=emb_dim, in_dim=in_dim, JK=JK, drop_ratio=dropout_ratio)\n",
    "if node_est == 'quantum':\n",
    "  node_imp_estimator = QGNN_node_estimator(nodes_per_graph_original, qnn_layers, in_dim, device=device,\n",
    "                                           entanglement_type=entanglement_type, encoding_type=encoding_type)\n",
    "\n",
    "model = graphcl(gnn, node_imp_estimator, emb_dim, out_dim)\n",
    "model.to(device)\n",
    "\n",
    "import cupy as cp\n",
    "#set up optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00bb1df0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:30:38.060804Z",
     "iopub.status.busy": "2024-10-15T09:30:38.059855Z",
     "iopub.status.idle": "2024-10-15T09:31:06.681281Z",
     "shell.execute_reply": "2024-10-15T09:31:06.680208Z"
    },
    "id": "M_gVJlaDX8RW",
    "outputId": "cf57e5cb-9fd5-4b02-dd46-9718c01592fb",
    "papermill": {
     "duration": 28.668903,
     "end_time": "2024-10-15T09:31:06.683445",
     "exception": false,
     "start_time": "2024-10-15T09:30:38.014542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====epoch 1\n",
      "5.912722873687744\n",
      "5.374323940277099\n",
      "5.383988761901856\n",
      "UNI :  -1.4783016681671142\n",
      "ALIGN :  0.11802187412977219\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "con_loss = []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    print(\"====epoch \" + str(epoch))\n",
    "    qg_dataset.augment = False\n",
    "    train_loss, ra_loss, cp_loss, uni_loss, al_loss = train(epoch, model=model, device=device, dataset=qg_dataset, optimizer=optimizer, batch_size=batch_size,\n",
    "                                      nodes_per_graph=qg_dataset.nodes_per_graph, aug_ratio=aug_ratio, loss_temp=loss_temp, lamda=lamda,\n",
    "                                      irc_safety=True, q_edge_attr=True, node_est=node_est)\n",
    "    con_loss.append(train_loss)\n",
    "    print(train_loss)\n",
    "    print(ra_loss)\n",
    "    print(cp_loss)\n",
    "    print('UNI : ', uni_loss)\n",
    "    print('ALIGN : ', al_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c2eb369",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:31:06.772689Z",
     "iopub.status.busy": "2024-10-15T09:31:06.771949Z",
     "iopub.status.idle": "2024-10-15T09:31:30.235050Z",
     "shell.execute_reply": "2024-10-15T09:31:30.234173Z"
    },
    "id": "geSjHgy0YDwt",
    "papermill": {
     "duration": 23.509765,
     "end_time": "2024-10-15T09:31:30.237547",
     "exception": false,
     "start_time": "2024-10-15T09:31:06.727782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Finding All Unique Particles ---\n",
      "\n",
      "--- Inserting Masses ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:00, 3006.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calculating Momenta and Energies ---\n",
      "\n",
      "--- Calculating Edge Tensors ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7000/7000 [00:11<00:00, 610.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating graphs ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7000/7000 [00:03<00:00, 2003.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# nodes_per_graph_original = 10\n",
    "test_dataset = QuarkGluonGraphDataset(dataset_name='Quark Gluon', raw_dir=main_dir, save_dir='/content',\n",
    "                                    data_folder_name=jet_folder_path, datafile_name=jet_file_path, labelsfile_name=jet_file_path,\n",
    "                                    datatype='particles', dataset_size=7000, nodes_per_graph=nodes_per_graph_original, spectral_augmentation=False, irc_safety_aug=True,\n",
    "                                    device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8cd96a3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:31:30.353924Z",
     "iopub.status.busy": "2024-10-15T09:31:30.353512Z",
     "iopub.status.idle": "2024-10-15T09:31:30.359390Z",
     "shell.execute_reply": "2024-10-15T09:31:30.358500Z"
    },
    "id": "2NHBtA-yYGK5",
    "papermill": {
     "duration": 0.065949,
     "end_time": "2024-10-15T09:31:30.361360",
     "exception": false,
     "start_time": "2024-10-15T09:31:30.295411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_samples = torch.tensor(np.arange(2000,7000).astype('int32'))\n",
    "test_sampler = SubsetRandomSampler(test_samples)\n",
    "\n",
    "test_dataloader = test_dataloader = GraphDataLoader(\n",
    "    test_dataset, sampler=test_sampler, batch_size=500, drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2eadb07d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:31:30.475236Z",
     "iopub.status.busy": "2024-10-15T09:31:30.474567Z",
     "iopub.status.idle": "2024-10-15T09:31:41.788446Z",
     "shell.execute_reply": "2024-10-15T09:31:41.787448Z"
    },
    "id": "zG95SQuHYHB3",
    "papermill": {
     "duration": 11.373176,
     "end_time": "2024-10-15T09:31:41.791059",
     "exception": false,
     "start_time": "2024-10-15T09:31:30.417883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cls_embds = torch.Tensor([])\n",
    "cls_labels = torch.Tensor([])\n",
    "\n",
    "for batched_graph, labels in test_dataloader:\n",
    "  graphs = []\n",
    "  unbatched_graph = dgl.unbatch(batched_graph)\n",
    "  for graph in unbatched_graph:\n",
    "    graphs.append(dgl.add_self_loop(graph))\n",
    "  batched_graph = dgl.batch(graphs)\n",
    "  batch_t = torch.arange(0, batched_graph.batch_size).reshape(-1,1).expand(batched_graph.batch_size, test_dataset.nodes_per_graph).reshape(-1,)\n",
    "\n",
    "  ## For custom GNN\n",
    "  # cls_emb = gnn.forward(batched_graph.ndata[\"node_attr\"].float(), torch.stack(batched_graph.edges()), batched_graph.edata[\"edge_attr\"].float())\n",
    "\n",
    "  ## For ParticleNet\n",
    "  pf_feats = batched_graph.ndata[\"node_attr\"].reshape(len(unbatched_graph), nodes_per_graph_original, -1).float()\n",
    "  points = pf_feats[:,:,1:3]\n",
    "  cls_emb = gnn.forward(points.reshape(points.shape[0], points.shape[2], points.shape[1])\n",
    "                     , pf_feats.reshape(pf_feats.shape[0], pf_feats.shape[2], pf_feats.shape[1]), None)\n",
    "  cls_emb = cls_emb.reshape(cls_emb.shape[0], cls_emb.shape[2], cls_emb.shape[1])\n",
    "  cls_emb = cls_emb.reshape(cls_emb.shape[0]*cls_emb.shape[1], cls_emb.shape[2])\n",
    "\n",
    "  # cls_emb = batched_graph.ndata[\"node_attr\"].float()\n",
    "  cls_emb = global_mean_pool(cls_emb, batch_t)\n",
    "  cls_embds = torch.cat((cls_embds, cls_emb.detach()), 0)     #cls_emb\n",
    "  cls_labels = torch.cat((cls_labels, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0a76aca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:31:41.904832Z",
     "iopub.status.busy": "2024-10-15T09:31:41.904023Z",
     "iopub.status.idle": "2024-10-15T09:31:41.910467Z",
     "shell.execute_reply": "2024-10-15T09:31:41.909632Z"
    },
    "id": "bpwPGFaRYJH-",
    "papermill": {
     "duration": 0.064621,
     "end_time": "2024-10-15T09:31:41.912399",
     "exception": false,
     "start_time": "2024-10-15T09:31:41.847778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cls_epochs = 1000\n",
    "cls_train_data = cls_embds[ : int(0.8*len(cls_embds))]\n",
    "targets = cls_labels[ : int(0.8*len(cls_embds))]\n",
    "cls_test_data = cls_embds[int(0.8*len(cls_embds)) : ]\n",
    "testtargets = cls_labels[int(0.8*len(cls_embds)) : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46a824c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:31:42.029215Z",
     "iopub.status.busy": "2024-10-15T09:31:42.028864Z",
     "iopub.status.idle": "2024-10-15T09:31:42.039126Z",
     "shell.execute_reply": "2024-10-15T09:31:42.038242Z"
    },
    "id": "c9DjNmLGZHe6",
    "papermill": {
     "duration": 0.073151,
     "end_time": "2024-10-15T09:31:42.041062",
     "exception": false,
     "start_time": "2024-10-15T09:31:41.967911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Reference - https://github.com/sdogsq/LorentzNet-release/blob/main/scripts/QGTaggingROC/ROC.py\n",
    "\n",
    "# Function that takes the labels and score of the positive class\n",
    "# (top class) and returns a ROC curve, as well as the signal efficiency\n",
    "# and background rejection at a given targe signal efficiency, defaults\n",
    "# to 0.3\n",
    "\n",
    "def buildROC(labels, score, targetEff=[0.3,0.5]):\n",
    "    if not isinstance(targetEff, list):\n",
    "        targetEff = [targetEff]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(labels, score)\n",
    "    idx = [np.argmin(np.abs(tpr - Eff)) for Eff in targetEff]\n",
    "    eB, eS = fpr[idx], tpr[idx]\n",
    "    return fpr, tpr, threshold, eB, eS\n",
    "\n",
    "### Reference - https://github.com/bmdillon/JetCLR/blob/main/scripts/modules/perf_eval.py\n",
    "\n",
    "def find_nearest( array, value ):\n",
    "    array = np.asarray( array )\n",
    "    idx = ( np.abs( array-value ) ).argmin()\n",
    "    return array[idx]\n",
    "\n",
    "def get_perf_stats( labels, measures ):\n",
    "    measures = np.nan_to_num( measures )\n",
    "    auc = metrics.roc_auc_score( labels, measures )\n",
    "    fpr,tpr,thresholds = metrics.roc_curve( labels, measures )\n",
    "    fpr2 = [ fpr[i] for i in range( len( fpr ) ) if tpr[i]>=0.5]\n",
    "    tpr2 = [ tpr[i] for i in range( len( tpr ) ) if tpr[i]>=0.5]\n",
    "    try:\n",
    "        imtafe = np.nan_to_num( 1 / fpr2[ list( tpr2 ).index( find_nearest( list( tpr2 ), 0.5 ) ) ] )\n",
    "    except:\n",
    "        imtafe = 1\n",
    "    return auc, imtafe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfd72b45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:31:42.156093Z",
     "iopub.status.busy": "2024-10-15T09:31:42.155218Z",
     "iopub.status.idle": "2024-10-15T09:31:48.459471Z",
     "shell.execute_reply": "2024-10-15T09:31:48.458420Z"
    },
    "id": "FtrCG9eSYLSx",
    "papermill": {
     "duration": 6.365217,
     "end_time": "2024-10-15T09:31:48.461830",
     "exception": false,
     "start_time": "2024-10-15T09:31:42.096613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier = torch.nn.Sequential(\n",
    "    torch.nn.Linear(128,1),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "\n",
    "def train_classifier(cls_epochs, classifier, cls_train_data, labels, cls_test_data, testlabels):\n",
    "  optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08)\n",
    "  cls_loss = []\n",
    "  cls_accuracy = []\n",
    "  test_cls_loss = []\n",
    "  test_cls_accuracy = []\n",
    "\n",
    "  for ce in range(cls_epochs):\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    t_correct = 0\n",
    "    t_total = 0\n",
    "    optimizer.zero_grad()\n",
    "    outputs = classifier(cls_train_data)\n",
    "    loss = torch.nn.BCELoss()(outputs,labels.view(-1,1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    predicted = np.round(outputs.cpu().detach().numpy())\n",
    "    total += labels.size(0)\n",
    "    correct += np.sum(torch.eq(torch.Tensor(predicted), labels.view(-1,1)).cpu().detach().numpy())\n",
    "    accuracy = 100 * correct / total\n",
    "    cls_loss.append(loss.cpu().detach().numpy())\n",
    "    cls_accuracy.append(accuracy)\n",
    "    testoutputs = classifier(cls_test_data)\n",
    "    testloss = torch.nn.BCELoss()(testoutputs, testlabels.view(-1,1))\n",
    "    testpredicted = np.round(testoutputs.cpu().detach().numpy())\n",
    "    t_total += testlabels.size(0)\n",
    "    t_correct += np.sum(torch.eq(torch.Tensor(testpredicted), testlabels.view(-1,1)).cpu().detach().numpy())\n",
    "    testaccuracy = 100 * t_correct / t_total\n",
    "    test_cls_loss.append(testloss.cpu().detach().numpy())  #np.mean(e_loss)\n",
    "    test_cls_accuracy.append(testaccuracy)\n",
    "    if epochs % 50 == 0:\n",
    "      print(f'Epochs : {ce} ; Loss : {loss.cpu().detach().numpy()} ; Accuracy : {accuracy} ; Test Loss : {testloss} ; Test accuracy : {testaccuracy}' )   #np.mean(e_loss)\n",
    "\n",
    "  testoutputs = classifier(cls_test_data)\n",
    "  # fpr, tpr, thresholds = metrics.roc_curve(testlabels.cpu(), testoutputs.cpu().detach().numpy())\n",
    "  fpr, tpr, threshold, eB, eS = buildROC(testlabels.cpu(), testoutputs.cpu().detach().numpy())\n",
    "  auc = metrics.auc(fpr, tpr)\n",
    "  f1_score = metrics.f1_score(testlabels.cpu(), np.round(testoutputs.cpu().detach().numpy()), average='macro')\n",
    "  _ , imtafe = get_perf_stats(testlabels.cpu(), testoutputs.cpu().detach().numpy())\n",
    "  return cls_loss, cls_accuracy, test_cls_loss, test_cls_accuracy, fpr, tpr, auc, eB, eS, f1_score, imtafe\n",
    "\n",
    "\n",
    "cls_loss, cls_accuracy, test_cls_loss, test_cls_accuracy, fpr, tpr, auc, eB, eS, f1_score, imtafe = train_classifier(cls_epochs, classifier, cls_train_data, targets, cls_test_data, testtargets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c13cbfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:31:48.577318Z",
     "iopub.status.busy": "2024-10-15T09:31:48.576605Z",
     "iopub.status.idle": "2024-10-15T09:31:49.585727Z",
     "shell.execute_reply": "2024-10-15T09:31:49.584696Z"
    },
    "id": "90PD3BcGZqTE",
    "papermill": {
     "duration": 1.069372,
     "end_time": "2024-10-15T09:31:49.588672",
     "exception": false,
     "start_time": "2024-10-15T09:31:48.519300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.72\n",
      "F1 Score: 0.67\n",
      "Imtafe (other metrics): 5.883720930232559\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "def plot_loss_accuracy(cls_loss, cls_accuracy, test_cls_loss, test_cls_accuracy, epochs):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, epochs + 1), cls_loss, label='Train Loss', color='blue')\n",
    "    plt.plot(range(1, epochs + 1), test_cls_loss, label='Test Loss', color='red')\n",
    "    plt.title('Training and Testing Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, epochs + 1), cls_accuracy, label='Train Accuracy', color='blue')\n",
    "    plt.plot(range(1, epochs + 1), test_cls_accuracy, label='Test Accuracy', color='red')\n",
    "    plt.title('Training and Testing Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, auc):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='red', linestyle='--')  # Diagonal line\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming your classifier training is done and you've collected all metrics\n",
    "epochs = cls_epochs  # Total number of epochs used for training\n",
    "plot_loss_accuracy(cls_loss, cls_accuracy, test_cls_loss, test_cls_accuracy, epochs)\n",
    "plot_roc_curve(fpr, tpr, auc)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(f'AUC: {auc:.2f}')\n",
    "print(f'F1 Score: {f1_score:.2f}')\n",
    "print(f'Imtafe (other metrics): {imtafe}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a64ad81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:31:49.707976Z",
     "iopub.status.busy": "2024-10-15T09:31:49.707550Z",
     "iopub.status.idle": "2024-10-15T09:31:50.004723Z",
     "shell.execute_reply": "2024-10-15T09:31:50.003707Z"
    },
    "id": "RPawpog4YODT",
    "papermill": {
     "duration": 0.359102,
     "end_time": "2024-10-15T09:31:50.006756",
     "exception": false,
     "start_time": "2024-10-15T09:31:49.647654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7b32d2e8e410>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABh7klEQVR4nO3dd1yVdf/H8ddh7yUyRJyJouJCJbVhRWmZ7dLS1HZmptldad7Z1srq5920bA93mpWmFZUrc8+cKAoOcCAgDsY51++PS4+RqIDAOcD7+XicB3Bd3+s6n3Ol8u66vsNiGIaBiIiIiBNzcXQBIiIiIuejwCIiIiJOT4FFREREnJ4Ci4iIiDg9BRYRERFxegosIiIi4vQUWERERMTpKbCIiIiI03NzdAHlxWazsXfvXvz9/bFYLI4uR0RERErAMAyOHDlCnTp1cHE5+32UahNY9u7dS3R0tKPLEBERkTJIS0ujbt26Z91fbQKLv78/YH7ggIAAB1cjIiIiJZGTk0N0dLT99/jZVJvAcuoxUEBAgAKLiIhIFXO+7hzqdCsiIiJOT4FFREREnJ4Ci4iIiDi9atOHRUREqg+r1UpBQYGjy5By4Orqipub2wVPOaLAIiIiTiU3N5fdu3djGIajS5Fy4uPjQ2RkJB4eHmU+hwKLiIg4DavVyu7du/Hx8aF27dqaCLSKMwyD/Px8Dhw4QEpKCk2aNDnn5HDnosAiIiJOo6CgAMMwqF27Nt7e3o4uR8qBt7c37u7u7Nq1i/z8fLy8vMp0HnW6FRERp6M7K9VLWe+qFDlHOdQhIiIiUqEUWERERMTpKbCIiIg4oQYNGjBu3DhHl+E0FFhEREQugMViOefr+eefL9N5ly9fzoMPPnhBtXXt2pWhQ4de0DmchUYJnc/vo+HoQeg6HPzCHF2NiIg4mX379tm/nzJlCqNGjWLLli32bX5+fvbvDcPAarXi5nb+X7+1a9cu30KruDLdYXnvvfdo0KABXl5eJCQksGzZsrO27dq1a7GJs0ePHvY2hmEwatQoIiMj8fb2JjExkW3btpWltPK38nNY8QnkZji6EhGRGscwDI7lFzrkVdKJ6yIiIuyvwMBALBaL/efNmzfj7+/PTz/9RHx8PJ6enixatIjt27dz4403Eh4ejp+fHx06dODXX38tct5/PxKyWCx8/PHH3Hzzzfj4+NCkSRO+//77C7q+3377LS1atMDT05MGDRrw5ptvFtn//vvv06RJE7y8vAgPD+e2226z75s+fTpxcXF4e3tTq1YtEhMTOXr06AXVcy6lvsMyZcoUhg0bxvjx40lISGDcuHF069aNLVu2EBZ25h2IGTNmkJ+fb//50KFDtG7dmttvv92+7fXXX+ftt9/miy++oGHDhjz77LN069aNjRs3lnm8drnx9DfDSt4Rx9YhIlIDHS+w0nzUPIe898YXu+HjUT4PIoYPH84bb7xBo0aNCA4OJi0tjeuuu45XXnkFT09PvvzyS3r27MmWLVuoV6/eWc/zwgsv8PrrrzN27Fjeeecd+vTpw65duwgJCSl1TStXruSOO+7g+eefp1evXvz555888sgj1KpViwEDBrBixQoee+wxvvrqKzp37kxmZiYLFy4EzLtKd955J6+//jo333wzR44cYeHChRU6O3Gp/0u89dZbPPDAA9xzzz0AjB8/ntmzZ/Ppp58yfPjwM9r/+yJOnjwZHx8fe2AxDINx48bx3//+lxtvvBGAL7/8kvDwcL777jt69+5d6g9Vrjz9za8KLCIiUkYvvvgiV199tf3nkJAQWrdubf/5pZdeYubMmXz//fc8+uijZz3PgAEDuPPOOwEYPXo0b7/9NsuWLaN79+6lrumtt97iqquu4tlnnwUgJiaGjRs3MnbsWAYMGEBqaiq+vr5cf/31+Pv7U79+fdq2bQuYgaWwsJBbbrmF+vXrAxAXF1fqGkqjVIElPz+flStXMmLECPs2FxcXEhMTWbJkSYnO8cknn9C7d298fX0BSElJIT09ncTERHubwMBAEhISWLJkiQKLiEgN5u3uysYXuznsvctL+/bti/ycm5vL888/z+zZs+2//I8fP05qauo5z9OqVSv7976+vgQEBLB///4y1bRp0yb7jYJTunTpwrhx47BarVx99dXUr1+fRo0a0b17d7p3725/HNW6dWuuuuoq4uLi6NatG9dccw233XYbwcHBZaqlJErVh+XgwYNYrVbCw8OLbA8PDyc9Pf28xy9btowNGzZw//3327edOq6058zLyyMnJ6fIqyKsyrACcPjwwQo5v4iInJ3FYsHHw80hr/KcbffU/6Sf8p///IeZM2cyevRoFi5cyJo1a4iLiyvShaI47u7uZ1wfm81WbnX+k7+/P6tWrWLSpElERkYyatQoWrduTVZWFq6urvzyyy/89NNPNG/enHfeeYemTZuSkpJSIbVAJQ9r/uSTT4iLi6Njx44XfK4xY8YQGBhof0VHR5dDhWdKP2H+4Tiem10h5xcRkZpn8eLFDBgwgJtvvpm4uDgiIiLYuXNnpdYQGxvL4sWLz6grJiYGV1fz7pKbmxuJiYm8/vrrrFu3jp07d/Lbb78BZljq0qULL7zwAqtXr8bDw4OZM2dWWL2leiQUGhqKq6srGRlFR8xkZGQQERFxzmOPHj3K5MmTefHFF4tsP3VcRkYGkZGRRc7Zpk2bs55vxIgRDBs2zP5zTk5OhYSWQjdfyIfCYxVzB0dERGqeJk2aMGPGDHr27InFYuHZZ5+tsDslBw4cYM2aNUW2RUZG8sQTT9ChQwdeeuklevXqxZIlS3j33Xd5//33Afjxxx/ZsWMHl112GcHBwcyZMwebzUbTpk1ZunQpSUlJXHPNNYSFhbF06VIOHDhAbGxshXwGKOUdFg8PD+Lj40lKSrJvs9lsJCUl0alTp3MeO23aNPLy8ujbt2+R7Q0bNiQiIqLIOXNycli6dOk5z+np6UlAQECRV0Wwupvj5wuP6w6LiIiUj7feeovg4GA6d+5Mz5496datG+3atauQ95o4cSJt27Yt8powYQLt2rVj6tSpTJ48mZYtWzJq1ChefPFFBgwYAEBQUBAzZszgyiuvJDY2lvHjxzNp0iRatGhBQEAACxYs4LrrriMmJob//ve/vPnmm1x77bUV8hkALEYpxyBNmTKF/v378+GHH9KxY0fGjRvH1KlT2bx5M+Hh4fTr14+oqCjGjBlT5LhLL72UqKgoJk+efMY5X3vtNV599dUiw5rXrVtXqmHNOTk5BAYGkp2dXa7h5du3n+DWzI9JjrqJix74otzOKyIiZzpx4gQpKSk0bNjQ8dNaSLk513/Xkv7+LvWw5l69enHgwAFGjRpFeno6bdq0Ye7cufZOs6mpqWcsI71lyxYWLVrEzz//XOw5n3rqKY4ePcqDDz5IVlYWl1xyCXPnznWKP6wWjRISERFxuFLfYXFWFXWH5bsv3uKmlBdICehIw2G/lNt5RUTkTLrDUj2Vxx0WLX54Hm7e5sVzLch1cCUiIiI1lwLLeXj6BgLgVlhx6yOIiIjIuSmwnIdfoDlrn4dVgUVERMRRFFjOIyDQXAvJy3bMwZWIiIjUXAos5xEcXAsAH+M4hs3q4GpERERqJgWW8wgJMQOLi8UgJ1uTx4mIiDiCAst5eHn7kn9yupq9GfscXI2IiFRXXbt2ZejQoY4uw2kpsJyPxcIRlyAAMtL3OLYWERFxOj179qR79+7F7lu4cCEWi4V169Zd8Pt8/vnnBAUFXfB5qioFlhI44WGOFDqUocAiIiJF3Xffffzyyy/s3r37jH2fffYZ7du3p1WrVg6orHpRYCkBF99QAHbs2kVeoTreiojIaddffz21a9fm888/L7I9NzeXadOmcd9993Ho0CHuvPNOoqKi8PHxIS4ujkmTJpVrHampqdx44434+fkREBDAHXfcQUZGhn3/2rVrueKKK/D39ycgIID4+HhWrFgBwK5du+jZsyfBwcH4+vrSokUL5syZU671XahSryVUEwXVrgOHID87g6b/ncsd7evy6i2tcHGxOLo0EZHqzTCgwEHTSrj7gOX8/867ubnRr18/Pv/8c0aOHInl5DHTpk3DarVy5513kpubS3x8PE8//TQBAQHMnj2bu+++m8aNG9OxY8cLLtVms9nDyvz58yksLGTQoEH06tWLP/74A4A+ffrQtm1bPvjgA1xdXVmzZg3u7u4ADBo0iPz8fBYsWICvry8bN27Ez8/vgusqTwosJeAdFAFAuGsOWGHqit20rx/CHR2iHVyZiEg1V3AMRtdxzHs/sxc8fEvU9N5772Xs2LHMnz+frl27AubjoFtvvZXAwEACAwP5z3/+Y28/ePBg5s2bx9SpU8slsCQlJbF+/XpSUlKIjjZ/N3355Ze0aNGC5cuX06FDB1JTU3nyySdp1qwZAE2aNLEfn5qayq233kpcXBwAjRo1uuCaypseCZVEgPmX5b44D564OgaADxdsp5qsGykiIheoWbNmdO7cmU8//RSA5ORkFi5cyH333QeA1WrlpZdeIi4ujpCQEPz8/Jg3bx6pqanl8v6bNm0iOjraHlYAmjdvTlBQEJs2bQJg2LBh3H///SQmJvLqq6+yfft2e9vHHnuMl19+mS5duvDcc8+VSyfh8qY7LCURZP4BsGSnMaBnA97/YzvbDxxl+c7DdGwY4uDiRESqMXcf806Ho967FO677z4GDx7Me++9x2effUbjxo25/PLLARg7diz/+9//GDduHHFxcfj6+jJ06FDy8/MrovJiPf/889x1113Mnj2bn376ieeee47Jkydz8803c//999OtWzdmz57Nzz//zJgxY3jzzTcZPHhwpdV3PrrDUhKBJxNrVhr+Xu7c0Nq84zJ5WfkkYxEROQuLxXws44hXCfqv/NMdd9yBi4sLEydO5Msvv+Tee++192dZvHgxN954I3379qV169Y0atSIrVu3lttlio2NJS0tjbS0NPu2jRs3kpWVRfPmze3bYmJiePzxx/n555+55ZZb+Oyzz+z7oqOjefjhh5kxYwZPPPEEEyZMKLf6yoMCS0kE1Te/5qZDXi69O5oBZvb6fWQfK3BgYSIi4iz8/Pzo1asXI0aMYN++fQwYMMC+r0mTJvzyyy/8+eefbNq0iYceeqjICJ6SslqtrFmzpshr06ZNJCYmEhcXR58+fVi1ahXLli2jX79+XH755bRv357jx4/z6KOP8scff7Br1y4WL17M8uXLiY2NBWDo0KHMmzePlJQUVq1axe+//27f5ywUWErCtxb4hZvfH9hMm+ggmkX4k1doY+bqM8fdi4hIzXTfffdx+PBhunXrRp06pzsL//e//6Vdu3Z069aNrl27EhERwU033VTq8+fm5tK2bdsir549e2KxWJg1axbBwcFcdtllJCYm0qhRI6ZMmQKAq6srhw4dol+/fsTExHDHHXdw7bXX8sILLwBmEBo0aBCxsbF0796dmJgY3n///XK5JuXFYlSTnqM5OTkEBgaSnZ1NQEBA+b/BV7fA9iTo8RZ0uI8v/tzJc9//TUy4H3OHXKYhziIi5eDEiROkpKTQsGFDvLy8HF2OlJNz/Xct6e9v3WEpqeiTw85S5gNwU9so/D3daHvwB3LGdYRvH4C8XAcWKCIiUn0psJTURYnm1+QkyDtCoLc7b7VM4TX3CQTlbIX1U2HOk46tUUREpJpSYCmpqHgIjYH8XFgwFg5uIzH5FQD+sp3smLR2Ihzafo6TiIiISFkosJSUxQKJZuckFr8NH1+FJS+HYxEduNc6kt+trc19q792XI0iIiLVlAJLaTS7Djo+CBhwIhuC6uPTdyLDurdgivUKAKyrvwGbFkgUEREpTwospXXt69BvFtz8ITy8EPzCuLdLQw7XvZLDhh+uRzNg12JHVykiUqVVkwGsclJ5/PdUYCktiwUadYXWvcErEAAXFwtPXBvHPGt7AHJWTnNggSIiVZerqytApU5ZLxXv2DFzxe1Tq0OXhdYSKicdG4Ywv0532P8Hlk3fg/X/wFWXV0SkNNzc3PDx8eHAgQO4u7vj4qL/r67KDMPg2LFj7N+/n6CgIHsgLQv9Ri1H1/a8g0Mfv0ItaxbJy+dy0cXXO7okEZEqxWKxEBkZSUpKCrt27XJ0OVJOgoKCiIiIuKBzKLCUo5bRtfgz5Ao6H/6elPlf0Tihh33hKxERKRkPDw+aNGmix0LVhLu7+wXdWTlFgaWcNbuyH3z7Pe2PLWLO2lR6tKnv6JJERKocFxcXTc0vRejhYDkLaX4FR91DCLbksmD2RI7lFzq6JBERkSpPgaW8ubrh0f5uAG7Om8V7vyc7uCAREZGqT4GlArhf/BA2ixsXu2xizcIf2XFAiyKKiIhcCAWWihAYhSW+PwCjXD7jle9WahIkERGRC6DAUkEsV/4Xq3ctmrrs5q7U5/hljRZFFBERKSsFloriE4Jr728otHhwletqYr+/nrztCx1dlYiISJWkwFKR6nfCevcs9hNCtLEPz6+uh5+Ga3FEERGRUlJgqWCejTqzosdPTCo0V3Nm6Qcw7xnHFiUiIlLFKLBUgmvbN2Vm3ad5LP9Rc8PS8bB1nmOLEhERqUIUWCqBxWJhVM/m/GB05qPCHubGH4dBwQnHFiYiIlJFKLBUkpZRgfTuUI+3Cm/jgCUUcnbDik8cXZaIiEiVoMBSif5zTQweXr68kX+zuWHhm5B3xLFFiYiIVAEKLJWolp8nT1zTlOnWy9hFJBw7BEvec3RZIiIiTk+BpZL1SahHTGQwr+ffbm5Y/DYcyXBsUSIiIk5OgaWSubm68NKNLZhtS2CNrTEUHIU/xji6LBEREaemwOIA7RuEcEu7urxS0AcAY9UXsH+Tg6sSERFxXgosDjLi2lg2e7RkrrUDFsMGPwzRDLgiIiJnocDiILX9PXn86hheKuhLLt6QthQW/Z+jyxIREXFKCiwO1K9TffwjGvFcfn9zw++jIUULJIqIiPybAosDubm68MINLfjWdikzrZeAYYXp90D2HkeXJiIi4lQUWBwsoVEtbmoTxYiC+0hxbQRHD8DUflCY5+jSREREnIYCixN45rpY3Dx96XdsMHnuAbBnBfz0tKPLEhERcRplCizvvfceDRo0wMvLi4SEBJYtW3bO9llZWQwaNIjIyEg8PT2JiYlhzpw59v1Wq5Vnn32Whg0b4u3tTePGjXnppZcwDKMs5VU5YQFeDE1sQpoRzhPWRzGwwMrPYNVXji5NRETEKZQ6sEyZMoVhw4bx3HPPsWrVKlq3bk23bt3Yv39/se3z8/O5+uqr2blzJ9OnT2fLli1MmDCBqKgoe5vXXnuNDz74gHfffZdNmzbx2muv8frrr/POO++U/ZNVMf07N6BJmB8/HmvJb5H3mxtnPwH71jq2MBERESdgMUp5GyMhIYEOHTrw7rvvAmCz2YiOjmbw4MEMHz78jPbjx49n7NixbN68GXd392LPef311xMeHs4nn5xevfjWW2/F29ubr7/+ukR15eTkEBgYSHZ2NgEBAaX5SE7jz+0HuWvCUlwtNlY3+ZyA1F8hrAU8+Ae4eTi6PBERkXJX0t/fpbrDkp+fz8qVK0lMTDx9AhcXEhMTWbJkSbHHfP/993Tq1IlBgwYRHh5Oy5YtGT16NFbr6UnSOnfuTFJSElu3bgVg7dq1LFq0iGuvvfasteTl5ZGTk1PkVdV1bhzK9a0isRouDDl+H4ZPLdj/Nyx8w9GliYiIOFSpAsvBgwexWq2Eh4cX2R4eHk56enqxx+zYsYPp06djtVqZM2cOzz77LG+++SYvv/yyvc3w4cPp3bs3zZo1w93dnbZt2zJ06FD69Olz1lrGjBlDYGCg/RUdHV2aj+K0RvaIxcfDld/TDJbGPmNuXPgm7Fvn2MJEREQcqMJHCdlsNsLCwvjoo4+Ij4+nV69ejBw5kvHjx9vbTJ06lW+++YaJEyeyatUqvvjiC9544w2++OKLs553xIgRZGdn219paWkV/VEqRWSgN49d1QSAR9fUoyCmJ9gKYdYjYC1wcHUiIiKOUarAEhoaiqurKxkZGUW2Z2RkEBERUewxkZGRxMTE4Orqat8WGxtLeno6+fn5ADz55JP2uyxxcXHcfffdPP7444wZc/ZVjD09PQkICCjyqi7u7dKQxrV9OXi0gHGeD4F3CKSv19T9IiJSY5UqsHh4eBAfH09SUpJ9m81mIykpiU6dOhV7TJcuXUhOTsZms9m3bd26lcjISDw8zI6kx44dw8WlaCmurq5FjqlJPNxceOGGlgB8sCKHPZ1fMHfMfx3SNziwMhEREcco9SOhYcOGMWHCBL744gs2bdrEwIEDOXr0KPfccw8A/fr1Y8SIEfb2AwcOJDMzkyFDhrB161Zmz57N6NGjGTRokL1Nz549eeWVV5g9ezY7d+5k5syZvPXWW9x8883l8BGrpkuahHJdXAQ2A4ZuaIzRrAfYCvRoSEREaiS30h7Qq1cvDhw4wKhRo0hPT6dNmzbMnTvX3hE3NTW1yN2S6Oho5s2bx+OPP06rVq2IiopiyJAhPP306Zlc33nnHZ599lkeeeQR9u/fT506dXjooYcYNWpUOXzEquu/PZrz++YDLN+VxU9tnuS6nYvNeVkWj4PLnnR0eSIiIpWm1POwOKvqMA9Lcd77PZmx87ZQ29+TBd0y8P7xEXBxg3vmQnQHR5cnIiJyQSpkHhapfPdf2pCGob4cOJLHG/vaQItbzFFD0++F44cdXZ6IiEilUGBxcp5urjx/QwsAPl+yi20Jr0BwQ8hOhe8HQ/W4QSYiInJOCixVwOUxtenWIhyrzeC/P+3CuO1TcHGHTT/A8o8dXZ6IiEiFU2CpIp69vjle7i4sTcnk+wPhcM1L5o55z2gWXBERqfYUWKqIusE+DOp6EQCj52wit8390PQ6sObD9Hsg/6iDKxQREak4CixVyAOXNaJ+LR8ycvJ4+7dkuPE9CIiCQ8kw98yVskVERKoLBZYqxMvdled7mh1wP12UwrYj7nDzh4AFVn0JG2c5tkAREZEKosBSxVzRLIzE2HAKbQbP//A3RoNL4JKh5s7vH4PsPQ6tT0REpCIosFRBz/VsjqebC4uTDzF7/T7o+gzUaQsnsmDmQ2CzOrpEERGRcqXAUgVFh/gwsGtjAF74YSPZBRa49RNw94WdC+HPtx1coYiISPlSYKmiHr68MY1OzoD7+tzNUKsxXPuaufO3l2H3SscWKCIiUo4UWKooL3dXRt8SB8A3S1NZuSsT2vaF5jeZU/dP6w/HMh1bpIiISDlRYKnCLm5Uizva1wVgxIz15FsNuOFtCGkE2Wkw40Gw2RxcpYiIyIVTYKninrkullq+HmzNyOWjBdvBKxDu+BLcvCD5F1j4hqNLFBERuWAKLFVckI8Hz17fHIC3f0sm5eBRiIiDHm+ZDX4fDdt/c2CFIiIiF06BpRq4sU0dLm0SSn6hjZEz12MYBrTtA+36AQZ8ez9k73Z0mSIiImWmwFINWCwWXr6pJZ5uLvy5/RAzVp2cPO7asRDRCo4dgmkDoDDfoXWKiIiUlQJLNVG/li9DE2MAeHn2RjKP5oO7l9mfxSsQdi+Hn//r4CpFRETKRoGlGrn/0oY0i/Dn8LECXp690dwY0hBu/sj8ftmHsH664woUEREpIwWWasTd1YUxt8RhscCMVXtYnHzQ3NG0O1wyzPz++8fgwBbHFSkiIlIGCizVTNt6wdx9cX3AnJvlWH6hueOKkdDgUig4ClPuhrxcB1YpIiJSOgos1dCT3ZoSGehFauYx3vx5q7nR1Q1u+xT8IuDgFvhhCBiGYwsVEREpIQWWasjfy90+bf+ni1NYlXrY3OEXBrd/DhZX2DAdlk1wXJEiIiKloMBSTV3RNIxb2kVhGPDU9HXkFVrNHfU7wdUvmt/PewbSljuuSBERkRJSYKnGRl3fnFA/T5L35/JOUvLpHZ0GQewNYCsw52c5eshhNYqIiJSEAks1FuTjwcs3tQDgg/nb2bAn29xhscCN70FIY8jZDTPuB5vVgZWKiIicmwJLNde9ZSTXxUVgtRk8NX0dBdaTqzd7BUCvr8DN21xrKOlFxxYqIiJyDgosNcALN7QkyMedjfty+HD+9tM7wlvAje+a3y8ep0nlRETEaSmw1AC1/T15rufJFZ2TktmWceT0zrjboMtQ8/tZg2Dv6sovUERE5DwUWGqIm9pEcWWzMPKtNp6cvg6r7R9zsFw1Ci66GgpPwOQ+kLvfcYWKiIgUQ4GlhrBYLLxyc0v8Pd1Yk5bFp4tSTu90cYVbP4ZaF0HOHpjaTys7i4iIU1FgqUEiA715pkcsAGN/3kLy/n88GvIOgt6TwDMAUpfA3KcdU6SIiEgxFFhqmN4dork8pjb5hTaGTV1L4alRQwC1Y8w7LVhgxaew/BOH1SkiIvJPCiw1jMVi4bVbWxHg5ca63dm8/8f2og1iupl9WgB+egp2Lqr8IkVERP5FgaUGigj04sUbWwLwdtK20xPKnXLJ49DyVrAVwpS+cGh7MWcRERGpPAosNdSNberQvUUEhTaDJ6auPb3WEJyeCTeqPRw/DN/cDscyHVesiIjUeAosNdSpUUO1fD3YknGEcb9uK9rA3RvunASB0ZC5HabcrZFDIiLiMAosNVgtP09G3xIHwIfzt7Ny17/uoviFwV1TwMMfdi2CH4aAYRRzJhERkYqlwFLDdWsRwS1to7AZ8MTUtRzLLyzaILwF3P45WFxg7URY9JZD6hQRkZpNgUV47oYWRAR4sfPQMV6fu+XMBk0S4drXze+TXoS/Z1ZugSIiUuMpsAiB3u68flsrAD7/cyeLth08s1HHByBhoPn9zIdh94pKrFBERGo6BRYB4LKY2vS9uB4AT0xbw+GjxXSw7fYKNOlmrjk0qTcc3lm5RYqISI2lwCJ2I69rTqPavmTk5DF8xjqMf3ewdXGF2z6B8Dg4egC+ugWOHnJMsSIiUqMosIidt4crb/dui7urhXl/ZzB1RdqZjTz9oc+008OdJ94B+Ucrv1gREalRFFikiJZRgTxxTVMAXvhhIykHiwkjAZHQ91vwCoI9K2D6vWAtPLOdiIhIOVFgkTM8eGkjOjWqxbF8K0Mnr6bgnwsknlK7Kdw1Fdy8YOtc+HGo5mgREZEKo8AiZ3BxsfDmHa0J8HJj7e5s/vfvWXBPqZcAt31qztGy+iv4Y0zlFioiIjWGAosUq06QN2NuMYc6v/dHMstSzrKWULMe0ONN8/v5r8GKTyupQhERqUkUWOSserSK5Lb4uhgGPD5lDdnHC4pv2P5euOwp8/vZT8Dm2ZVXpIiI1AgKLHJOz9/QgnohPuzJOs6z3204c6jzKVc8A23vBsNmdsLduahyCxURkWqtTIHlvffeo0GDBnh5eZGQkMCyZcvO2T4rK4tBgwYRGRmJp6cnMTExzJkzp0ibPXv20LdvX2rVqoW3tzdxcXGsWKHZVB3Nz9ON/+vVBlcXC9+v3cv0lbuLb2ixwPXjIOZac2K5ib1hz6pKrVVERKqvUgeWKVOmMGzYMJ577jlWrVpF69at6datG/v37y+2fX5+PldffTU7d+5k+vTpbNmyhQkTJhAVFWVvc/jwYbp06YK7uzs//fQTGzdu5M033yQ4OLjsn0zKTXz9YB5PbALAqFl/k7z/SPENXd3MhRIbXAr5R+DrW2D/psorVEREqi2LcdZ7/MVLSEigQ4cOvPvuuwDYbDaio6MZPHgww4cPP6P9+PHjGTt2LJs3b8bd3b3Ycw4fPpzFixezcOHCMnwEU05ODoGBgWRnZxMQEFDm80jxrDaD/p8uY1HyQZqG+zPr0S54ubsW3zjvCHx5kzlHi18E3DsXQhpWar0iIlI1lPT3d6nusOTn57Ny5UoSExNPn8DFhcTERJYsWVLsMd9//z2dOnVi0KBBhIeH07JlS0aPHo3Vai3Spn379tx+++2EhYXRtm1bJkyYcM5a8vLyyMnJKfKSiuPqYuGtXq0J9fNgS8YRXvxx49kbn5oNN6w55KbDlzdCzt7KK1ZERKqdUgWWgwcPYrVaCQ8PL7I9PDyc9PT0Yo/ZsWMH06dPx2q1MmfOHJ599lnefPNNXn755SJtPvjgA5o0acK8efMYOHAgjz32GF988cVZaxkzZgyBgYH2V3R0dGk+ipRBmL8X43q1xWKBiUtT+XHdOUKITwjcPROCG0LWLvOOi9YdEhGRMqrwUUI2m42wsDA++ugj4uPj6dWrFyNHjmT8+PFF2rRr147Ro0fTtm1bHnzwQR544IEibf5txIgRZGdn219pacWseyPl7pImoTzStTEAI75dT+qhY2dv7B8B/WZBQBQc3GL2aTmhO2EiIlJ6pQosoaGhuLq6kpGRUWR7RkYGERERxR4TGRlJTEwMrq6n+zvExsaSnp5Ofn6+vU3z5s2LHBcbG0tqaupZa/H09CQgIKDISyrH44kxtK8fzJG8Qh6dtIr8wmKm7j8luD7c/R341IJ9a8zFEvNyK6tUERGpJkoVWDw8PIiPjycpKcm+zWazkZSURKdOnYo9pkuXLiQnJ2Oznf6ltnXrViIjI/Hw8LC32bJlS5Hjtm7dSv369UtTnlQSN1cX3r6zLUE+7qzbnc1rczef+4DaMdB3BngGQuoSrfAsIiKlVupHQsOGDWPChAl88cUXbNq0iYEDB3L06FHuueceAPr168eIESPs7QcOHEhmZiZDhgxh69atzJ49m9GjRzNo0CB7m8cff5y//vqL0aNHk5yczMSJE/noo4+KtBHnUifImzduaw3AJ4tS+HVjxnkOaGP2afEMgF2LYWIvyD/H4yQREZF/KHVg6dWrF2+88QajRo2iTZs2rFmzhrlz59o74qamprJv3z57++joaObNm8fy5ctp1aoVjz32GEOGDCkyBLpDhw7MnDmTSZMm0bJlS1566SXGjRtHnz59yuEjSkVJbB7OvV3M4cpPTFtLWuZ5AkjdePNOi4c/7FwIk++EguOVUKmIiFR1pZ6HxVlpHhbHyC+0cfuHS1iblkVcVCDTHu509vlZTkn9C766BQqOQuMrofckcPeqnIJFRMSpVMg8LCL/5uHmwvt92hHs4876Pdm88MM55mc5pd7F0Hc6uPvC9t9gSl8ozKv4YkVEpMpSYJELFhXkzf96m/OzTFqWyrQVJRhiXr8z9JkKbt6Q/AtMuVuhRUREzkqBRcrFZTG1eTwxBoD/freBjXtLMN9Kg0vgring5gXb5sGk3uqIKyIixVJgkXLz6BUX0bVpbfIKbQz8ZiXZxwvOf1Cjy81p/N19zMdDmqdFRESKocAi5cbFxcK4Xm2ICvJm16FjPDF1LTZbCfp0N7zMHPJ8avTQVzfDieyKL1hERKoMBRYpV0E+HozvG4+Hqwu/bsrgwwU7SnZgvYvNafy9AmH3MnPBxGOZFVusiIhUGQosUu7i6gbywo0tABg7bzN/bj9YsgPrxkP/H81p/Peuhi96Qu6BCqxURESqCgUWqRC9O0RzW3xdbAY8OnE1uw+XsDNtZCsYMBv8wiFjA3zeA3L2nf84ERGp1hRYpEJYLBZevqklLaMCyDyaz4NfruR4vrVkB4fFwoA5p1d5/qw7ZKZUbMEiIuLUFFikwni5u/Lh3e2p5evBxn05PPXtOko8sXLoRXDPHAiqD4d3wqfdIH1DhdYrIiLOS4FFKlRUkDcf9I3HzcXCD2v3lrwTLkBwA7jvZwhrAbkZ8Nl1sGtJhdUqIiLOS4FFKlzHhiE8d4PZCfe1uZv5Y8v+kh/sHwH3zIboiyEvG766CbbOq5hCRUTEaSmwSKXom1CP3h2iMQx4bNJqdh48WvKDvYPNeVqadIPCEzDpTlg7ueKKFRERp6PAIpXCYrHwwo0taFcviJwThTzw5Qpy8wpLfgIPH+j9DbTqDYYVZj4ES96vuIJFRMSpKLBIpfF0c2V833jCAzzZtj+XYVPWlGwm3FNc3eGmD+DiR8yf542AX58Hm61C6hUREeehwCKVKizAiw/vbo+Hqws/b8zg/37dWroTuLhAt9Fw5bPmz4v+D2Y+qJWeRUSqOQUWqXRtooMYc0scAO/8lsx3q/eU7gQWC1z2H/Nui4sbrJ8GX90Cxw9XQLUiIuIMFFjEIW6Nr8vAro0BeGr6OlbsLMO6QW3ugj7TzUUTdy2CT7pBVmo5VyoiIs5AgUUc5slrmtKtRTj5VhsPfbWStMwSTt//T42vgHvngn8dc1bcjxPNdYhERKRaUWARh3FxsfB/vdrQMiqAQ0fzuffz5eScKCj9iSJawv2/QnjLkxPM9YCtP5d/wSIi4jAKLOJQPh5ufNyvg33k0OCJqym0lmHUT2AU3PMTNLoCCo7CpN6wbEL5FywiIg6hwCIOFxHoxcf9OuDl7sL8rQd4efamsp3IKwD6TIM2fc25Wub8B34cBtYy3LURERGnosAiTiGubiDjerUB4PM/d/LVkp1lO5GrO9z4LiS+AFhgxSfw9a1wrAydekVExGkosIjT6N4ykqe6NwXg+R828vvmUqw59E8WC1wyFHpPBHdfSJlvdsY9uK38ihURkUqlwCJOZeDljbktvi5Wm8GgiatYvzu77Cdrdp252nNgNGRuh4+vgu2/lV+xIiJSaRRYxKlYLBbG3BLHpU1COZZv5Z7Pl5dtuPMpES3hgd8gOgFOZMPXt8HSj8AoxZIAIiLicAos4nTcXV14v087YiMDOJibR//PlnH4aH7ZT+gXBv1/gNZ3mp1xf3oSZj0KBSfKr2gREalQCizilPy93Pn8ng7UCfRix4GjPPDlCk4UWMt+QjdPcyr/q18Eiwus+Ro+6w5ZaeVXtIiIVBgFFnFa4QFefH5vR/y93Fix6zCPl3Z153+zWKDLEOj7LXgHmzPifnQ5pCwov6JFRKRCKLCIU4sJ9+ejk6s7/7QhvexztPxT4yvhwfkQ0QqOHYIvb4I/31W/FhERJ6bAIk6vU+NajL29FQCfLk7h44U7LvykwfXNEUStepv9Wn4eCd/eD/lHL/zcIiJS7hRYpEq4sU0Uw69tBsDLszfx3eo9F35Sd2+4eTxc+zq4uMGG6fDJNXBo+4WfW0REypUCi1QZD13WiAGdGwDwn2lryz6x3D9ZLJDwkDmKyDcMMjbAh5fD3zMv/NwiIlJuFFikyrBYLIy6vjk3talDoc1g4DcrWbGznKbcr98ZHloA9TpD/hGYNgBm/wcK88rn/CIickEUWKRKcXGxMPb21lzRtDYnCmzc+/lyNqfnlM/JAyLNOy2XDDN/Xj4BPrkaMsuhz4yIiFwQBRapcsyJ5eJpXz+YnBOF9Ptk2YXNhvtPrm6Q+Bz0mQ7eIbBvrfmIaOOs8jm/iIiUiQKLVEneHq580r8DzSL82X8kj76fLOXAkXJ8fNPkanh4EURfDHk5MLUfzHlKj4hERBxEgUWqrEAfd764tyPRId7sOnSM/p8uI+dEQTm+QRQM+NGcbA5g2Yfmqs8Htpbfe4iISIkosEiVFh7gxVf3JhDq58nGfTnc9/lyjuUXlt8buLqb0/nfOcV8RJS+Dj68DFZ8ponmREQqkQKLVHkNQn354t4O+Hu5sXznYR78cuWFrTtUnKbdYeCf0PByKDwOPw6FKX3hWDmNUhIRkXNSYJFqoUWdQL64tyO+Hq4sSj7II9+sIr/QVr5vEhAJd38HV78ELu6w+Uf4oDPsmF++7yMiImdQYJFqo129YD4Z0AFPNxd+27yfoVNWU2gt59Di4gJdHoP7f4VaTeDIPvjyRvhlFBTml+97iYiInQKLVCsXN6rFR/3MxRLnrE/nqenrLmyF57Op0wYemg/xAwADFv8PPr4KMjaW/3uJiIgCi1Q/l8fU5t272uLqYmHG6j2M/G4DRkV0kPXwhZ7/g15fg3ew2SH3o8th0f+BrZz70IiI1HAKLFItXdMignG92uBigUnLUnnxx40VE1oAYnvCI0shpjtY8+HX5+HT7nAwuWLeT0SkBlJgkWqrZ+s6vHZrKwA+W7yTV+durrjQ4h8Od06GG98HzwDYvQzGXwJ/jQdbOfejERGpgRRYpFq7vX00L93UEoAP5+/g1Z8qMLRYLNC2DzyyBBp1NYc/z30avrwBDu+qmPcUEakhFFik2rv74vq8eGMLAD5cUMGhBSCwrjn8uceb4O4DOxeaw5+Xf6y7LSIiZaTAIjVCv04NeOkfoWVMRYcWiwU63A8DF0O9TpCfC7OfgM+v09T+IiJloMAiNcbdnRrYHw99tGAHo+dsqtjQAhDSCAbMhmtfB3dfSF0C47vA/LGat0VEpBTKFFjee+89GjRogJeXFwkJCSxbtuyc7bOyshg0aBCRkZF4enoSExPDnDlzim376quvYrFYGDp0aFlKEzmnuy+uz8snQ8uEhSm8MrsSQouLKyQ8BIOWwkVXmyOJfn8ZPuoKe1ZW7HuLiFQTpQ4sU6ZMYdiwYTz33HOsWrWK1q1b061bN/bv319s+/z8fK6++mp27tzJ9OnT2bJlCxMmTCAqKuqMtsuXL+fDDz+kVatWpf8kIiXU9x+h5eNFlRRaAIKioc80uGWCuZDi/r/N1Z/nPgP5Ryv+/UVEqrBSB5a33nqLBx54gHvuuYfmzZszfvx4fHx8+PTTT4tt/+mnn5KZmcl3331Hly5daNCgAZdffjmtW7cu0i43N5c+ffowYcIEgoODy/ZpREqo78X1eeXm06GlQudp+SeLBVrdAY8uh1a9wLDBX+/B+xfDlrkV//4iIlVUqQJLfn4+K1euJDEx8fQJXFxITExkyZIlxR7z/fff06lTJwYNGkR4eDgtW7Zk9OjRWK1FZwIdNGgQPXr0KHLuc8nLyyMnJ6fIS6Q0+iTUZ/TNcYA5T8uIGeuxVsQ0/sXxDYVbPoI+0yEwGrJSYVIvmHSX+b2IiBRRqsBy8OBBrFYr4eHhRbaHh4eTnp5e7DE7duxg+vTpWK1W5syZw7PPPsubb77Jyy+/bG8zefJkVq1axZgxY0pcy5gxYwgMDLS/oqOjS/NRRAC4K6Eeb9zeGhcLTF6exrCpaygo7wUTz6XJ1fDIX9BlCLi4wZbZ8G5HWPiWOuWKiPxDhY8SstlshIWF8dFHHxEfH0+vXr0YOXIk48ePByAtLY0hQ4bwzTff4OXlVeLzjhgxguzsbPsrLS2toj6CVHO3xdflnTvb4eZiYdaavQz6ZhV5hZW4FpCnH1z9Ijy8COpfYk44l/SCOZooZUHl1SEi4sRKFVhCQ0NxdXUlIyOjyPaMjAwiIiKKPSYyMpKYmBhcXV3t22JjY0lPT7c/Ytq/fz/t2rXDzc0NNzc35s+fz9tvv42bm9sZj45O8fT0JCAgoMhLpKx6tIrkw7vj8XBz4eeNGdz/xQqO51fyAoZhsTDgR7j5I/CtDQe3whc94dsH4EjG+Y8XEanGShVYPDw8iI+PJykpyb7NZrORlJREp06dij2mS5cuJCcnY/vHDJ9bt24lMjISDw8PrrrqKtavX8+aNWvsr/bt29OnTx/WrFlTJOiIVKSrYsP5bEAHfDxcWbjtIP0/XcaREwWVW4TFAq17waMroMMDgAXWT4V34mHROCjMq9x6REScRKkfCQ0bNowJEybwxRdfsGnTJgYOHMjRo0e55557AOjXrx8jRoywtx84cCCZmZkMGTKErVu3Mnv2bEaPHs2gQYMA8Pf3p2XLlkVevr6+1KpVi5YtW5bTxxQpmS4XhfLVfR3x93Rj2c5M+n68lKxjDuhL4h0EPd6AB3+HqHjIPwK/PgfvJcDm2VAZI5pERJxIqQNLr169eOONNxg1ahRt2rRhzZo1zJ07194RNzU1lX379tnbR0dHM2/ePJYvX06rVq147LHHGDJkCMOHDy+/TyFSjuLrhzDpwYsJ9nFn7e5sen34Fxk5JxxTTJ22cN+vcNN48IuAwykw+S748kbI2OiYmkREHMBiVMrkExUvJyeHwMBAsrOz1Z9FysXWjCP0/Xgp+4/kUTfYm6/uS6BhqK/jCsrLhUVvwZ/vgjUPLC7Q/l64YiT4hDiuLhGRC1DS399aS0jkLGLC/fl2YGca1PJh9+Hj3PbBn6zfne24gjz94KpR8OgyiL3BnHRu+cfwdlv46wMNgxaRak2BReQcokN8mD6wMy2jAjh0NJ/eHy3hz+SDji0quAH0+gr6/wjhLeFEFswdDu91gPXTwVaJ88iIiFQSBRaR8wj182TSAxfTqVEtjuZbGfDZcuas33f+Aytaw0vhoQVw/TjwC4fDO+Hb++DjKzV/i4hUOwosIiXg7+XOZ/d04NqWEeRbbQyauIqv/9rl6LLMlaDb3wOPrTb7snj4wd7V5vwtX98GGX87ukIRkXKhwCJSQl7urrx7VzvuSqiHYcB/v9vA/37dVjmLJp6Phy9c/hQ8tgY6PmhO85/8C3zQBWYOhOzdjq5QROSCaJSQSCkZhsH//bqNt5O2AdC7QzQv3dQSd1cnyv+HtkPSi7DxO/NnV09zRNElj4N/+DkPFRGpTCX9/a3AIlJGXy3ZyXPf/43NgMtiavN+n3b4ebo5uqyidq+EX0bBrkXmz27ekPAgdBmqodAi4hQUWEQqwa8bMxg8aTXHC6zERgbw2YAORASWfBHPSmEYsON3+O0V2LPC3ObhDxcPhE6DzFl1RUQcRIFFpJKs253FvZ8v52BuPpGBXnx2TweaRTjhn0HDgK3z4PdXIH2duc0rEDoPhoSHwdPfsfWJSI2kwCJSidIyjzHgs2VsP3AUf083PugbzyVNQh1dVvFsNtj8I/w+Gg5sMrd5h5h3Wzo+YIYYEZFKosAiUsmyjxXwwFcrWJaSiZuLhTG3xHF7+2hHl3V2NitsmAF/jIHM7eY2z0BIeMh8XKQ+LiJSCRRYRBwgr9DKk9PW8f3avQA8dlUThl7VBBcXi4MrOwdrIfw9Axa8AQe3mNs8/MxRRZ0e1agiEalQCiwiDmKzGbzx8xbe/8O8a9EjLpI3bm+Nt4ergys7D5sNNv8AC8ZC+npzm5sXtOsPXYZAYJRj6xORakmBRcTBpi5PY+R36ymwGsRFBTKhX3vnG0FUHMOAbT/D/NdPjypycYfWvc0OurWbOrY+EalWFFhEnMDSHYcY+M0qMo/mE+bvycf929OqbpCjyyoZw4CU+TB/7Ol5XABirjWDS/3OYHHiR10iUiUosIg4ibTMY9z3xXK2ZuTi6ebCG7e3pmfrOo4uq3RS/4LFb8OWOcDJfzKi4qHzYxDb01zTSESkDBRYRJzIkRMFDJm8ht827wdgyFVNGOLsnXGLc3AbLHkX1kwCa565LbihOSS6TR/w8HFsfSJS5SiwiDgZq83g1Z82MWFhClCFOuMWJ3c/LPsIln8Mxw+b27xDIH4AdLgPAus6tDwRqToUWESc1D874zaPDODDu+OJDqmidybyj8Lqb8y7Llm7zG0WV/MxUcLDUO9i9XMRkXNSYBFxYstSMhn49UoOHc0nyMedd+9s57wz45aEtRC2/gRLP4SdC09vj2hlTkTX8jZwrwIjpESk0imwiDi5vVnHGfj1StbuzsbFAsOvbcYDlzbCUtXvSKRvgGUfwrqpUHjC3OZTy3xc1P5ePS4SkSIUWESqgBMFVp79bgPTVu4G4PpWkbx+Wyt8PNwcXFk5OJYJq740+7lkp5nbLC7QpBu0vwcuStToIhFRYBGpKgzD4Oulqbzw/d8U2gyaRfjz0d3tqVerivZr+TdroTkceumHRedzCYw2Z9Ft2xcCIh1Xn4g4lAKLSBWzfGcmA79excHcPAK93Xn7zrZcHlPb0WWVrwNbYeXnsOYbOJFlbrO4QtNrzbsuja4EFxdHVigilUyBRaQKSs8+wcBvVrI6NQuLxZyvZfCVTXCtavO1nE/Bcdg4C1Z8Bml/nd4eVB/a9YPWd2rtIpEaQoFFpIrKK7Tywg8bmbg0FYBLm4Qyrlcbavl5OriyCpKx0bzrsnYy5GWb2ywu0OgKaHMXNLteI4xEqjEFFpEqbubq3TwzYwPHC6xEBHjx7l1tad8gxNFlVZz8Y/D3TPNx0a7Fp7d7BULLW6FNX4hqp3ldRKoZBRaRamBrxhEGfr2S7QeO4upiYXj3Ztx/acOqP/T5fDJ3mNP/r510eoQRQO1m5l2XVr3BP9xx9YlIuVFgEakmjuYV8szM9cxasxeAa5qHM/b21gR6uzu4skpgs8HOBbBmImz8HgqPm9strtCoK8TdDs16gJf+zotUVQosItWIYRh8szSVF3/YSL7VRr0QH97v046WUYGOLq3ynMiGv78zHxmlLT293c0LYrqb4aXJ1eBWTfv6iFRTCiwi1dD63dk8MnElaZnH8XB14ZnrmtG/c4Pq/4jo3w5thw3fmrPpHtp2ertnIDS/wQwvDS7RxHQiVYACi0g1lX2sgP9MX8svGzMASIwN4/XbWhPi6+HgyhzAMCB9HayfBuu/hSN7T+/zi4AWN0OLm6BuR83vIuKkFFhEqjHDMPhyyS5embOJ/EIb4QGe/F+vNnRuXIUXULxQNhuk/mmGl7+/Oz0xHZjhJbYnNL8R6nfWnRcRJ6LAIlIDbNybw+BJq9h+4CgWCwzqehFDEpvg7lrD7yYU5kFykjk53ZY5kJdzep9vbXNul+Y3QoNLwbUarNskUoUpsIjUEMfyC3nxh41MXm4O/21XL4j/9W5LdEg1WYvoQhXmwY75ZnjZ/GPROy/eIdDsOoi9ARpeBu7eDitTpKZSYBGpYX5ct5cRM9Zz5EQh/p5ujL4ljp6t6zi6LOdiLYCUBafDy7FDp/e5+0DjK811jWK6g28NfrwmUokUWERqoLTMYwyZvJpVqVkA3NIuiudvaEGAVw2Ys6W0rIVmn5eNs2DLT5Cz5x87LRCdYIaXptdBaBPNsCtSQRRYRGqoQquN/yVt473fk7EZEBXkzRu3t6ZT41qOLs15nRpttOUns8/LvrVF94c0MoNLTDeIvhjcauCILJEKosAiUsOt3JXJ41PWkpp5DIsF7r+kIU9c0xQvd42QOa/s3bB1rhlgUhaANf/0Pg8/aHg5XHQVXJQIwfUdV6dINaDAIiIczSvk5dkbmbTM7JDbNNyft3q1pkWdGjRD7oXKOwLbfzPDS/KvcPRA0f21mpgz7F50FdTvoo67IqWkwCIidkmbMnj623UczM3H3dXCsKub8uBljXB1Ub+MUrHZzEdHyb+aw6bTloJhPb3fzducYfeiq8y7MGGx6vsich4KLCJSxKHcPEbMWM/PJ2fI7dAgmDdvb0O9Whr+XGYnss0h08m/mAGmSMddzDlfGl5mhpeGl0FIQ8fUKeLEFFhE5AyGYTBt5W5e/GEjuXmF+Hi4MvzaZvRNqI+L7rZcGMOAA5th2y+w4w9IXQIFx4q2Cap3MsB0Nb/6hzugUBHnosAiImeVlnmMJ6atZVlKJgAJDUN4/bZW1K/l6+DKqpHCPNi9wuy0mzIfdi8HW2HRNrWbmbPt1u9svvwjHFOriAMpsIjIOdlsBl/9tYtXf9rM8QIr3u6uPNmtKQM6N9DdloqQl2vedUmZbz5GSl8P/Ouf35BGUK8z1O9kBpjghuoDI9WeAouIlEjqoWM8/e06luwwZ31tXz+Y129rRaPafg6urJo7lmnefdn1pzmBXfoGzggwfhGn777U6wRhzbXqtFQ7CiwiUmI2m8HEZamMmbOJo/lWPN1c+M81Tbn3koYaSVRZjmdB2jIzvOxaAntWgq2gaBvPAIiKh7odTr7ag0+IQ8oVKS8KLCJSarsPH2P4t+tZlHwQgLb1gnj91lY0Cfd3cGU1UMFxM7TsWmKGmLRlkJ97ZrtaF50OL3U7QFgLrUAtVYoCi4iUiWEYTFmexsuzN5GbV4i7q4WBlzfmkSsu0iy5jmQthAObzM67acvNr4e2ndnO3QfqtIO68RDZBuq0UV8YcWoKLCJyQfZmHefZ7zaQtHk/AI1CfXnl5jitSeRMjmXCnlWwe5kZYHavhLzsM9t5BUFkazO8RLaBOm0huIFCjDiFCg0s7733HmPHjiU9PZ3WrVvzzjvv0LFjx7O2z8rKYuTIkcyYMYPMzEzq16/PuHHjuO666wAYM2YMM2bMYPPmzXh7e9O5c2dee+01mjZtWuKaFFhEyp9hGPy0IZ3nv/+b/UfyALijfV2euS6WIB8tAOh0bDbzrkvaMti7CvaugYwNRddCOuWfIaZOW4hoZd6JUadeqWQVFlimTJlCv379GD9+PAkJCYwbN45p06axZcsWwsLCzmifn59Ply5dCAsL45lnniEqKopdu3YRFBRE69atAejevTu9e/emQ4cOFBYW8swzz7BhwwY2btyIr2/J5oVQYBGpODknCnh97ma+/isVgFq+Hozq2ZwbWtfBov9Ld26F+eajpL1rYO9q2LcGMv4uPsS4+0J4cwhvCeEtICLOHJnkpX9TpeJUWGBJSEigQ4cOvPvuuwDYbDaio6MZPHgww4cPP6P9+PHjGTt2LJs3b8bd3b1E73HgwAHCwsKYP38+l112WYmOUWARqXgrd2UyYsZ6tmaYnT8vbRLKKzfFaXr/qqYwH/ZvNMPL3jUnQ8xGsOYV3z6ovhliIk4GmfCWuhsj5aZCAkt+fj4+Pj5Mnz6dm266yb69f//+ZGVlMWvWrDOOue666wgJCcHHx4dZs2ZRu3Zt7rrrLp5++mlcXYvvwJecnEyTJk1Yv349LVu2LLZNXl4eeXmn/3Ll5OQQHR2twCJSwfILbXy0YDtv/5ZMfqENTzcXHr3iIh64rJE65VZl1kLI3G5OaJfx98nXhjPXRzrFzRtqx5iz9dZuevJrMzPcaJSSlEJJA0up/lQdPHgQq9VKeHjR9S/Cw8PZvHlzscfs2LGD3377jT59+jBnzhySk5N55JFHKCgo4Lnnnjujvc1mY+jQoXTp0uWsYQXMfi8vvPBCacoXkXLg4ebCo1c2oUerOoycuZ4/tx/izV+28u2q3Tx/Qwu6Nj3z0bBUAa5uJ4NHU4i77fT2Y5n/CDAnw8z+TVB4HPatNV9FzuNpDrW2h5iTX0MagZv6PUnZleoOy969e4mKiuLPP/+kU6dO9u1PPfUU8+fPZ+nSpWccExMTw4kTJ0hJSbHfUXnrrbcYO3Ys+/btO6P9wIED+emnn1i0aBF169Y9ay26wyLieIZh8MO6fbz840Z7p9xuLcJ59vrm1A3WY6Jqy1oIWbvMxR4PbIYDW05+3WoGmeK4uJkjk0Iam4GmViPza0hjCIjS46UarELusISGhuLq6kpGRkaR7RkZGUREFL9oV2RkJO7u7kUe/8TGxpKenk5+fj4eHqcT96OPPsqPP/7IggULzhlWADw9PfH09CxN+SJSziwWCze0rsMVTWvzdtI2Pl28k3l/ZzB/6wEGX9mE+y9tiKebHhNVO65uUKux+WrW4/R2mw2yU4sGmFOBJv8IHEo2X9vmFT2fm5d5B6ZW45OBpvHpMOMXpuHXApQysHh4eBAfH09SUpK9D4vNZiMpKYlHH3202GO6dOnCxIkTsdlsuJxM0Fu3biUyMtIeVgzDYPDgwcycOZM//viDhg0bXsBHEpHK5u/lzsgezbktPppRszawNCWTsfO2MH2l+Zjo8pjaji5RKoOLi3kXJbgBxHQ7vd0wIGfv6cCSuePk99vhcAoUnjA7Ae/feOY53X0huL7ZNya4vnnuU98H1QdPrXlVU5RpWHP//v358MMP6dixI+PGjWPq1Kls3ryZ8PBw+vXrR1RUFGPGjAEgLS2NFi1a0L9/fwYPHsy2bdu49957eeyxxxg5ciQAjzzyCBMnTmTWrFlF5l4JDAzE29u7RHVplJCIczAMg+/X7uXl2Zs4cPIxUfcWEYzsEUt0iB4Tyb+cerz0zxBzKNnsAJyVxhkLQv6bT+iZQSa4AQRGm4+a3L0q4UPIhajQiePeffdd+8Rxbdq04e233yYhIQGArl270qBBAz7//HN7+yVLlvD444+zZs0aoqKiuO+++4qMEjrbPA6fffYZAwYMKFFNCiwizuXIiQLG/bqNz//cidVm4OHmwv2XNOSRKy7Cz1OjSKQECk5Adhoc3gVZO82vh3eaAefwLjiRdf5z+IRCYBQE1DW/BtY1g8ypr/6RGtXkYJqaX0Scwub0HF76cSOLkw8BUNvfk6e6NeXWdnVx0UrQciGOZ50OL6e+ngo02buh4Nj5z2FxAb8IM8AERp0MMRHmNv+TL79w8PRXX5oKosAiIk7DMAx+2ZjBK3M2seuQ+UskLiqQUT2b06FBiIOrk2rJMOD4YXMemew9kLPbDDHZe05u2232q7EVlOx87r7gH27ekfEL/0eY+WewCTOXPFCwKRUFFhFxOnmFVr74cyfvJCVzJK8QgB6tIhlxbTMNg5bKZ7PB0f3/CDQnw0xuBhxJN1+5GZCXU/JzuriDb6j5KMo3FHxrn/x68nuff23z8KvxAUeBRUSc1sHcPN78eSuTl6diGODp5sIDlzbi4a6N1b9FnE/+0dPh5cg+OHLya5Gf04tfKft83LxOBxifUPAONl8+Iae/9w4G7xDwDjK/9woEl+ozXYACi4g4vY17c3jxx7/5a0cmYC6qOCSxCXd2rIe7qyYSkyqm4AQcOwRHD8DRg+bXYwf/8fPBovvONsneeVnM0HJGqAk2H0l5BYBnwD++Bpp9cE5tc/dxqrs6CiwiUiUYhsG8vzN4be5mUg4eBaBhqC9PdmvKtS0jtBq0VF/5R88MMyeyzOUQjh/+1ysLjmdCfu6Fv6+LW9EA4xl48us/tnn4mT97+Jlz3Zz6OSIO3Mp30lYFFhGpUgqsNiYvS+V/Sds4mJsPQNt6QYy4NpaODdUxVwQwV9o+kXU6yBQJN5lwIhtO5Jj9bop8zYa8I2DYLuz9H99ojqYqRwosIlIl5eYV8tGCHUxYsIPjBVYAEmPDGX5tUy4K83dwdSJVmGGYd3WKCzP/Djl5ueZyCvlHT36fa34duNi8A1OOFFhEpErbn3OCcUnbmLI8DavNwMUCvTpEMzQxhvAAzV4qUl0osIhItZC8P5fX527m543moquebi7061SfgV0vIsTX4zxHi4izU2ARkWplxc5MXv1pMyt2HQbA18OV+y5pyP2XNSLAy93B1YlIWSmwiEi1YxgGf2w9wJs/b2HDHnMyr0Bvdx66vBEDOjfAx0NzuIhUNQosIlJtGYbB3A3pvPXLVrbtN4d5hvp58EjXi7groR5e7tVnUi2R6k6BRUSqPavN4Pu1e/i/X7aRmmmuURQZ6MXgK5twW3xdPNw0+ZyIs1NgEZEao8BqY9qK3bydtI30nBMARAV5M7BrY25vXxdPN91xEXFWCiwiUuOcKLDyzdJUxs/fzoEjeYB5x2Vg18bc0T5aj4pEnJACi4jUWCcKrExelsoH87eTkWMGlzB/Tx6+vLH6uIg4GQUWEanxThRYmbYijff/2M6+bPNRUaifJw9d1og+F9fTqCIRJ6DAIiJyUl6hlW9X7uG935PZk2WukFvL14P7L21E34vr4a95XEQcRoFFRORfCqw2Zq7aw7u/J9tHFfl7uXH3xfW5p0tDavuX7yq0InJ+CiwiImdRYLUxa81exs/fTvLJeVw83Fy4o31dHry0MfVq+Ti4QpGaQ4FFROQ8bDaDXzdl8P4f21mTlgWAiwWub1WHhy9vTPM6+rdEpKIpsIiIlJBhGCxNyeSDP7Yzf+sB+/auTWsz8PLGdGwYgsVicWCFItWXAouISBn8vTeb8fN3MHvdXmwn/3VsWy+I+y9pRLcW4bi5avZckfKkwCIicgF2HTrKRwt2MG3lbvILbYA5e+49XRrQq0O0RhaJlBMFFhGRcnDgSB5f/bWLr//aRebRfAD8PN3o3SGa/p0bEB2iDroiF0KBRUSkHJ0osDJz9R4+WZRiH1nkYoFrW0Zy36UNaVcv2MEVilRNCiwiIhXAZjOYv+0AnyxMYVHyQfv2dvWCuE/9XERKTYFFRKSCbdqXw6eLUpi1Zi/5VrOfS2SgF30vrk+vDtGE+mkiOpHzUWAREakk+4+c4Kslu/hmaaq9n4uHqwvXt4qkX+cGtIkOcmyBIk5MgUVEpJKdKLAyZ/0+vliyi7UnJ6IDaF03kH6dGtCjVaRWihb5FwUWEREHWpOWxZdLdvLj2n32x0Uhvh707hBNn4vrExXk7eAKRZyDAouIiBM4lJvH5OVpfPPXLvZmnwDM0UVXxYZzV8d6XBZTG1cXzaIrNZcCi4iIEym02vh1036+XLKTP7cfsm+PCvKmV4do7mgfTUSglwMrFHEMBRYRESeVvP8Ik5al8e2q3WQdKwDA1cXClc3CdNdFahwFFhERJ3eiwMrcDelMXJrKsp2Z9u266yI1iQKLiEgVkrz/CBOXmnddso+bd11cLHBls3B6dYima9PauGtCOqmGFFhERKqgs911CfXz5Oa2dbi9fTQx4f4OrFCkfCmwiIhUccn7jzB5WRrfrdnDwdx8+/bWdQO5rX00N7SqQ6CPVo2Wqk2BRUSkmiiw2vh9836mrdzN75v3U2gz/9n2cHOhW4sIbo+vS5eLQtVRV6okBRYRkWroYG4e363ew7QVu9mSccS+PTLQi1vb1eXW+Lo0DPV1YIUipaPAIiJSjRmGwfo92UxbsZtZa/aQc6LQvq91dBA3talDz9Z1tACjOD0FFhGRGuJEgZVfNmYwfeVuFm47wMknRri6WLi0SSg3tYnimhbh+Hi4ObZQkWIosIiI1ED7j5zgx7X7mLVmD2t3Z9u3+3i4ck3zcG5qG8UlF4XipiHS4iQUWEREargdB3L5bs1evlu9h9TMY/btoX4eXN+qDje3jaJV3UAsFnXWFcdRYBEREcDs77I6LYvvVu/hx3X7yDx6eoh0/Vo+9IiLpEerSJpHBii8SKVTYBERkTMUWG0s3HaA71bv5eeN6ZwosNn3NQr1pUerSK5vVYeYcD+FF6kUCiwiInJOx/ILSdq0n9nr9vH7lv3kFZ4OLxeF+XF9q0iubxXJRWGaWVcqjgKLiIiUWG5eIUmbMvhh7T4WbD1AvvV0eGkW4W9/bNSotp8Dq5TqSIFFRETKJOdEAb/8ncHs9ftYuO0ABdbTvyaahvvTrUU43VpGqM+LlAsFFhERuWDZxwqYtzGdH9ft48/kg/ZlAQDqBnvTvUUE3VpG0K5esJYGkDIp6e/vMg3Ef++992jQoAFeXl4kJCSwbNmyc7bPyspi0KBBREZG4unpSUxMDHPmzLmgc4qISMUL9HHnjvbRfHlvR1b+92reuqM13VqE4+Xuwu7Dx/l4UQq3j19Cwugknpm5nvlbD5D/j74wIuWl1HdYpkyZQr9+/Rg/fjwJCQmMGzeOadOmsWXLFsLCws5on5+fT5cuXQgLC+OZZ54hKiqKXbt2ERQUROvWrct0zuLoDouISOU5ll/Igq0HmPd3Br9uyuDIP5YG8Pdy46pmYXRvGcGlTWrj66kZduXsKuyRUEJCAh06dODdd98FwGazER0dzeDBgxk+fPgZ7cePH8/YsWPZvHkz7u7FL4Ne2nMWR4FFRMQx8gttLNlxiHl/p/Pz3xkczM2z7/Nwc6FTo1okxoZxZWw4UUHeDqxUnFGFBJb8/Hx8fHyYPn06N910k317//79ycrKYtasWWccc9111xESEoKPjw+zZs2idu3a3HXXXTz99NO4urqW6ZwAeXl55OWd/kuRk5NDdHS0AouIiANZbQarUg8zb0M68zamk5Z5vMj+2MgAEmPDuCo2nFZRgbio30uNV9LAUqr7dAcPHsRqtRIeHl5ke3h4OJs3by72mB07dvDbb7/Rp08f5syZQ3JyMo888ggFBQU899xzZTonwJgxY3jhhRdKU76IiFQwVxcLHRqE0KFBCCN7xJK8P5dfN+0naVMGq1IPs2lfDpv25fDOb8mE+nlyZbPaXBUbzqVNQrU4o5xThf/psNlshIWF8dFHH+Hq6kp8fDx79uxh7NixPPfcc2U+74gRIxg2bJj951N3WERExDlYLBaahPvTJNyfgV0bk3k0n9837ydpcwYLth7kYG4eU1fsZuqK3Xi4udC5cS2uig2na0xtokN8HF2+OJlSBZbQ0FBcXV3JyMgosj0jI4OIiIhij4mMjMTd3R1XV1f7ttjYWNLT08nPzy/TOQE8PT3x9PQsTfkiIuJAIb4e3Bpfl1vj65JfaGNZSia/bsogaXMGaZnH+WPLAf7YcgCARrV9uTymNl2bhpHQMAQvd9fznF2qu1INa/bw8CA+Pp6kpCT7NpvNRlJSEp06dSr2mC5dupCcnIzNdnqY29atW4mMjMTDw6NM5xQRkarNw82FS5qE8vwNLVjw5BX8/PhlPNW9KR0bhODqYmHHgaN8tngn/T9dRusXfqb/p8v4bHEKOw7kUk2mD5NSKtOw5v79+/Phhx/SsWNHxo0bx9SpU9m8eTPh4eH069ePqKgoxowZA0BaWhotWrSgf//+DB48mG3btnHvvffy2GOPMXLkyBKdsyQ0SkhEpHrIOVHAn8kH+WPLAeZvPcC+7BNF9keHeNM1JozLY2rTqXEtDZuu4iqk0y1Ar169OHDgAKNGjSI9PZ02bdowd+5ce7BITU3FxeX0jZvo6GjmzZvH448/TqtWrYiKimLIkCE8/fTTJT6niIjUHAFe7nRvGUn3lpEYhsG2/bn8sWU/87ceYFlKJmmZx/nqr1189dcuPFxdaN8gmEuahHLJRaG0qBOoGXerKU3NLyIiVcbRvEKWbD/E/K0H+GPr/jOGTQd6u9O5cS26XGQGmPq1fLTekZPTWkIiIlKtGYZBysGjLEo+yMJtB/lr+yGO5BUWaRMV5M0lF4XSpUkonRvXItRPgzWcjQKLiIjUKIVWG+v2ZLN420EWJR9kVerhIitNgzlxXZfGtejSJJSODULU/8UJKLCIiEiNdiy/kGUpmSxOPsii5ENs2pdTZL+bi4W4uoFc3KgWFzeqRfv6wQowDqDAIiIi8g8Hc/P4c/sh+x2YPVlF+7+4uliIizoVYEJo3yAEPwWYCqfAIiIicg5pmcdYmpLJXzsO8deOQ+w+fGaAaRkVyMWNQux3YPy9il/EV8pOgUVERKQUdh8+xtIdJwNMyqEzRiC5WCAuKpCEk+GlfYMQQnw9HFRt9aHAIiIicgH2ZB1n6cm7L0tTMtl16NgZbRrX9qVDgxDi6wfToUGIhlGXgQKLiIhIOdqbdZylKYdYlnKYFTsz2bY/94w2oX6eJ+++mAGmeZ0A3F1LtQpOjaPAIiIiUoEOH81nVephlu80A8y63dnkW21F2ni7u9ImOogODYKJbxBC23pBBKgfTBEKLCIiIpXoRIGVDXuyWb7zMCt3ZbJi12GyjhUUaWOxwEW1/WgTHUTbesG0rRdETLh/jV5OQIFFRETEgWw2g+0Hcs07MLsyWbHzMKmZZ/aD8fVwpVXdINrWC7IHmdr+NWdGXgUWERERJ3MoN481aVmsTs1iddph1qZlk/uv5QQA6gZ7m3dgooNoUy+IFnUC8HRzdUDFFU+BRURExMlZT96FWZ162AwxqVls3X+Ef/9m9nB1IbZOAK2iAomrG0iruoFcVNsPt2rQoVeBRUREpAo6cqKA9buzWZ2WZQ8yh47mn9HOy92FFnXM8NKqbiBxUUE0CvXFpYr1h1FgERERqQYMwyAt8zhrd2exfk8263ZnsWFPTrGPknw9XGkZdTLA1A2iVVSg088No8AiIiJSTdlsBimHjrJ+dzbrdmezfo8ZYo4XWM9oG+DlRlzdQFpGBdKiTiAt6gTQoJav04xMUmARERGpQU71h1m3O5v1u7NYuzubjftyyC+0ndHW292V2Eh/mtcJoEWdQJpHBtA0wh8v98rv2KvAIiIiUsMVWG1szTjC+t3ZrN9jBpjN+44UeyfG1cVC49q+9gDTok4AzesEEORTseslKbCIiIjIGaw2g5SDR/l7rxlgNu7N4e+9OWQW07EXICrIm9iTAabvxfXLfY4YBRYREREpEcMwyMjJY+O+bP7eYwaYjftyzpjo7q8RVxER6FWu713S399u5fquIiIiUuVYLBYiAr2ICPTiymbh9u05JwrYdPIOzI6DuYQHOG4GXgUWERERKVaAlzsJjWqR0KiWo0uh6k+RJyIiItWeAouIiIg4PQUWERERcXoKLCIiIuL0FFhERETE6SmwiIiIiNNTYBERERGnp8AiIiIiTk+BRURERJyeAouIiIg4PQUWERERcXoKLCIiIuL0FFhERETE6VWb1ZoNwwAgJyfHwZWIiIhISZ36vX3q9/jZVJvAcuTIEQCio6MdXImIiIiU1pEjRwgMDDzrfotxvkhTRdhsNvbu3Yu/vz8Wi6XczpuTk0N0dDRpaWkEBASU23mlKF3nyqNrXTl0nSuHrnPlqahrbRgGR44coU6dOri4nL2nSrW5w+Li4kLdunUr7PwBAQH6y1AJdJ0rj6515dB1rhy6zpWnIq71ue6snKJOtyIiIuL0FFhERETE6SmwnIenpyfPPfccnp6eji6lWtN1rjy61pVD17ly6DpXHkdf62rT6VZERESqL91hEREREaenwCIiIiJOT4FFREREnJ4Ci4iIiDg9BZbzeO+992jQoAFeXl4kJCSwbNkyR5dUZYwZM4YOHTrg7+9PWFgYN910E1u2bCnS5sSJEwwaNIhatWrh5+fHrbfeSkZGRpE2qamp9OjRAx8fH8LCwnjyyScpLCyszI9Spbz66qtYLBaGDh1q36brXH727NlD3759qVWrFt7e3sTFxbFixQr7fsMwGDVqFJGRkXh7e5OYmMi2bduKnCMzM5M+ffoQEBBAUFAQ9913H7m5uZX9UZyW1Wrl2WefpWHDhnh7e9O4cWNeeumlImvN6DqXzYIFC+jZsyd16tTBYrHw3XffFdlfXtd13bp1XHrppXh5eREdHc3rr79+4cUbclaTJ082PDw8jE8//dT4+++/jQceeMAICgoyMjIyHF1aldCtWzfjs88+MzZs2GCsWbPGuO6664x69eoZubm59jYPP/ywER0dbSQlJRkrVqwwLr74YqNz5872/YWFhUbLli2NxMREY/Xq1cacOXOM0NBQY8SIEY74SE5v2bJlRoMGDYxWrVoZQ4YMsW/XdS4fmZmZRv369Y0BAwYYS5cuNXbs2GHMmzfPSE5Otrd59dVXjcDAQOO7774z1q5da9xwww1Gw4YNjePHj9vbdO/e3WjdurXx119/GQsXLjQuuugi484773TER3JKr7zyilGrVi3jxx9/NFJSUoxp06YZfn5+xv/+9z97G13nspkzZ44xcuRIY8aMGQZgzJw5s8j+8riu2dnZRnh4uNGnTx9jw4YNxqRJkwxvb2/jww8/vKDaFVjOoWPHjsagQYPsP1utVqNOnTrGmDFjHFhV1bV//34DMObPn28YhmFkZWUZ7u7uxrRp0+xtNm3aZADGkiVLDMMw/3K5uLgY6enp9jYffPCBERAQYOTl5VXuB3ByR44cMZo0aWL88ssvxuWXX24PLLrO5efpp582LrnkkrPut9lsRkREhDF27Fj7tqysLMPT09OYNGmSYRiGsXHjRgMwli9fbm/z008/GRaLxdizZ0/FFV+F9OjRw7j33nuLbLvllluMPn36GIah61xe/h1Yyuu6vv/++0ZwcHCRfzuefvppo2nTphdUrx4JnUV+fj4rV64kMTHRvs3FxYXExESWLFniwMqqruzsbABCQkIAWLlyJQUFBUWucbNmzahXr579Gi9ZsoS4uDjCw8Ptbbp160ZOTg5///13JVbv/AYNGkSPHj2KXE/QdS5P33//Pe3bt+f2228nLCyMtm3bMmHCBPv+lJQU0tPTi1zrwMBAEhISilzroKAg2rdvb2+TmJiIi4sLS5curbwP48Q6d+5MUlISW7duBWDt2rUsWrSIa6+9FtB1rijldV2XLFnCZZddhoeHh71Nt27d2LJlC4cPHy5zfdVm8cPydvDgQaxWa5F/wAHCw8PZvHmzg6qqumw2G0OHDqVLly60bNkSgPT0dDw8PAgKCirSNjw8nPT0dHub4v4bnNonpsmTJ7Nq1SqWL19+xj5d5/KzY8cOPvjgA4YNG8YzzzzD8uXLeeyxx/Dw8KB///72a1XctfzntQ4LCyuy383NjZCQEF3rk4YPH05OTg7NmjXD1dUVq9XKK6+8Qp8+fQB0nStIeV3X9PR0GjZseMY5Tu0LDg4uU30KLFIpBg0axIYNG1i0aJGjS6l20tLSGDJkCL/88gteXl6OLqdas9lstG/fntGjRwPQtm1bNmzYwPjx4+nfv7+Dq6s+pk6dyjfffMPEiRNp0aIFa9asYejQodSpU0fXuQbTI6GzCA0NxdXV9YyRFBkZGURERDioqqrp0Ucf5ccff+T333+nbt269u0RERHk5+eTlZVVpP0/r3FERESx/w1O7RPzkc/+/ftp164dbm5uuLm5MX/+fN5++23c3NwIDw/XdS4nkZGRNG/evMi22NhYUlNTgdPX6lz/bkRERLB///4i+wsLC8nMzNS1PunJJ59k+PDh9O7dm7i4OO6++24ef/xxxowZA+g6V5Tyuq4V9e+JAstZeHh4EB8fT1JSkn2bzWYjKSmJTp06ObCyqsMwDB599FFmzpzJb7/9dsYtwvj4eNzd3Ytc4y1btpCammq/xp06dWL9+vVF/oL88ssvBAQEnPGLo6a66qqrWL9+PWvWrLG/2rdvT58+fezf6zqXjy5dupwxNH/r1q3Ur18fgIYNGxIREVHkWufk5LB06dIi1zorK4uVK1fa2/z222/YbDYSEhIq4VM4v2PHjuHiUvTXk6urKzabDdB1rijldV07derEggULKCgosLf55ZdfaNq0aZkfBwEa1nwukydPNjw9PY3PP//c2Lhxo/Hggw8aQUFBRUZSyNkNHDjQCAwMNP744w9j37599texY8fsbR5++GGjXr16xm+//WasWLHC6NSpk9GpUyf7/lPDba+55hpjzZo1xty5c43atWtruO15/HOUkGHoOpeXZcuWGW5ubsYrr7xibNu2zfjmm28MHx8f4+uvv7a3efXVV42goCBj1qxZxrp164wbb7yx2GGhbdu2NZYuXWosWrTIaNKkSY0fbvtP/fv3N6KiouzDmmfMmGGEhoYaTz31lL2NrnPZHDlyxFi9erWxevVqAzDeeustY/Xq1cauXbsMwyif65qVlWWEh4cbd999t7FhwwZj8uTJho+Pj4Y1V7R33nnHqFevnuHh4WF07NjR+OuvvxxdUpUBFPv67LPP7G2OHz9uPPLII0ZwcLDh4+Nj3Hzzzca+ffuKnGfnzp3Gtddea3h7exuhoaHGE088YRQUFFTyp6la/h1YdJ3Lzw8//GC0bNnS8PT0NJo1a2Z89NFHRfbbbDbj2WefNcLDww1PT0/jqquuMrZs2VKkzaFDh4w777zT8PPzMwICAox77rnHOHLkSGV+DKeWk5NjDBkyxKhXr57h5eVlNGrUyBg5cmSRYbK6zmXz+++/F/vvcv/+/Q3DKL/runbtWuOSSy4xPD09jaioKOPVV1+94NothvGPqQNFREREnJD6sIiIiIjTU2ARERERp6fAIiIiIk5PgUVEREScngKLiIiIOD0FFhEREXF6CiwiIiLi9BRYRERExOkpsIiIiIjTU2ARERERp6fAIiIiIk5PgUVERESc3v8DXZCqb1RFvVoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cls_loss, label='Train Loss')\n",
    "plt.plot(test_cls_loss, label='Val Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd9f4a36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:31:50.128346Z",
     "iopub.status.busy": "2024-10-15T09:31:50.127953Z",
     "iopub.status.idle": "2024-10-15T09:31:50.412357Z",
     "shell.execute_reply": "2024-10-15T09:31:50.411385Z"
    },
    "id": "3Xxf7zLSZQfa",
    "papermill": {
     "duration": 0.346968,
     "end_time": "2024-10-15T09:31:50.414443",
     "exception": false,
     "start_time": "2024-10-15T09:31:50.067475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7b32d2b8eb00>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cls_accuracy, label='Train Accuracy')\n",
    "plt.plot(test_cls_accuracy, label='Val Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f309054d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:31:50.536381Z",
     "iopub.status.busy": "2024-10-15T09:31:50.535396Z",
     "iopub.status.idle": "2024-10-15T09:31:50.818697Z",
     "shell.execute_reply": "2024-10-15T09:31:50.817734Z"
    },
    "id": "1d5JA8Q0ZSRM",
    "papermill": {
     "duration": 0.346746,
     "end_time": "2024-10-15T09:31:50.820917",
     "exception": false,
     "start_time": "2024-10-15T09:31:50.474171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7b32d1aacca0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAG1CAYAAAD9WC4XAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9j0lEQVR4nO3de3RU1f3+8WeSMLlAEiMxIWgELxVErSiRGIxFJBK8oJaFUi+A1NZiKVXTVkGBUFSCgkgLaCpqtRVEcaG1yA+KUdRoFAnSekEUAUEkEVRISCBDZvbvD74zZJJJMrnM/f1aa9YiZ86Z7DkOzsPen723xRhjBAAAEMaiAt0AAAAAXyPwAACAsEfgAQAAYY/AAwAAwh6BBwAAhD0CDwAACHsEHgAAEPZiAt2AYOBwOPTtt98qMTFRFosl0M0BAABeMMaourpaPXv2VFRUy304BB5J3377rTIzMwPdDAAA0A67du3SSSed1OI5BB5JiYmJko7esKSkpAC3BgAAeKOqqkqZmZmu7/GWEHgk1zBWUlISgQcAgBDjTTkKRcsAACDsEXgAAEDYI/AAAICwR+ABAABhj6LldrDb7aqvrw90MxAGYmJiFB0dHehmAEDYI/C0gTFGe/fuVXV1tYwxgW4OwoDFYlFiYqJOOOEEFr0EAB8i8LRBdXW1qqqq1L17d8XHx/MFhQ4xxujQoUP6/vvvFRcXx5IIAOBDBB4vGWP0/fffKzExUSkpKYFuDsJEXFyc6urqXJ8tQjQA+AZFy16y2+2y2+3q1q1boJuCMJOYmOj6fAEAfIPA4yXnlxEFpuhszs8UgQcAfCfoAs/bb7+tESNGqGfPnrJYLHrllVdavWbdunU6//zzFRsbq9NPP13PPPOMz9rHkAM6G58pAPC9oAs8NTU1Ovfcc7Vo0SKvzt++fbuuvPJKDRkyRJs2bdKdd96pX/3qV1qzZo2PWwoAAEJF0BUtX3755br88su9Pr+4uFinnHKKHnnkEUnSmWeeqdLSUj366KPKz8/3VTMBAMD/Mcbo0JHWh+Xju0QHrFc76AJPW5WVlSkvL8/tWH5+vu68885mr6mrq1NdXZ3r56qqKl81DwCAsNI43BgjXVdcps/2tP5d+tnMfCVYAxM9gm5Iq60qKiqUnp7udiw9PV1VVVU6dOiQx2uKioqUnJzsemRmZnZqmx577DFZLBZlZ2d7fH7Hjh2yWCyaO3eux+fnzp0ri8WiHTt2NHnu5Zdf1uWXX67U1FRZrVb17NlT119/vd54443OfAteee+995Sbm6uEhAT16NFDv//973Xw4MFWr3vmmWdksViafSxZssR17ooVKzR69GideuqpSkhIUJ8+ffSHP/xB+/fvb/K6d911l84//3wdf/zxSkhI0JlnnqkZM2Z4bFN5ebmGDx+upKQkJSYmatiwYdq0aZPbOc7/Ts09fv3rXzd53Y0bN+rqq692teHss8/WX//619ZvJgCEAIfD6Mq/lqrf9DWux1mFa7wKO4EW8j087TFlyhQVFBS4fq6qqurU0LNkyRL17t1b69ev19atW3X66ad3+DWNMfrlL3+pZ555Ruedd54KCgrUo0cP7dmzRy+//LKGDh2qd999V4MGDeqEd9C6TZs2aejQoTrzzDM1b948ffPNN5o7d66+/PJL/b//9/9avPZnP/uZ/vnPfzY5/uijj+q///2vhg4d6jp22223qWfPnrr55pt18skn6+OPP9bChQu1atUqbdy4UfHx8a5zP/zwQ1188cUaP3684uLi9NFHH2n27Nl6/fXX9fbbbysq6mi+37hxo3Jzc5WZmanCwkI5HA499thjGjx4sNavX68+ffpIkk444QSP7Vy9erWWLFmiYcOGuR3/z3/+oxEjRui8887TtGnT1K1bN3311Vf65ptvvL+xABBknD06xkhXLSjV9n01Hs/rl5Gk5RNy1NKIVXyXAM50NkFMknn55ZdbPOfiiy82d9xxh9uxp59+2iQlJXn9ew4cOGAkmQMHDjR7zuHDh82XX35pDh8+3OJrbdu2zUgyK1asMCeccIKZMWNGk3O2b99uJJk5c+Z4fI05c+YYSWb79u1Njt15553G4XA0ueYf//iH+eCDD1psW2e6/PLLTUZGhts9W7x4sZFk1qxZ0+bXq62tNYmJieayyy5zO/7mm282OffZZ581kszixYtbfd25c+caSaasrMx17IorrjApKSlm3759rmPffvut6datmxk5cmSrrzl06FCTlJRkDh065Dp24MABk56ebn7+858bu93e6ms05O1nCwD8zW53mMvnv2163bPS7XHJnDfNwcNHTE3dsYen7yZf8+b72ynkh7RycnJUUlLidmzt2rXKyckJSHuWLFmilJQUXXnllRo1apTb8Ex7HTp0SEVFRerbt69ruKuxMWPGaODAgR3+Xd6oqqrS2rVrdfPNN7tthzB27Fh169ZNL774Yptf89///reqq6t10003uR2/5JJLmpz785//XJK0efPmVl+3d+/ekuQ2BPbOO+8oLy9P3bt3dx3LyMjQ4MGDtXLlyhaH5fbs2aM333xTI0eOVFxcnOv40qVLVVlZqQcffFBRUVGqqamRw+FotX0AEAyMMaq11bs9aurqNXTeW02Gq/plJKmkYLC6xsYowXrsEexLbATdkNbBgwe1detW18/bt2/Xpk2bdPzxx+vkk0/WlClTtHv3bv3jH/+QJE2YMEELFy7U3XffrV/+8pd644039OKLL+q1114LSPuXLFmikSNHymq16oYbbtDjjz+uDz/8UBdccEG7X7O0tFQ//PCD7rzzzg4tfPjjjz96tbhdQkKCEhISmn3+448/Vn19vbKystyOW61W9e/fXx999FGb27ZkyRLFx8dr5MiRrZ5bUVEhSUpNTW3yXH19vfbv3y+bzaZPPvlEU6dOVWJiolsYrKurcxsKc0pISHBdd+GFF3r83cuWLZPD4WgSzF5//XUlJSVp9+7duvbaa/XFF1+oa9euGjNmjB599FG3cAQAgWYaFB57U3R8SmpXrZyUK4slsDOtOiLoAs+GDRs0ZMgQ18/OWptx48bpmWee0Z49e7Rz507X86eccopee+013XXXXfrLX/6ik046SU8++WRApqSXl5fr888/14IFCyRJubm5Oumkk7RkyZIOBR5nT8Y555zTofadd955+vrrr1s9r7CwUDNmzGj2+T179kg62ivSWEZGht555502teuHH37Q6tWrde211yoxMbHV8x966CFFR0dr1KhRTZ7bsGGDW+9enz599Oqrr+r44493O/b+++/Lbre7AqTNZtMHH3wgSdq9e3ezv3vJkiXKyMjQpZde6nb8yy+/VH19va655hrdeuutKioq0rp167RgwQLt379fzz//fKvvCwA6m/EwXbwts6qkoz06KyflKioq9EJOQ0EXeC655BIZY5p93tMqypdcckm7ehU625IlS5Senu4KbBaLRaNHj9Zzzz2nRx55pN29M85p896Egdba19zMtYZOPfXUFp93vkZsbGyT5+Li4rz6HQ299NJLstlsTXpNPFm6dKmeeuop3X333frJT37S5Pl+/fpp7dq1qqmp0XvvvafXX3+9yRDVb3/7W91+++269dZbdffdd8vhcOiBBx5wBbnm2v/FF1+ovLxcd911l6sA2ungwYOqra3VhAkTXLOyRo4cKZvNpr/97W+aOXOmx/YCgK8YYzSquEzlX//o1fnNFR2Hao9OY0EXeEKV3W7XsmXLNGTIEG3fvt11PDs7W4888ohKSkqazOppjfMD5qyTqa6u7lAbL7roog5d7+QcDmq4lpHT4cOHPQ4XtWTJkiU6/vjjW11w8p133tGtt96q/Px8Pfjggx7PSUpKcq3LdM0112jp0qW65pprtHHjRp177rmSjg6D7tq1S3PmzNGzzz4rScrKytLdd9+tBx98sNkNYp31WJ6CmfM933DDDW7Hb7zxRv3tb39TWVkZgQdAp/HUc9NYrc3eYthpHHDCJdg0h8DTSd544w3t2bNHy5Yt07Jly5o833Aas7Oeo7mehNraWrfz+vbtK+lo7cy1117b7jbu3bvXqxqebt26tbgrvHMoy9kj0tCePXvUs2dPr9u0c+dOvfPOO7rtttvUpUuXZs/773//q6uvvlpnn322XnrpJcXEePfRHTlypMaMGaNly5a5Ao8kPfjgg/rjH/+oTz/9VMnJyTrnnHN07733SpLOOOMMj6+1dOlS9enTRwMGDGjyXM+ePfXpp582WRMqLS1N0tH6KQDoDG3tuZGkDVPzlGB1H2UI94DTGIGnkyxZskRpaWke9wBbsWKFXn75ZRUXFys+Pl4nnHCCEhIStGXLFo+vtWXLFiUkJLiKcnNzc5WSkqLnn39e9957b7uHxi644IJOqeE5++yzFRMTow0bNuj66693HbfZbNq0aZPbsdY8//zzMsa0OJz11Vdfafjw4UpLS9OqVataDGON1dXVyeFw6MCBA02eS0lJUW5uruvn119/XSeddJIrYDb0wQcfaOvWrZo5c6bH3zNgwACtXbtWu3fvdq3jI0nffvutpKNr+gAIb970unSG1npuGsvqlaLuXa0RFW48IfB0gkOHDmnFihW67rrrPBbS9uzZU88//7xeffVVjR49WtHR0Ro2bJj+/e9/a+fOnTr55JNd5+7cuVP//ve/NWzYMFewSUhI0D333KPJkyfrnnvu0Zw5c5p8cJ977jmdccYZLU5N76wanuTkZOXl5em5557TtGnTXLVF//znP3Xw4EFdd911rnNra2u1c+dOpaamepxVtXTpUp188sluwaOhiooKDRs2TFFRUVqzZk2zwWH//v3q2rVrk16iJ598UpKazChr7IUXXtCHH36ouXPnNqnPcbZTOjpE5cn111+v2bNn66mnnnIraH7yyScVExPjcXo9gNBnGizK15ZC4M7iqeemsUjryWkOgacTvPrqq6qurtbVV1/t8fkLL7xQJ5xwgpYsWaLRo0dLkmbNmqULL7xQ559/vm677Tb17t1bO3bs0BNPPCGLxaJZs2a5vcaf/vQnffrpp3rkkUf05ptvatSoUerRo4cqKir0yiuvaP369XrvvfdabGdn1fBIR4eEBg0apMGDB+u2227TN998o0ceeUTDhg3T8OHDXeetX79eQ4YM8dhr9Mknn+h///ufJk+e3OxfxuHDh2vbtm26++67VVpaqtLSUtdz6enpuuyyyyRJ69at0+9//3uNGjVKP/nJT2Sz2fTOO+9oxYoVysrK0s033+y67u2339bMmTM1bNgwde/eXe+//77+/ve/a/jw4brjjjuatMFut+uFF17QhRdeqNNOO81jO8877zz98pe/1NNPP636+noNHjxY69at0/LlyzVlypQ2DfMBCA0Oh9FVC0oDtq0CPTdt5LPlD0NIR1daHjFihImLizM1NTXNXn/LLbeYLl26uK3uu3nzZjN69GiTlpZmYmJiTFpamvnFL35hNm/e3OzrvPTSS2bYsGHm+OOPNzExMSYjI8OMHj3arFu3zst323neeecdM2jQIBMXF2dOOOEEM3HiRFNVVeV2zptvvmkkmcLCwibXT5482Ugy//vf/5r9HZKafQwePNh13tatW83YsWPNqaeeauLj401cXJw566yzTGFhoTl48KDba27dutUMGzbMpKammtjYWNO3b19TVFRk6urqPLZh9erVRpL561//2uL9sNlsZsaMGaZXr16mS5cu5vTTTzePPvpoi9cYw0rLQKhwOByuVYUPHj5iLpnzZpMViC+f/3aTFYh99QjEysbBpi0rLVuMaWEOeISoqqpScnKyDhw44LZycEN1dXXatWuXMjMzPU7HBtqLzxYQ/FrqzQmHRflClTff304MaQEAIppppdi4pU0zw2VRvkhA4AEARBzTzmLjhr05Ej06oYTAAwCIKO0tNqY3J7QReAAAEcEYo1qb3ePwVHPbKjREb05oI/AAAIJea3U2rV/fdOiKYuPIQuBpIya1obPxmQJaZtqxlUJrGJ6KPAQeLzlXPfZmLyqgLZyfqfZuGQKEm8a9OW3dSqElzqGrBCs9OpGGwOOl6OhoRUdH6+DBg+ratWugm4MwUl1d7fp8AZGutd4cb7ZSaAlDV5GLwOMli8Wi7t2767vvvpPValV8fDx/adAhxhgdOnRIBw8eVFpaGp8nRDxjjL6vsTUbdthKAR1B4GmDxMREHT58WD/88AN1F+gUFotFSUlJrg1YgUjknD3VuKi4cW8OvTPoCAJPG1gsFqWlpal79+6qr68PdHMQBmJiYhjKQkRqbeE/enPQ2Qg87UC9BQC0TcNC5JZWN6aoGL5C4AEA+JQ308oJOvA1Ag8AwKcOHfE8rbzh6sbU58DXCDwAAL9pWIhMyIE/EXgAAB3W0tYPtbZjxxOs0Uqw8tUD/+NTBwBot+amlAPBhsADAGgXh8PoqgWlXgedrF4piu/CDFcEBoEHANBmxjQNOw2LkD2hZgeBROABAHjNWatTa7O7ws4pqV21clIuU8oR1Ag8AIAmPBUhN7dg4MpJueoay9cJghufUACApNa3e/Akq1dKh3YvB/yFwAMAaFMBMgsGIhQReAAgwjkcRkPnvaXt+2rcjjdXhEzIQSgi8ABAhGm8kedVC0pdYcdZgEzvDcINgQcAIkRriwSektpVJQWDFRVFyEH4IfAAQARorUanX0aSVk7KJewgbBF4ACCMOXt1Gg5bSU3rcxi+Qrgj8ABAmGlpejmLBCJSEXgAIEy0VqPDsBUiGYEHAMKAMUajistU/vWPTZ5zDl/Rq4NIRuABgBBnjNH3NTa3sMPigIA7Ag8AhDBPPTsbpuape1crIQdogMADACHA02aeklRrs7uFnaxeKYQdwAMCDwAEOW/3uaJnB2gegQcAglhz+1w1Rs8O0DICDwAEicbDVi3tc9UYhclAywg8ABAgjTfxbG79HIl9roCOIvAAQAB4W5cjsWAg0BkIPADgZy3V5TTe40piuAroDAQeAPCxxkNXLdXlEG4A3yDwAICPtLa3FXU5gP8QeADAB1ra20qiLgfwNwIPAPjAoSP2Zve2khi6AvyNwAMAnaDxGjq1tmN/ZgVkIPAIPADQTs6Q09oaOglWenOAQCPwAEA7tFaj45TVK0XxXaL91CoAzSHwAEAbOHt1Gu9SLrGGDhDMCDwA4KXmenU2TM1TgjWacAMEMQIPADTDUyFy47DDLuVAaAjKwLNo0SLNmTNHFRUVOvfcc7VgwQINHDiw2fPnz5+vxx9/XDt37lRqaqpGjRqloqIixcXF+bHVAMJJazU69OoAoSXoAs8LL7yggoICFRcXKzs7W/Pnz1d+fr62bNmitLS0JucvXbpUkydP1tNPP61Bgwbpiy++0C233CKLxaJ58+YF4B0ACBWNe3Aa8tSb40SvDhB6LMYYE+hGNJSdna0LLrhACxculCQ5HA5lZmZq0qRJmjx5cpPzf/e732nz5s0qKSlxHfvDH/6gDz74QKWlpR5/R11dnerq6lw/V1VVKTMzUwcOHFBSUlInvyMAwcTbqeQNOXtznOjVAYJDVVWVkpOTvfr+jvJTm7xis9lUXl6uvLw817GoqCjl5eWprKzM4zWDBg1SeXm51q9fL0natm2bVq1apSuuuKLZ31NUVKTk5GTXIzMzs3PfCICgY4xRTV29rvxrqfpNX6OzCtd4FXacvTkJ1hjXg7ADhJ6gGtLat2+f7Ha70tPT3Y6np6fr888/93jNjTfeqH379ik3N1fGGNXX12vChAm69957m/09U6ZMUUFBgetnZw8PgPDUUj2Op6nkDdGbA4SHoAo87bFu3TrNmjVLjz32mLKzs7V161bdcccduv/++zVt2jSP18TGxio2NtbPLQXgTw3rcxrX4zQMOQQaIDIEVeBJTU1VdHS0Kisr3Y5XVlaqR48eHq+ZNm2axowZo1/96leSpHPOOUc1NTW67bbbdN999ykqKqhG7QD4mDFGtTZ7s/U57GsFRKagSgNWq1UDBgxwK0B2OBwqKSlRTk6Ox2tqa2ubhJro6KPFhUFWjw2gkx0NN/Wuh7NGp7n6HGZXAZErqHp4JKmgoEDjxo1TVlaWBg4cqPnz56umpkbjx4+XJI0dO1YnnniiioqKJEkjRozQvHnzdN5557mGtKZNm6YRI0a4gg+A8ONwGF21oLTFwuPG9TkMXwGRK+gCz+jRo7V3715Nnz5dFRUV6t+/v1avXu0qZN65c6dbj87UqVNlsVg0depU7d69WyeccIJGjBihBx98MFBvAYCPORxGQ+e9pe37ajw+7ww67FIOwCno1uEJhLbM4wcQWI3DzimpXbVyUi4bdgIRqC3f30HXwwMAzTHm6DBWw7BTUjBYUVGEGwAtI/AACHrOKea1NrurZoewA6AtCDwAglpziwaunJRL2AHgtaCalg4ADRlj9H2NrUnYyeqV4ra3FQC0hh4eAEGlpc09nZt4UpQMoK0IPAACquEWEC3tYM6igQA6gsADIGDasngga+oA6AgCD4CAaGnxQDb3BNDZCDwA/M7TejoNFw8k5ADobAQeAD7VsEbHifV0APgbgQeATxzdydzebBGyE+vpAPAHAg+ATuHtbKuGWE8HgL8QeAB0iDc9OQ2LkBuiVgeAvxB4ALRZS4sDNsSUcgDBgsADoFXeDlc17smhBwdAsCDwAGiWt4XH9OQACHYEHgAeNbdLuROLAwIIJQQeAE142qWc4SoAoYzAA8CNp56dDVPz2LgTQEiLCnQDAASXQ0fsbmGHXcoBhAN6eAC4zcKqtR3bBoKeHQDhgsADRLiWipOZdQUgXDCkBUS4WpvdY9jJ6pWi+C5s+wAgPNDDA0QwY4yuKy5z/bxhap5rbytmYQEIJwQeIAI5a3ZqbXbXgoL9MpKo1wEQtgg8QATwZmuIo2vsEHYAhCcCDxDmWlsxWTpar+McygKAcETgAcJc43V1nNgaAkAkIfAAYaildXUoSgYQiQg8QJhxOIyuWlDqcXfzBGu0Eqz8tQcQeViHBwgjxjQfdlhXB0Ak4596QBjwNM38lNSuWjkpl93NAUAEHiDkNTeEtXJSrrrG8lccACSGtICQ1twQFtPMAcAd//wDQpQxRt/X2DwOYTF8BQDuCDxACPK0mCBDWADQPIa0gBDUeDFBhrAAoGX8cxAIQcYc+/OGqXls+gkAraCHBwgxzllZTglW6nUAoDUEHiCEOBxGQ+e9pe37aiQd3Q+LxQQBoHUEHiBEOKegO8POsVlZ9O4AQGuo4QGCWONNQBtOQS8pGKyoKMIOAHiDwAMEIWOMam12XVdc5nFfrJWTcgk7ANAGBB4gSDh7c4xRs0FHYgo6ALQHgQcIAp4WEnTql5Gk5RNy2AQUADqAwAMEgcYLCUrHgg7TzgGg4wg8QBBovJBggjWanhwA6EQEHsDPGs68OvqzmiwkmGDlryYAdCb+rwr4kXOV5OYKkllIEAB8g8AD+FDD3hxnT45z4cDG+mUksZAgAPgIgQfwgdbW0Tm2SvKxY9TsAIDvEHiATuLtOjrOnhwWDgQA/yHwAJ2gpdoc1tEBgMAj8AAd5NzUs3HYYR0dAAgeBB6ggxpv6umszaEnBwCCB4EH6ADnUJbTykm56hrLXysACDZRgW6AJ4sWLVLv3r0VFxen7OxsrV+/vsXz9+/fr4kTJyojI0OxsbE644wztGrVKj+1FpHm6AysetXU1WvovLdc08z7ZSSxqScABKmg+6foCy+8oIKCAhUXFys7O1vz589Xfn6+tmzZorS0tCbn22w2XXbZZUpLS9NLL72kE088UV9//bWOO+44/zceYa+5TT6PDWUxhAUAwchiTMNdfAIvOztbF1xwgRYuXChJcjgcyszM1KRJkzR58uQm5xcXF2vOnDn6/PPP1aVLF69+R11dnerq6lw/V1VVKTMzUwcOHFBSUlLnvBGEHWOMvq+xKeuB192OM80cAAKjqqpKycnJXn1/B9WQls1mU3l5ufLy8lzHoqKilJeXp7KyMo/XvPrqq8rJydHEiROVnp6us88+W7NmzZLdbvd4viQVFRUpOTnZ9cjMzOz094Lw4nAYXfnXUrews2Fqnj6bma/Xfk/YAYBgF1SBZ9++fbLb7UpPT3c7np6eroqKCo/XbNu2TS+99JLsdrtWrVqladOm6ZFHHtEDDzzQ7O+ZMmWKDhw44Hrs2rWrU98HwovDYTR03ltu086zeqWoe1erEqwxDGMBQAgIuhqetnI4HEpLS9MTTzyh6OhoDRgwQLt379acOXNUWFjo8ZrY2FjFxsb6uaUIRc6w4yxMdtbqsLYOAISWoAo8qampio6OVmVlpdvxyspK9ejRw+M1GRkZ6tKli6Kjj82OOfPMM1VRUSGbzSar1erTNiN8eQo7JQWDGb4CgBAUVENaVqtVAwYMUElJieuYw+FQSUmJcnJyPF5z0UUXaevWrXI4HK5jX3zxhTIyMgg7aBdjTJMp54QdAAhtQRV4JKmgoECLFy/Ws88+q82bN+v2229XTU2Nxo8fL0kaO3aspkyZ4jr/9ttv1w8//KA77rhDX3zxhV577TXNmjVLEydODNRbQAhzTjs/q3ANYQcAwkhQDWlJ0ujRo7V3715Nnz5dFRUV6t+/v1avXu0qZN65c6eioo7ltMzMTK1Zs0Z33XWXfvrTn+rEE0/UHXfcoXvuuSdQbwEh7NARu9saO0w5B4DwEHTr8ARCW+bxIzwZY3ToiF21Nrtr6vmGqXnq3tVKcTIABKm2fH8HXQ8P4C/OkGOMdF1xWZPdzpmJBQDhg8CDiHN0Lyy7x5DjlNUrRfFd2BcLAMIFgQcRxbm7uaeg0y8jScsn5MhikeK70LsDAOGEwIOI0XhdHYmQAwCRgsCDiGDM0Z4dVkwGgMhE4EHYc+5y7hzGYl0dAIg8BB6EreaKk1lXBwAiD4EHYcm5YnLDRQSlo7OvEqzMvgKASEPgQViqtTVdMXn5hBxqdgAgQvk08Kxbt06XXHKJL38F0IRz6rkTKyYDAHyyeei7776roUOHaujQob54eaBZjWdj9ctIIuwAANrWw3PkyBEtXbpU5eXliomJUW5urkaOHOl6ftOmTZo8ebLWrl0rY4yysrI6vcFAY84tIqSjQ1kNZ2OtnJRL2AEAeB94qqur9bOf/Uz/+9//5Nxv9C9/+YtGjhyp5cuXa/r06Zo1a5YcDofOP/98zZgxQ1dddZXPGo7I1to+WBKzsQAAx3gdeB566CH997//1bnnnqubbrpJkvTcc89pxYoV+sUvfqEXX3xRp59+uubOnaurr77aZw0GmpuB1RCzsQAADVmMs7umFeecc44OHjyoLVu2yGq1SpIOHz6svn37ateuXRo+fLhWrFih2NhYnzbYF9qyvTwCy7mIYNYDr7sdb7hFhMQ2EQAQCdry/e11D8+2bdt0yy23uMKOJMXFxenKK69UcXGx5s6dG5JhB6HDU8/Ohql5SrBGE3AAAC3yOvAcOnRI6enpTY6npaVJkvr06dN5rQI8OHTEfW2drF4pzMACAHil09bhiYryyQx3wCPW1gEAtEWbAs8nn3yiF198sckxSVq+fLk8lQNdf/31HWge4BkrJgMA2sLrouWoqCiPXzDOyxs/Z4yRxWKR3W7vhGb6FkXLoaHWVq9+09dIkj6bma8EKzujAEAk80nRcmFhYYcbBgAAEAgEHoQEY4xqbcHfWwgACE6MCSDoebPQIAAALWnT1KqysjJdeumlSkxMVFJSki677DKtX7/eV21DhDram1PvenxfY2syHT2+C6soAwC853XR8scff6zs7GwdPnzY7Xh8fLzWr1+vs846yycN9AeKloOHw3F0t3NPe2NJTEcHABzTlu9vr3t4Zs+ercOHD+u+++5TRUWFKioqNG3aNB06dEgPPfRQhxsNGNNy2GGhQQBAe3ndw3PyySerd+/eevvtt92ODx48WDt27NDXX3/tkwb6Az08waHhtPNTUrtq5aRcNcw2bB8BAGjIJz08lZWVuvDCC5scz87OVmVlZdtbCbRg5aRcdY2NUYL12IOwAwBoL68Dz5EjR9StW7cmx7t27aojR450aqMAsg0AoDOxARYAAAh7bVqH57nnntP777/vdmzr1q2SpCuuuKLJ+RaLRa+99loHmgcAANBxbQo8W7dudQWcxlavXt3kGDUXaAvvyucBAGg7rwPP9u3bfdkORDjn+jsAAPiC14GnV69evmwHIpjDYTR03lvavq9GktQvI4mVlAEAncrrouXo6Gjdf//9vmwLIlDjsHNs/R2GQwEAncfrwGOMkZdrFAJeca6s3DDslBQMVlQUYQcA0LmYlo6AOXTE7tpGgrADAPAlAg+CwspJuYQdAIDPtCnwUFcBX+GjBQDwpTYFnhkzZig6OtrrR0xMm5b5QYQwxqjWVq9amz3QTQEARIg2JZKkpCQdd9xxPmoKIoExRqOKy1T+9Y+BbgoAIIK0KfDcddddmj59uq/agghQa7M3CTtZvVJYdwcA4FOMOcFvGq+mvGFqnhKs0YrvEk19GADApwg88IvGa+70y0hS965Wgg4AwC+Ylg6/qLW5r7nDasoAAH8i8MDnjDG6rrjM9TNr7gAA/M3rIS2Hw+HLdiCMNVxRuV9GkhKsFCgDAPyLHh741fIJOQxlAQD8jsADn2u45yxZBwAQCAQe+FTj+h0AAAKBwAOfaly/wwKDAIBAIPDAb6jfAQAECgsPwieMMTp0xO62QShZBwAQKAQedDrnFhLOoSwAAAKNIS10KucWEo3DDhuEAgACiR4edKqGRcrHtpAQG4QCAAIqaHt4Fi1apN69eysuLk7Z2dlav369V9ctW7ZMFotF1157rW8bCI8arrmzclKuusbGKMEaQ9gBAARUUAaeF154QQUFBSosLNTGjRt17rnnKj8/X999912L1+3YsUN//OMfdfHFF/uppZCODmPV2upVU1evqxaUuo6TcQAAwSIoA8+8efP061//WuPHj1e/fv1UXFyshIQEPf30081eY7fbddNNN+nPf/6zTj31VD+2NnIZY1RTV68r/1qqftPX6KzCNdq+r0YSa+4AAIJL0NXw2Gw2lZeXa8qUKa5jUVFRysvLU1lZ8yv2zpw5U2lpabr11lv1zjvvtPg76urqVFdX5/q5qorZRN5yTjc3RrquuMzjTKx+GUn/V7tDFw8AIDgEXeDZt2+f7Ha70tPT3Y6np6fr888/93hNaWmpnnrqKW3atMmr31FUVKQ///nPHW1qxDHGaFRxmcq//rHJc/0ykv5vYUEKlAEAwSfoAk9bVVdXa8yYMVq8eLFSU1O9umbKlCkqKChw/VxVVaXMzExfNTFs1NrsTcKOM+gkWAk5AIDgFXSBJzU1VdHR0aqsrHQ7XllZqR49ejQ5/6uvvtKOHTs0YsQI1zGHwyFJiomJ0ZYtW3Taaae5XRMbG6vY2FgftD58Nd4EdMPUPCVYo+nNAQCEhKArWrZarRowYIBKSkpcxxwOh0pKSpSTk9Pk/L59++rjjz/Wpk2bXI+rr75aQ4YM0aZNm+i56SSNNwHt3tXKdHMAQMgIuh4eSSooKNC4ceOUlZWlgQMHav78+aqpqdH48eMlSWPHjtWJJ56ooqIixcXF6eyzz3a7/rjjjpOkJsfRfg3X12ETUABAqAnKwDN69Gjt3btX06dPV0VFhfr376/Vq1e7Cpl37typqKig65wKW869sZzIOgCAUGMxpuG/3SNTVVWVkpOTdeDAASUlJQW6OUHF4TAaOu8tt/V1Xvs9U84BAIHXlu9vuknQrMZh59jeWIQdAEBoCcohLQSGc1HBo3+WrlpQ6hZ2SgoGKyqKsAMACD0EHkhqeVFBwg4AINQxpAVJR6edN7eCMmEHABDq6OFBE85FBSW2iQAAhAcCD5pIsEYrwcpHAwAQPhjSgiT3hQUBAAg3BB40WVgQAIBwQ+CJcMYYt+nn/TKSFN8lOsCtAgCgcxF4Ilyt7dimoCwsCAAIVwSeCGaM0XXFZa6fV07KZfo5ACAsEXgi2KEjx3p3+mUkuaaiAwAQbgg8kCQtn5DDUBYAIGyx2EoEcu6ZVWuzu46RdQAA4YzAE2GcU9CdQ1kAAEQCAk8EcTiMhs57yzUF3SmrVwpT0QEAYY3AEyEar7dzbAo6+2UBAMIfgSdCNJyRdUpqV3ZABwBEFGZpRSDW2wEARBoCTwRi9AoAEGkIPAAAIOwReCKEMYFuAQAAgUPgiQCN98wCACDSEHgiQOM9s1hzBwAQaQg8EaDhcBZ7ZgEAIhGBJ8w1Hs4i6wAAIhGBJ8wxnAUAAIEnojCcBQCIVASeCELWAQBEKgIPAAAIewQeAAAQ9gg8AAAg7BF4AABA2CPwAACAsEfgAQAAYY/AE+bYJR0AAAJPWHM4jK5aUBroZgAAEHAEnjDlcBgNnfeWtu+rkcS2EgCAyEbgCUPGHO3ZcYadU1K7auWkXLaVAABELAJPGGq4YegpqV1VUjBYUVGEHQBA5CLwhLmVk3IJOwCAiEfgCTPGGNXa7K6fGcUCAECKCXQD0Hmcs7Kcw1kAAOAoenjChLNQuWHYyeqVwswsAABED0/YaFyovHJSrhKs0czMAgBABJ6wtHJSrrrG8p8WAAAnhrTCEJ06AAC4I/CEgcYzswAAgDvGPUKcMUajistU/vWPgW4KAABBix6eEHfoiN0t7DAzCwCApujhCXHGHPvzhql56t7VyswsAAAaoYcnhDkXGnRiGjoAAJ4ReEJU4x3R+2UkMZQFAEAzCDwhytNCg/TuAADgGYEnRDWs3WFHdAAAWkbgCUHGGF1XXOb6mY4dAABaFrSBZ9GiRerdu7fi4uKUnZ2t9evXN3vu4sWLdfHFFyslJUUpKSnKy8tr8fxQ13A4i9odAABaF5SB54UXXlBBQYEKCwu1ceNGnXvuucrPz9d3333n8fx169bphhtu0JtvvqmysjJlZmZq2LBh2r17t59b7n/LJ+RQuwMAQCssxjSsBgkO2dnZuuCCC7Rw4UJJksPhUGZmpiZNmqTJkye3er3dbldKSooWLlyosWPHtnp+VVWVkpOTdeDAASUlJXW4/b5Wa6tXv+lrJEmfzcxXgpXllAAAkact399B18Njs9lUXl6uvLw817GoqCjl5eWprKyshSuPqa2t1ZEjR3T88cd7fL6urk5VVVVuDwAAEL6CLvDs27dPdrtd6enpbsfT09NVUVHh1Wvcc8896tmzp1toaqioqEjJycmuR2ZmZofbDQAAglfQBZ6Omj17tpYtW6aXX35ZcXFxHs+ZMmWKDhw44Hrs2rXLz60EAAD+FHTFH6mpqYqOjlZlZaXb8crKSvXo0aPFa+fOnavZs2fr9ddf109/+tNmz4uNjVVsbGyntBcAAAS/oOvhsVqtGjBggEpKSlzHHA6HSkpKlJOT0+x1Dz/8sO6//36tXr1aWVlZ/mgqAAAIEUHXwyNJBQUFGjdunLKysjRw4EDNnz9fNTU1Gj9+vCRp7NixOvHEE1VUVCRJeuihhzR9+nQtXbpUvXv3dtX6dOvWTd26dQvY+wAAAMEhKAPP6NGjtXfvXk2fPl0VFRXq37+/Vq9e7Spk3rlzp6KijnVOPf7447LZbBo1apTb6xQWFmrGjBn+bDoAAAhCQbkOj7+F2jo8NXX1OquQdXgAAJEtpNfhQcsa76MFAABaR+AJMeyjBQBA2xF4Qhj7aAEA4B0CTwgj6wAA4B0CT4ihxBwAgLYj8IQQCpYBAGgfAk8IqbVRsAwAQHsQeEJE494dCpYBAPAegSdENO7dSbDSuwMAgLcIPCGA3h0AADqGPQmCjDFGh47Y3Y7RuwMAQMcQeIKIMUajistU/vWPzZ5D7w4AAG3HkFYQOXTE3mLYyeqVQu8OAADtQA9PkNowNa9JuInvEk3vDgAA7UDgCSINV1FOsEYrwcp/HgAAOgNDWkGCVZQBAPAdAk+QOHSEVZQBAPAVAk8QYiYWAACdi8AThMg6AAB0LgIPAAAIewQeAAAQ9gg8AAAg7BF4AABA2CPwBImGiw4CAIDOReAJAiw6CACAbxF4ggCLDgIA4FsEniDDooMAAHQ+Ak8QaFi/Q9YBAKDzEXgCjPodAAB8j8ATYLU26ncAAPA1Ak8AORxGVy0odf1M/Q4AAL5B4AkQh8No6Ly3tH1fjaSjvTsJVnp3AADwBQJPABhztGfHGXZOSe2qlZNy6d0BAMBHCDwB0HDdnVNSu6qkYLCiogg7AAD4CoEnwFZOyiXsAADgYwSeAGMUCwAA3yPwAACAsEfgAQAAYY/AAwAAwh6BBwAAhD0CDwAACHsEHgAAEPYIPAAAIOwReAAAQNgj8AAAgLBH4AkAYwLdAgAAIguBx8+MMbquuCzQzQAAIKIQePys4U7p/TKSFN8lOsAtAgAg/BF4/MgYo1qb3fXz8gk5srB7KAAAPhcT6AZECmOMRhWXqfzrH13HyDoAAPgHPTx+Umuzu4WdrF4pDGcBAOAn9PD4QeNC5Q1T89S9q5XhLAAA/IQeHj9oXKhM2AEAwL8IPD5GoTIAAIHHkJYPUagMAEBwoIfHhw4doVAZAIBgELSBZ9GiRerdu7fi4uKUnZ2t9evXt3j+8uXL1bdvX8XFxemcc87RqlWr/NRS72yYmsdwFgAAARKUgeeFF15QQUGBCgsLtXHjRp177rnKz8/Xd9995/H89957TzfccINuvfVWffTRR7r22mt17bXX6pNPPvFzy5uXYI0m7AAAECAWY4JvK8vs7GxdcMEFWrhwoSTJ4XAoMzNTkyZN0uTJk5ucP3r0aNXU1GjlypWuYxdeeKH69++v4uLiVn9fVVWVkpOTdeDAASUlJXXa+6i11avf9DWSpM9m5ivBSskUAACdpS3f30HXw2Oz2VReXq68vDzXsaioKOXl5amszPOmm2VlZW7nS1J+fn6z59fV1amqqsrtAQAAwlfQBZ59+/bJbrcrPT3d7Xh6eroqKio8XlNRUdGm84uKipScnOx6ZGZmdk7jAQBAUAq6wOMPU6ZM0YEDB1yPXbt2+eT3xHeJ1mcz8/XZzHxmZwEAEEBBV1SSmpqq6OhoVVZWuh2vrKxUjx49PF7To0ePNp0fGxur2NjYzmlwCywWC3U7AAAEgaDr4bFarRowYIBKSkpcxxwOh0pKSpSTk+PxmpycHLfzJWnt2rXNng8AACJLUHY/FBQUaNy4ccrKytLAgQM1f/581dTUaPz48ZKksWPH6sQTT1RRUZEk6Y477tDgwYP1yCOP6Morr9SyZcu0YcMGPfHEE4F8GwAAIEgEZeAZPXq09u7dq+nTp6uiokL9+/fX6tWrXYXJO3fuVFTUsc6pQYMGaenSpZo6daruvfde/eQnP9Err7yis88+O1BvAQAABJGgXIfH33y1Dg8AAPCdkF6HBwAAoLMReAAAQNgj8AAAgLBH4AEAAGGPwAMAAMIegQcAAIQ9Ag8AAAh7BB4AABD2CDwAACDsBeXWEv7mXGy6qqoqwC0BAADecn5ve7NpBIFHUnV1tSQpMzMzwC0BAABtVV1dreTk5BbPYS8tSQ6HQ99++60SExNlsVg69bWrqqqUmZmpXbt2sU+XD3Gf/YP77B/cZ//hXvuHr+6zMUbV1dXq2bOn26bintDDIykqKkonnXSST39HUlISf5n8gPvsH9xn/+A++w/32j98cZ9b69lxomgZAACEPQIPAAAIewQeH4uNjVVhYaFiY2MD3ZSwxn32D+6zf3Cf/Yd77R/BcJ8pWgYAAGGPHh4AABD2CDwAACDsEXgAAEDYI/AAAICwR+DpBIsWLVLv3r0VFxen7OxsrV+/vsXzly9frr59+youLk7nnHOOVq1a5aeWhra23OfFixfr4osvVkpKilJSUpSXl9fqfxcc1dbPs9OyZctksVh07bXX+raBYaKt93n//v2aOHGiMjIyFBsbqzPOOIP/d3ihrfd5/vz56tOnj+Lj45WZmam77rpLhw8f9lNrQ9Pbb7+tESNGqGfPnrJYLHrllVdavWbdunU6//zzFRsbq9NPP13PPPOMz9spgw5ZtmyZsVqt5umnnzaffvqp+fWvf22OO+44U1lZ6fH8d99910RHR5uHH37YfPbZZ2bq1KmmS5cu5uOPP/Zzy0NLW+/zjTfeaBYtWmQ++ugjs3nzZnPLLbeY5ORk88033/i55aGlrffZafv27ebEE080F198sbnmmmv809gQ1tb7XFdXZ7KysswVV1xhSktLzfbt2826devMpk2b/Nzy0NLW+7xkyRITGxtrlixZYrZv327WrFljMjIyzF133eXnloeWVatWmfvuu8+sWLHCSDIvv/xyi+dv27bNJCQkmIKCAvPZZ5+ZBQsWmOjoaLN69WqftpPA00EDBw40EydOdP1st9tNz549TVFRkcfzr7/+enPllVe6HcvOzja/+c1vfNrOUNfW+9xYfX29SUxMNM8++6yvmhgW2nOf6+vrzaBBg8yTTz5pxo0bR+DxQlvv8+OPP25OPfVUY7PZ/NXEsNDW+zxx4kRz6aWXuh0rKCgwF110kU/bGU68CTx33323Oeuss9yOjR492uTn5/uwZcYwpNUBNptN5eXlysvLcx2LiopSXl6eysrKPF5TVlbmdr4k5efnN3s+2nefG6utrdWRI0d0/PHH+6qZIa+993nmzJlKS0vTrbfe6o9mhrz23OdXX31VOTk5mjhxotLT03X22Wdr1qxZstvt/mp2yGnPfR40aJDKy8tdw17btm3TqlWrdMUVV/ilzZEiUN+DbB7aAfv27ZPdbld6errb8fT0dH3++ecer6moqPB4fkVFhc/aGerac58bu+eee9SzZ88mf8lwTHvuc2lpqZ566ilt2rTJDy0MD+25z9u2bdMbb7yhm266SatWrdLWrVv129/+VkeOHFFhYaE/mh1y2nOfb7zxRu3bt0+5ubkyxqi+vl4TJkzQvffe648mR4zmvgerqqp06NAhxcfH++T30sODsDd79mwtW7ZML7/8suLi4gLdnLBRXV2tMWPGaPHixUpNTQ10c8Kaw+FQWlqannjiCQ0YMECjR4/Wfffdp+Li4kA3LaysW7dOs2bN0mOPPaaNGzdqxYoVeu2113T//fcHumnoBPTwdEBqaqqio6NVWVnpdryyslI9evTweE2PHj3adD7ad5+d5s6dq9mzZ+v111/XT3/6U182M+S19T5/9dVX2rFjh0aMGOE65nA4JEkxMTHasmWLTjvtNN82OgS15/OckZGhLl26KDo62nXszDPPVEVFhWw2m6xWq0/bHIrac5+nTZumMWPG6Fe/+pUk6ZxzzlFNTY1uu+023XfffYqKoo+gMzT3PZiUlOSz3h2JHp4OsVqtGjBggEpKSlzHHA6HSkpKlJOT4/GanJwct/Mlae3atc2ej/bdZ0l6+OGHdf/992v16tXKysryR1NDWlvvc9++ffXxxx9r06ZNrsfVV1+tIUOGaNOmTcrMzPRn80NGez7PF110kbZu3eoKlJL0xRdfKCMjg7DTjPbc59ra2iahxhkyDdtOdpqAfQ/6tCQ6AixbtszExsaaZ555xnz22WfmtttuM8cdd5ypqKgwxhgzZswYM3nyZNf57777romJiTFz5841mzdvNoWFhUxL90Jb7/Ps2bON1Wo1L730ktmzZ4/rUV1dHai3EBLaep8bY5aWd9p6n3fu3GkSExPN7373O7NlyxazcuVKk5aWZh544IFAvYWQ0Nb7XFhYaBITE83zzz9vtm3bZv7zn/+Y0047zVx//fWBegshobq62nz00Ufmo48+MpLMvHnzzEcffWS+/vprY4wxkydPNmPGjHGd75yW/qc//cls3rzZLFq0iGnpoWLBggXm5JNPNlar1QwcONC8//77rucGDx5sxo0b53b+iy++aM444wxjtVrNWWedZV577TU/tzg0teU+9+rVy0hq8igsLPR/w0NMWz/PDRF4vNfW+/zee++Z7OxsExsba0499VTz4IMPmvr6ej+3OvS05T4fOXLEzJgxw5x22mkmLi7OZGZmmt/+9rfmxx9/9H/DQ8ibb77p8f+3zns7btw4M3jw4CbX9O/f31itVnPqqaeav//97z5vp8UY+ukAAEB4o4YHAACEPQIPAAAIewQeAAAQ9gg8AAAg7BF4AABA2CPwAACAsEfgAQAAYY/AAwAAwh6BBwAAhD0CD4Cgt2PHDlkslhYf+/fvlyT17t3b7Xh0dLRSU1M1bNgw/etf/3J73XXr1jV5ndjYWPXu3Vvjx4/Xl19+GYB3C8AXYgLdAADw1mmnnaabb77Z43NxcXGuP0dHR2vq1KmSJJvNps8//1yvvvqq1q5dq7lz5+oPf/iD27UDBgzQVVddJUk6cOCA3n33XT3zzDNasWKF1q9frz59+vjoHQHwF/bSAhD0duzYoVNOOUX5+flavXp1i+f27t1bFRUVOnz4sNvx//znPxo+fLji4+O1d+9eJSQkaN26dRoyZIh+85vfqLi42O38CRMm6G9/+5vGjh2rZ599ttPfEwD/YkgLQEQYNmyY+vTpo9raWn366aetnn/rrbdKksrLy33dNAB+QOABEHEsFovX58bEMPIPhAP+JgMIGVu3btWMGTOaHB8+fLguvPDCFq8tKSnRli1b1LVrV5111lmt/q6nnnpKkpSbm9uutgIILgQeACHjq6++0p///Ocmx4877ji3wFNfX+8KRkeOHNGWLVv0r3/9S8YY3X///YqPj3e7fsOGDa7zq6qqVFpaqg8//FBnnHGGq/gZQGgj8AAIGd4ULUuS3W53BaOoqCilpKTo0ksv1cSJE3X11Vc3Ob+8vLxJrU6fPn1UWlqq1NTUzmk8gICihgdA2ImNjZUxRsYY2e127du3T2vWrPEYdiTpN7/5jYwxcjgc2r17t/74xz9qy5Ytuu6662S32/3cegC+QOABgP9jsVjUs2dPzZkzRzfffLPWrVunBQsWBLpZADoBgQcAPHj44YcVHx+vBx54QNXV1YFuDoAOIvAAgAcZGRmaMGGCvv/+e82fPz/QzQHQQQQeAGjGPffco4SEBM2bN8+1VxeA0ETgAYBmpKen6/bbb9f+/fs1b968QDcHQAewlxYAAAh79PAAAICwR+ABAABhj8ADAADCHoEHAACEPQIPAAAIewQeAAAQ9gg8AAAg7BF4AABA2CPwAACAsEfgAQAAYY/AAwAAwh6BBwAAhL3/Dz0S8edWKjGvAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.patches as mpl_patches\n",
    "\n",
    "font = {'family': 'serif',\n",
    "        'color':  'darkblue',\n",
    "        'weight': 'normal',\n",
    "        'size': 12,\n",
    "        }\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('FPR', fontsize=14)\n",
    "plt.ylabel('TPR', fontsize=14)\n",
    "# plt.text(0.9, 0.9, 'AUC = '+str(auc.round(6)), fontdict=font, wrap=True)\n",
    "# create a list with two empty handles (or more if needed)\n",
    "handles = [mpl_patches.Rectangle((0, 0), 1, 1, fc=\"white\", ec=\"white\",\n",
    "                                 lw=0, alpha=0)]\n",
    "\n",
    "# create the corresponding number of labels (= the text you want to display)\n",
    "labels = []\n",
    "labels.append(\"AUC = \"+str(auc.round(6)))\n",
    "\n",
    "# create the legend, supressing the blank space of the empty line symbol and the\n",
    "# padding between symbol and label by setting handlelenght and handletextpad\n",
    "plt.legend(handles, labels, loc='best', fontsize='large',\n",
    "          fancybox=True, framealpha=0.7,\n",
    "          handlelength=0, handletextpad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ff156d66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:31:50.942596Z",
     "iopub.status.busy": "2024-10-15T09:31:50.942157Z",
     "iopub.status.idle": "2024-10-15T09:31:50.947835Z",
     "shell.execute_reply": "2024-10-15T09:31:50.946929Z"
    },
    "id": "dxQgZz78ZU0c",
    "papermill": {
     "duration": 0.069551,
     "end_time": "2024-10-15T09:31:50.949838",
     "exception": false,
     "start_time": "2024-10-15T09:31:50.880287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  67.1\n",
      "AUC :  0.7239762525803717\n",
      "F1 score :  0.6659946559144947\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy : ', max(test_cls_accuracy))\n",
    "print('AUC : ', auc)\n",
    "print('F1 score : ', f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8f21994",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:31:51.076019Z",
     "iopub.status.busy": "2024-10-15T09:31:51.075599Z",
     "iopub.status.idle": "2024-10-15T09:31:51.085734Z",
     "shell.execute_reply": "2024-10-15T09:31:51.084512Z"
    },
    "papermill": {
     "duration": 0.07705,
     "end_time": "2024-10-15T09:31:51.087999",
     "exception": false,
     "start_time": "2024-10-15T09:31:51.010949",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # qnn layer\n",
    "# parameters = [2, 3, 4, 5]\n",
    "\n",
    "# for paramx in parameters:\n",
    "#     # Set up model\n",
    "#     device = 'cuda'\n",
    "#     num_layer_gnn = 2\n",
    "#     num_layer_gnn_est = 2\n",
    "#     qnn_layers = paramx # 3\n",
    "#     emb_dim = 128 # classical\n",
    "#     in_dim = 8\n",
    "#     inter_dim = 256 # gnn\n",
    "#     out_dim = 128 # don't change\n",
    "#     JK = 'last' # unchanged\n",
    "#     dropout_ratio = 0.1 # classical\n",
    "#     gnn_type = 'gat' # unchanged\n",
    "#     lr = 0.001\n",
    "#     decay = 0\n",
    "#     aug_ratio = 0.1\n",
    "#     batch_size = 2000\n",
    "#     loss_temp = 0.1\n",
    "#     lamda = 0.1\n",
    "#     node_est = 'quantum'\n",
    "#     entanglement_type = 'CNOT'\n",
    "#     encoding_type = 'RY'\n",
    "    \n",
    "#     # Dataset\n",
    "#     qg_dataset = QuarkGluonGraphDataset(dataset_name='Quark Gluon', raw_dir=main_dir, save_dir='/content',\n",
    "#                                         data_folder_name=jet_folder_path, datafile_name=jet_file_path, labelsfile_name=jet_file_path,\n",
    "#                                         datatype='particles', dataset_size=10000, nodes_per_graph=nodes_per_graph_original,\n",
    "#                                         spectral_augmentation=False, irc_safety_aug=True, device='cuda')\n",
    "    \n",
    "#     # Model\n",
    "#     gnn = ParticleNetTagger1Path(in_dim, 2)\n",
    "#     if node_est == 'classical':\n",
    "#         node_imp_estimator = GNN_imp_estimator(num_layer=num_layer_gnn_est, emb_dim=emb_dim, in_dim=in_dim, JK=JK, drop_ratio=dropout_ratio)\n",
    "#     if node_est == 'quantum':\n",
    "#         node_imp_estimator = QGNN_node_estimator(nodes_per_graph_original, qnn_layers, in_dim, device=device,\n",
    "#                                                  entanglement_type=entanglement_type, encoding_type=encoding_type)\n",
    "    \n",
    "#     model = graphcl(gnn, node_imp_estimator, emb_dim, out_dim)\n",
    "#     model.to(device)\n",
    "    \n",
    "#     # Optimizer with current learning rate\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=decay)\n",
    "\n",
    "\n",
    "# ############## after training ###############\n",
    "#     epochs = 50\n",
    "#     con_loss = []\n",
    "\n",
    "#     for epoch in range(1, epochs + 1):\n",
    "#         print(\"====epoch \" + str(epoch))\n",
    "#         qg_dataset.augment = False\n",
    "#         train_loss, ra_loss, cp_loss, uni_loss, al_loss = train(epoch, model=model, device=device, dataset=qg_dataset, optimizer=optimizer, batch_size=batch_size,\n",
    "#                                           nodes_per_graph=qg_dataset.nodes_per_graph, aug_ratio=aug_ratio, loss_temp=loss_temp, lamda=lamda,\n",
    "#                                           irc_safety=True, q_edge_attr=True, node_est=node_est)\n",
    "#         con_loss.append(train_loss)\n",
    "#         print(train_loss)\n",
    "#         print(ra_loss)\n",
    "#         print(cp_loss)\n",
    "#         print('UNI : ', uni_loss)\n",
    "#         print('ALIGN : ', al_loss)\n",
    "\n",
    "#     # nodes_per_graph_original = 10\n",
    "#     test_dataset = QuarkGluonGraphDataset(dataset_name='Quark Gluon', raw_dir=main_dir, save_dir='/content',\n",
    "#                                         data_folder_name=jet_folder_path, datafile_name=jet_file_path, labelsfile_name=jet_file_path,\n",
    "#                                         datatype='particles', dataset_size=7000, nodes_per_graph=nodes_per_graph_original, spectral_augmentation=False, irc_safety_aug=True,\n",
    "#                                         device='cuda')\n",
    "\n",
    "#     test_samples = torch.tensor(np.arange(2000,7000).astype('int32'))\n",
    "#     test_sampler = SubsetRandomSampler(test_samples)\n",
    "\n",
    "#     test_dataloader = test_dataloader = GraphDataLoader(\n",
    "#         test_dataset, sampler=test_sampler, batch_size=500, drop_last=False\n",
    "#     )\n",
    "\n",
    "#     cls_embds = torch.Tensor([])\n",
    "#     cls_labels = torch.Tensor([])\n",
    "\n",
    "#     for batched_graph, labels in test_dataloader:\n",
    "#           graphs = []\n",
    "#           unbatched_graph = dgl.unbatch(batched_graph)\n",
    "#           for graph in unbatched_graph:\n",
    "#             graphs.append(dgl.add_self_loop(graph))\n",
    "#           batched_graph = dgl.batch(graphs)\n",
    "#           batch_t = torch.arange(0, batched_graph.batch_size).reshape(-1,1).expand(batched_graph.batch_size, test_dataset.nodes_per_graph).reshape(-1,)\n",
    "\n",
    "#           ## For custom GNN\n",
    "#           # cls_emb = gnn.forward(batched_graph.ndata[\"node_attr\"].float(), torch.stack(batched_graph.edges()), batched_graph.edata[\"edge_attr\"].float())\n",
    "\n",
    "#           ## For ParticleNet\n",
    "#           pf_feats = batched_graph.ndata[\"node_attr\"].reshape(len(unbatched_graph), nodes_per_graph_original, -1).float()\n",
    "#           points = pf_feats[:,:,1:3]\n",
    "#           cls_emb = gnn.forward(points.reshape(points.shape[0], points.shape[2], points.shape[1])\n",
    "#                              , pf_feats.reshape(pf_feats.shape[0], pf_feats.shape[2], pf_feats.shape[1]), None)\n",
    "#           cls_emb = cls_emb.reshape(cls_emb.shape[0], cls_emb.shape[2], cls_emb.shape[1])\n",
    "#           cls_emb = cls_emb.reshape(cls_emb.shape[0]*cls_emb.shape[1], cls_emb.shape[2])\n",
    "\n",
    "#           # cls_emb = batched_graph.ndata[\"node_attr\"].float()\n",
    "#           cls_emb = global_mean_pool(cls_emb, batch_t)\n",
    "#           cls_embds = torch.cat((cls_embds, cls_emb.detach()), 0)     #cls_emb\n",
    "#           cls_labels = torch.cat((cls_labels, labels))\n",
    "\n",
    "#     cls_epochs = 1000\n",
    "#     cls_train_data = cls_embds[ : int(0.8*len(cls_embds))]\n",
    "#     targets = cls_labels[ : int(0.8*len(cls_embds))]\n",
    "#     cls_test_data = cls_embds[int(0.8*len(cls_embds)) : ]\n",
    "#     testtargets = cls_labels[int(0.8*len(cls_embds)) : ]\n",
    "\n",
    "#     cls_loss, cls_accuracy, test_cls_loss, test_cls_accuracy, fpr, tpr, auc, eB, eS, f1_score, imtafe = train_classifier(cls_epochs, classifier, cls_train_data, targets, cls_test_data, testtargets)\n",
    "\n",
    "#     # Print the performance metrics\n",
    "#     print(f'Imtafe (other metrics): {imtafe}')\n",
    "\n",
    "#     print('Accuracy : ', max(test_cls_accuracy))\n",
    "#     print('AUC : ', auc)\n",
    "#     print('F1 score : ', f1_score)\n",
    "#     # Print or log results for comparison\n",
    "#     print(f\"Finished training with parameter: {paramx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e3b74fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:31:51.230696Z",
     "iopub.status.busy": "2024-10-15T09:31:51.230257Z",
     "iopub.status.idle": "2024-10-15T09:31:51.240146Z",
     "shell.execute_reply": "2024-10-15T09:31:51.239141Z"
    },
    "papermill": {
     "duration": 0.084267,
     "end_time": "2024-10-15T09:31:51.242396",
     "exception": false,
     "start_time": "2024-10-15T09:31:51.158129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # input dimension\n",
    "\n",
    "# parameters = [5,6,7,8,9,10]\n",
    "\n",
    "# for paramx in parameters:\n",
    "#     # Set up model\n",
    "#     device = 'cuda'\n",
    "#     num_layer_gnn = 2\n",
    "#     num_layer_gnn_est = 2\n",
    "#     qnn_layers = 3\n",
    "#     emb_dim = 128 # classical\n",
    "#     in_dim = paramx # 8\n",
    "#     inter_dim = 256 # gnn\n",
    "#     out_dim = 128 # don't change\n",
    "#     JK = 'last' # unchanged\n",
    "#     dropout_ratio = 0.1 # classical\n",
    "#     gnn_type = 'gat' # unchanged\n",
    "#     lr = 0.001\n",
    "#     decay = 0\n",
    "#     aug_ratio = 0.1\n",
    "#     batch_size = 2000\n",
    "#     loss_temp = 0.1\n",
    "#     lamda = 0.1\n",
    "#     node_est = 'quantum'\n",
    "#     entanglement_type = 'CNOT'\n",
    "#     encoding_type = 'RY'\n",
    "    \n",
    "#     # Dataset\n",
    "#     qg_dataset = QuarkGluonGraphDataset(dataset_name='Quark Gluon', raw_dir=main_dir, save_dir='/content',\n",
    "#                                         data_folder_name=jet_folder_path, datafile_name=jet_file_path, labelsfile_name=jet_file_path,\n",
    "#                                         datatype='particles', dataset_size=10000, nodes_per_graph=nodes_per_graph_original,\n",
    "#                                         spectral_augmentation=False, irc_safety_aug=True, device='cuda')\n",
    "    \n",
    "#     # Model\n",
    "#     gnn = ParticleNetTagger1Path(in_dim, 2)\n",
    "#     if node_est == 'classical':\n",
    "#         node_imp_estimator = GNN_imp_estimator(num_layer=num_layer_gnn_est, emb_dim=emb_dim, in_dim=in_dim, JK=JK, drop_ratio=dropout_ratio)\n",
    "#     if node_est == 'quantum':\n",
    "#         node_imp_estimator = QGNN_node_estimator(nodes_per_graph_original, qnn_layers, in_dim, device=device,\n",
    "#                                                  entanglement_type=entanglement_type, encoding_type=encoding_type)\n",
    "    \n",
    "#     model = graphcl(gnn, node_imp_estimator, emb_dim, out_dim)\n",
    "#     model.to(device)\n",
    "    \n",
    "#     # Optimizer with current learning rate\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=decay)\n",
    "\n",
    "\n",
    "# ############## after training ###############\n",
    "#     epochs = 50\n",
    "#     con_loss = []\n",
    "\n",
    "#     for epoch in range(1, epochs + 1):\n",
    "#         print(\"====epoch \" + str(epoch))\n",
    "#         qg_dataset.augment = False\n",
    "#         train_loss, ra_loss, cp_loss, uni_loss, al_loss = train(epoch, model=model, device=device, dataset=qg_dataset, optimizer=optimizer, batch_size=batch_size,\n",
    "#                                           nodes_per_graph=qg_dataset.nodes_per_graph, aug_ratio=aug_ratio, loss_temp=loss_temp, lamda=lamda,\n",
    "#                                           irc_safety=True, q_edge_attr=True, node_est=node_est)\n",
    "#         con_loss.append(train_loss)\n",
    "#         print(train_loss)\n",
    "#         print(ra_loss)\n",
    "#         print(cp_loss)\n",
    "#         print('UNI : ', uni_loss)\n",
    "#         print('ALIGN : ', al_loss)\n",
    "\n",
    "#     # nodes_per_graph_original = 10\n",
    "#     test_dataset = QuarkGluonGraphDataset(dataset_name='Quark Gluon', raw_dir=main_dir, save_dir='/content',\n",
    "#                                         data_folder_name=jet_folder_path, datafile_name=jet_file_path, labelsfile_name=jet_file_path,\n",
    "#                                         datatype='particles', dataset_size=7000, nodes_per_graph=nodes_per_graph_original, spectral_augmentation=False, irc_safety_aug=True,\n",
    "#                                         device='cuda')\n",
    "\n",
    "#     test_samples = torch.tensor(np.arange(2000,7000).astype('int32'))\n",
    "#     test_sampler = SubsetRandomSampler(test_samples)\n",
    "\n",
    "#     test_dataloader = test_dataloader = GraphDataLoader(\n",
    "#         test_dataset, sampler=test_sampler, batch_size=500, drop_last=False\n",
    "#     )\n",
    "\n",
    "#     cls_embds = torch.Tensor([])\n",
    "#     cls_labels = torch.Tensor([])\n",
    "\n",
    "#     for batched_graph, labels in test_dataloader:\n",
    "#           graphs = []\n",
    "#           unbatched_graph = dgl.unbatch(batched_graph)\n",
    "#           for graph in unbatched_graph:\n",
    "#             graphs.append(dgl.add_self_loop(graph))\n",
    "#           batched_graph = dgl.batch(graphs)\n",
    "#           batch_t = torch.arange(0, batched_graph.batch_size).reshape(-1,1).expand(batched_graph.batch_size, test_dataset.nodes_per_graph).reshape(-1,)\n",
    "\n",
    "#           ## For custom GNN\n",
    "#           # cls_emb = gnn.forward(batched_graph.ndata[\"node_attr\"].float(), torch.stack(batched_graph.edges()), batched_graph.edata[\"edge_attr\"].float())\n",
    "\n",
    "#           ## For ParticleNet\n",
    "#           pf_feats = batched_graph.ndata[\"node_attr\"].reshape(len(unbatched_graph), nodes_per_graph_original, -1).float()\n",
    "#           points = pf_feats[:,:,1:3]\n",
    "#           cls_emb = gnn.forward(points.reshape(points.shape[0], points.shape[2], points.shape[1])\n",
    "#                              , pf_feats.reshape(pf_feats.shape[0], pf_feats.shape[2], pf_feats.shape[1]), None)\n",
    "#           cls_emb = cls_emb.reshape(cls_emb.shape[0], cls_emb.shape[2], cls_emb.shape[1])\n",
    "#           cls_emb = cls_emb.reshape(cls_emb.shape[0]*cls_emb.shape[1], cls_emb.shape[2])\n",
    "\n",
    "#           # cls_emb = batched_graph.ndata[\"node_attr\"].float()\n",
    "#           cls_emb = global_mean_pool(cls_emb, batch_t)\n",
    "#           cls_embds = torch.cat((cls_embds, cls_emb.detach()), 0)     #cls_emb\n",
    "#           cls_labels = torch.cat((cls_labels, labels))\n",
    "\n",
    "#     cls_epochs = 1000\n",
    "#     cls_train_data = cls_embds[ : int(0.8*len(cls_embds))]\n",
    "#     targets = cls_labels[ : int(0.8*len(cls_embds))]\n",
    "#     cls_test_data = cls_embds[int(0.8*len(cls_embds)) : ]\n",
    "#     testtargets = cls_labels[int(0.8*len(cls_embds)) : ]\n",
    "\n",
    "#     cls_loss, cls_accuracy, test_cls_loss, test_cls_accuracy, fpr, tpr, auc, eB, eS, f1_score, imtafe = train_classifier(cls_epochs, classifier, cls_train_data, targets, cls_test_data, testtargets)\n",
    "\n",
    "#     # Print the performance metrics\n",
    "#     print(f'Imtafe (other metrics): {imtafe}')\n",
    "\n",
    "#     print('Accuracy : ', max(test_cls_accuracy))\n",
    "#     print('AUC : ', auc)\n",
    "#     print('F1 score : ', f1_score)\n",
    "#     # Print or log results for comparison\n",
    "#     print(f\"Finished training with parameter: {paramx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9393b74b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:31:51.373282Z",
     "iopub.status.busy": "2024-10-15T09:31:51.372890Z",
     "iopub.status.idle": "2024-10-15T09:31:51.382247Z",
     "shell.execute_reply": "2024-10-15T09:31:51.381275Z"
    },
    "papermill": {
     "duration": 0.075934,
     "end_time": "2024-10-15T09:31:51.384236",
     "exception": false,
     "start_time": "2024-10-15T09:31:51.308302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # augmentation ratio\n",
    "\n",
    "# parameters = [0.2, 0.3, 0.1, 0.4]\n",
    "\n",
    "# for paramx in parameters:\n",
    "#     # Set up model\n",
    "#     device = 'cuda'\n",
    "#     num_layer_gnn = 2\n",
    "#     num_layer_gnn_est = 2\n",
    "#     qnn_layers = 3\n",
    "#     emb_dim = 128\n",
    "#     in_dim = 8\n",
    "#     inter_dim = 256\n",
    "#     out_dim = 128\n",
    "#     JK = 'last'\n",
    "#     dropout_ratio = 0.1 \n",
    "#     gnn_type = 'gat'\n",
    "#     lr = 0.001\n",
    "#     decay = 0\n",
    "#     aug_ratio = paramx # 0.1\n",
    "#     batch_size = 2000\n",
    "#     loss_temp = 0.1\n",
    "#     lamda = 0.1\n",
    "#     node_est = 'quantum'\n",
    "#     entanglement_type = 'CNOT'\n",
    "#     encoding_type = 'RY'\n",
    "    \n",
    "#     # Dataset\n",
    "#     qg_dataset = QuarkGluonGraphDataset(dataset_name='Quark Gluon', raw_dir=main_dir, save_dir='/content',\n",
    "#                                         data_folder_name=jet_folder_path, datafile_name=jet_file_path, labelsfile_name=jet_file_path,\n",
    "#                                         datatype='particles', dataset_size=10000, nodes_per_graph=nodes_per_graph_original,\n",
    "#                                         spectral_augmentation=False, irc_safety_aug=True, device='cuda')\n",
    "    \n",
    "#     # Model\n",
    "#     gnn = ParticleNetTagger1Path(in_dim, 2)\n",
    "#     if node_est == 'classical':\n",
    "#         node_imp_estimator = GNN_imp_estimator(num_layer=num_layer_gnn_est, emb_dim=emb_dim, in_dim=in_dim, JK=JK, drop_ratio=dropout_ratio)\n",
    "#     if node_est == 'quantum':\n",
    "#         node_imp_estimator = QGNN_node_estimator(nodes_per_graph_original, qnn_layers, in_dim, device=device,\n",
    "#                                                  entanglement_type=entanglement_type, encoding_type=encoding_type)\n",
    "    \n",
    "#     model = graphcl(gnn, node_imp_estimator, emb_dim, out_dim)\n",
    "#     model.to(device)\n",
    "    \n",
    "#     # Optimizer with current learning rate\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=decay)\n",
    "\n",
    "\n",
    "# ############## after training ###############\n",
    "#     epochs = 50\n",
    "#     con_loss = []\n",
    "\n",
    "#     for epoch in range(1, epochs + 1):\n",
    "#         print(\"====epoch \" + str(epoch))\n",
    "#         qg_dataset.augment = False\n",
    "#         train_loss, ra_loss, cp_loss, uni_loss, al_loss = train(epoch, model=model, device=device, dataset=qg_dataset, optimizer=optimizer, batch_size=batch_size,\n",
    "#                                           nodes_per_graph=qg_dataset.nodes_per_graph, aug_ratio=aug_ratio, loss_temp=loss_temp, lamda=lamda,\n",
    "#                                           irc_safety=True, q_edge_attr=True, node_est=node_est)\n",
    "#         con_loss.append(train_loss)\n",
    "#         print(train_loss)\n",
    "#         print(ra_loss)\n",
    "#         print(cp_loss)\n",
    "#         print('UNI : ', uni_loss)\n",
    "#         print('ALIGN : ', al_loss)\n",
    "\n",
    "#     # nodes_per_graph_original = 10\n",
    "#     test_dataset = QuarkGluonGraphDataset(dataset_name='Quark Gluon', raw_dir=main_dir, save_dir='/content',\n",
    "#                                         data_folder_name=jet_folder_path, datafile_name=jet_file_path, labelsfile_name=jet_file_path,\n",
    "#                                         datatype='particles', dataset_size=7000, nodes_per_graph=nodes_per_graph_original, spectral_augmentation=False, irc_safety_aug=True,\n",
    "#                                         device='cuda')\n",
    "\n",
    "#     test_samples = torch.tensor(np.arange(2000,7000).astype('int32'))\n",
    "#     test_sampler = SubsetRandomSampler(test_samples)\n",
    "\n",
    "#     test_dataloader = test_dataloader = GraphDataLoader(\n",
    "#         test_dataset, sampler=test_sampler, batch_size=500, drop_last=False\n",
    "#     )\n",
    "\n",
    "#     cls_embds = torch.Tensor([])\n",
    "#     cls_labels = torch.Tensor([])\n",
    "\n",
    "#     for batched_graph, labels in test_dataloader:\n",
    "#           graphs = []\n",
    "#           unbatched_graph = dgl.unbatch(batched_graph)\n",
    "#           for graph in unbatched_graph:\n",
    "#             graphs.append(dgl.add_self_loop(graph))\n",
    "#           batched_graph = dgl.batch(graphs)\n",
    "#           batch_t = torch.arange(0, batched_graph.batch_size).reshape(-1,1).expand(batched_graph.batch_size, test_dataset.nodes_per_graph).reshape(-1,)\n",
    "\n",
    "#           ## For custom GNN\n",
    "#           # cls_emb = gnn.forward(batched_graph.ndata[\"node_attr\"].float(), torch.stack(batched_graph.edges()), batched_graph.edata[\"edge_attr\"].float())\n",
    "\n",
    "#           ## For ParticleNet\n",
    "#           pf_feats = batched_graph.ndata[\"node_attr\"].reshape(len(unbatched_graph), nodes_per_graph_original, -1).float()\n",
    "#           points = pf_feats[:,:,1:3]\n",
    "#           cls_emb = gnn.forward(points.reshape(points.shape[0], points.shape[2], points.shape[1])\n",
    "#                              , pf_feats.reshape(pf_feats.shape[0], pf_feats.shape[2], pf_feats.shape[1]), None)\n",
    "#           cls_emb = cls_emb.reshape(cls_emb.shape[0], cls_emb.shape[2], cls_emb.shape[1])\n",
    "#           cls_emb = cls_emb.reshape(cls_emb.shape[0]*cls_emb.shape[1], cls_emb.shape[2])\n",
    "\n",
    "#           # cls_emb = batched_graph.ndata[\"node_attr\"].float()\n",
    "#           cls_emb = global_mean_pool(cls_emb, batch_t)\n",
    "#           cls_embds = torch.cat((cls_embds, cls_emb.detach()), 0)     #cls_emb\n",
    "#           cls_labels = torch.cat((cls_labels, labels))\n",
    "\n",
    "#     cls_epochs = 1000\n",
    "#     cls_train_data = cls_embds[ : int(0.8*len(cls_embds))]\n",
    "#     targets = cls_labels[ : int(0.8*len(cls_embds))]\n",
    "#     cls_test_data = cls_embds[int(0.8*len(cls_embds)) : ]\n",
    "#     testtargets = cls_labels[int(0.8*len(cls_embds)) : ]\n",
    "\n",
    "#     cls_loss, cls_accuracy, test_cls_loss, test_cls_accuracy, fpr, tpr, auc, eB, eS, f1_score, imtafe = train_classifier(cls_epochs, classifier, cls_train_data, targets, cls_test_data, testtargets)\n",
    "\n",
    "#     # Print the performance metrics\n",
    "#     print(f'Imtafe (other metrics): {imtafe}')\n",
    "\n",
    "#     print('Accuracy : ', max(test_cls_accuracy))\n",
    "#     print('AUC : ', auc)\n",
    "#     print('F1 score : ', f1_score)\n",
    "#     # Print or log results for comparison\n",
    "#     print(f\"Finished training with parameter: {paramx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2787abb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:31:51.516364Z",
     "iopub.status.busy": "2024-10-15T09:31:51.515996Z",
     "iopub.status.idle": "2024-10-15T09:31:51.525097Z",
     "shell.execute_reply": "2024-10-15T09:31:51.524227Z"
    },
    "papermill": {
     "duration": 0.079928,
     "end_time": "2024-10-15T09:31:51.527143",
     "exception": false,
     "start_time": "2024-10-15T09:31:51.447215",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # encoding type\n",
    "\n",
    "# parameters = ['AmplitudeEncoding', 'DisplacementEncoding']\n",
    "\n",
    "# for paramx in parameters:\n",
    "#     # Set up model\n",
    "#     device = 'cuda'\n",
    "#     num_layer_gnn = 2\n",
    "#     num_layer_gnn_est = 2\n",
    "#     qnn_layers = 3\n",
    "#     emb_dim = 128\n",
    "#     in_dim = 8\n",
    "#     inter_dim = 256\n",
    "#     out_dim = 128\n",
    "#     JK = 'last'\n",
    "#     dropout_ratio = 0.1 \n",
    "#     gnn_type = 'gat'\n",
    "#     lr = 0.001\n",
    "#     decay = 0\n",
    "#     aug_ratio = 0.1\n",
    "#     batch_size = 2000\n",
    "#     loss_temp = 0.1\n",
    "#     lamda = 0.1\n",
    "#     node_est = 'quantum'\n",
    "#     entanglement_type = 'CNOT'\n",
    "#     encoding_type = paramx #'RY'\n",
    "    \n",
    "#     # Dataset\n",
    "#     qg_dataset = QuarkGluonGraphDataset(dataset_name='Quark Gluon', raw_dir=main_dir, save_dir='/content',\n",
    "#                                         data_folder_name=jet_folder_path, datafile_name=jet_file_path, labelsfile_name=jet_file_path,\n",
    "#                                         datatype='particles', dataset_size=10000, nodes_per_graph=nodes_per_graph_original,\n",
    "#                                         spectral_augmentation=False, irc_safety_aug=True, device='cuda')\n",
    "    \n",
    "#     # Model\n",
    "#     gnn = ParticleNetTagger1Path(in_dim, 2)\n",
    "#     if node_est == 'classical':\n",
    "#         node_imp_estimator = GNN_imp_estimator(num_layer=num_layer_gnn_est, emb_dim=emb_dim, in_dim=in_dim, JK=JK, drop_ratio=dropout_ratio)\n",
    "#     if node_est == 'quantum':\n",
    "#         node_imp_estimator = QGNN_node_estimator(nodes_per_graph_original, qnn_layers, in_dim, device=device,\n",
    "#                                                  entanglement_type=entanglement_type, encoding_type=encoding_type)\n",
    "    \n",
    "#     model = graphcl(gnn, node_imp_estimator, emb_dim, out_dim)\n",
    "#     model.to(device)\n",
    "    \n",
    "#     # Optimizer with current learning rate\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=decay)\n",
    "\n",
    "\n",
    "# ############## after training ###############\n",
    "#     epochs = 50\n",
    "#     con_loss = []\n",
    "\n",
    "#     for epoch in range(1, epochs + 1):\n",
    "#         print(\"====epoch \" + str(epoch))\n",
    "#         qg_dataset.augment = False\n",
    "#         train_loss, ra_loss, cp_loss, uni_loss, al_loss = train(epoch, model=model, device=device, dataset=qg_dataset, optimizer=optimizer, batch_size=batch_size,\n",
    "#                                           nodes_per_graph=qg_dataset.nodes_per_graph, aug_ratio=aug_ratio, loss_temp=loss_temp, lamda=lamda,\n",
    "#                                           irc_safety=True, q_edge_attr=True, node_est=node_est)\n",
    "#         con_loss.append(train_loss)\n",
    "#         print(train_loss)\n",
    "#         print(ra_loss)\n",
    "#         print(cp_loss)\n",
    "#         print('UNI : ', uni_loss)\n",
    "#         print('ALIGN : ', al_loss)\n",
    "\n",
    "#     # nodes_per_graph_original = 10\n",
    "#     test_dataset = QuarkGluonGraphDataset(dataset_name='Quark Gluon', raw_dir=main_dir, save_dir='/content',\n",
    "#                                         data_folder_name=jet_folder_path, datafile_name=jet_file_path, labelsfile_name=jet_file_path,\n",
    "#                                         datatype='particles', dataset_size=7000, nodes_per_graph=nodes_per_graph_original, spectral_augmentation=False, irc_safety_aug=True,\n",
    "#                                         device='cuda')\n",
    "\n",
    "#     test_samples = torch.tensor(np.arange(2000,7000).astype('int32'))\n",
    "#     test_sampler = SubsetRandomSampler(test_samples)\n",
    "\n",
    "#     test_dataloader = GraphDataLoader(\n",
    "#         test_dataset, sampler=test_sampler, batch_size=500, drop_last=False\n",
    "#     )\n",
    "\n",
    "#     cls_embds = torch.Tensor([])\n",
    "#     cls_labels = torch.Tensor([])\n",
    "\n",
    "#     for batched_graph, labels in test_dataloader:\n",
    "#           graphs = []\n",
    "#           unbatched_graph = dgl.unbatch(batched_graph)\n",
    "#           for graph in unbatched_graph:\n",
    "#             graphs.append(dgl.add_self_loop(graph))\n",
    "#           batched_graph = dgl.batch(graphs)\n",
    "#           batch_t = torch.arange(0, batched_graph.batch_size).reshape(-1,1).expand(batched_graph.batch_size, test_dataset.nodes_per_graph).reshape(-1,)\n",
    "\n",
    "#           ## For custom GNN\n",
    "#           # cls_emb = gnn.forward(batched_graph.ndata[\"node_attr\"].float(), torch.stack(batched_graph.edges()), batched_graph.edata[\"edge_attr\"].float())\n",
    "\n",
    "#           ## For ParticleNet\n",
    "#           pf_feats = batched_graph.ndata[\"node_attr\"].reshape(len(unbatched_graph), nodes_per_graph_original, -1).float()\n",
    "#           points = pf_feats[:,:,1:3]\n",
    "#           cls_emb = gnn.forward(points.reshape(points.shape[0], points.shape[2], points.shape[1])\n",
    "#                              , pf_feats.reshape(pf_feats.shape[0], pf_feats.shape[2], pf_feats.shape[1]), None)\n",
    "#           cls_emb = cls_emb.reshape(cls_emb.shape[0], cls_emb.shape[2], cls_emb.shape[1])\n",
    "#           cls_emb = cls_emb.reshape(cls_emb.shape[0]*cls_emb.shape[1], cls_emb.shape[2])\n",
    "\n",
    "#           # cls_emb = batched_graph.ndata[\"node_attr\"].float()\n",
    "#           cls_emb = global_mean_pool(cls_emb, batch_t)\n",
    "#           cls_embds = torch.cat((cls_embds, cls_emb.detach()), 0)     #cls_emb\n",
    "#           cls_labels = torch.cat((cls_labels, labels))\n",
    "\n",
    "#     cls_epochs = 1000\n",
    "#     cls_train_data = cls_embds[ : int(0.8*len(cls_embds))]\n",
    "#     targets = cls_labels[ : int(0.8*len(cls_embds))]\n",
    "#     cls_test_data = cls_embds[int(0.8*len(cls_embds)) : ]\n",
    "#     testtargets = cls_labels[int(0.8*len(cls_embds)) : ]\n",
    "\n",
    "#     cls_loss, cls_accuracy, test_cls_loss, test_cls_accuracy, fpr, tpr, auc, eB, eS, f1_score, imtafe = train_classifier(cls_epochs, classifier, cls_train_data, targets, cls_test_data, testtargets)\n",
    "\n",
    "#     # Print the performance metrics\n",
    "#     print(f'Imtafe (other metrics): {imtafe}')\n",
    "\n",
    "#     print('Accuracy : ', max(test_cls_accuracy))\n",
    "#     print('AUC : ', auc)\n",
    "#     print('F1 score : ', f1_score)\n",
    "#     # Print or log results for comparison\n",
    "#     print(f\"Finished training with parameter: {paramx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf8b2e7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:31:51.656505Z",
     "iopub.status.busy": "2024-10-15T09:31:51.656094Z",
     "iopub.status.idle": "2024-10-15T09:31:51.688397Z",
     "shell.execute_reply": "2024-10-15T09:31:51.687322Z"
    },
    "papermill": {
     "duration": 0.099929,
     "end_time": "2024-10-15T09:31:51.690630",
     "exception": false,
     "start_time": "2024-10-15T09:31:51.590701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchquantum as tq\n",
    "\n",
    "class BetterBetterTorchLayer(torch.nn.Module):\n",
    "    def __init__(self, nodes_per_graph, num_layers, input_dim, device, entanglement_type='CNOT', encoding_type='RY'):\n",
    "        super(BetterBetterTorchLayer, self).__init__()\n",
    "        self.device = device\n",
    "        self.num_qubits = nodes_per_graph\n",
    "        self.entanglement_type = entanglement_type\n",
    "        self.encoding_type = encoding_type  # Encoding type\n",
    "        inputs = []\n",
    "        self.node_attr_count = 0\n",
    "        self.amplitude_encoding = False\n",
    "        self.IQP_encoding = False\n",
    "        self.displacement_encoding = False\n",
    "        \n",
    "        # Choose the type of encoding\n",
    "        if self.encoding_type == 'AmplitudeEncoding':\n",
    "            self.amplitude_encoding = True\n",
    "        elif self.encoding_type == 'IQPEncoding':\n",
    "            self.IQP_encoding = True\n",
    "        elif self.encoding_type == 'DisplacementEncoding':\n",
    "            self.displacement_encoding = True\n",
    "        else:\n",
    "            self.amplitude_encoding = False\n",
    "            self.IQP_encoding = False\n",
    "            self.displacement_encoding = False\n",
    "\n",
    "        # Standard gate encoding for node attributes\n",
    "        q_control = 0  # Define the control qubit as the first qubit (you can modify this as needed)\n",
    "        q2 = 1  # Define a second qubit for gates like SWAP (you can modify this as well)\n",
    "        theta, phi, lambda_ = 0.5, 0.3, 0.1  # Example values for U3 gate parameters (adjustable)\n",
    "\n",
    "        if not self.amplitude_encoding and not self.IQP_encoding and not self.displacement_encoding:\n",
    "            for q in range(self.num_qubits):\n",
    "                for d in range(input_dim):\n",
    "                    if self.encoding_type == 'RY':\n",
    "                        # Y-axis rotation encoding\n",
    "                        inputs.append({'input_idx': self.node_attr_count, 'func': 'ry', 'wires': [q]})\n",
    "                    \n",
    "                    elif self.encoding_type == 'RZ':\n",
    "                        # Z-axis rotation encoding\n",
    "                        inputs.append({'input_idx': self.node_attr_count, 'func': 'rz', 'wires': [q]})\n",
    "                    \n",
    "                    elif self.encoding_type == 'RX':\n",
    "                        # X-axis rotation encoding\n",
    "                        inputs.append({'input_idx': self.node_attr_count, 'func': 'rx', 'wires': [q]})\n",
    "                    \n",
    "                    elif self.encoding_type == 'H':\n",
    "                        # Hadamard gate encoding for superposition\n",
    "                        inputs.append({'input_idx': self.node_attr_count, 'func': 'h', 'wires': [q]})\n",
    "                    \n",
    "                    elif self.encoding_type == 'Phase':\n",
    "                        # Phase gate encoding\n",
    "                        inputs.append({'input_idx': self.node_attr_count, 'func': 'p', 'wires': [q]})\n",
    "                    \n",
    "                    self.node_attr_count += 1\n",
    "\n",
    "            # Prepare edge inputs\n",
    "            self.edge_attr_count = self.node_attr_count + 1\n",
    "            for q in range(self.num_qubits):\n",
    "                for e in range(q + 1, self.num_qubits):\n",
    "                    inputs.append({'input_idx': self.edge_attr_count, 'func': 'crz', 'wires': [q, e]})\n",
    "                    self.edge_attr_count += 1\n",
    "            self.edge_attr_count -= self.node_attr_count\n",
    "\n",
    "        self.encoder = tq.GeneralEncoder(inputs)\n",
    "        self.q_layers = tq.QuantumModuleList()\n",
    "\n",
    "        # Build quantum layers with entanglement\n",
    "        for layer in range(num_layers):\n",
    "            self.q_layers.append(\n",
    "                tq.Op1QAllLayer(op=tq.RX, n_wires=self.num_qubits, has_params=True, trainable=True)\n",
    "            )\n",
    "            self.q_layers.append(\n",
    "                tq.Op1QAllLayer(op=tq.RY, n_wires=self.num_qubits, has_params=True, trainable=True)\n",
    "            )\n",
    "            self.q_layers.append(\n",
    "                tq.Op1QAllLayer(op=tq.RZ, n_wires=self.num_qubits, has_params=True, trainable=True)\n",
    "            )\n",
    "\n",
    "            # Apply entanglement layer based on selected type\n",
    "            if self.entanglement_type == 'CNOT':\n",
    "                self.q_layers.append(\n",
    "                    tq.Op2QAllLayer(op=tq.CNOT, n_wires=self.num_qubits, jump=(layer + 1) % (self.num_qubits - 1), circular=True)\n",
    "                )\n",
    "            elif self.entanglement_type == 'CZ':\n",
    "                self.q_layers.append(\n",
    "                    tq.Op2QAllLayer(op=tq.CZ, n_wires=self.num_qubits, jump=(layer + 1) % (self.num_qubits - 1), circular=True)\n",
    "                )\n",
    "            elif self.entanglement_type == 'SWAP':\n",
    "                self.q_layers.append(\n",
    "                    tq.Op2QAllLayer(op=tq.SWAP, n_wires=self.num_qubits, jump=(layer + 1) % (self.num_qubits - 1), circular=True)\n",
    "                )\n",
    "            elif self.entanglement_type == 'CNOTbutterfly':\n",
    "                self.q_layers.append(\n",
    "                    tq.Op2QButterflyLayer(op=tq.CNOT, n_wires=self.num_qubits, has_params=False, trainable=False, wire_reverse=False)\n",
    "                )\n",
    "            elif self.entanglement_type == 'CZbutterfly':\n",
    "                self.q_layers.append(\n",
    "                    tq.Op2QButterflyLayer(op=tq.CZ, n_wires=self.num_qubits, has_params=False, trainable=False, wire_reverse=False)\n",
    "                )\n",
    "            elif self.entanglement_type == 'SWAPbutterfly':\n",
    "                self.q_layers.append(\n",
    "                    tq.Op2QButterflyLayer(op=tq.SWAP, n_wires=self.num_qubits, has_params=False, trainable=False, wire_reverse=False)\n",
    "                )\n",
    "\n",
    "\n",
    "    def forward(self, node_inputs, node_indices, edge_inputs):\n",
    "        qdev = tq.QuantumDevice(n_wires=self.num_qubits, bsz=node_inputs.shape[0], device=self.device, record_op=True)\n",
    "\n",
    "        if self.amplitude_encoding:\n",
    "            # Convert to a size that is a power of 2\n",
    "            converted_data = pad_or_truncate_to_power_of_two(node_inputs)\n",
    "            # Normalize the data\n",
    "            normalized_data = normalize_data(converted_data)\n",
    "            # Initialize the amplitude embedding layer\n",
    "            amplitude_encoder = AmplitudeEmbedding(num_qubits=self.num_qubits, normalize=False, pad_with=0.0)\n",
    "            # Apply amplitude encoding\n",
    "            amplitude_encoder(qdev, normalized_data)\n",
    "\n",
    "        elif self.IQP_encoding:\n",
    "            # Initialize the circuit\n",
    "            encoder = IQPEmbedding(wires=range(self.num_qubits), n_repeats=3)\n",
    "            # Apply the circuit to the quantum device\n",
    "            encoder(qdev, node_inputs)\n",
    "\n",
    "        elif self.displacement_encoding:\n",
    "            # Initialize the circuit\n",
    "            encoder = DisplacementEmbedding(n_features=self.num_qubits, wires=list(range(self.num_qubits)), method=\"amplitude\") # \"amplitude\", \"phase\"\n",
    "            # Apply the circuit to the quantum device\n",
    "            encoder(qdev, node_inputs)\n",
    "\n",
    "        else:\n",
    "            # Default to gate encoding\n",
    "            self.encoder(qdev, torch.cat((node_inputs.reshape(node_inputs.shape[0], -1), edge_inputs.reshape(edge_inputs.shape[0], -1)), dim=1))\n",
    "\n",
    "        # Apply quantum layers\n",
    "        for l in range(len(self.q_layers)):\n",
    "            self.q_layers[l](qdev)\n",
    "\n",
    "        # Return the squared amplitude of the final quantum state\n",
    "        return torch.abs(qdev.get_states_1d()) ** 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e7692ee4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T09:31:51.822272Z",
     "iopub.status.busy": "2024-10-15T09:31:51.821872Z",
     "iopub.status.idle": "2024-10-15T10:16:29.301438Z",
     "shell.execute_reply": "2024-10-15T10:16:29.300488Z"
    },
    "papermill": {
     "duration": 2677.546101,
     "end_time": "2024-10-15T10:16:29.304011",
     "exception": false,
     "start_time": "2024-10-15T09:31:51.757910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Finding All Unique Particles ---\n",
      "\n",
      "--- Inserting Masses ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:00, 2840.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calculating Momenta and Energies ---\n",
      "\n",
      "--- Calculating Edge Tensors ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10000/10000 [00:16<00:00, 603.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating graphs ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10000/10000 [00:05<00:00, 1805.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====epoch 1\n",
      "5.553491878509521\n",
      "5.046589994430542\n",
      "5.069019317626953\n",
      "UNI :  -1.7709832191467285\n",
      "ALIGN :  0.17721537947654725\n",
      "====epoch 2\n",
      "3.792087125778198\n",
      "3.4393951416015627\n",
      "3.5269203662872313\n",
      "UNI :  -2.9864415645599367\n",
      "ALIGN :  0.2821631282567978\n",
      "====epoch 3\n",
      "3.2443585872650145\n",
      "2.9357951641082765\n",
      "3.0856342792510985\n",
      "UNI :  -3.2934274673461914\n",
      "ALIGN :  0.34813210368156433\n",
      "====epoch 4\n",
      "2.8909756660461428\n",
      "2.6096980571746826\n",
      "2.812776279449463\n",
      "UNI :  -3.454831266403198\n",
      "ALIGN :  0.3656076967716217\n",
      "====epoch 5\n",
      "2.650821018218994\n",
      "2.387614440917969\n",
      "2.6320653915405274\n",
      "UNI :  -3.5280832767486574\n",
      "ALIGN :  0.36794829964637754\n",
      "====epoch 6\n",
      "2.469573402404785\n",
      "2.2191949844360352\n",
      "2.5037840366363526\n",
      "UNI :  -3.578374242782593\n",
      "ALIGN :  0.36585658192634585\n",
      "====epoch 7\n",
      "2.2825785160064695\n",
      "2.0460792064666746\n",
      "2.3649927616119384\n",
      "UNI :  -3.6116716861724854\n",
      "ALIGN :  0.35385397672653196\n",
      "====epoch 8\n",
      "2.1733038425445557\n",
      "1.9435661077499389\n",
      "2.2973770618438722\n",
      "UNI :  -3.6351611614227295\n",
      "ALIGN :  0.3551230847835541\n",
      "====epoch 9\n",
      "2.0659708976745605\n",
      "1.8436981916427613\n",
      "2.222726821899414\n",
      "UNI :  -3.655454969406128\n",
      "ALIGN :  0.35421462059020997\n",
      "====epoch 10\n",
      "1.9663228511810302\n",
      "1.750296449661255\n",
      "2.1602641582489013\n",
      "UNI :  -3.671457052230835\n",
      "ALIGN :  0.3528198003768921\n",
      "====epoch 11\n",
      "1.8521477460861206\n",
      "1.6438849449157715\n",
      "2.0826279640197756\n",
      "UNI :  -3.685369110107422\n",
      "ALIGN :  0.34578053951263427\n",
      "====epoch 12\n",
      "1.7938221931457519\n",
      "1.5885987520217895\n",
      "2.0522343158721923\n",
      "UNI :  -3.6967599391937256\n",
      "ALIGN :  0.34626818299293516\n",
      "====epoch 13\n",
      "1.688009548187256\n",
      "1.4902202129364013\n",
      "1.97789306640625\n",
      "UNI :  -3.7065297603607177\n",
      "ALIGN :  0.3368592083454132\n",
      "====epoch 14\n",
      "1.6234794855117798\n",
      "1.4293154716491698\n",
      "1.9416401386260986\n",
      "UNI :  -3.7183900356292723\n",
      "ALIGN :  0.3359649062156677\n",
      "====epoch 15\n",
      "1.5724728584289551\n",
      "1.3809273004531861\n",
      "1.9154554605484009\n",
      "UNI :  -3.7280430793762207\n",
      "ALIGN :  0.336895227432251\n",
      "====epoch 16\n",
      "1.5180787086486816\n",
      "1.329961395263672\n",
      "1.8811734437942504\n",
      "UNI :  -3.735740327835083\n",
      "ALIGN :  0.3349299967288971\n",
      "====epoch 17\n",
      "1.4450120449066162\n",
      "1.2618213653564454\n",
      "1.8319069862365722\n",
      "UNI :  -3.742475652694702\n",
      "ALIGN :  0.3282152533531189\n",
      "====epoch 18\n",
      "1.3868081331253053\n",
      "1.206975245475769\n",
      "1.798328733444214\n",
      "UNI :  -3.7485830783843994\n",
      "ALIGN :  0.32392346262931826\n",
      "====epoch 19\n",
      "1.3522736072540282\n",
      "1.173966360092163\n",
      "1.7830726623535156\n",
      "UNI :  -3.7526625633239745\n",
      "ALIGN :  0.32238091230392457\n",
      "====epoch 20\n",
      "1.3111842155456543\n",
      "1.1352993488311767\n",
      "1.7588483810424804\n",
      "UNI :  -3.75791335105896\n",
      "ALIGN :  0.3214828908443451\n",
      "====epoch 21\n",
      "1.2725276708602906\n",
      "1.0993061304092406\n",
      "1.732215690612793\n",
      "UNI :  -3.7633553981781005\n",
      "ALIGN :  0.3203322350978851\n",
      "====epoch 22\n",
      "1.2118008136749268\n",
      "1.0421950817108154\n",
      "1.6960570096969605\n",
      "UNI :  -3.7673943519592283\n",
      "ALIGN :  0.31323354244232177\n",
      "====epoch 23\n",
      "1.1940801382064818\n",
      "1.0251178026199341\n",
      "1.689623236656189\n",
      "UNI :  -3.7684281349182127\n",
      "ALIGN :  0.31389018297195437\n",
      "====epoch 24\n",
      "1.1445244312286378\n",
      "0.978606355190277\n",
      "1.6591807842254638\n",
      "UNI :  -3.7723717212677004\n",
      "ALIGN :  0.3100598812103271\n",
      "====epoch 25\n",
      "1.102012848854065\n",
      "0.9388025045394898\n",
      "1.632103681564331\n",
      "UNI :  -3.7755391120910646\n",
      "ALIGN :  0.30511545538902285\n",
      "====epoch 26\n",
      "1.0843814373016358\n",
      "0.9220883131027222\n",
      "1.6229309797286988\n",
      "UNI :  -3.777166318893433\n",
      "ALIGN :  0.3056180953979492\n",
      "====epoch 27\n",
      "1.0403709411621094\n",
      "0.8806633710861206\n",
      "1.5970756769180299\n",
      "UNI :  -3.7811902523040772\n",
      "ALIGN :  0.3024752140045166\n",
      "====epoch 28\n",
      "0.9822811007499694\n",
      "0.8260327816009522\n",
      "1.562483286857605\n",
      "UNI :  -3.7862340927124025\n",
      "ALIGN :  0.29711090922355654\n",
      "====epoch 29\n",
      "0.9723814487457275\n",
      "0.8164560914039611\n",
      "1.5592536211013794\n",
      "UNI :  -3.790140914916992\n",
      "ALIGN :  0.29791719913482667\n",
      "====epoch 30\n",
      "0.9522217392921448\n",
      "0.7970440745353699\n",
      "1.5517764329910277\n",
      "UNI :  -3.794932556152344\n",
      "ALIGN :  0.2985613226890564\n",
      "====epoch 31\n",
      "0.9137937903404236\n",
      "0.7608703732490539\n",
      "1.529234027862549\n",
      "UNI :  -3.7969672203063967\n",
      "ALIGN :  0.29425902366638185\n",
      "====epoch 32\n",
      "0.8665796279907226\n",
      "0.7163899898529053\n",
      "1.5018961906433106\n",
      "UNI :  -3.79993257522583\n",
      "ALIGN :  0.2895170092582703\n",
      "====epoch 33\n",
      "0.8631385803222656\n",
      "0.7131817698478699\n",
      "1.4995680570602417\n",
      "UNI :  -3.8035066604614256\n",
      "ALIGN :  0.2930436134338379\n",
      "====epoch 34\n",
      "0.8026561498641968\n",
      "0.6565829873085022\n",
      "1.4607314109802245\n",
      "UNI :  -3.805638647079468\n",
      "ALIGN :  0.2846965670585632\n",
      "====epoch 35\n",
      "0.8019249439239502\n",
      "0.6550309419631958\n",
      "1.4689399480819703\n",
      "UNI :  -3.808135509490967\n",
      "ALIGN :  0.2881057679653168\n",
      "====epoch 36\n",
      "0.7645635724067688\n",
      "0.6207781791687011\n",
      "1.4378538846969604\n",
      "UNI :  -3.810620403289795\n",
      "ALIGN :  0.283283132314682\n",
      "====epoch 37\n",
      "0.7345435142517089\n",
      "0.5926174044609069\n",
      "1.4192611217498778\n",
      "UNI :  -3.8108365535736084\n",
      "ALIGN :  0.2798259139060974\n",
      "====epoch 38\n",
      "0.7437714457511901\n",
      "0.6010112047195435\n",
      "1.4276023387908936\n",
      "UNI :  -3.812334394454956\n",
      "ALIGN :  0.2839028835296631\n",
      "====epoch 39\n",
      "0.7226606249809265\n",
      "0.5804404497146607\n",
      "1.422201657295227\n",
      "UNI :  -3.812448740005493\n",
      "ALIGN :  0.2802590072154999\n",
      "====epoch 40\n",
      "0.6852463960647583\n",
      "0.5455358147621154\n",
      "1.39710590839386\n",
      "UNI :  -3.8121872901916505\n",
      "ALIGN :  0.276416540145874\n",
      "====epoch 41\n",
      "0.6611234903335571\n",
      "0.521658968925476\n",
      "1.3946450710296632\n",
      "UNI :  -3.8165849685668944\n",
      "ALIGN :  0.2753747582435608\n",
      "====epoch 42\n",
      "0.651178514957428\n",
      "0.512297761440277\n",
      "1.388807225227356\n",
      "UNI :  -3.8216513633728026\n",
      "ALIGN :  0.27661683559417727\n",
      "====epoch 43\n",
      "0.6134528279304504\n",
      "0.4768864452838898\n",
      "1.3656638383865356\n",
      "UNI :  -3.8259982585906984\n",
      "ALIGN :  0.2728022873401642\n",
      "====epoch 44\n",
      "0.6056249022483826\n",
      "0.46920024752616885\n",
      "1.3642465591430664\n",
      "UNI :  -3.8274868965148925\n",
      "ALIGN :  0.2729074537754059\n",
      "====epoch 45\n",
      "0.581679618358612\n",
      "0.44621631503105164\n",
      "1.354633092880249\n",
      "UNI :  -3.8290214061737062\n",
      "ALIGN :  0.2717960953712463\n",
      "====epoch 46\n",
      "0.5687060594558716\n",
      "0.4336901843547821\n",
      "1.3501585483551026\n",
      "UNI :  -3.829745578765869\n",
      "ALIGN :  0.2702586591243744\n",
      "====epoch 47\n",
      "0.5527665019035339\n",
      "0.4186322808265686\n",
      "1.3413421630859375\n",
      "UNI :  -3.830741119384766\n",
      "ALIGN :  0.26901748180389407\n",
      "====epoch 48\n",
      "0.5188961029052734\n",
      "0.38699979782104493\n",
      "1.3189629554748534\n",
      "UNI :  -3.8329265117645264\n",
      "ALIGN :  0.26495242714881895\n",
      "====epoch 49\n",
      "0.5154297828674317\n",
      "0.38386335372924807\n",
      "1.3156642675399781\n",
      "UNI :  -3.8331621646881104\n",
      "ALIGN :  0.2657488226890564\n",
      "====epoch 50\n",
      "0.4799022376537323\n",
      "0.3497718334197998\n",
      "1.301304006576538\n",
      "UNI :  -3.833983325958252\n",
      "ALIGN :  0.2602791666984558\n",
      "--- Finding All Unique Particles ---\n",
      "\n",
      "--- Inserting Masses ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:00, 3657.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calculating Momenta and Energies ---\n",
      "\n",
      "--- Calculating Edge Tensors ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7000/7000 [00:11<00:00, 600.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating graphs ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7000/7000 [00:03<00:00, 2073.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs : 0 ; Loss : 0.7540867328643799 ; Accuracy : 49.7 ; Test Loss : 0.7424947023391724 ; Test accuracy : 51.1\n",
      "Epochs : 1 ; Loss : 0.7520630359649658 ; Accuracy : 49.575 ; Test Loss : 0.7415111660957336 ; Test accuracy : 51.1\n",
      "Epochs : 2 ; Loss : 0.7505215406417847 ; Accuracy : 49.4 ; Test Loss : 0.7409443855285645 ; Test accuracy : 51.4\n",
      "Epochs : 3 ; Loss : 0.7494303584098816 ; Accuracy : 49.75 ; Test Loss : 0.7407053709030151 ; Test accuracy : 51.4\n",
      "Epochs : 4 ; Loss : 0.7487177848815918 ; Accuracy : 50.025 ; Test Loss : 0.7406826019287109 ; Test accuracy : 51.3\n",
      "Epochs : 5 ; Loss : 0.7482854127883911 ; Accuracy : 49.95 ; Test Loss : 0.7407637238502502 ; Test accuracy : 51.7\n",
      "Epochs : 6 ; Loss : 0.7480273842811584 ; Accuracy : 49.95 ; Test Loss : 0.7408517599105835 ; Test accuracy : 51.2\n",
      "Epochs : 7 ; Loss : 0.7478484511375427 ; Accuracy : 49.9 ; Test Loss : 0.7408756613731384 ; Test accuracy : 51.4\n",
      "Epochs : 8 ; Loss : 0.7476749420166016 ; Accuracy : 49.875 ; Test Loss : 0.7407931089401245 ; Test accuracy : 51.2\n",
      "Epochs : 9 ; Loss : 0.7474595308303833 ; Accuracy : 49.825 ; Test Loss : 0.7405877113342285 ; Test accuracy : 51.1\n",
      "Epochs : 10 ; Loss : 0.7471789717674255 ; Accuracy : 49.925 ; Test Loss : 0.7402632236480713 ; Test accuracy : 51.0\n",
      "Epochs : 11 ; Loss : 0.7468298077583313 ; Accuracy : 50.025 ; Test Loss : 0.7398374080657959 ; Test accuracy : 51.1\n",
      "Epochs : 12 ; Loss : 0.7464216947555542 ; Accuracy : 50.025 ; Test Loss : 0.7393353581428528 ; Test accuracy : 51.3\n",
      "Epochs : 13 ; Loss : 0.7459717392921448 ; Accuracy : 50.1 ; Test Loss : 0.7387842535972595 ; Test accuracy : 51.4\n",
      "Epochs : 14 ; Loss : 0.7454996705055237 ; Accuracy : 50.05 ; Test Loss : 0.7382102608680725 ; Test accuracy : 51.6\n",
      "Epochs : 15 ; Loss : 0.7450242042541504 ; Accuracy : 50.05 ; Test Loss : 0.737635612487793 ; Test accuracy : 51.5\n",
      "Epochs : 16 ; Loss : 0.7445603609085083 ; Accuracy : 50.2 ; Test Loss : 0.7370769381523132 ; Test accuracy : 51.6\n",
      "Epochs : 17 ; Loss : 0.7441180944442749 ; Accuracy : 50.225 ; Test Loss : 0.7365450859069824 ; Test accuracy : 51.5\n",
      "Epochs : 18 ; Loss : 0.743701696395874 ; Accuracy : 50.15 ; Test Loss : 0.7360448241233826 ; Test accuracy : 52.1\n",
      "Epochs : 19 ; Loss : 0.7433100938796997 ; Accuracy : 50.35 ; Test Loss : 0.7355760335922241 ; Test accuracy : 52.6\n",
      "Epochs : 20 ; Loss : 0.7429379820823669 ; Accuracy : 50.3 ; Test Loss : 0.7351348996162415 ; Test accuracy : 52.6\n",
      "Epochs : 21 ; Loss : 0.7425773739814758 ; Accuracy : 50.325 ; Test Loss : 0.7347157597541809 ; Test accuracy : 52.2\n",
      "Epochs : 22 ; Loss : 0.7422193884849548 ; Accuracy : 50.475 ; Test Loss : 0.7343126535415649 ; Test accuracy : 52.4\n",
      "Epochs : 23 ; Loss : 0.7418563365936279 ; Accuracy : 50.525 ; Test Loss : 0.7339206337928772 ; Test accuracy : 52.4\n",
      "Epochs : 24 ; Loss : 0.7414824366569519 ; Accuracy : 50.6 ; Test Loss : 0.733536422252655 ; Test accuracy : 52.6\n",
      "Epochs : 25 ; Loss : 0.7410950064659119 ; Accuracy : 50.675 ; Test Loss : 0.7331586480140686 ; Test accuracy : 52.8\n",
      "Epochs : 26 ; Loss : 0.740693986415863 ; Accuracy : 50.675 ; Test Loss : 0.7327873706817627 ; Test accuracy : 52.9\n",
      "Epochs : 27 ; Loss : 0.7402819395065308 ; Accuracy : 50.625 ; Test Loss : 0.7324233651161194 ; Test accuracy : 53.1\n",
      "Epochs : 28 ; Loss : 0.7398626804351807 ; Accuracy : 50.525 ; Test Loss : 0.7320675253868103 ; Test accuracy : 53.1\n",
      "Epochs : 29 ; Loss : 0.7394405603408813 ; Accuracy : 50.5 ; Test Loss : 0.7317202687263489 ; Test accuracy : 53.3\n",
      "Epochs : 30 ; Loss : 0.7390196323394775 ; Accuracy : 50.575 ; Test Loss : 0.7313805222511292 ; Test accuracy : 52.8\n",
      "Epochs : 31 ; Loss : 0.7386026382446289 ; Accuracy : 50.625 ; Test Loss : 0.7310463190078735 ; Test accuracy : 53.0\n",
      "Epochs : 32 ; Loss : 0.7381911873817444 ; Accuracy : 50.625 ; Test Loss : 0.7307143807411194 ; Test accuracy : 52.9\n",
      "Epochs : 33 ; Loss : 0.7377853393554688 ; Accuracy : 50.925 ; Test Loss : 0.7303805947303772 ; Test accuracy : 52.8\n",
      "Epochs : 34 ; Loss : 0.7373837232589722 ; Accuracy : 50.975 ; Test Loss : 0.7300407290458679 ; Test accuracy : 52.6\n",
      "Epochs : 35 ; Loss : 0.7369845509529114 ; Accuracy : 50.95 ; Test Loss : 0.7296909689903259 ; Test accuracy : 52.6\n",
      "Epochs : 36 ; Loss : 0.7365856170654297 ; Accuracy : 50.9 ; Test Loss : 0.729328453540802 ; Test accuracy : 52.7\n",
      "Epochs : 37 ; Loss : 0.7361851930618286 ; Accuracy : 50.95 ; Test Loss : 0.7289516925811768 ; Test accuracy : 52.6\n",
      "Epochs : 38 ; Loss : 0.7357819080352783 ; Accuracy : 50.975 ; Test Loss : 0.7285605072975159 ; Test accuracy : 52.8\n",
      "Epochs : 39 ; Loss : 0.7353752851486206 ; Accuracy : 51.075 ; Test Loss : 0.7281561493873596 ; Test accuracy : 52.9\n",
      "Epochs : 40 ; Loss : 0.7349655628204346 ; Accuracy : 51.0 ; Test Loss : 0.727741003036499 ; Test accuracy : 53.1\n",
      "Epochs : 41 ; Loss : 0.7345536947250366 ; Accuracy : 51.0 ; Test Loss : 0.7273179888725281 ; Test accuracy : 53.0\n",
      "Epochs : 42 ; Loss : 0.7341408133506775 ; Accuracy : 51.075 ; Test Loss : 0.7268902063369751 ; Test accuracy : 53.3\n",
      "Epochs : 43 ; Loss : 0.7337281703948975 ; Accuracy : 51.05 ; Test Loss : 0.7264609932899475 ; Test accuracy : 53.2\n",
      "Epochs : 44 ; Loss : 0.7333166599273682 ; Accuracy : 51.125 ; Test Loss : 0.7260326743125916 ; Test accuracy : 53.5\n",
      "Epochs : 45 ; Loss : 0.7329067587852478 ; Accuracy : 51.25 ; Test Loss : 0.725607693195343 ; Test accuracy : 53.7\n",
      "Epochs : 46 ; Loss : 0.7324985861778259 ; Accuracy : 51.3 ; Test Loss : 0.7251873016357422 ; Test accuracy : 53.8\n",
      "Epochs : 47 ; Loss : 0.7320919632911682 ; Accuracy : 51.325 ; Test Loss : 0.7247723937034607 ; Test accuracy : 54.0\n",
      "Epochs : 48 ; Loss : 0.7316861152648926 ; Accuracy : 51.3 ; Test Loss : 0.7243632078170776 ; Test accuracy : 53.9\n",
      "Epochs : 49 ; Loss : 0.7312806844711304 ; Accuracy : 51.4 ; Test Loss : 0.7239600419998169 ; Test accuracy : 53.8\n",
      "Epochs : 50 ; Loss : 0.7308748960494995 ; Accuracy : 51.425 ; Test Loss : 0.7235627174377441 ; Test accuracy : 54.0\n",
      "Epochs : 51 ; Loss : 0.7304686903953552 ; Accuracy : 51.4 ; Test Loss : 0.7231707572937012 ; Test accuracy : 54.2\n",
      "Epochs : 52 ; Loss : 0.7300617098808289 ; Accuracy : 51.425 ; Test Loss : 0.7227837443351746 ; Test accuracy : 54.0\n",
      "Epochs : 53 ; Loss : 0.7296541333198547 ; Accuracy : 51.525 ; Test Loss : 0.7224010825157166 ; Test accuracy : 54.0\n",
      "Epochs : 54 ; Loss : 0.7292463779449463 ; Accuracy : 51.5 ; Test Loss : 0.7220221161842346 ; Test accuracy : 54.1\n",
      "Epochs : 55 ; Loss : 0.7288388609886169 ; Accuracy : 51.55 ; Test Loss : 0.7216458916664124 ; Test accuracy : 54.1\n",
      "Epochs : 56 ; Loss : 0.7284318208694458 ; Accuracy : 51.7 ; Test Loss : 0.7212713360786438 ; Test accuracy : 54.2\n",
      "Epochs : 57 ; Loss : 0.7280256152153015 ; Accuracy : 51.725 ; Test Loss : 0.720897376537323 ; Test accuracy : 54.2\n",
      "Epochs : 58 ; Loss : 0.7276202440261841 ; Accuracy : 51.7 ; Test Loss : 0.7205229997634888 ; Test accuracy : 54.1\n",
      "Epochs : 59 ; Loss : 0.7272158265113831 ; Accuracy : 51.75 ; Test Loss : 0.7201470136642456 ; Test accuracy : 54.1\n",
      "Epochs : 60 ; Loss : 0.7268121242523193 ; Accuracy : 51.85 ; Test Loss : 0.7197685837745667 ; Test accuracy : 54.1\n",
      "Epochs : 61 ; Loss : 0.7264090180397034 ; Accuracy : 51.95 ; Test Loss : 0.7193872332572937 ; Test accuracy : 53.9\n",
      "Epochs : 62 ; Loss : 0.7260063886642456 ; Accuracy : 52.0 ; Test Loss : 0.7190026044845581 ; Test accuracy : 54.0\n",
      "Epochs : 63 ; Loss : 0.7256040573120117 ; Accuracy : 52.05 ; Test Loss : 0.7186147570610046 ; Test accuracy : 54.0\n",
      "Epochs : 64 ; Loss : 0.7252019643783569 ; Accuracy : 52.1 ; Test Loss : 0.7182241678237915 ; Test accuracy : 54.1\n",
      "Epochs : 65 ; Loss : 0.7248002290725708 ; Accuracy : 52.125 ; Test Loss : 0.7178313136100769 ; Test accuracy : 54.1\n",
      "Epochs : 66 ; Loss : 0.7243989706039429 ; Accuracy : 52.2 ; Test Loss : 0.7174370288848877 ; Test accuracy : 54.1\n",
      "Epochs : 67 ; Loss : 0.7239981889724731 ; Accuracy : 52.2 ; Test Loss : 0.7170422077178955 ; Test accuracy : 54.0\n",
      "Epochs : 68 ; Loss : 0.7235981225967407 ; Accuracy : 52.225 ; Test Loss : 0.7166476249694824 ; Test accuracy : 54.0\n",
      "Epochs : 69 ; Loss : 0.7231988906860352 ; Accuracy : 52.25 ; Test Loss : 0.7162540555000305 ; Test accuracy : 54.1\n",
      "Epochs : 70 ; Loss : 0.7228003144264221 ; Accuracy : 52.325 ; Test Loss : 0.7158622145652771 ; Test accuracy : 54.3\n",
      "Epochs : 71 ; Loss : 0.7224025726318359 ; Accuracy : 52.4 ; Test Loss : 0.7154724597930908 ; Test accuracy : 54.3\n",
      "Epochs : 72 ; Loss : 0.7220055460929871 ; Accuracy : 52.5 ; Test Loss : 0.7150850892066956 ; Test accuracy : 54.3\n",
      "Epochs : 73 ; Loss : 0.7216092944145203 ; Accuracy : 52.55 ; Test Loss : 0.7147005200386047 ; Test accuracy : 54.3\n",
      "Epochs : 74 ; Loss : 0.7212135791778564 ; Accuracy : 52.6 ; Test Loss : 0.714318573474884 ; Test accuracy : 54.5\n",
      "Epochs : 75 ; Loss : 0.7208185791969299 ; Accuracy : 52.625 ; Test Loss : 0.7139392495155334 ; Test accuracy : 54.5\n",
      "Epochs : 76 ; Loss : 0.7204241156578064 ; Accuracy : 52.6 ; Test Loss : 0.7135623097419739 ; Test accuracy : 54.6\n",
      "Epochs : 77 ; Loss : 0.7200303077697754 ; Accuracy : 52.6 ; Test Loss : 0.7131873965263367 ; Test accuracy : 54.6\n",
      "Epochs : 78 ; Loss : 0.7196372151374817 ; Accuracy : 52.65 ; Test Loss : 0.7128142714500427 ; Test accuracy : 54.5\n",
      "Epochs : 79 ; Loss : 0.7192448973655701 ; Accuracy : 52.775 ; Test Loss : 0.7124423980712891 ; Test accuracy : 54.5\n",
      "Epochs : 80 ; Loss : 0.7188532948493958 ; Accuracy : 52.825 ; Test Loss : 0.7120714783668518 ; Test accuracy : 54.5\n",
      "Epochs : 81 ; Loss : 0.7184625864028931 ; Accuracy : 52.95 ; Test Loss : 0.7117010951042175 ; Test accuracy : 54.5\n",
      "Epochs : 82 ; Loss : 0.7180725932121277 ; Accuracy : 53.0 ; Test Loss : 0.711330771446228 ; Test accuracy : 54.5\n",
      "Epochs : 83 ; Loss : 0.7176834344863892 ; Accuracy : 52.95 ; Test Loss : 0.7109603881835938 ; Test accuracy : 54.6\n",
      "Epochs : 84 ; Loss : 0.7172950506210327 ; Accuracy : 52.925 ; Test Loss : 0.7105896472930908 ; Test accuracy : 54.5\n",
      "Epochs : 85 ; Loss : 0.7169075012207031 ; Accuracy : 52.975 ; Test Loss : 0.7102185487747192 ; Test accuracy : 54.5\n",
      "Epochs : 86 ; Loss : 0.7165206670761108 ; Accuracy : 53.0 ; Test Loss : 0.7098470330238342 ; Test accuracy : 54.5\n",
      "Epochs : 87 ; Loss : 0.7161346673965454 ; Accuracy : 53.125 ; Test Loss : 0.7094753384590149 ; Test accuracy : 54.6\n",
      "Epochs : 88 ; Loss : 0.7157495021820068 ; Accuracy : 53.125 ; Test Loss : 0.709103524684906 ; Test accuracy : 54.6\n",
      "Epochs : 89 ; Loss : 0.7153650522232056 ; Accuracy : 53.15 ; Test Loss : 0.7087320685386658 ; Test accuracy : 54.6\n",
      "Epochs : 90 ; Loss : 0.7149814367294312 ; Accuracy : 53.25 ; Test Loss : 0.7083610892295837 ; Test accuracy : 54.6\n",
      "Epochs : 91 ; Loss : 0.7145986557006836 ; Accuracy : 53.325 ; Test Loss : 0.7079910039901733 ; Test accuracy : 54.5\n",
      "Epochs : 92 ; Loss : 0.7142167091369629 ; Accuracy : 53.325 ; Test Loss : 0.7076218128204346 ; Test accuracy : 54.6\n",
      "Epochs : 93 ; Loss : 0.713835597038269 ; Accuracy : 53.325 ; Test Loss : 0.7072539329528809 ; Test accuracy : 54.8\n",
      "Epochs : 94 ; Loss : 0.7134553790092468 ; Accuracy : 53.4 ; Test Loss : 0.7068874835968018 ; Test accuracy : 54.8\n",
      "Epochs : 95 ; Loss : 0.7130759358406067 ; Accuracy : 53.35 ; Test Loss : 0.7065224647521973 ; Test accuracy : 54.9\n",
      "Epochs : 96 ; Loss : 0.712697446346283 ; Accuracy : 53.275 ; Test Loss : 0.7061591148376465 ; Test accuracy : 54.8\n",
      "Epochs : 97 ; Loss : 0.7123196721076965 ; Accuracy : 53.225 ; Test Loss : 0.7057972550392151 ; Test accuracy : 54.8\n",
      "Epochs : 98 ; Loss : 0.7119427919387817 ; Accuracy : 53.225 ; Test Loss : 0.7054369449615479 ; Test accuracy : 54.9\n",
      "Epochs : 99 ; Loss : 0.7115668058395386 ; Accuracy : 53.225 ; Test Loss : 0.7050778865814209 ; Test accuracy : 55.0\n",
      "Epochs : 100 ; Loss : 0.7111915349960327 ; Accuracy : 53.3 ; Test Loss : 0.7047201991081238 ; Test accuracy : 55.0\n",
      "Epochs : 101 ; Loss : 0.710817277431488 ; Accuracy : 53.3 ; Test Loss : 0.7043635249137878 ; Test accuracy : 55.0\n",
      "Epochs : 102 ; Loss : 0.7104438543319702 ; Accuracy : 53.325 ; Test Loss : 0.7040078043937683 ; Test accuracy : 54.9\n",
      "Epochs : 103 ; Loss : 0.7100712656974792 ; Accuracy : 53.375 ; Test Loss : 0.7036528587341309 ; Test accuracy : 55.0\n",
      "Epochs : 104 ; Loss : 0.7096995711326599 ; Accuracy : 53.4 ; Test Loss : 0.7032986283302307 ; Test accuracy : 55.0\n",
      "Epochs : 105 ; Loss : 0.7093287706375122 ; Accuracy : 53.475 ; Test Loss : 0.7029449343681335 ; Test accuracy : 55.0\n",
      "Epochs : 106 ; Loss : 0.7089587450027466 ; Accuracy : 53.475 ; Test Loss : 0.7025917172431946 ; Test accuracy : 55.0\n",
      "Epochs : 107 ; Loss : 0.7085896730422974 ; Accuracy : 53.5 ; Test Loss : 0.7022390961647034 ; Test accuracy : 54.9\n",
      "Epochs : 108 ; Loss : 0.7082215547561646 ; Accuracy : 53.625 ; Test Loss : 0.7018870115280151 ; Test accuracy : 54.9\n",
      "Epochs : 109 ; Loss : 0.707854151725769 ; Accuracy : 53.675 ; Test Loss : 0.7015354633331299 ; Test accuracy : 55.0\n",
      "Epochs : 110 ; Loss : 0.7074877023696899 ; Accuracy : 53.7 ; Test Loss : 0.7011845707893372 ; Test accuracy : 54.8\n",
      "Epochs : 111 ; Loss : 0.7071220874786377 ; Accuracy : 53.8 ; Test Loss : 0.7008343935012817 ; Test accuracy : 55.0\n",
      "Epochs : 112 ; Loss : 0.7067574262619019 ; Accuracy : 53.875 ; Test Loss : 0.7004850506782532 ; Test accuracy : 54.9\n",
      "Epochs : 113 ; Loss : 0.7063935995101929 ; Accuracy : 53.95 ; Test Loss : 0.7001367807388306 ; Test accuracy : 54.9\n",
      "Epochs : 114 ; Loss : 0.7060307264328003 ; Accuracy : 54.05 ; Test Loss : 0.6997894048690796 ; Test accuracy : 54.8\n",
      "Epochs : 115 ; Loss : 0.7056686878204346 ; Accuracy : 54.1 ; Test Loss : 0.6994431614875793 ; Test accuracy : 54.8\n",
      "Epochs : 116 ; Loss : 0.7053075432777405 ; Accuracy : 54.125 ; Test Loss : 0.6990981101989746 ; Test accuracy : 54.8\n",
      "Epochs : 117 ; Loss : 0.7049472332000732 ; Accuracy : 54.2 ; Test Loss : 0.6987541913986206 ; Test accuracy : 54.8\n",
      "Epochs : 118 ; Loss : 0.7045879364013672 ; Accuracy : 54.25 ; Test Loss : 0.6984114050865173 ; Test accuracy : 54.9\n",
      "Epochs : 119 ; Loss : 0.7042294144630432 ; Accuracy : 54.275 ; Test Loss : 0.6980698108673096 ; Test accuracy : 54.8\n",
      "Epochs : 120 ; Loss : 0.7038717269897461 ; Accuracy : 54.325 ; Test Loss : 0.6977292895317078 ; Test accuracy : 55.0\n",
      "Epochs : 121 ; Loss : 0.7035150527954102 ; Accuracy : 54.35 ; Test Loss : 0.6973897814750671 ; Test accuracy : 55.0\n",
      "Epochs : 122 ; Loss : 0.7031592130661011 ; Accuracy : 54.4 ; Test Loss : 0.6970514059066772 ; Test accuracy : 55.2\n",
      "Epochs : 123 ; Loss : 0.7028042674064636 ; Accuracy : 54.5 ; Test Loss : 0.6967138648033142 ; Test accuracy : 55.1\n",
      "Epochs : 124 ; Loss : 0.7024502158164978 ; Accuracy : 54.6 ; Test Loss : 0.6963772177696228 ; Test accuracy : 55.2\n",
      "Epochs : 125 ; Loss : 0.7020969986915588 ; Accuracy : 54.625 ; Test Loss : 0.6960414052009583 ; Test accuracy : 55.2\n",
      "Epochs : 126 ; Loss : 0.7017447352409363 ; Accuracy : 54.725 ; Test Loss : 0.6957064270973206 ; Test accuracy : 55.2\n",
      "Epochs : 127 ; Loss : 0.7013933658599854 ; Accuracy : 54.75 ; Test Loss : 0.6953723430633545 ; Test accuracy : 55.1\n",
      "Epochs : 128 ; Loss : 0.7010427713394165 ; Accuracy : 54.8 ; Test Loss : 0.695038914680481 ; Test accuracy : 55.0\n",
      "Epochs : 129 ; Loss : 0.7006930708885193 ; Accuracy : 54.85 ; Test Loss : 0.6947063207626343 ; Test accuracy : 55.1\n",
      "Epochs : 130 ; Loss : 0.7003443837165833 ; Accuracy : 55.0 ; Test Loss : 0.6943745613098145 ; Test accuracy : 55.1\n",
      "Epochs : 131 ; Loss : 0.6999964714050293 ; Accuracy : 55.0 ; Test Loss : 0.6940436959266663 ; Test accuracy : 55.3\n",
      "Epochs : 132 ; Loss : 0.6996495723724365 ; Accuracy : 55.05 ; Test Loss : 0.6937136054039001 ; Test accuracy : 55.3\n",
      "Epochs : 133 ; Loss : 0.699303388595581 ; Accuracy : 55.1 ; Test Loss : 0.6933844685554504 ; Test accuracy : 55.3\n",
      "Epochs : 134 ; Loss : 0.698958158493042 ; Accuracy : 55.2 ; Test Loss : 0.6930562853813171 ; Test accuracy : 55.3\n",
      "Epochs : 135 ; Loss : 0.6986138820648193 ; Accuracy : 55.25 ; Test Loss : 0.6927290558815002 ; Test accuracy : 55.3\n",
      "Epochs : 136 ; Loss : 0.6982704401016235 ; Accuracy : 55.25 ; Test Loss : 0.6924028396606445 ; Test accuracy : 55.5\n",
      "Epochs : 137 ; Loss : 0.6979277729988098 ; Accuracy : 55.275 ; Test Loss : 0.6920776963233948 ; Test accuracy : 55.6\n",
      "Epochs : 138 ; Loss : 0.6975861191749573 ; Accuracy : 55.3 ; Test Loss : 0.6917534470558167 ; Test accuracy : 55.6\n",
      "Epochs : 139 ; Loss : 0.6972452998161316 ; Accuracy : 55.4 ; Test Loss : 0.6914302110671997 ; Test accuracy : 55.6\n",
      "Epochs : 140 ; Loss : 0.6969053149223328 ; Accuracy : 55.45 ; Test Loss : 0.6911080479621887 ; Test accuracy : 55.6\n",
      "Epochs : 141 ; Loss : 0.6965662837028503 ; Accuracy : 55.45 ; Test Loss : 0.6907867789268494 ; Test accuracy : 55.6\n",
      "Epochs : 142 ; Loss : 0.6962280869483948 ; Accuracy : 55.475 ; Test Loss : 0.6904665231704712 ; Test accuracy : 55.6\n",
      "Epochs : 143 ; Loss : 0.6958906650543213 ; Accuracy : 55.45 ; Test Loss : 0.6901471614837646 ; Test accuracy : 55.6\n",
      "Epochs : 144 ; Loss : 0.695554256439209 ; Accuracy : 55.45 ; Test Loss : 0.6898287534713745 ; Test accuracy : 55.6\n",
      "Epochs : 145 ; Loss : 0.6952186822891235 ; Accuracy : 55.45 ; Test Loss : 0.6895111799240112 ; Test accuracy : 55.6\n",
      "Epochs : 146 ; Loss : 0.6948838829994202 ; Accuracy : 55.525 ; Test Loss : 0.6891945004463196 ; Test accuracy : 55.7\n",
      "Epochs : 147 ; Loss : 0.6945500373840332 ; Accuracy : 55.475 ; Test Loss : 0.6888787150382996 ; Test accuracy : 55.7\n",
      "Epochs : 148 ; Loss : 0.6942170262336731 ; Accuracy : 55.475 ; Test Loss : 0.6885637640953064 ; Test accuracy : 55.8\n",
      "Epochs : 149 ; Loss : 0.6938849091529846 ; Accuracy : 55.475 ; Test Loss : 0.6882496476173401 ; Test accuracy : 55.8\n",
      "Epochs : 150 ; Loss : 0.693553626537323 ; Accuracy : 55.5 ; Test Loss : 0.6879364848136902 ; Test accuracy : 56.0\n",
      "Epochs : 151 ; Loss : 0.693223237991333 ; Accuracy : 55.55 ; Test Loss : 0.6876240968704224 ; Test accuracy : 56.1\n",
      "Epochs : 152 ; Loss : 0.6928936839103699 ; Accuracy : 55.6 ; Test Loss : 0.687312662601471 ; Test accuracy : 56.1\n",
      "Epochs : 153 ; Loss : 0.6925649642944336 ; Accuracy : 55.675 ; Test Loss : 0.6870021224021912 ; Test accuracy : 56.1\n",
      "Epochs : 154 ; Loss : 0.6922371983528137 ; Accuracy : 55.825 ; Test Loss : 0.6866925358772278 ; Test accuracy : 56.1\n",
      "Epochs : 155 ; Loss : 0.6919102072715759 ; Accuracy : 55.9 ; Test Loss : 0.686383843421936 ; Test accuracy : 56.2\n",
      "Epochs : 156 ; Loss : 0.6915839910507202 ; Accuracy : 56.0 ; Test Loss : 0.6860759854316711 ; Test accuracy : 56.2\n",
      "Epochs : 157 ; Loss : 0.6912588477134705 ; Accuracy : 56.075 ; Test Loss : 0.6857691407203674 ; Test accuracy : 56.3\n",
      "Epochs : 158 ; Loss : 0.6909343600273132 ; Accuracy : 56.125 ; Test Loss : 0.6854632496833801 ; Test accuracy : 56.3\n",
      "Epochs : 159 ; Loss : 0.6906108260154724 ; Accuracy : 56.175 ; Test Loss : 0.6851581931114197 ; Test accuracy : 56.5\n",
      "Epochs : 160 ; Loss : 0.6902881264686584 ; Accuracy : 56.125 ; Test Loss : 0.6848541498184204 ; Test accuracy : 56.6\n",
      "Epochs : 161 ; Loss : 0.6899662017822266 ; Accuracy : 56.175 ; Test Loss : 0.684550940990448 ; Test accuracy : 56.6\n",
      "Epochs : 162 ; Loss : 0.6896451711654663 ; Accuracy : 56.25 ; Test Loss : 0.684248685836792 ; Test accuracy : 56.7\n",
      "Epochs : 163 ; Loss : 0.6893250346183777 ; Accuracy : 56.25 ; Test Loss : 0.6839473247528076 ; Test accuracy : 56.7\n",
      "Epochs : 164 ; Loss : 0.6890056729316711 ; Accuracy : 56.325 ; Test Loss : 0.6836467981338501 ; Test accuracy : 56.7\n",
      "Epochs : 165 ; Loss : 0.6886871457099915 ; Accuracy : 56.325 ; Test Loss : 0.683347225189209 ; Test accuracy : 56.5\n",
      "Epochs : 166 ; Loss : 0.6883694529533386 ; Accuracy : 56.475 ; Test Loss : 0.68304842710495 ; Test accuracy : 56.7\n",
      "Epochs : 167 ; Loss : 0.6880526542663574 ; Accuracy : 56.5 ; Test Loss : 0.6827505230903625 ; Test accuracy : 56.7\n",
      "Epochs : 168 ; Loss : 0.6877366900444031 ; Accuracy : 56.6 ; Test Loss : 0.6824535131454468 ; Test accuracy : 56.7\n",
      "Epochs : 169 ; Loss : 0.6874215602874756 ; Accuracy : 56.625 ; Test Loss : 0.6821573972702026 ; Test accuracy : 56.5\n",
      "Epochs : 170 ; Loss : 0.6871071457862854 ; Accuracy : 56.625 ; Test Loss : 0.6818620562553406 ; Test accuracy : 56.4\n",
      "Epochs : 171 ; Loss : 0.6867936849594116 ; Accuracy : 56.65 ; Test Loss : 0.6815675497055054 ; Test accuracy : 56.5\n",
      "Epochs : 172 ; Loss : 0.6864809989929199 ; Accuracy : 56.725 ; Test Loss : 0.6812739372253418 ; Test accuracy : 56.6\n",
      "Epochs : 173 ; Loss : 0.6861691474914551 ; Accuracy : 56.775 ; Test Loss : 0.6809812188148499 ; Test accuracy : 56.5\n",
      "Epochs : 174 ; Loss : 0.6858580708503723 ; Accuracy : 56.775 ; Test Loss : 0.6806895136833191 ; Test accuracy : 56.7\n",
      "Epochs : 175 ; Loss : 0.6855478882789612 ; Accuracy : 56.875 ; Test Loss : 0.6803985238075256 ; Test accuracy : 56.8\n",
      "Epochs : 176 ; Loss : 0.6852385401725769 ; Accuracy : 56.9 ; Test Loss : 0.6801084280014038 ; Test accuracy : 56.8\n",
      "Epochs : 177 ; Loss : 0.6849299669265747 ; Accuracy : 56.875 ; Test Loss : 0.6798192262649536 ; Test accuracy : 57.0\n",
      "Epochs : 178 ; Loss : 0.6846221685409546 ; Accuracy : 56.875 ; Test Loss : 0.679530918598175 ; Test accuracy : 57.1\n",
      "Epochs : 179 ; Loss : 0.6843152046203613 ; Accuracy : 56.9 ; Test Loss : 0.6792434453964233 ; Test accuracy : 57.2\n",
      "Epochs : 180 ; Loss : 0.6840090751647949 ; Accuracy : 57.025 ; Test Loss : 0.6789568662643433 ; Test accuracy : 57.2\n",
      "Epochs : 181 ; Loss : 0.6837037801742554 ; Accuracy : 57.075 ; Test Loss : 0.6786711812019348 ; Test accuracy : 57.3\n",
      "Epochs : 182 ; Loss : 0.6833993196487427 ; Accuracy : 57.075 ; Test Loss : 0.6783862709999084 ; Test accuracy : 57.3\n",
      "Epochs : 183 ; Loss : 0.6830956339836121 ; Accuracy : 57.1 ; Test Loss : 0.6781021952629089 ; Test accuracy : 57.3\n",
      "Epochs : 184 ; Loss : 0.6827927827835083 ; Accuracy : 57.2 ; Test Loss : 0.677819013595581 ; Test accuracy : 57.3\n",
      "Epochs : 185 ; Loss : 0.6824905872344971 ; Accuracy : 57.275 ; Test Loss : 0.6775367259979248 ; Test accuracy : 57.3\n",
      "Epochs : 186 ; Loss : 0.6821892857551575 ; Accuracy : 57.25 ; Test Loss : 0.6772551536560059 ; Test accuracy : 57.3\n",
      "Epochs : 187 ; Loss : 0.6818888187408447 ; Accuracy : 57.25 ; Test Loss : 0.6769745349884033 ; Test accuracy : 57.4\n",
      "Epochs : 188 ; Loss : 0.6815891265869141 ; Accuracy : 57.25 ; Test Loss : 0.6766946911811829 ; Test accuracy : 57.4\n",
      "Epochs : 189 ; Loss : 0.6812902092933655 ; Accuracy : 57.325 ; Test Loss : 0.6764156818389893 ; Test accuracy : 57.4\n",
      "Epochs : 190 ; Loss : 0.6809921860694885 ; Accuracy : 57.3 ; Test Loss : 0.6761375069618225 ; Test accuracy : 57.5\n",
      "Epochs : 191 ; Loss : 0.6806948184967041 ; Accuracy : 57.275 ; Test Loss : 0.6758602261543274 ; Test accuracy : 57.6\n",
      "Epochs : 192 ; Loss : 0.6803982853889465 ; Accuracy : 57.325 ; Test Loss : 0.6755837202072144 ; Test accuracy : 57.7\n",
      "Epochs : 193 ; Loss : 0.6801025867462158 ; Accuracy : 57.35 ; Test Loss : 0.6753079891204834 ; Test accuracy : 57.8\n",
      "Epochs : 194 ; Loss : 0.6798076033592224 ; Accuracy : 57.4 ; Test Loss : 0.6750331521034241 ; Test accuracy : 57.8\n",
      "Epochs : 195 ; Loss : 0.6795134544372559 ; Accuracy : 57.5 ; Test Loss : 0.6747592091560364 ; Test accuracy : 57.7\n",
      "Epochs : 196 ; Loss : 0.6792200803756714 ; Accuracy : 57.6 ; Test Loss : 0.674485981464386 ; Test accuracy : 57.9\n",
      "Epochs : 197 ; Loss : 0.6789274215698242 ; Accuracy : 57.675 ; Test Loss : 0.6742135882377625 ; Test accuracy : 58.0\n",
      "Epochs : 198 ; Loss : 0.6786356568336487 ; Accuracy : 57.65 ; Test Loss : 0.6739420294761658 ; Test accuracy : 58.1\n",
      "Epochs : 199 ; Loss : 0.6783445477485657 ; Accuracy : 57.675 ; Test Loss : 0.6736713647842407 ; Test accuracy : 58.2\n",
      "Epochs : 200 ; Loss : 0.6780543327331543 ; Accuracy : 57.775 ; Test Loss : 0.6734014749526978 ; Test accuracy : 58.2\n",
      "Epochs : 201 ; Loss : 0.6777647733688354 ; Accuracy : 57.75 ; Test Loss : 0.6731323599815369 ; Test accuracy : 58.2\n",
      "Epochs : 202 ; Loss : 0.6774761080741882 ; Accuracy : 57.85 ; Test Loss : 0.6728640794754028 ; Test accuracy : 58.2\n",
      "Epochs : 203 ; Loss : 0.6771881580352783 ; Accuracy : 57.925 ; Test Loss : 0.6725965738296509 ; Test accuracy : 58.2\n",
      "Epochs : 204 ; Loss : 0.6769009828567505 ; Accuracy : 57.95 ; Test Loss : 0.6723299622535706 ; Test accuracy : 58.2\n",
      "Epochs : 205 ; Loss : 0.6766145825386047 ; Accuracy : 57.925 ; Test Loss : 0.6720641255378723 ; Test accuracy : 58.3\n",
      "Epochs : 206 ; Loss : 0.6763288974761963 ; Accuracy : 57.95 ; Test Loss : 0.6717990636825562 ; Test accuracy : 58.3\n",
      "Epochs : 207 ; Loss : 0.6760439872741699 ; Accuracy : 57.975 ; Test Loss : 0.6715348362922668 ; Test accuracy : 58.2\n",
      "Epochs : 208 ; Loss : 0.6757599115371704 ; Accuracy : 58.0 ; Test Loss : 0.6712713241577148 ; Test accuracy : 58.2\n",
      "Epochs : 209 ; Loss : 0.6754764914512634 ; Accuracy : 58.1 ; Test Loss : 0.6710087060928345 ; Test accuracy : 58.3\n",
      "Epochs : 210 ; Loss : 0.6751939058303833 ; Accuracy : 58.175 ; Test Loss : 0.6707468032836914 ; Test accuracy : 58.7\n",
      "Epochs : 211 ; Loss : 0.6749120354652405 ; Accuracy : 58.25 ; Test Loss : 0.6704857349395752 ; Test accuracy : 58.8\n",
      "Epochs : 212 ; Loss : 0.674630880355835 ; Accuracy : 58.375 ; Test Loss : 0.6702253818511963 ; Test accuracy : 58.8\n",
      "Epochs : 213 ; Loss : 0.6743505597114563 ; Accuracy : 58.4 ; Test Loss : 0.669965922832489 ; Test accuracy : 58.7\n",
      "Epochs : 214 ; Loss : 0.6740708947181702 ; Accuracy : 58.425 ; Test Loss : 0.669707179069519 ; Test accuracy : 58.7\n",
      "Epochs : 215 ; Loss : 0.6737920045852661 ; Accuracy : 58.525 ; Test Loss : 0.6694492697715759 ; Test accuracy : 58.7\n",
      "Epochs : 216 ; Loss : 0.6735139489173889 ; Accuracy : 58.575 ; Test Loss : 0.6691920757293701 ; Test accuracy : 58.7\n",
      "Epochs : 217 ; Loss : 0.6732365489006042 ; Accuracy : 58.65 ; Test Loss : 0.6689357161521912 ; Test accuracy : 58.8\n",
      "Epochs : 218 ; Loss : 0.6729598641395569 ; Accuracy : 58.65 ; Test Loss : 0.6686801314353943 ; Test accuracy : 58.9\n",
      "Epochs : 219 ; Loss : 0.6726840138435364 ; Accuracy : 58.675 ; Test Loss : 0.6684253215789795 ; Test accuracy : 59.1\n",
      "Epochs : 220 ; Loss : 0.6724088191986084 ; Accuracy : 58.725 ; Test Loss : 0.6681712865829468 ; Test accuracy : 59.0\n",
      "Epochs : 221 ; Loss : 0.6721344590187073 ; Accuracy : 58.75 ; Test Loss : 0.6679180264472961 ; Test accuracy : 59.2\n",
      "Epochs : 222 ; Loss : 0.6718607544898987 ; Accuracy : 58.75 ; Test Loss : 0.6676654815673828 ; Test accuracy : 59.1\n",
      "Epochs : 223 ; Loss : 0.6715878248214722 ; Accuracy : 58.7 ; Test Loss : 0.6674137115478516 ; Test accuracy : 59.1\n",
      "Epochs : 224 ; Loss : 0.671315610408783 ; Accuracy : 58.75 ; Test Loss : 0.6671627759933472 ; Test accuracy : 59.1\n",
      "Epochs : 225 ; Loss : 0.671044111251831 ; Accuracy : 58.775 ; Test Loss : 0.6669125556945801 ; Test accuracy : 59.2\n",
      "Epochs : 226 ; Loss : 0.6707732677459717 ; Accuracy : 58.75 ; Test Loss : 0.6666631102561951 ; Test accuracy : 59.2\n",
      "Epochs : 227 ; Loss : 0.6705031991004944 ; Accuracy : 58.775 ; Test Loss : 0.6664143800735474 ; Test accuracy : 59.2\n",
      "Epochs : 228 ; Loss : 0.6702339053153992 ; Accuracy : 58.825 ; Test Loss : 0.6661664843559265 ; Test accuracy : 59.2\n",
      "Epochs : 229 ; Loss : 0.6699653267860413 ; Accuracy : 58.875 ; Test Loss : 0.6659192442893982 ; Test accuracy : 59.1\n",
      "Epochs : 230 ; Loss : 0.6696974039077759 ; Accuracy : 58.9 ; Test Loss : 0.6656728386878967 ; Test accuracy : 59.2\n",
      "Epochs : 231 ; Loss : 0.6694301962852478 ; Accuracy : 58.95 ; Test Loss : 0.6654271483421326 ; Test accuracy : 59.2\n",
      "Epochs : 232 ; Loss : 0.6691637635231018 ; Accuracy : 58.975 ; Test Loss : 0.6651822328567505 ; Test accuracy : 59.5\n",
      "Epochs : 233 ; Loss : 0.6688981056213379 ; Accuracy : 59.05 ; Test Loss : 0.6649380326271057 ; Test accuracy : 59.6\n",
      "Epochs : 234 ; Loss : 0.6686330437660217 ; Accuracy : 59.0 ; Test Loss : 0.6646945476531982 ; Test accuracy : 59.7\n",
      "Epochs : 235 ; Loss : 0.6683686971664429 ; Accuracy : 59.05 ; Test Loss : 0.6644518375396729 ; Test accuracy : 59.9\n",
      "Epochs : 236 ; Loss : 0.6681050658226013 ; Accuracy : 59.1 ; Test Loss : 0.6642098426818848 ; Test accuracy : 59.9\n",
      "Epochs : 237 ; Loss : 0.6678422093391418 ; Accuracy : 59.075 ; Test Loss : 0.6639686822891235 ; Test accuracy : 59.9\n",
      "Epochs : 238 ; Loss : 0.6675800085067749 ; Accuracy : 59.1 ; Test Loss : 0.6637281775474548 ; Test accuracy : 59.9\n",
      "Epochs : 239 ; Loss : 0.6673185229301453 ; Accuracy : 59.15 ; Test Loss : 0.6634883880615234 ; Test accuracy : 59.9\n",
      "Epochs : 240 ; Loss : 0.6670576333999634 ; Accuracy : 59.15 ; Test Loss : 0.6632493138313293 ; Test accuracy : 60.0\n",
      "Epochs : 241 ; Loss : 0.6667975187301636 ; Accuracy : 59.2 ; Test Loss : 0.6630110144615173 ; Test accuracy : 60.0\n",
      "Epochs : 242 ; Loss : 0.6665381789207458 ; Accuracy : 59.25 ; Test Loss : 0.6627734899520874 ; Test accuracy : 60.0\n",
      "Epochs : 243 ; Loss : 0.6662794351577759 ; Accuracy : 59.325 ; Test Loss : 0.6625366806983948 ; Test accuracy : 59.9\n",
      "Epochs : 244 ; Loss : 0.666021466255188 ; Accuracy : 59.375 ; Test Loss : 0.6623005270957947 ; Test accuracy : 59.9\n",
      "Epochs : 245 ; Loss : 0.6657641530036926 ; Accuracy : 59.425 ; Test Loss : 0.6620650887489319 ; Test accuracy : 59.8\n",
      "Epochs : 246 ; Loss : 0.6655074954032898 ; Accuracy : 59.425 ; Test Loss : 0.6618303656578064 ; Test accuracy : 59.9\n",
      "Epochs : 247 ; Loss : 0.6652515530586243 ; Accuracy : 59.4 ; Test Loss : 0.6615964770317078 ; Test accuracy : 59.9\n",
      "Epochs : 248 ; Loss : 0.664996325969696 ; Accuracy : 59.425 ; Test Loss : 0.6613631248474121 ; Test accuracy : 59.9\n",
      "Epochs : 249 ; Loss : 0.6647417545318604 ; Accuracy : 59.5 ; Test Loss : 0.6611306667327881 ; Test accuracy : 59.9\n",
      "Epochs : 250 ; Loss : 0.6644878387451172 ; Accuracy : 59.575 ; Test Loss : 0.6608986854553223 ; Test accuracy : 59.9\n",
      "Epochs : 251 ; Loss : 0.6642346382141113 ; Accuracy : 59.625 ; Test Loss : 0.6606676578521729 ; Test accuracy : 59.9\n",
      "Epochs : 252 ; Loss : 0.6639821529388428 ; Accuracy : 59.65 ; Test Loss : 0.6604371666908264 ; Test accuracy : 59.9\n",
      "Epochs : 253 ; Loss : 0.663730263710022 ; Accuracy : 59.65 ; Test Loss : 0.6602075099945068 ; Test accuracy : 60.1\n",
      "Epochs : 254 ; Loss : 0.6634790897369385 ; Accuracy : 59.775 ; Test Loss : 0.6599785089492798 ; Test accuracy : 60.1\n",
      "Epochs : 255 ; Loss : 0.6632286310195923 ; Accuracy : 59.8 ; Test Loss : 0.6597501635551453 ; Test accuracy : 60.1\n",
      "Epochs : 256 ; Loss : 0.6629787683486938 ; Accuracy : 59.8 ; Test Loss : 0.659522533416748 ; Test accuracy : 60.1\n",
      "Epochs : 257 ; Loss : 0.6627296209335327 ; Accuracy : 59.825 ; Test Loss : 0.6592956185340881 ; Test accuracy : 60.1\n",
      "Epochs : 258 ; Loss : 0.6624811291694641 ; Accuracy : 59.875 ; Test Loss : 0.6590693593025208 ; Test accuracy : 60.0\n",
      "Epochs : 259 ; Loss : 0.662233293056488 ; Accuracy : 59.95 ; Test Loss : 0.6588438153266907 ; Test accuracy : 59.8\n",
      "Epochs : 260 ; Loss : 0.6619861125946045 ; Accuracy : 59.975 ; Test Loss : 0.6586190462112427 ; Test accuracy : 59.7\n",
      "Epochs : 261 ; Loss : 0.6617396473884583 ; Accuracy : 60.125 ; Test Loss : 0.6583948731422424 ; Test accuracy : 59.6\n",
      "Epochs : 262 ; Loss : 0.6614937782287598 ; Accuracy : 60.15 ; Test Loss : 0.6581713557243347 ; Test accuracy : 59.8\n",
      "Epochs : 263 ; Loss : 0.6612486243247986 ; Accuracy : 60.225 ; Test Loss : 0.6579486131668091 ; Test accuracy : 59.8\n",
      "Epochs : 264 ; Loss : 0.6610041856765747 ; Accuracy : 60.3 ; Test Loss : 0.657726526260376 ; Test accuracy : 59.8\n",
      "Epochs : 265 ; Loss : 0.6607602834701538 ; Accuracy : 60.325 ; Test Loss : 0.6575050950050354 ; Test accuracy : 59.7\n",
      "Epochs : 266 ; Loss : 0.6605170965194702 ; Accuracy : 60.375 ; Test Loss : 0.6572843194007874 ; Test accuracy : 59.8\n",
      "Epochs : 267 ; Loss : 0.6602745056152344 ; Accuracy : 60.4 ; Test Loss : 0.6570643186569214 ; Test accuracy : 59.8\n",
      "Epochs : 268 ; Loss : 0.6600326299667358 ; Accuracy : 60.4 ; Test Loss : 0.6568448543548584 ; Test accuracy : 59.7\n",
      "Epochs : 269 ; Loss : 0.6597914099693298 ; Accuracy : 60.475 ; Test Loss : 0.6566261053085327 ; Test accuracy : 59.7\n",
      "Epochs : 270 ; Loss : 0.6595507264137268 ; Accuracy : 60.55 ; Test Loss : 0.6564081311225891 ; Test accuracy : 59.7\n",
      "Epochs : 271 ; Loss : 0.6593108177185059 ; Accuracy : 60.6 ; Test Loss : 0.6561907529830933 ; Test accuracy : 59.7\n",
      "Epochs : 272 ; Loss : 0.6590715646743774 ; Accuracy : 60.65 ; Test Loss : 0.6559740304946899 ; Test accuracy : 59.7\n",
      "Epochs : 273 ; Loss : 0.6588327884674072 ; Accuracy : 60.65 ; Test Loss : 0.6557580232620239 ; Test accuracy : 59.7\n",
      "Epochs : 274 ; Loss : 0.6585948467254639 ; Accuracy : 60.7 ; Test Loss : 0.6555426120758057 ; Test accuracy : 59.8\n",
      "Epochs : 275 ; Loss : 0.6583573818206787 ; Accuracy : 60.725 ; Test Loss : 0.6553279161453247 ; Test accuracy : 59.8\n",
      "Epochs : 276 ; Loss : 0.6581206321716309 ; Accuracy : 60.725 ; Test Loss : 0.6551138758659363 ; Test accuracy : 59.8\n",
      "Epochs : 277 ; Loss : 0.6578845381736755 ; Accuracy : 60.725 ; Test Loss : 0.6549004912376404 ; Test accuracy : 59.8\n",
      "Epochs : 278 ; Loss : 0.6576490998268127 ; Accuracy : 60.725 ; Test Loss : 0.6546876430511475 ; Test accuracy : 59.8\n",
      "Epochs : 279 ; Loss : 0.6574141979217529 ; Accuracy : 60.725 ; Test Loss : 0.6544755697250366 ; Test accuracy : 59.8\n",
      "Epochs : 280 ; Loss : 0.6571799516677856 ; Accuracy : 60.7 ; Test Loss : 0.6542642116546631 ; Test accuracy : 59.9\n",
      "Epochs : 281 ; Loss : 0.6569464206695557 ; Accuracy : 60.75 ; Test Loss : 0.6540533900260925 ; Test accuracy : 59.9\n",
      "Epochs : 282 ; Loss : 0.6567134857177734 ; Accuracy : 60.8 ; Test Loss : 0.6538432240486145 ; Test accuracy : 59.9\n",
      "Epochs : 283 ; Loss : 0.6564810872077942 ; Accuracy : 60.85 ; Test Loss : 0.653633713722229 ; Test accuracy : 60.1\n",
      "Epochs : 284 ; Loss : 0.6562494039535522 ; Accuracy : 60.875 ; Test Loss : 0.653424859046936 ; Test accuracy : 60.2\n",
      "Epochs : 285 ; Loss : 0.6560183167457581 ; Accuracy : 60.975 ; Test Loss : 0.6532166600227356 ; Test accuracy : 60.3\n",
      "Epochs : 286 ; Loss : 0.6557878851890564 ; Accuracy : 60.975 ; Test Loss : 0.6530091166496277 ; Test accuracy : 60.3\n",
      "Epochs : 287 ; Loss : 0.6555579900741577 ; Accuracy : 60.975 ; Test Loss : 0.6528021693229675 ; Test accuracy : 60.4\n",
      "Epochs : 288 ; Loss : 0.6553287506103516 ; Accuracy : 61.0 ; Test Loss : 0.6525959372520447 ; Test accuracy : 60.4\n",
      "Epochs : 289 ; Loss : 0.6551001071929932 ; Accuracy : 60.95 ; Test Loss : 0.6523903012275696 ; Test accuracy : 60.4\n",
      "Epochs : 290 ; Loss : 0.6548721790313721 ; Accuracy : 61.0 ; Test Loss : 0.6521852016448975 ; Test accuracy : 60.4\n",
      "Epochs : 291 ; Loss : 0.654644787311554 ; Accuracy : 61.05 ; Test Loss : 0.6519808173179626 ; Test accuracy : 60.4\n",
      "Epochs : 292 ; Loss : 0.6544179916381836 ; Accuracy : 61.1 ; Test Loss : 0.6517770886421204 ; Test accuracy : 60.4\n",
      "Epochs : 293 ; Loss : 0.654191792011261 ; Accuracy : 61.15 ; Test Loss : 0.651573896408081 ; Test accuracy : 60.5\n",
      "Epochs : 294 ; Loss : 0.6539663076400757 ; Accuracy : 61.175 ; Test Loss : 0.651371419429779 ; Test accuracy : 60.5\n",
      "Epochs : 295 ; Loss : 0.6537413001060486 ; Accuracy : 61.2 ; Test Loss : 0.6511695981025696 ; Test accuracy : 60.7\n",
      "Epochs : 296 ; Loss : 0.653516948223114 ; Accuracy : 61.25 ; Test Loss : 0.6509683132171631 ; Test accuracy : 60.8\n",
      "Epochs : 297 ; Loss : 0.6532931923866272 ; Accuracy : 61.35 ; Test Loss : 0.6507676839828491 ; Test accuracy : 60.7\n",
      "Epochs : 298 ; Loss : 0.6530700325965881 ; Accuracy : 61.425 ; Test Loss : 0.6505675911903381 ; Test accuracy : 60.5\n",
      "Epochs : 299 ; Loss : 0.6528475284576416 ; Accuracy : 61.425 ; Test Loss : 0.6503682136535645 ; Test accuracy : 60.6\n",
      "Epochs : 300 ; Loss : 0.6526255011558533 ; Accuracy : 61.55 ; Test Loss : 0.6501694321632385 ; Test accuracy : 60.7\n",
      "Epochs : 301 ; Loss : 0.6524041891098022 ; Accuracy : 61.575 ; Test Loss : 0.6499712467193604 ; Test accuracy : 60.7\n",
      "Epochs : 302 ; Loss : 0.6521834135055542 ; Accuracy : 61.625 ; Test Loss : 0.6497737169265747 ; Test accuracy : 60.7\n",
      "Epochs : 303 ; Loss : 0.6519632935523987 ; Accuracy : 61.625 ; Test Loss : 0.6495766639709473 ; Test accuracy : 60.7\n",
      "Epochs : 304 ; Loss : 0.6517437100410461 ; Accuracy : 61.725 ; Test Loss : 0.6493803858757019 ; Test accuracy : 60.8\n",
      "Epochs : 305 ; Loss : 0.6515246629714966 ; Accuracy : 61.75 ; Test Loss : 0.6491845846176147 ; Test accuracy : 60.8\n",
      "Epochs : 306 ; Loss : 0.6513063311576843 ; Accuracy : 61.725 ; Test Loss : 0.6489895582199097 ; Test accuracy : 60.8\n",
      "Epochs : 307 ; Loss : 0.6510884761810303 ; Accuracy : 61.725 ; Test Loss : 0.648794949054718 ; Test accuracy : 60.8\n",
      "Epochs : 308 ; Loss : 0.650871217250824 ; Accuracy : 61.825 ; Test Loss : 0.6486010551452637 ; Test accuracy : 60.8\n",
      "Epochs : 309 ; Loss : 0.6506546139717102 ; Accuracy : 61.9 ; Test Loss : 0.6484077572822571 ; Test accuracy : 60.8\n",
      "Epochs : 310 ; Loss : 0.6504385471343994 ; Accuracy : 61.925 ; Test Loss : 0.6482149958610535 ; Test accuracy : 60.8\n",
      "Epochs : 311 ; Loss : 0.6502230763435364 ; Accuracy : 62.0 ; Test Loss : 0.6480228304862976 ; Test accuracy : 60.9\n",
      "Epochs : 312 ; Loss : 0.6500082015991211 ; Accuracy : 62.0 ; Test Loss : 0.6478313207626343 ; Test accuracy : 60.9\n",
      "Epochs : 313 ; Loss : 0.6497938632965088 ; Accuracy : 62.05 ; Test Loss : 0.6476402878761292 ; Test accuracy : 61.0\n",
      "Epochs : 314 ; Loss : 0.6495801210403442 ; Accuracy : 62.075 ; Test Loss : 0.6474499702453613 ; Test accuracy : 61.1\n",
      "Epochs : 315 ; Loss : 0.6493669152259827 ; Accuracy : 62.025 ; Test Loss : 0.6472602486610413 ; Test accuracy : 61.2\n",
      "Epochs : 316 ; Loss : 0.6491543054580688 ; Accuracy : 62.025 ; Test Loss : 0.6470710039138794 ; Test accuracy : 61.2\n",
      "Epochs : 317 ; Loss : 0.6489422917366028 ; Accuracy : 62.075 ; Test Loss : 0.6468824148178101 ; Test accuracy : 61.2\n",
      "Epochs : 318 ; Loss : 0.6487308144569397 ; Accuracy : 62.025 ; Test Loss : 0.6466943621635437 ; Test accuracy : 61.3\n",
      "Epochs : 319 ; Loss : 0.6485199332237244 ; Accuracy : 62.1 ; Test Loss : 0.6465069651603699 ; Test accuracy : 61.3\n",
      "Epochs : 320 ; Loss : 0.648309588432312 ; Accuracy : 62.125 ; Test Loss : 0.646320104598999 ; Test accuracy : 61.3\n",
      "Epochs : 321 ; Loss : 0.6480998396873474 ; Accuracy : 62.125 ; Test Loss : 0.6461338400840759 ; Test accuracy : 61.3\n",
      "Epochs : 322 ; Loss : 0.6478906273841858 ; Accuracy : 62.125 ; Test Loss : 0.6459481716156006 ; Test accuracy : 61.4\n",
      "Epochs : 323 ; Loss : 0.6476818919181824 ; Accuracy : 62.15 ; Test Loss : 0.6457630395889282 ; Test accuracy : 61.4\n",
      "Epochs : 324 ; Loss : 0.647473931312561 ; Accuracy : 62.225 ; Test Loss : 0.6455785036087036 ; Test accuracy : 61.5\n",
      "Epochs : 325 ; Loss : 0.6472663879394531 ; Accuracy : 62.275 ; Test Loss : 0.6453945636749268 ; Test accuracy : 61.7\n",
      "Epochs : 326 ; Loss : 0.6470593810081482 ; Accuracy : 62.35 ; Test Loss : 0.6452111005783081 ; Test accuracy : 61.7\n",
      "Epochs : 327 ; Loss : 0.646852970123291 ; Accuracy : 62.425 ; Test Loss : 0.6450282335281372 ; Test accuracy : 61.8\n",
      "Epochs : 328 ; Loss : 0.6466470956802368 ; Accuracy : 62.45 ; Test Loss : 0.6448459625244141 ; Test accuracy : 61.8\n",
      "Epochs : 329 ; Loss : 0.6464418172836304 ; Accuracy : 62.475 ; Test Loss : 0.6446642875671387 ; Test accuracy : 61.8\n",
      "Epochs : 330 ; Loss : 0.6462370753288269 ; Accuracy : 62.5 ; Test Loss : 0.644483208656311 ; Test accuracy : 61.8\n",
      "Epochs : 331 ; Loss : 0.6460328698158264 ; Accuracy : 62.525 ; Test Loss : 0.6443025469779968 ; Test accuracy : 61.7\n",
      "Epochs : 332 ; Loss : 0.6458291411399841 ; Accuracy : 62.55 ; Test Loss : 0.6441225409507751 ; Test accuracy : 61.9\n",
      "Epochs : 333 ; Loss : 0.6456260681152344 ; Accuracy : 62.575 ; Test Loss : 0.6439430117607117 ; Test accuracy : 61.9\n",
      "Epochs : 334 ; Loss : 0.6454234719276428 ; Accuracy : 62.675 ; Test Loss : 0.6437641382217407 ; Test accuracy : 62.0\n",
      "Epochs : 335 ; Loss : 0.645221471786499 ; Accuracy : 62.7 ; Test Loss : 0.6435858607292175 ; Test accuracy : 62.1\n",
      "Epochs : 336 ; Loss : 0.6450199484825134 ; Accuracy : 62.75 ; Test Loss : 0.6434080004692078 ; Test accuracy : 62.1\n",
      "Epochs : 337 ; Loss : 0.6448190212249756 ; Accuracy : 62.8 ; Test Loss : 0.6432307362556458 ; Test accuracy : 62.1\n",
      "Epochs : 338 ; Loss : 0.644618570804596 ; Accuracy : 62.8 ; Test Loss : 0.6430540680885315 ; Test accuracy : 62.1\n",
      "Epochs : 339 ; Loss : 0.6444187164306641 ; Accuracy : 62.825 ; Test Loss : 0.6428779363632202 ; Test accuracy : 62.1\n",
      "Epochs : 340 ; Loss : 0.6442193984985352 ; Accuracy : 62.875 ; Test Loss : 0.6427022814750671 ; Test accuracy : 62.2\n",
      "Epochs : 341 ; Loss : 0.6440205574035645 ; Accuracy : 62.925 ; Test Loss : 0.6425273418426514 ; Test accuracy : 62.1\n",
      "Epochs : 342 ; Loss : 0.6438223123550415 ; Accuracy : 62.975 ; Test Loss : 0.642352819442749 ; Test accuracy : 62.2\n",
      "Epochs : 343 ; Loss : 0.6436245441436768 ; Accuracy : 62.975 ; Test Loss : 0.6421787142753601 ; Test accuracy : 62.2\n",
      "Epochs : 344 ; Loss : 0.6434273719787598 ; Accuracy : 62.95 ; Test Loss : 0.6420053839683533 ; Test accuracy : 62.2\n",
      "Epochs : 345 ; Loss : 0.643230676651001 ; Accuracy : 63.025 ; Test Loss : 0.6418324708938599 ; Test accuracy : 62.3\n",
      "Epochs : 346 ; Loss : 0.6430345177650452 ; Accuracy : 63.025 ; Test Loss : 0.6416601538658142 ; Test accuracy : 62.4\n",
      "Epochs : 347 ; Loss : 0.6428388953208923 ; Accuracy : 63.125 ; Test Loss : 0.6414883136749268 ; Test accuracy : 62.4\n",
      "Epochs : 348 ; Loss : 0.6426437497138977 ; Accuracy : 63.125 ; Test Loss : 0.6413170695304871 ; Test accuracy : 62.5\n",
      "Epochs : 349 ; Loss : 0.6424492001533508 ; Accuracy : 63.175 ; Test Loss : 0.6411463022232056 ; Test accuracy : 62.5\n",
      "Epochs : 350 ; Loss : 0.6422551870346069 ; Accuracy : 63.2 ; Test Loss : 0.6409761309623718 ; Test accuracy : 62.5\n",
      "Epochs : 351 ; Loss : 0.6420615315437317 ; Accuracy : 63.25 ; Test Loss : 0.6408064365386963 ; Test accuracy : 62.5\n",
      "Epochs : 352 ; Loss : 0.641868531703949 ; Accuracy : 63.25 ; Test Loss : 0.640637218952179 ; Test accuracy : 62.5\n",
      "Epochs : 353 ; Loss : 0.6416760683059692 ; Accuracy : 63.25 ; Test Loss : 0.6404685974121094 ; Test accuracy : 62.5\n",
      "Epochs : 354 ; Loss : 0.6414840221405029 ; Accuracy : 63.275 ; Test Loss : 0.6403005123138428 ; Test accuracy : 62.7\n",
      "Epochs : 355 ; Loss : 0.6412925124168396 ; Accuracy : 63.275 ; Test Loss : 0.6401329040527344 ; Test accuracy : 62.7\n",
      "Epochs : 356 ; Loss : 0.641101598739624 ; Accuracy : 63.275 ; Test Loss : 0.639965832233429 ; Test accuracy : 62.7\n",
      "Epochs : 357 ; Loss : 0.6409110426902771 ; Accuracy : 63.3 ; Test Loss : 0.6397993564605713 ; Test accuracy : 62.7\n",
      "Epochs : 358 ; Loss : 0.6407211422920227 ; Accuracy : 63.35 ; Test Loss : 0.639633297920227 ; Test accuracy : 62.7\n",
      "Epochs : 359 ; Loss : 0.6405316591262817 ; Accuracy : 63.375 ; Test Loss : 0.6394677758216858 ; Test accuracy : 62.9\n",
      "Epochs : 360 ; Loss : 0.6403427720069885 ; Accuracy : 63.35 ; Test Loss : 0.6393027901649475 ; Test accuracy : 62.9\n",
      "Epochs : 361 ; Loss : 0.6401543021202087 ; Accuracy : 63.35 ; Test Loss : 0.6391382813453674 ; Test accuracy : 62.9\n",
      "Epochs : 362 ; Loss : 0.6399663686752319 ; Accuracy : 63.375 ; Test Loss : 0.6389743089675903 ; Test accuracy : 62.9\n",
      "Epochs : 363 ; Loss : 0.6397789120674133 ; Accuracy : 63.375 ; Test Loss : 0.6388108730316162 ; Test accuracy : 63.0\n",
      "Epochs : 364 ; Loss : 0.6395919322967529 ; Accuracy : 63.375 ; Test Loss : 0.6386479139328003 ; Test accuracy : 63.1\n",
      "Epochs : 365 ; Loss : 0.6394055485725403 ; Accuracy : 63.375 ; Test Loss : 0.6384854912757874 ; Test accuracy : 63.1\n",
      "Epochs : 366 ; Loss : 0.6392196416854858 ; Accuracy : 63.35 ; Test Loss : 0.6383236050605774 ; Test accuracy : 63.3\n",
      "Epochs : 367 ; Loss : 0.6390341520309448 ; Accuracy : 63.325 ; Test Loss : 0.6381621360778809 ; Test accuracy : 63.3\n",
      "Epochs : 368 ; Loss : 0.6388491988182068 ; Accuracy : 63.325 ; Test Loss : 0.6380012631416321 ; Test accuracy : 63.3\n",
      "Epochs : 369 ; Loss : 0.6386647820472717 ; Accuracy : 63.35 ; Test Loss : 0.6378408074378967 ; Test accuracy : 63.5\n",
      "Epochs : 370 ; Loss : 0.6384807825088501 ; Accuracy : 63.375 ; Test Loss : 0.6376809477806091 ; Test accuracy : 63.5\n",
      "Epochs : 371 ; Loss : 0.6382972598075867 ; Accuracy : 63.4 ; Test Loss : 0.6375214457511902 ; Test accuracy : 63.8\n",
      "Epochs : 372 ; Loss : 0.638114333152771 ; Accuracy : 63.4 ; Test Loss : 0.637362539768219 ; Test accuracy : 63.8\n",
      "Epochs : 373 ; Loss : 0.637931764125824 ; Accuracy : 63.425 ; Test Loss : 0.637204110622406 ; Test accuracy : 63.7\n",
      "Epochs : 374 ; Loss : 0.6377498507499695 ; Accuracy : 63.45 ; Test Loss : 0.6370461583137512 ; Test accuracy : 63.7\n",
      "Epochs : 375 ; Loss : 0.6375682950019836 ; Accuracy : 63.475 ; Test Loss : 0.6368886828422546 ; Test accuracy : 63.7\n",
      "Epochs : 376 ; Loss : 0.637387216091156 ; Accuracy : 63.475 ; Test Loss : 0.636731743812561 ; Test accuracy : 63.8\n",
      "Epochs : 377 ; Loss : 0.6372066736221313 ; Accuracy : 63.5 ; Test Loss : 0.6365753412246704 ; Test accuracy : 63.9\n",
      "Epochs : 378 ; Loss : 0.6370266675949097 ; Accuracy : 63.525 ; Test Loss : 0.6364193558692932 ; Test accuracy : 63.9\n",
      "Epochs : 379 ; Loss : 0.6368470788002014 ; Accuracy : 63.6 ; Test Loss : 0.6362638473510742 ; Test accuracy : 64.0\n",
      "Epochs : 380 ; Loss : 0.6366678476333618 ; Accuracy : 63.625 ; Test Loss : 0.636108934879303 ; Test accuracy : 64.1\n",
      "Epochs : 381 ; Loss : 0.63648921251297 ; Accuracy : 63.7 ; Test Loss : 0.6359543204307556 ; Test accuracy : 64.1\n",
      "Epochs : 382 ; Loss : 0.6363110542297363 ; Accuracy : 63.75 ; Test Loss : 0.635800302028656 ; Test accuracy : 64.1\n",
      "Epochs : 383 ; Loss : 0.6361333727836609 ; Accuracy : 63.75 ; Test Loss : 0.6356467604637146 ; Test accuracy : 64.2\n",
      "Epochs : 384 ; Loss : 0.6359561681747437 ; Accuracy : 63.775 ; Test Loss : 0.6354936957359314 ; Test accuracy : 64.2\n",
      "Epochs : 385 ; Loss : 0.6357793807983398 ; Accuracy : 63.825 ; Test Loss : 0.6353411078453064 ; Test accuracy : 64.2\n",
      "Epochs : 386 ; Loss : 0.635603129863739 ; Accuracy : 63.925 ; Test Loss : 0.6351889371871948 ; Test accuracy : 64.2\n",
      "Epochs : 387 ; Loss : 0.6354272961616516 ; Accuracy : 63.975 ; Test Loss : 0.6350373029708862 ; Test accuracy : 64.2\n",
      "Epochs : 388 ; Loss : 0.6352519989013672 ; Accuracy : 64.05 ; Test Loss : 0.6348861455917358 ; Test accuracy : 64.3\n",
      "Epochs : 389 ; Loss : 0.6350770592689514 ; Accuracy : 64.125 ; Test Loss : 0.6347355246543884 ; Test accuracy : 64.3\n",
      "Epochs : 390 ; Loss : 0.6349025964736938 ; Accuracy : 64.125 ; Test Loss : 0.6345852613449097 ; Test accuracy : 64.2\n",
      "Epochs : 391 ; Loss : 0.634728729724884 ; Accuracy : 64.175 ; Test Loss : 0.6344354748725891 ; Test accuracy : 64.2\n",
      "Epochs : 392 ; Loss : 0.6345552206039429 ; Accuracy : 64.175 ; Test Loss : 0.6342862248420715 ; Test accuracy : 64.2\n",
      "Epochs : 393 ; Loss : 0.6343821883201599 ; Accuracy : 64.175 ; Test Loss : 0.6341373324394226 ; Test accuracy : 64.1\n",
      "Epochs : 394 ; Loss : 0.6342096328735352 ; Accuracy : 64.2 ; Test Loss : 0.6339890360832214 ; Test accuracy : 64.1\n",
      "Epochs : 395 ; Loss : 0.6340374946594238 ; Accuracy : 64.225 ; Test Loss : 0.6338410973548889 ; Test accuracy : 64.1\n",
      "Epochs : 396 ; Loss : 0.6338658332824707 ; Accuracy : 64.25 ; Test Loss : 0.6336937546730042 ; Test accuracy : 64.0\n",
      "Epochs : 397 ; Loss : 0.633694589138031 ; Accuracy : 64.3 ; Test Loss : 0.6335467100143433 ; Test accuracy : 64.1\n",
      "Epochs : 398 ; Loss : 0.6335238218307495 ; Accuracy : 64.35 ; Test Loss : 0.6334002017974854 ; Test accuracy : 64.1\n",
      "Epochs : 399 ; Loss : 0.6333535313606262 ; Accuracy : 64.375 ; Test Loss : 0.6332541704177856 ; Test accuracy : 64.1\n",
      "Epochs : 400 ; Loss : 0.6331836581230164 ; Accuracy : 64.375 ; Test Loss : 0.6331085562705994 ; Test accuracy : 64.1\n",
      "Epochs : 401 ; Loss : 0.6330143213272095 ; Accuracy : 64.375 ; Test Loss : 0.6329634189605713 ; Test accuracy : 64.3\n",
      "Epochs : 402 ; Loss : 0.6328453421592712 ; Accuracy : 64.35 ; Test Loss : 0.6328187584877014 ; Test accuracy : 64.2\n",
      "Epochs : 403 ; Loss : 0.632676899433136 ; Accuracy : 64.4 ; Test Loss : 0.6326744556427002 ; Test accuracy : 64.2\n",
      "Epochs : 404 ; Loss : 0.6325087547302246 ; Accuracy : 64.4 ; Test Loss : 0.632530689239502 ; Test accuracy : 64.2\n",
      "Epochs : 405 ; Loss : 0.632341206073761 ; Accuracy : 64.45 ; Test Loss : 0.6323873996734619 ; Test accuracy : 64.2\n",
      "Epochs : 406 ; Loss : 0.6321739554405212 ; Accuracy : 64.45 ; Test Loss : 0.6322445273399353 ; Test accuracy : 64.2\n",
      "Epochs : 407 ; Loss : 0.6320073008537292 ; Accuracy : 64.425 ; Test Loss : 0.6321020722389221 ; Test accuracy : 64.1\n",
      "Epochs : 408 ; Loss : 0.6318409442901611 ; Accuracy : 64.425 ; Test Loss : 0.6319600939750671 ; Test accuracy : 64.1\n",
      "Epochs : 409 ; Loss : 0.631675124168396 ; Accuracy : 64.4 ; Test Loss : 0.6318185329437256 ; Test accuracy : 64.1\n",
      "Epochs : 410 ; Loss : 0.6315097212791443 ; Accuracy : 64.45 ; Test Loss : 0.6316773891448975 ; Test accuracy : 64.1\n",
      "Epochs : 411 ; Loss : 0.631344735622406 ; Accuracy : 64.5 ; Test Loss : 0.6315367817878723 ; Test accuracy : 64.1\n",
      "Epochs : 412 ; Loss : 0.6311802268028259 ; Accuracy : 64.425 ; Test Loss : 0.6313965320587158 ; Test accuracy : 64.2\n",
      "Epochs : 413 ; Loss : 0.6310161352157593 ; Accuracy : 64.45 ; Test Loss : 0.6312567591667175 ; Test accuracy : 64.2\n",
      "Epochs : 414 ; Loss : 0.630852460861206 ; Accuracy : 64.525 ; Test Loss : 0.6311174631118774 ; Test accuracy : 64.3\n",
      "Epochs : 415 ; Loss : 0.630689263343811 ; Accuracy : 64.55 ; Test Loss : 0.630978524684906 ; Test accuracy : 64.3\n",
      "Epochs : 416 ; Loss : 0.6305264234542847 ; Accuracy : 64.575 ; Test Loss : 0.6308401226997375 ; Test accuracy : 64.2\n",
      "Epochs : 417 ; Loss : 0.6303640604019165 ; Accuracy : 64.6 ; Test Loss : 0.6307020783424377 ; Test accuracy : 64.2\n",
      "Epochs : 418 ; Loss : 0.630202054977417 ; Accuracy : 64.6 ; Test Loss : 0.6305645108222961 ; Test accuracy : 64.2\n",
      "Epochs : 419 ; Loss : 0.6300405859947205 ; Accuracy : 64.6 ; Test Loss : 0.6304273009300232 ; Test accuracy : 64.2\n",
      "Epochs : 420 ; Loss : 0.6298794150352478 ; Accuracy : 64.65 ; Test Loss : 0.6302905678749084 ; Test accuracy : 64.2\n",
      "Epochs : 421 ; Loss : 0.6297187805175781 ; Accuracy : 64.65 ; Test Loss : 0.6301541924476624 ; Test accuracy : 64.2\n",
      "Epochs : 422 ; Loss : 0.6295585036277771 ; Accuracy : 64.7 ; Test Loss : 0.6300183534622192 ; Test accuracy : 64.2\n",
      "Epochs : 423 ; Loss : 0.6293986439704895 ; Accuracy : 64.7 ; Test Loss : 0.6298828721046448 ; Test accuracy : 64.3\n",
      "Epochs : 424 ; Loss : 0.6292392611503601 ; Accuracy : 64.75 ; Test Loss : 0.6297478079795837 ; Test accuracy : 64.5\n",
      "Epochs : 425 ; Loss : 0.6290803551673889 ; Accuracy : 64.775 ; Test Loss : 0.6296132206916809 ; Test accuracy : 64.5\n",
      "Epochs : 426 ; Loss : 0.6289217472076416 ; Accuracy : 64.775 ; Test Loss : 0.6294790506362915 ; Test accuracy : 64.5\n",
      "Epochs : 427 ; Loss : 0.6287635564804077 ; Accuracy : 64.8 ; Test Loss : 0.6293452382087708 ; Test accuracy : 64.6\n",
      "Epochs : 428 ; Loss : 0.6286057829856873 ; Accuracy : 64.75 ; Test Loss : 0.629211962223053 ; Test accuracy : 64.6\n",
      "Epochs : 429 ; Loss : 0.6284485459327698 ; Accuracy : 64.825 ; Test Loss : 0.6290789246559143 ; Test accuracy : 64.7\n",
      "Epochs : 430 ; Loss : 0.6282916069030762 ; Accuracy : 64.85 ; Test Loss : 0.6289464235305786 ; Test accuracy : 64.7\n",
      "Epochs : 431 ; Loss : 0.6281350255012512 ; Accuracy : 64.85 ; Test Loss : 0.6288143396377563 ; Test accuracy : 64.8\n",
      "Epochs : 432 ; Loss : 0.627979040145874 ; Accuracy : 64.825 ; Test Loss : 0.6286826729774475 ; Test accuracy : 64.8\n",
      "Epochs : 433 ; Loss : 0.6278233528137207 ; Accuracy : 64.9 ; Test Loss : 0.6285513639450073 ; Test accuracy : 64.9\n",
      "Epochs : 434 ; Loss : 0.627668023109436 ; Accuracy : 64.9 ; Test Loss : 0.6284205913543701 ; Test accuracy : 64.9\n",
      "Epochs : 435 ; Loss : 0.6275132298469543 ; Accuracy : 64.875 ; Test Loss : 0.628290057182312 ; Test accuracy : 64.8\n",
      "Epochs : 436 ; Loss : 0.6273587346076965 ; Accuracy : 64.95 ; Test Loss : 0.6281599998474121 ; Test accuracy : 64.8\n",
      "Epochs : 437 ; Loss : 0.6272045969963074 ; Accuracy : 64.925 ; Test Loss : 0.6280304193496704 ; Test accuracy : 64.8\n",
      "Epochs : 438 ; Loss : 0.6270509958267212 ; Accuracy : 64.95 ; Test Loss : 0.6279011368751526 ; Test accuracy : 64.8\n",
      "Epochs : 439 ; Loss : 0.6268978118896484 ; Accuracy : 65.0 ; Test Loss : 0.6277723908424377 ; Test accuracy : 64.8\n",
      "Epochs : 440 ; Loss : 0.6267449259757996 ; Accuracy : 65.05 ; Test Loss : 0.627643883228302 ; Test accuracy : 64.8\n",
      "Epochs : 441 ; Loss : 0.6265925168991089 ; Accuracy : 65.05 ; Test Loss : 0.6275158524513245 ; Test accuracy : 64.9\n",
      "Epochs : 442 ; Loss : 0.6264404654502869 ; Accuracy : 65.15 ; Test Loss : 0.6273882985115051 ; Test accuracy : 64.9\n",
      "Epochs : 443 ; Loss : 0.6262888312339783 ; Accuracy : 65.15 ; Test Loss : 0.6272610425949097 ; Test accuracy : 65.1\n",
      "Epochs : 444 ; Loss : 0.6261375546455383 ; Accuracy : 65.15 ; Test Loss : 0.6271342635154724 ; Test accuracy : 65.1\n",
      "Epochs : 445 ; Loss : 0.6259866952896118 ; Accuracy : 65.2 ; Test Loss : 0.6270078420639038 ; Test accuracy : 65.2\n",
      "Epochs : 446 ; Loss : 0.625836193561554 ; Accuracy : 65.225 ; Test Loss : 0.6268817186355591 ; Test accuracy : 65.2\n",
      "Epochs : 447 ; Loss : 0.6256861686706543 ; Accuracy : 65.275 ; Test Loss : 0.6267561316490173 ; Test accuracy : 65.2\n",
      "Epochs : 448 ; Loss : 0.6255364418029785 ; Accuracy : 65.3 ; Test Loss : 0.6266309022903442 ; Test accuracy : 65.2\n",
      "Epochs : 449 ; Loss : 0.6253871917724609 ; Accuracy : 65.3 ; Test Loss : 0.6265061497688293 ; Test accuracy : 65.3\n",
      "Epochs : 450 ; Loss : 0.625238299369812 ; Accuracy : 65.3 ; Test Loss : 0.6263816356658936 ; Test accuracy : 65.3\n",
      "Epochs : 451 ; Loss : 0.6250897645950317 ; Accuracy : 65.35 ; Test Loss : 0.626257598400116 ; Test accuracy : 65.2\n",
      "Epochs : 452 ; Loss : 0.6249417066574097 ; Accuracy : 65.375 ; Test Loss : 0.626133918762207 ; Test accuracy : 65.2\n",
      "Epochs : 453 ; Loss : 0.6247939467430115 ; Accuracy : 65.375 ; Test Loss : 0.6260106563568115 ; Test accuracy : 65.2\n",
      "Epochs : 454 ; Loss : 0.6246466040611267 ; Accuracy : 65.4 ; Test Loss : 0.6258877515792847 ; Test accuracy : 65.3\n",
      "Epochs : 455 ; Loss : 0.6244996190071106 ; Accuracy : 65.4 ; Test Loss : 0.6257652640342712 ; Test accuracy : 65.3\n",
      "Epochs : 456 ; Loss : 0.6243530511856079 ; Accuracy : 65.5 ; Test Loss : 0.6256430745124817 ; Test accuracy : 65.3\n",
      "Epochs : 457 ; Loss : 0.6242068409919739 ; Accuracy : 65.475 ; Test Loss : 0.6255214214324951 ; Test accuracy : 65.2\n",
      "Epochs : 458 ; Loss : 0.6240609288215637 ; Accuracy : 65.525 ; Test Loss : 0.6254000663757324 ; Test accuracy : 65.2\n",
      "Epochs : 459 ; Loss : 0.6239155530929565 ; Accuracy : 65.55 ; Test Loss : 0.6252790093421936 ; Test accuracy : 65.2\n",
      "Epochs : 460 ; Loss : 0.6237704753875732 ; Accuracy : 65.55 ; Test Loss : 0.625158429145813 ; Test accuracy : 65.2\n",
      "Epochs : 461 ; Loss : 0.6236258149147034 ; Accuracy : 65.6 ; Test Loss : 0.6250382661819458 ; Test accuracy : 65.2\n",
      "Epochs : 462 ; Loss : 0.6234814524650574 ; Accuracy : 65.6 ; Test Loss : 0.6249183416366577 ; Test accuracy : 65.3\n",
      "Epochs : 463 ; Loss : 0.6233375668525696 ; Accuracy : 65.6 ; Test Loss : 0.6247988939285278 ; Test accuracy : 65.3\n",
      "Epochs : 464 ; Loss : 0.6231939792633057 ; Accuracy : 65.7 ; Test Loss : 0.6246798634529114 ; Test accuracy : 65.4\n",
      "Epochs : 465 ; Loss : 0.6230508089065552 ; Accuracy : 65.725 ; Test Loss : 0.624561071395874 ; Test accuracy : 65.5\n",
      "Epochs : 466 ; Loss : 0.6229079961776733 ; Accuracy : 65.75 ; Test Loss : 0.6244427561759949 ; Test accuracy : 65.5\n",
      "Epochs : 467 ; Loss : 0.6227655410766602 ; Accuracy : 65.775 ; Test Loss : 0.6243247389793396 ; Test accuracy : 65.5\n",
      "Epochs : 468 ; Loss : 0.6226234436035156 ; Accuracy : 65.825 ; Test Loss : 0.6242071986198425 ; Test accuracy : 65.5\n",
      "Epochs : 469 ; Loss : 0.6224817037582397 ; Accuracy : 65.825 ; Test Loss : 0.6240899562835693 ; Test accuracy : 65.5\n",
      "Epochs : 470 ; Loss : 0.6223404407501221 ; Accuracy : 65.825 ; Test Loss : 0.6239730715751648 ; Test accuracy : 65.6\n",
      "Epochs : 471 ; Loss : 0.6221994757652283 ; Accuracy : 65.875 ; Test Loss : 0.6238565444946289 ; Test accuracy : 65.7\n",
      "Epochs : 472 ; Loss : 0.6220588684082031 ; Accuracy : 65.95 ; Test Loss : 0.6237403750419617 ; Test accuracy : 65.6\n",
      "Epochs : 473 ; Loss : 0.6219186186790466 ; Accuracy : 66.0 ; Test Loss : 0.6236246824264526 ; Test accuracy : 65.6\n",
      "Epochs : 474 ; Loss : 0.621778666973114 ; Accuracy : 66.0 ; Test Loss : 0.6235092878341675 ; Test accuracy : 65.6\n",
      "Epochs : 475 ; Loss : 0.6216391921043396 ; Accuracy : 66.05 ; Test Loss : 0.623394250869751 ; Test accuracy : 65.5\n",
      "Epochs : 476 ; Loss : 0.6215000152587891 ; Accuracy : 66.1 ; Test Loss : 0.6232795119285583 ; Test accuracy : 65.6\n",
      "Epochs : 477 ; Loss : 0.621361255645752 ; Accuracy : 66.1 ; Test Loss : 0.6231651902198792 ; Test accuracy : 65.6\n",
      "Epochs : 478 ; Loss : 0.6212226748466492 ; Accuracy : 66.1 ; Test Loss : 0.6230512857437134 ; Test accuracy : 65.6\n",
      "Epochs : 479 ; Loss : 0.6210846304893494 ; Accuracy : 66.15 ; Test Loss : 0.6229376792907715 ; Test accuracy : 65.6\n",
      "Epochs : 480 ; Loss : 0.6209469437599182 ; Accuracy : 66.125 ; Test Loss : 0.6228244304656982 ; Test accuracy : 65.7\n",
      "Epochs : 481 ; Loss : 0.6208095550537109 ; Accuracy : 66.175 ; Test Loss : 0.6227115392684937 ; Test accuracy : 65.7\n",
      "Epochs : 482 ; Loss : 0.6206725239753723 ; Accuracy : 66.175 ; Test Loss : 0.6225990056991577 ; Test accuracy : 65.7\n",
      "Epochs : 483 ; Loss : 0.6205358505249023 ; Accuracy : 66.225 ; Test Loss : 0.6224868297576904 ; Test accuracy : 65.8\n",
      "Epochs : 484 ; Loss : 0.6203995943069458 ; Accuracy : 66.225 ; Test Loss : 0.622374951839447 ; Test accuracy : 65.8\n",
      "Epochs : 485 ; Loss : 0.6202635765075684 ; Accuracy : 66.225 ; Test Loss : 0.622263491153717 ; Test accuracy : 65.9\n",
      "Epochs : 486 ; Loss : 0.6201279759407043 ; Accuracy : 66.3 ; Test Loss : 0.6221523284912109 ; Test accuracy : 65.8\n",
      "Epochs : 487 ; Loss : 0.619992733001709 ; Accuracy : 66.275 ; Test Loss : 0.6220415234565735 ; Test accuracy : 65.8\n",
      "Epochs : 488 ; Loss : 0.6198577880859375 ; Accuracy : 66.325 ; Test Loss : 0.6219311356544495 ; Test accuracy : 65.8\n",
      "Epochs : 489 ; Loss : 0.6197232007980347 ; Accuracy : 66.3 ; Test Loss : 0.6218209862709045 ; Test accuracy : 65.8\n",
      "Epochs : 490 ; Loss : 0.6195889711380005 ; Accuracy : 66.275 ; Test Loss : 0.621711254119873 ; Test accuracy : 65.8\n",
      "Epochs : 491 ; Loss : 0.619455099105835 ; Accuracy : 66.3 ; Test Loss : 0.6216018795967102 ; Test accuracy : 65.8\n",
      "Epochs : 492 ; Loss : 0.6193216443061829 ; Accuracy : 66.275 ; Test Loss : 0.6214928030967712 ; Test accuracy : 65.7\n",
      "Epochs : 493 ; Loss : 0.6191883683204651 ; Accuracy : 66.3 ; Test Loss : 0.6213841438293457 ; Test accuracy : 65.6\n",
      "Epochs : 494 ; Loss : 0.6190555095672607 ; Accuracy : 66.375 ; Test Loss : 0.6212757229804993 ; Test accuracy : 65.6\n",
      "Epochs : 495 ; Loss : 0.618923008441925 ; Accuracy : 66.375 ; Test Loss : 0.621167778968811 ; Test accuracy : 65.7\n",
      "Epochs : 496 ; Loss : 0.618790864944458 ; Accuracy : 66.375 ; Test Loss : 0.6210599541664124 ; Test accuracy : 65.8\n",
      "Epochs : 497 ; Loss : 0.6186590194702148 ; Accuracy : 66.4 ; Test Loss : 0.6209526658058167 ; Test accuracy : 65.8\n",
      "Epochs : 498 ; Loss : 0.6185275316238403 ; Accuracy : 66.425 ; Test Loss : 0.6208456158638 ; Test accuracy : 65.9\n",
      "Epochs : 499 ; Loss : 0.6183964014053345 ; Accuracy : 66.4 ; Test Loss : 0.6207389235496521 ; Test accuracy : 66.0\n",
      "Epochs : 500 ; Loss : 0.6182655096054077 ; Accuracy : 66.4 ; Test Loss : 0.6206325888633728 ; Test accuracy : 66.0\n",
      "Epochs : 501 ; Loss : 0.6181350946426392 ; Accuracy : 66.425 ; Test Loss : 0.6205265522003174 ; Test accuracy : 66.0\n",
      "Epochs : 502 ; Loss : 0.6180049180984497 ; Accuracy : 66.45 ; Test Loss : 0.6204209327697754 ; Test accuracy : 66.0\n",
      "Epochs : 503 ; Loss : 0.6178751587867737 ; Accuracy : 66.425 ; Test Loss : 0.6203155517578125 ; Test accuracy : 66.0\n",
      "Epochs : 504 ; Loss : 0.6177456378936768 ; Accuracy : 66.4 ; Test Loss : 0.6202105283737183 ; Test accuracy : 66.0\n",
      "Epochs : 505 ; Loss : 0.6176164746284485 ; Accuracy : 66.4 ; Test Loss : 0.6201058626174927 ; Test accuracy : 66.0\n",
      "Epochs : 506 ; Loss : 0.6174876689910889 ; Accuracy : 66.4 ; Test Loss : 0.620001494884491 ; Test accuracy : 66.0\n",
      "Epochs : 507 ; Loss : 0.6173591613769531 ; Accuracy : 66.4 ; Test Loss : 0.6198974847793579 ; Test accuracy : 66.0\n",
      "Epochs : 508 ; Loss : 0.617231011390686 ; Accuracy : 66.45 ; Test Loss : 0.619793713092804 ; Test accuracy : 65.9\n",
      "Epochs : 509 ; Loss : 0.6171031594276428 ; Accuracy : 66.45 ; Test Loss : 0.6196904182434082 ; Test accuracy : 65.9\n",
      "Epochs : 510 ; Loss : 0.6169756054878235 ; Accuracy : 66.5 ; Test Loss : 0.6195873618125916 ; Test accuracy : 65.9\n",
      "Epochs : 511 ; Loss : 0.6168484687805176 ; Accuracy : 66.525 ; Test Loss : 0.6194846034049988 ; Test accuracy : 65.9\n",
      "Epochs : 512 ; Loss : 0.6167215704917908 ; Accuracy : 66.55 ; Test Loss : 0.6193821430206299 ; Test accuracy : 65.9\n",
      "Epochs : 513 ; Loss : 0.6165949702262878 ; Accuracy : 66.55 ; Test Loss : 0.6192800998687744 ; Test accuracy : 65.9\n",
      "Epochs : 514 ; Loss : 0.6164688467979431 ; Accuracy : 66.55 ; Test Loss : 0.619178295135498 ; Test accuracy : 65.9\n",
      "Epochs : 515 ; Loss : 0.6163429021835327 ; Accuracy : 66.55 ; Test Loss : 0.6190768480300903 ; Test accuracy : 65.9\n",
      "Epochs : 516 ; Loss : 0.616217315196991 ; Accuracy : 66.5 ; Test Loss : 0.6189757585525513 ; Test accuracy : 66.0\n",
      "Epochs : 517 ; Loss : 0.6160920858383179 ; Accuracy : 66.55 ; Test Loss : 0.6188749074935913 ; Test accuracy : 66.0\n",
      "Epochs : 518 ; Loss : 0.6159670948982239 ; Accuracy : 66.55 ; Test Loss : 0.6187744140625 ; Test accuracy : 65.9\n",
      "Epochs : 519 ; Loss : 0.6158425211906433 ; Accuracy : 66.6 ; Test Loss : 0.6186742186546326 ; Test accuracy : 65.9\n",
      "Epochs : 520 ; Loss : 0.6157181859016418 ; Accuracy : 66.6 ; Test Loss : 0.6185743808746338 ; Test accuracy : 65.9\n",
      "Epochs : 521 ; Loss : 0.6155942678451538 ; Accuracy : 66.625 ; Test Loss : 0.6184747815132141 ; Test accuracy : 65.9\n",
      "Epochs : 522 ; Loss : 0.6154704689979553 ; Accuracy : 66.65 ; Test Loss : 0.6183755993843079 ; Test accuracy : 65.9\n",
      "Epochs : 523 ; Loss : 0.615347146987915 ; Accuracy : 66.675 ; Test Loss : 0.6182766556739807 ; Test accuracy : 66.0\n",
      "Epochs : 524 ; Loss : 0.6152241230010986 ; Accuracy : 66.675 ; Test Loss : 0.6181780099868774 ; Test accuracy : 66.0\n",
      "Epochs : 525 ; Loss : 0.6151013374328613 ; Accuracy : 66.725 ; Test Loss : 0.6180797219276428 ; Test accuracy : 66.0\n",
      "Epochs : 526 ; Loss : 0.6149789094924927 ; Accuracy : 66.7 ; Test Loss : 0.6179817318916321 ; Test accuracy : 66.0\n",
      "Epochs : 527 ; Loss : 0.6148568391799927 ; Accuracy : 66.725 ; Test Loss : 0.6178839802742004 ; Test accuracy : 66.0\n",
      "Epochs : 528 ; Loss : 0.6147350072860718 ; Accuracy : 66.775 ; Test Loss : 0.6177866458892822 ; Test accuracy : 66.0\n",
      "Epochs : 529 ; Loss : 0.6146135330200195 ; Accuracy : 66.8 ; Test Loss : 0.6176896095275879 ; Test accuracy : 66.0\n",
      "Epochs : 530 ; Loss : 0.6144923567771912 ; Accuracy : 66.775 ; Test Loss : 0.6175928115844727 ; Test accuracy : 66.0\n",
      "Epochs : 531 ; Loss : 0.6143714189529419 ; Accuracy : 66.825 ; Test Loss : 0.6174962520599365 ; Test accuracy : 66.0\n",
      "Epochs : 532 ; Loss : 0.614250898361206 ; Accuracy : 66.85 ; Test Loss : 0.6174001097679138 ; Test accuracy : 65.9\n",
      "Epochs : 533 ; Loss : 0.6141305565834045 ; Accuracy : 66.8 ; Test Loss : 0.6173042058944702 ; Test accuracy : 65.9\n",
      "Epochs : 534 ; Loss : 0.6140105724334717 ; Accuracy : 66.825 ; Test Loss : 0.6172086596488953 ; Test accuracy : 65.9\n",
      "Epochs : 535 ; Loss : 0.6138908863067627 ; Accuracy : 66.825 ; Test Loss : 0.6171133518218994 ; Test accuracy : 65.9\n",
      "Epochs : 536 ; Loss : 0.6137715578079224 ; Accuracy : 66.825 ; Test Loss : 0.6170184016227722 ; Test accuracy : 65.9\n",
      "Epochs : 537 ; Loss : 0.6136524677276611 ; Accuracy : 66.9 ; Test Loss : 0.6169237494468689 ; Test accuracy : 65.9\n",
      "Epochs : 538 ; Loss : 0.6135337352752686 ; Accuracy : 66.9 ; Test Loss : 0.6168293952941895 ; Test accuracy : 65.9\n",
      "Epochs : 539 ; Loss : 0.6134153008460999 ; Accuracy : 66.85 ; Test Loss : 0.6167352795600891 ; Test accuracy : 65.9\n",
      "Epochs : 540 ; Loss : 0.6132971048355103 ; Accuracy : 66.85 ; Test Loss : 0.6166415214538574 ; Test accuracy : 65.9\n",
      "Epochs : 541 ; Loss : 0.6131792068481445 ; Accuracy : 66.85 ; Test Loss : 0.6165480017662048 ; Test accuracy : 65.9\n",
      "Epochs : 542 ; Loss : 0.6130616664886475 ; Accuracy : 66.9 ; Test Loss : 0.6164547801017761 ; Test accuracy : 65.9\n",
      "Epochs : 543 ; Loss : 0.6129443645477295 ; Accuracy : 66.925 ; Test Loss : 0.6163619160652161 ; Test accuracy : 65.9\n",
      "Epochs : 544 ; Loss : 0.6128273606300354 ; Accuracy : 66.95 ; Test Loss : 0.6162692308425903 ; Test accuracy : 65.9\n",
      "Epochs : 545 ; Loss : 0.6127106547355652 ; Accuracy : 66.975 ; Test Loss : 0.6161769032478333 ; Test accuracy : 65.9\n",
      "Epochs : 546 ; Loss : 0.6125942468643188 ; Accuracy : 66.975 ; Test Loss : 0.6160849332809448 ; Test accuracy : 65.9\n",
      "Epochs : 547 ; Loss : 0.6124781966209412 ; Accuracy : 66.975 ; Test Loss : 0.6159932017326355 ; Test accuracy : 65.9\n",
      "Epochs : 548 ; Loss : 0.6123623251914978 ; Accuracy : 66.925 ; Test Loss : 0.6159017086029053 ; Test accuracy : 65.8\n",
      "Epochs : 549 ; Loss : 0.6122468709945679 ; Accuracy : 66.925 ; Test Loss : 0.6158105134963989 ; Test accuracy : 65.8\n",
      "Epochs : 550 ; Loss : 0.6121315956115723 ; Accuracy : 66.925 ; Test Loss : 0.6157195568084717 ; Test accuracy : 65.8\n",
      "Epochs : 551 ; Loss : 0.6120166182518005 ; Accuracy : 66.975 ; Test Loss : 0.6156290173530579 ; Test accuracy : 65.8\n",
      "Epochs : 552 ; Loss : 0.6119019389152527 ; Accuracy : 66.975 ; Test Loss : 0.6155387163162231 ; Test accuracy : 65.8\n",
      "Epochs : 553 ; Loss : 0.6117876172065735 ; Accuracy : 67.0 ; Test Loss : 0.6154486536979675 ; Test accuracy : 65.8\n",
      "Epochs : 554 ; Loss : 0.6116734743118286 ; Accuracy : 67.0 ; Test Loss : 0.6153588891029358 ; Test accuracy : 65.9\n",
      "Epochs : 555 ; Loss : 0.6115596890449524 ; Accuracy : 67.05 ; Test Loss : 0.6152694225311279 ; Test accuracy : 65.9\n",
      "Epochs : 556 ; Loss : 0.6114462018013 ; Accuracy : 67.075 ; Test Loss : 0.6151801943778992 ; Test accuracy : 65.9\n",
      "Epochs : 557 ; Loss : 0.611332893371582 ; Accuracy : 67.1 ; Test Loss : 0.6150913238525391 ; Test accuracy : 65.9\n",
      "Epochs : 558 ; Loss : 0.6112200021743774 ; Accuracy : 67.1 ; Test Loss : 0.6150026321411133 ; Test accuracy : 65.9\n",
      "Epochs : 559 ; Loss : 0.611107349395752 ; Accuracy : 67.1 ; Test Loss : 0.6149143576622009 ; Test accuracy : 65.9\n",
      "Epochs : 560 ; Loss : 0.6109948754310608 ; Accuracy : 67.1 ; Test Loss : 0.6148262023925781 ; Test accuracy : 65.8\n",
      "Epochs : 561 ; Loss : 0.6108828186988831 ; Accuracy : 67.15 ; Test Loss : 0.614738404750824 ; Test accuracy : 65.8\n",
      "Epochs : 562 ; Loss : 0.6107709407806396 ; Accuracy : 67.175 ; Test Loss : 0.6146508455276489 ; Test accuracy : 65.8\n",
      "Epochs : 563 ; Loss : 0.6106594800949097 ; Accuracy : 67.225 ; Test Loss : 0.6145636439323425 ; Test accuracy : 65.8\n",
      "Epochs : 564 ; Loss : 0.610548198223114 ; Accuracy : 67.175 ; Test Loss : 0.6144766807556152 ; Test accuracy : 65.8\n",
      "Epochs : 565 ; Loss : 0.6104372143745422 ; Accuracy : 67.15 ; Test Loss : 0.6143898963928223 ; Test accuracy : 65.8\n",
      "Epochs : 566 ; Loss : 0.6103264689445496 ; Accuracy : 67.15 ; Test Loss : 0.6143034100532532 ; Test accuracy : 65.8\n",
      "Epochs : 567 ; Loss : 0.610215961933136 ; Accuracy : 67.175 ; Test Loss : 0.6142173409461975 ; Test accuracy : 65.9\n",
      "Epochs : 568 ; Loss : 0.6101058125495911 ; Accuracy : 67.2 ; Test Loss : 0.6141313910484314 ; Test accuracy : 65.9\n",
      "Epochs : 569 ; Loss : 0.60999596118927 ; Accuracy : 67.2 ; Test Loss : 0.6140457391738892 ; Test accuracy : 65.9\n",
      "Epochs : 570 ; Loss : 0.6098862886428833 ; Accuracy : 67.175 ; Test Loss : 0.6139603853225708 ; Test accuracy : 65.9\n",
      "Epochs : 571 ; Loss : 0.6097769737243652 ; Accuracy : 67.2 ; Test Loss : 0.6138752698898315 ; Test accuracy : 65.9\n",
      "Epochs : 572 ; Loss : 0.6096678972244263 ; Accuracy : 67.225 ; Test Loss : 0.6137904524803162 ; Test accuracy : 65.9\n",
      "Epochs : 573 ; Loss : 0.6095590591430664 ; Accuracy : 67.275 ; Test Loss : 0.6137058734893799 ; Test accuracy : 65.9\n",
      "Epochs : 574 ; Loss : 0.6094504594802856 ; Accuracy : 67.275 ; Test Loss : 0.6136215925216675 ; Test accuracy : 65.8\n",
      "Epochs : 575 ; Loss : 0.6093422770500183 ; Accuracy : 67.325 ; Test Loss : 0.6135375499725342 ; Test accuracy : 65.8\n",
      "Epochs : 576 ; Loss : 0.6092342138290405 ; Accuracy : 67.325 ; Test Loss : 0.61345374584198 ; Test accuracy : 65.7\n",
      "Epochs : 577 ; Loss : 0.6091265082359314 ; Accuracy : 67.325 ; Test Loss : 0.6133702397346497 ; Test accuracy : 65.7\n",
      "Epochs : 578 ; Loss : 0.6090191006660461 ; Accuracy : 67.35 ; Test Loss : 0.6132870316505432 ; Test accuracy : 65.7\n",
      "Epochs : 579 ; Loss : 0.6089118123054504 ; Accuracy : 67.35 ; Test Loss : 0.6132040023803711 ; Test accuracy : 65.7\n",
      "Epochs : 580 ; Loss : 0.6088048219680786 ; Accuracy : 67.375 ; Test Loss : 0.6131213307380676 ; Test accuracy : 65.7\n",
      "Epochs : 581 ; Loss : 0.6086981892585754 ; Accuracy : 67.425 ; Test Loss : 0.6130388379096985 ; Test accuracy : 65.7\n",
      "Epochs : 582 ; Loss : 0.6085918545722961 ; Accuracy : 67.5 ; Test Loss : 0.6129565834999084 ; Test accuracy : 65.6\n",
      "Epochs : 583 ; Loss : 0.6084856390953064 ; Accuracy : 67.525 ; Test Loss : 0.6128746271133423 ; Test accuracy : 65.5\n",
      "Epochs : 584 ; Loss : 0.6083797812461853 ; Accuracy : 67.5 ; Test Loss : 0.6127929091453552 ; Test accuracy : 65.6\n",
      "Epochs : 585 ; Loss : 0.6082741618156433 ; Accuracy : 67.525 ; Test Loss : 0.6127114295959473 ; Test accuracy : 65.6\n",
      "Epochs : 586 ; Loss : 0.6081687808036804 ; Accuracy : 67.55 ; Test Loss : 0.612630307674408 ; Test accuracy : 65.6\n",
      "Epochs : 587 ; Loss : 0.6080636382102966 ; Accuracy : 67.55 ; Test Loss : 0.612549364566803 ; Test accuracy : 65.6\n",
      "Epochs : 588 ; Loss : 0.6079588532447815 ; Accuracy : 67.55 ; Test Loss : 0.6124686598777771 ; Test accuracy : 65.6\n",
      "Epochs : 589 ; Loss : 0.6078541874885559 ; Accuracy : 67.55 ; Test Loss : 0.6123881936073303 ; Test accuracy : 65.5\n",
      "Epochs : 590 ; Loss : 0.6077498197555542 ; Accuracy : 67.525 ; Test Loss : 0.6123080253601074 ; Test accuracy : 65.5\n",
      "Epochs : 591 ; Loss : 0.6076458096504211 ; Accuracy : 67.525 ; Test Loss : 0.6122280955314636 ; Test accuracy : 65.5\n",
      "Epochs : 592 ; Loss : 0.6075420379638672 ; Accuracy : 67.525 ; Test Loss : 0.6121484041213989 ; Test accuracy : 65.5\n",
      "Epochs : 593 ; Loss : 0.6074383854866028 ; Accuracy : 67.525 ; Test Loss : 0.6120690107345581 ; Test accuracy : 65.6\n",
      "Epochs : 594 ; Loss : 0.607335090637207 ; Accuracy : 67.575 ; Test Loss : 0.6119897961616516 ; Test accuracy : 65.7\n",
      "Epochs : 595 ; Loss : 0.6072320938110352 ; Accuracy : 67.55 ; Test Loss : 0.611910879611969 ; Test accuracy : 65.7\n",
      "Epochs : 596 ; Loss : 0.6071292161941528 ; Accuracy : 67.575 ; Test Loss : 0.6118322014808655 ; Test accuracy : 65.7\n",
      "Epochs : 597 ; Loss : 0.6070266366004944 ; Accuracy : 67.575 ; Test Loss : 0.6117537021636963 ; Test accuracy : 65.7\n",
      "Epochs : 598 ; Loss : 0.6069243550300598 ; Accuracy : 67.575 ; Test Loss : 0.611675500869751 ; Test accuracy : 65.7\n",
      "Epochs : 599 ; Loss : 0.6068223118782043 ; Accuracy : 67.55 ; Test Loss : 0.6115975379943848 ; Test accuracy : 65.7\n",
      "Epochs : 600 ; Loss : 0.606720507144928 ; Accuracy : 67.525 ; Test Loss : 0.6115198731422424 ; Test accuracy : 65.7\n",
      "Epochs : 601 ; Loss : 0.6066189408302307 ; Accuracy : 67.575 ; Test Loss : 0.6114423274993896 ; Test accuracy : 65.7\n",
      "Epochs : 602 ; Loss : 0.6065176129341125 ; Accuracy : 67.55 ; Test Loss : 0.6113651394844055 ; Test accuracy : 65.7\n",
      "Epochs : 603 ; Loss : 0.6064165830612183 ; Accuracy : 67.575 ; Test Loss : 0.6112881302833557 ; Test accuracy : 65.7\n",
      "Epochs : 604 ; Loss : 0.6063158512115479 ; Accuracy : 67.575 ; Test Loss : 0.611211359500885 ; Test accuracy : 65.9\n",
      "Epochs : 605 ; Loss : 0.606215238571167 ; Accuracy : 67.6 ; Test Loss : 0.611134946346283 ; Test accuracy : 65.9\n",
      "Epochs : 606 ; Loss : 0.60611492395401 ; Accuracy : 67.6 ; Test Loss : 0.6110586524009705 ; Test accuracy : 65.9\n",
      "Epochs : 607 ; Loss : 0.6060147881507874 ; Accuracy : 67.625 ; Test Loss : 0.6109825968742371 ; Test accuracy : 66.0\n",
      "Epochs : 608 ; Loss : 0.6059149503707886 ; Accuracy : 67.65 ; Test Loss : 0.6109067797660828 ; Test accuracy : 66.1\n",
      "Epochs : 609 ; Loss : 0.6058154106140137 ; Accuracy : 67.6 ; Test Loss : 0.6108312606811523 ; Test accuracy : 66.1\n",
      "Epochs : 610 ; Loss : 0.6057159900665283 ; Accuracy : 67.575 ; Test Loss : 0.6107558608055115 ; Test accuracy : 66.1\n",
      "Epochs : 611 ; Loss : 0.6056169867515564 ; Accuracy : 67.575 ; Test Loss : 0.6106808185577393 ; Test accuracy : 66.1\n",
      "Epochs : 612 ; Loss : 0.605518102645874 ; Accuracy : 67.525 ; Test Loss : 0.6106060147285461 ; Test accuracy : 66.1\n",
      "Epochs : 613 ; Loss : 0.6054194569587708 ; Accuracy : 67.525 ; Test Loss : 0.6105313897132874 ; Test accuracy : 66.1\n",
      "Epochs : 614 ; Loss : 0.6053210496902466 ; Accuracy : 67.575 ; Test Loss : 0.6104569435119629 ; Test accuracy : 66.0\n",
      "Epochs : 615 ; Loss : 0.6052229404449463 ; Accuracy : 67.55 ; Test Loss : 0.6103828549385071 ; Test accuracy : 66.1\n",
      "Epochs : 616 ; Loss : 0.6051249504089355 ; Accuracy : 67.6 ; Test Loss : 0.6103088855743408 ; Test accuracy : 66.1\n",
      "Epochs : 617 ; Loss : 0.6050273180007935 ; Accuracy : 67.625 ; Test Loss : 0.6102351546287537 ; Test accuracy : 66.2\n",
      "Epochs : 618 ; Loss : 0.6049299240112305 ; Accuracy : 67.7 ; Test Loss : 0.6101616621017456 ; Test accuracy : 66.2\n",
      "Epochs : 619 ; Loss : 0.604832649230957 ; Accuracy : 67.7 ; Test Loss : 0.6100884079933167 ; Test accuracy : 66.2\n",
      "Epochs : 620 ; Loss : 0.6047357320785522 ; Accuracy : 67.725 ; Test Loss : 0.6100154519081116 ; Test accuracy : 66.3\n",
      "Epochs : 621 ; Loss : 0.6046389937400818 ; Accuracy : 67.725 ; Test Loss : 0.6099426746368408 ; Test accuracy : 66.3\n",
      "Epochs : 622 ; Loss : 0.6045424938201904 ; Accuracy : 67.725 ; Test Loss : 0.6098701357841492 ; Test accuracy : 66.4\n",
      "Epochs : 623 ; Loss : 0.6044461727142334 ; Accuracy : 67.725 ; Test Loss : 0.6097978353500366 ; Test accuracy : 66.5\n",
      "Epochs : 624 ; Loss : 0.6043502688407898 ; Accuracy : 67.725 ; Test Loss : 0.6097257137298584 ; Test accuracy : 66.5\n",
      "Epochs : 625 ; Loss : 0.604254424571991 ; Accuracy : 67.775 ; Test Loss : 0.6096538305282593 ; Test accuracy : 66.5\n",
      "Epochs : 626 ; Loss : 0.6041588187217712 ; Accuracy : 67.8 ; Test Loss : 0.6095821857452393 ; Test accuracy : 66.5\n",
      "Epochs : 627 ; Loss : 0.6040635108947754 ; Accuracy : 67.825 ; Test Loss : 0.6095107793807983 ; Test accuracy : 66.4\n",
      "Epochs : 628 ; Loss : 0.6039684414863586 ; Accuracy : 67.85 ; Test Loss : 0.6094395518302917 ; Test accuracy : 66.4\n",
      "Epochs : 629 ; Loss : 0.6038735508918762 ; Accuracy : 67.85 ; Test Loss : 0.6093685626983643 ; Test accuracy : 66.4\n",
      "Epochs : 630 ; Loss : 0.6037788987159729 ; Accuracy : 67.85 ; Test Loss : 0.6092977523803711 ; Test accuracy : 66.4\n",
      "Epochs : 631 ; Loss : 0.6036844849586487 ; Accuracy : 67.85 ; Test Loss : 0.609227180480957 ; Test accuracy : 66.4\n",
      "Epochs : 632 ; Loss : 0.6035903096199036 ; Accuracy : 67.85 ; Test Loss : 0.6091569066047668 ; Test accuracy : 66.4\n",
      "Epochs : 633 ; Loss : 0.6034963726997375 ; Accuracy : 67.875 ; Test Loss : 0.609086811542511 ; Test accuracy : 66.4\n",
      "Epochs : 634 ; Loss : 0.6034026145935059 ; Accuracy : 67.875 ; Test Loss : 0.6090168952941895 ; Test accuracy : 66.4\n",
      "Epochs : 635 ; Loss : 0.6033090353012085 ; Accuracy : 67.925 ; Test Loss : 0.608947217464447 ; Test accuracy : 66.4\n",
      "Epochs : 636 ; Loss : 0.603215754032135 ; Accuracy : 67.95 ; Test Loss : 0.6088777780532837 ; Test accuracy : 66.4\n",
      "Epochs : 637 ; Loss : 0.6031227111816406 ; Accuracy : 67.95 ; Test Loss : 0.6088085770606995 ; Test accuracy : 66.4\n",
      "Epochs : 638 ; Loss : 0.6030298471450806 ; Accuracy : 67.95 ; Test Loss : 0.6087394952774048 ; Test accuracy : 66.6\n",
      "Epochs : 639 ; Loss : 0.6029372811317444 ; Accuracy : 67.95 ; Test Loss : 0.608670711517334 ; Test accuracy : 66.7\n",
      "Epochs : 640 ; Loss : 0.6028448939323425 ; Accuracy : 67.975 ; Test Loss : 0.6086021065711975 ; Test accuracy : 66.8\n",
      "Epochs : 641 ; Loss : 0.602752685546875 ; Accuracy : 67.975 ; Test Loss : 0.6085337400436401 ; Test accuracy : 66.8\n",
      "Epochs : 642 ; Loss : 0.6026607155799866 ; Accuracy : 68.0 ; Test Loss : 0.6084656119346619 ; Test accuracy : 66.7\n",
      "Epochs : 643 ; Loss : 0.6025689840316772 ; Accuracy : 68.0 ; Test Loss : 0.6083976030349731 ; Test accuracy : 66.7\n",
      "Epochs : 644 ; Loss : 0.602477490901947 ; Accuracy : 68.025 ; Test Loss : 0.6083298921585083 ; Test accuracy : 66.7\n",
      "Epochs : 645 ; Loss : 0.6023861765861511 ; Accuracy : 68.05 ; Test Loss : 0.6082623600959778 ; Test accuracy : 66.7\n",
      "Epochs : 646 ; Loss : 0.6022951006889343 ; Accuracy : 68.05 ; Test Loss : 0.6081949472427368 ; Test accuracy : 66.7\n",
      "Epochs : 647 ; Loss : 0.6022042632102966 ; Accuracy : 68.025 ; Test Loss : 0.6081278324127197 ; Test accuracy : 66.7\n",
      "Epochs : 648 ; Loss : 0.602113664150238 ; Accuracy : 68.075 ; Test Loss : 0.6080609560012817 ; Test accuracy : 66.7\n",
      "Epochs : 649 ; Loss : 0.602023184299469 ; Accuracy : 68.075 ; Test Loss : 0.6079943180084229 ; Test accuracy : 66.8\n",
      "Epochs : 650 ; Loss : 0.601932942867279 ; Accuracy : 68.1 ; Test Loss : 0.6079277396202087 ; Test accuracy : 66.7\n",
      "Epochs : 651 ; Loss : 0.601842999458313 ; Accuracy : 68.075 ; Test Loss : 0.6078614592552185 ; Test accuracy : 66.8\n",
      "Epochs : 652 ; Loss : 0.6017531752586365 ; Accuracy : 68.075 ; Test Loss : 0.6077954173088074 ; Test accuracy : 66.8\n",
      "Epochs : 653 ; Loss : 0.6016635894775391 ; Accuracy : 68.075 ; Test Loss : 0.6077294945716858 ; Test accuracy : 66.8\n",
      "Epochs : 654 ; Loss : 0.6015742421150208 ; Accuracy : 68.05 ; Test Loss : 0.6076638698577881 ; Test accuracy : 66.8\n",
      "Epochs : 655 ; Loss : 0.6014851331710815 ; Accuracy : 67.975 ; Test Loss : 0.6075984239578247 ; Test accuracy : 66.8\n",
      "Epochs : 656 ; Loss : 0.6013962030410767 ; Accuracy : 67.975 ; Test Loss : 0.6075331568717957 ; Test accuracy : 66.8\n",
      "Epochs : 657 ; Loss : 0.6013074517250061 ; Accuracy : 67.975 ; Test Loss : 0.6074680685997009 ; Test accuracy : 66.9\n",
      "Epochs : 658 ; Loss : 0.6012188792228699 ; Accuracy : 67.95 ; Test Loss : 0.6074032187461853 ; Test accuracy : 66.9\n",
      "Epochs : 659 ; Loss : 0.6011306643486023 ; Accuracy : 67.95 ; Test Loss : 0.6073386073112488 ; Test accuracy : 66.9\n",
      "Epochs : 660 ; Loss : 0.6010425686836243 ; Accuracy : 67.975 ; Test Loss : 0.6072741150856018 ; Test accuracy : 66.9\n",
      "Epochs : 661 ; Loss : 0.6009547114372253 ; Accuracy : 68.0 ; Test Loss : 0.6072098612785339 ; Test accuracy : 66.9\n",
      "Epochs : 662 ; Loss : 0.6008670330047607 ; Accuracy : 68.025 ; Test Loss : 0.6071457862854004 ; Test accuracy : 66.9\n",
      "Epochs : 663 ; Loss : 0.6007795929908752 ; Accuracy : 68.025 ; Test Loss : 0.607081949710846 ; Test accuracy : 66.9\n",
      "Epochs : 664 ; Loss : 0.6006922721862793 ; Accuracy : 68.025 ; Test Loss : 0.6070182919502258 ; Test accuracy : 66.9\n",
      "Epochs : 665 ; Loss : 0.6006052494049072 ; Accuracy : 68.0 ; Test Loss : 0.6069548726081848 ; Test accuracy : 66.9\n",
      "Epochs : 666 ; Loss : 0.6005184054374695 ; Accuracy : 68.0 ; Test Loss : 0.6068915724754333 ; Test accuracy : 67.0\n",
      "Epochs : 667 ; Loss : 0.6004317998886108 ; Accuracy : 68.025 ; Test Loss : 0.606828510761261 ; Test accuracy : 67.0\n",
      "Epochs : 668 ; Loss : 0.6003453731536865 ; Accuracy : 68.025 ; Test Loss : 0.6067655682563782 ; Test accuracy : 67.0\n",
      "Epochs : 669 ; Loss : 0.6002590656280518 ; Accuracy : 68.025 ; Test Loss : 0.606702983379364 ; Test accuracy : 67.0\n",
      "Epochs : 670 ; Loss : 0.6001731157302856 ; Accuracy : 68.05 ; Test Loss : 0.6066403985023499 ; Test accuracy : 67.0\n",
      "Epochs : 671 ; Loss : 0.6000872254371643 ; Accuracy : 68.075 ; Test Loss : 0.6065781712532043 ; Test accuracy : 67.0\n",
      "Epochs : 672 ; Loss : 0.6000016331672668 ; Accuracy : 68.1 ; Test Loss : 0.6065160632133484 ; Test accuracy : 67.0\n",
      "Epochs : 673 ; Loss : 0.5999161601066589 ; Accuracy : 68.1 ; Test Loss : 0.6064541339874268 ; Test accuracy : 67.0\n",
      "Epochs : 674 ; Loss : 0.5998310446739197 ; Accuracy : 68.125 ; Test Loss : 0.6063924431800842 ; Test accuracy : 67.1\n",
      "Epochs : 675 ; Loss : 0.5997459292411804 ; Accuracy : 68.125 ; Test Loss : 0.6063309907913208 ; Test accuracy : 67.2\n",
      "Epochs : 676 ; Loss : 0.5996611714363098 ; Accuracy : 68.15 ; Test Loss : 0.6062695980072021 ; Test accuracy : 67.2\n",
      "Epochs : 677 ; Loss : 0.5995765924453735 ; Accuracy : 68.175 ; Test Loss : 0.6062084436416626 ; Test accuracy : 67.2\n",
      "Epochs : 678 ; Loss : 0.599492073059082 ; Accuracy : 68.2 ; Test Loss : 0.6061474680900574 ; Test accuracy : 67.3\n",
      "Epochs : 679 ; Loss : 0.5994078516960144 ; Accuracy : 68.2 ; Test Loss : 0.6060867309570312 ; Test accuracy : 67.3\n",
      "Epochs : 680 ; Loss : 0.5993238687515259 ; Accuracy : 68.2 ; Test Loss : 0.6060261726379395 ; Test accuracy : 67.3\n",
      "Epochs : 681 ; Loss : 0.5992400050163269 ; Accuracy : 68.225 ; Test Loss : 0.605965793132782 ; Test accuracy : 67.3\n",
      "Epochs : 682 ; Loss : 0.599156379699707 ; Accuracy : 68.225 ; Test Loss : 0.6059055924415588 ; Test accuracy : 67.4\n",
      "Epochs : 683 ; Loss : 0.5990729331970215 ; Accuracy : 68.25 ; Test Loss : 0.6058456301689148 ; Test accuracy : 67.4\n",
      "Epochs : 684 ; Loss : 0.598989725112915 ; Accuracy : 68.25 ; Test Loss : 0.6057857275009155 ; Test accuracy : 67.4\n",
      "Epochs : 685 ; Loss : 0.5989066958427429 ; Accuracy : 68.275 ; Test Loss : 0.6057261228561401 ; Test accuracy : 67.4\n",
      "Epochs : 686 ; Loss : 0.5988239049911499 ; Accuracy : 68.325 ; Test Loss : 0.6056666374206543 ; Test accuracy : 67.4\n",
      "Epochs : 687 ; Loss : 0.5987411141395569 ; Accuracy : 68.3 ; Test Loss : 0.6056073904037476 ; Test accuracy : 67.4\n",
      "Epochs : 688 ; Loss : 0.5986587405204773 ; Accuracy : 68.3 ; Test Loss : 0.6055483222007751 ; Test accuracy : 67.4\n",
      "Epochs : 689 ; Loss : 0.5985764265060425 ; Accuracy : 68.325 ; Test Loss : 0.6054894328117371 ; Test accuracy : 67.5\n",
      "Epochs : 690 ; Loss : 0.5984943509101868 ; Accuracy : 68.35 ; Test Loss : 0.6054307222366333 ; Test accuracy : 67.6\n",
      "Epochs : 691 ; Loss : 0.5984124541282654 ; Accuracy : 68.375 ; Test Loss : 0.6053720712661743 ; Test accuracy : 67.7\n",
      "Epochs : 692 ; Loss : 0.5983307361602783 ; Accuracy : 68.425 ; Test Loss : 0.605313777923584 ; Test accuracy : 67.7\n",
      "Epochs : 693 ; Loss : 0.5982492566108704 ; Accuracy : 68.425 ; Test Loss : 0.6052556037902832 ; Test accuracy : 67.8\n",
      "Epochs : 694 ; Loss : 0.5981679558753967 ; Accuracy : 68.425 ; Test Loss : 0.605197548866272 ; Test accuracy : 68.0\n",
      "Epochs : 695 ; Loss : 0.5980868935585022 ; Accuracy : 68.475 ; Test Loss : 0.6051397919654846 ; Test accuracy : 68.1\n",
      "Epochs : 696 ; Loss : 0.5980058908462524 ; Accuracy : 68.475 ; Test Loss : 0.6050820350646973 ; Test accuracy : 68.1\n",
      "Epochs : 697 ; Loss : 0.5979251265525818 ; Accuracy : 68.475 ; Test Loss : 0.6050246953964233 ; Test accuracy : 68.1\n",
      "Epochs : 698 ; Loss : 0.5978446006774902 ; Accuracy : 68.5 ; Test Loss : 0.6049672961235046 ; Test accuracy : 68.1\n",
      "Epochs : 699 ; Loss : 0.5977641940116882 ; Accuracy : 68.475 ; Test Loss : 0.6049103140830994 ; Test accuracy : 68.0\n",
      "Epochs : 700 ; Loss : 0.5976839661598206 ; Accuracy : 68.475 ; Test Loss : 0.6048532724380493 ; Test accuracy : 68.0\n",
      "Epochs : 701 ; Loss : 0.597603976726532 ; Accuracy : 68.475 ; Test Loss : 0.6047965288162231 ; Test accuracy : 68.0\n",
      "Epochs : 702 ; Loss : 0.5975241661071777 ; Accuracy : 68.475 ; Test Loss : 0.6047399640083313 ; Test accuracy : 68.0\n",
      "Epochs : 703 ; Loss : 0.5974445343017578 ; Accuracy : 68.475 ; Test Loss : 0.604683518409729 ; Test accuracy : 68.0\n",
      "Epochs : 704 ; Loss : 0.597365140914917 ; Accuracy : 68.5 ; Test Loss : 0.6046273708343506 ; Test accuracy : 68.0\n",
      "Epochs : 705 ; Loss : 0.597285807132721 ; Accuracy : 68.5 ; Test Loss : 0.6045712828636169 ; Test accuracy : 68.0\n",
      "Epochs : 706 ; Loss : 0.5972068309783936 ; Accuracy : 68.475 ; Test Loss : 0.6045154333114624 ; Test accuracy : 68.0\n",
      "Epochs : 707 ; Loss : 0.5971278548240662 ; Accuracy : 68.45 ; Test Loss : 0.6044597029685974 ; Test accuracy : 67.9\n",
      "Epochs : 708 ; Loss : 0.5970491766929626 ; Accuracy : 68.45 ; Test Loss : 0.6044041514396667 ; Test accuracy : 68.0\n",
      "Epochs : 709 ; Loss : 0.5969706177711487 ; Accuracy : 68.525 ; Test Loss : 0.6043487787246704 ; Test accuracy : 68.0\n",
      "Epochs : 710 ; Loss : 0.596892237663269 ; Accuracy : 68.525 ; Test Loss : 0.6042935252189636 ; Test accuracy : 68.0\n",
      "Epochs : 711 ; Loss : 0.5968140959739685 ; Accuracy : 68.525 ; Test Loss : 0.6042385101318359 ; Test accuracy : 68.0\n",
      "Epochs : 712 ; Loss : 0.5967361330986023 ; Accuracy : 68.45 ; Test Loss : 0.6041836738586426 ; Test accuracy : 68.0\n",
      "Epochs : 713 ; Loss : 0.5966582894325256 ; Accuracy : 68.45 ; Test Loss : 0.6041289567947388 ; Test accuracy : 68.0\n",
      "Epochs : 714 ; Loss : 0.5965806841850281 ; Accuracy : 68.525 ; Test Loss : 0.6040744185447693 ; Test accuracy : 68.0\n",
      "Epochs : 715 ; Loss : 0.5965031981468201 ; Accuracy : 68.55 ; Test Loss : 0.6040200591087341 ; Test accuracy : 68.0\n",
      "Epochs : 716 ; Loss : 0.5964259505271912 ; Accuracy : 68.55 ; Test Loss : 0.6039659380912781 ; Test accuracy : 68.0\n",
      "Epochs : 717 ; Loss : 0.5963488221168518 ; Accuracy : 68.575 ; Test Loss : 0.6039118766784668 ; Test accuracy : 68.0\n",
      "Epochs : 718 ; Loss : 0.5962718725204468 ; Accuracy : 68.6 ; Test Loss : 0.6038580536842346 ; Test accuracy : 68.0\n",
      "Epochs : 719 ; Loss : 0.5961951613426208 ; Accuracy : 68.6 ; Test Loss : 0.603804349899292 ; Test accuracy : 68.0\n",
      "Epochs : 720 ; Loss : 0.5961185693740845 ; Accuracy : 68.625 ; Test Loss : 0.6037508845329285 ; Test accuracy : 68.0\n",
      "Epochs : 721 ; Loss : 0.5960422158241272 ; Accuracy : 68.65 ; Test Loss : 0.6036974787712097 ; Test accuracy : 67.9\n",
      "Epochs : 722 ; Loss : 0.5959659814834595 ; Accuracy : 68.7 ; Test Loss : 0.6036443114280701 ; Test accuracy : 68.0\n",
      "Epochs : 723 ; Loss : 0.5958899259567261 ; Accuracy : 68.725 ; Test Loss : 0.60359126329422 ; Test accuracy : 68.0\n",
      "Epochs : 724 ; Loss : 0.5958141088485718 ; Accuracy : 68.725 ; Test Loss : 0.6035383343696594 ; Test accuracy : 68.0\n",
      "Epochs : 725 ; Loss : 0.595738410949707 ; Accuracy : 68.75 ; Test Loss : 0.6034857034683228 ; Test accuracy : 68.0\n",
      "Epochs : 726 ; Loss : 0.5956628918647766 ; Accuracy : 68.75 ; Test Loss : 0.6034331917762756 ; Test accuracy : 68.0\n",
      "Epochs : 727 ; Loss : 0.5955875515937805 ; Accuracy : 68.75 ; Test Loss : 0.6033807396888733 ; Test accuracy : 68.0\n",
      "Epochs : 728 ; Loss : 0.595512330532074 ; Accuracy : 68.775 ; Test Loss : 0.6033285856246948 ; Test accuracy : 68.0\n",
      "Epochs : 729 ; Loss : 0.5954373478889465 ; Accuracy : 68.775 ; Test Loss : 0.6032764911651611 ; Test accuracy : 68.0\n",
      "Epochs : 730 ; Loss : 0.5953625440597534 ; Accuracy : 68.75 ; Test Loss : 0.6032246351242065 ; Test accuracy : 68.0\n",
      "Epochs : 731 ; Loss : 0.5952878594398499 ; Accuracy : 68.75 ; Test Loss : 0.6031728982925415 ; Test accuracy : 68.0\n",
      "Epochs : 732 ; Loss : 0.5952134132385254 ; Accuracy : 68.75 ; Test Loss : 0.603121280670166 ; Test accuracy : 68.0\n",
      "Epochs : 733 ; Loss : 0.5951390862464905 ; Accuracy : 68.75 ; Test Loss : 0.6030699014663696 ; Test accuracy : 68.0\n",
      "Epochs : 734 ; Loss : 0.5950649380683899 ; Accuracy : 68.775 ; Test Loss : 0.6030186414718628 ; Test accuracy : 68.0\n",
      "Epochs : 735 ; Loss : 0.5949908494949341 ; Accuracy : 68.775 ; Test Loss : 0.6029675602912903 ; Test accuracy : 68.0\n",
      "Epochs : 736 ; Loss : 0.5949171185493469 ; Accuracy : 68.775 ; Test Loss : 0.6029165387153625 ; Test accuracy : 68.0\n",
      "Epochs : 737 ; Loss : 0.5948434472084045 ; Accuracy : 68.825 ; Test Loss : 0.6028658151626587 ; Test accuracy : 68.0\n",
      "Epochs : 738 ; Loss : 0.5947700142860413 ; Accuracy : 68.8 ; Test Loss : 0.6028152108192444 ; Test accuracy : 68.0\n",
      "Epochs : 739 ; Loss : 0.5946967005729675 ; Accuracy : 68.85 ; Test Loss : 0.6027646660804749 ; Test accuracy : 68.0\n",
      "Epochs : 740 ; Loss : 0.5946235060691833 ; Accuracy : 68.85 ; Test Loss : 0.6027143597602844 ; Test accuracy : 68.1\n",
      "Epochs : 741 ; Loss : 0.5945505499839783 ; Accuracy : 68.875 ; Test Loss : 0.6026642322540283 ; Test accuracy : 68.2\n",
      "Epochs : 742 ; Loss : 0.5944777727127075 ; Accuracy : 68.875 ; Test Loss : 0.602614164352417 ; Test accuracy : 68.2\n",
      "Epochs : 743 ; Loss : 0.5944050550460815 ; Accuracy : 68.925 ; Test Loss : 0.6025643348693848 ; Test accuracy : 68.3\n",
      "Epochs : 744 ; Loss : 0.5943326354026794 ; Accuracy : 68.975 ; Test Loss : 0.6025146842002869 ; Test accuracy : 68.3\n",
      "Epochs : 745 ; Loss : 0.5942602753639221 ; Accuracy : 68.975 ; Test Loss : 0.6024650931358337 ; Test accuracy : 68.3\n",
      "Epochs : 746 ; Loss : 0.5941881537437439 ; Accuracy : 68.975 ; Test Loss : 0.6024156808853149 ; Test accuracy : 68.3\n",
      "Epochs : 747 ; Loss : 0.5941160917282104 ; Accuracy : 69.025 ; Test Loss : 0.6023664474487305 ; Test accuracy : 68.3\n",
      "Epochs : 748 ; Loss : 0.5940443277359009 ; Accuracy : 69.0 ; Test Loss : 0.6023173332214355 ; Test accuracy : 68.3\n",
      "Epochs : 749 ; Loss : 0.5939726233482361 ; Accuracy : 69.025 ; Test Loss : 0.6022684574127197 ; Test accuracy : 68.3\n",
      "Epochs : 750 ; Loss : 0.5939011573791504 ; Accuracy : 69.075 ; Test Loss : 0.6022196412086487 ; Test accuracy : 68.4\n",
      "Epochs : 751 ; Loss : 0.5938297510147095 ; Accuracy : 69.175 ; Test Loss : 0.602171003818512 ; Test accuracy : 68.6\n",
      "Epochs : 752 ; Loss : 0.5937585830688477 ; Accuracy : 69.225 ; Test Loss : 0.6021224856376648 ; Test accuracy : 68.7\n",
      "Epochs : 753 ; Loss : 0.5936875939369202 ; Accuracy : 69.225 ; Test Loss : 0.602074146270752 ; Test accuracy : 68.7\n",
      "Epochs : 754 ; Loss : 0.5936167240142822 ; Accuracy : 69.25 ; Test Loss : 0.6020259261131287 ; Test accuracy : 68.7\n",
      "Epochs : 755 ; Loss : 0.5935460329055786 ; Accuracy : 69.275 ; Test Loss : 0.6019779443740845 ; Test accuracy : 68.7\n",
      "Epochs : 756 ; Loss : 0.5934755206108093 ; Accuracy : 69.275 ; Test Loss : 0.6019299626350403 ; Test accuracy : 68.7\n",
      "Epochs : 757 ; Loss : 0.5934050679206848 ; Accuracy : 69.275 ; Test Loss : 0.6018822193145752 ; Test accuracy : 68.7\n",
      "Epochs : 758 ; Loss : 0.5933348536491394 ; Accuracy : 69.275 ; Test Loss : 0.6018345952033997 ; Test accuracy : 68.7\n",
      "Epochs : 759 ; Loss : 0.5932648181915283 ; Accuracy : 69.3 ; Test Loss : 0.6017871499061584 ; Test accuracy : 68.7\n",
      "Epochs : 760 ; Loss : 0.5931949019432068 ; Accuracy : 69.325 ; Test Loss : 0.6017398834228516 ; Test accuracy : 68.7\n",
      "Epochs : 761 ; Loss : 0.5931251645088196 ; Accuracy : 69.35 ; Test Loss : 0.6016926765441895 ; Test accuracy : 68.8\n",
      "Epochs : 762 ; Loss : 0.5930555462837219 ; Accuracy : 69.375 ; Test Loss : 0.6016456484794617 ; Test accuracy : 68.9\n",
      "Epochs : 763 ; Loss : 0.5929861068725586 ; Accuracy : 69.375 ; Test Loss : 0.6015987992286682 ; Test accuracy : 68.9\n",
      "Epochs : 764 ; Loss : 0.5929168462753296 ; Accuracy : 69.375 ; Test Loss : 0.6015520095825195 ; Test accuracy : 68.9\n",
      "Epochs : 765 ; Loss : 0.5928477048873901 ; Accuracy : 69.4 ; Test Loss : 0.60150545835495 ; Test accuracy : 68.9\n",
      "Epochs : 766 ; Loss : 0.592778742313385 ; Accuracy : 69.375 ; Test Loss : 0.6014590263366699 ; Test accuracy : 68.9\n",
      "Epochs : 767 ; Loss : 0.5927098393440247 ; Accuracy : 69.375 ; Test Loss : 0.6014127135276794 ; Test accuracy : 68.8\n",
      "Epochs : 768 ; Loss : 0.5926411747932434 ; Accuracy : 69.375 ; Test Loss : 0.6013664603233337 ; Test accuracy : 68.8\n",
      "Epochs : 769 ; Loss : 0.5925726890563965 ; Accuracy : 69.4 ; Test Loss : 0.6013205051422119 ; Test accuracy : 68.8\n",
      "Epochs : 770 ; Loss : 0.5925043821334839 ; Accuracy : 69.425 ; Test Loss : 0.6012746095657349 ; Test accuracy : 68.8\n",
      "Epochs : 771 ; Loss : 0.5924360752105713 ; Accuracy : 69.45 ; Test Loss : 0.6012288331985474 ; Test accuracy : 68.8\n",
      "Epochs : 772 ; Loss : 0.5923680663108826 ; Accuracy : 69.45 ; Test Loss : 0.6011832356452942 ; Test accuracy : 68.8\n",
      "Epochs : 773 ; Loss : 0.5923001766204834 ; Accuracy : 69.475 ; Test Loss : 0.6011377573013306 ; Test accuracy : 68.8\n",
      "Epochs : 774 ; Loss : 0.5922324657440186 ; Accuracy : 69.475 ; Test Loss : 0.601092517375946 ; Test accuracy : 68.9\n",
      "Epochs : 775 ; Loss : 0.5921648144721985 ; Accuracy : 69.5 ; Test Loss : 0.6010472774505615 ; Test accuracy : 68.9\n",
      "Epochs : 776 ; Loss : 0.5920973420143127 ; Accuracy : 69.5 ; Test Loss : 0.6010022163391113 ; Test accuracy : 68.9\n",
      "Epochs : 777 ; Loss : 0.5920301079750061 ; Accuracy : 69.5 ; Test Loss : 0.6009572744369507 ; Test accuracy : 68.9\n",
      "Epochs : 778 ; Loss : 0.5919629335403442 ; Accuracy : 69.55 ; Test Loss : 0.6009125709533691 ; Test accuracy : 69.0\n",
      "Epochs : 779 ; Loss : 0.5918958783149719 ; Accuracy : 69.55 ; Test Loss : 0.6008679270744324 ; Test accuracy : 69.0\n",
      "Epochs : 780 ; Loss : 0.5918290019035339 ; Accuracy : 69.525 ; Test Loss : 0.6008234024047852 ; Test accuracy : 69.0\n",
      "Epochs : 781 ; Loss : 0.591762363910675 ; Accuracy : 69.525 ; Test Loss : 0.6007790565490723 ; Test accuracy : 69.1\n",
      "Epochs : 782 ; Loss : 0.5916957855224609 ; Accuracy : 69.55 ; Test Loss : 0.6007348299026489 ; Test accuracy : 69.1\n",
      "Epochs : 783 ; Loss : 0.5916293859481812 ; Accuracy : 69.6 ; Test Loss : 0.6006907820701599 ; Test accuracy : 69.1\n",
      "Epochs : 784 ; Loss : 0.5915631055831909 ; Accuracy : 69.6 ; Test Loss : 0.6006467938423157 ; Test accuracy : 69.1\n",
      "Epochs : 785 ; Loss : 0.591497004032135 ; Accuracy : 69.6 ; Test Loss : 0.600602924823761 ; Test accuracy : 69.1\n",
      "Epochs : 786 ; Loss : 0.5914310216903687 ; Accuracy : 69.675 ; Test Loss : 0.6005592346191406 ; Test accuracy : 69.1\n",
      "Epochs : 787 ; Loss : 0.5913652181625366 ; Accuracy : 69.7 ; Test Loss : 0.6005157232284546 ; Test accuracy : 69.0\n",
      "Epochs : 788 ; Loss : 0.5912995338439941 ; Accuracy : 69.7 ; Test Loss : 0.6004723310470581 ; Test accuracy : 69.1\n",
      "Epochs : 789 ; Loss : 0.5912339687347412 ; Accuracy : 69.7 ; Test Loss : 0.6004289984703064 ; Test accuracy : 69.1\n",
      "Epochs : 790 ; Loss : 0.5911685824394226 ; Accuracy : 69.7 ; Test Loss : 0.6003859043121338 ; Test accuracy : 69.1\n",
      "Epochs : 791 ; Loss : 0.5911033153533936 ; Accuracy : 69.725 ; Test Loss : 0.6003428101539612 ; Test accuracy : 69.1\n",
      "Epochs : 792 ; Loss : 0.5910382270812988 ; Accuracy : 69.725 ; Test Loss : 0.6002999544143677 ; Test accuracy : 69.1\n",
      "Epochs : 793 ; Loss : 0.5909733176231384 ; Accuracy : 69.75 ; Test Loss : 0.6002572178840637 ; Test accuracy : 69.1\n",
      "Epochs : 794 ; Loss : 0.5909084677696228 ; Accuracy : 69.75 ; Test Loss : 0.6002146005630493 ; Test accuracy : 69.0\n",
      "Epochs : 795 ; Loss : 0.5908437967300415 ; Accuracy : 69.75 ; Test Loss : 0.6001720428466797 ; Test accuracy : 69.0\n",
      "Epochs : 796 ; Loss : 0.590779185295105 ; Accuracy : 69.725 ; Test Loss : 0.6001297235488892 ; Test accuracy : 68.9\n",
      "Epochs : 797 ; Loss : 0.5907148718833923 ; Accuracy : 69.75 ; Test Loss : 0.6000874042510986 ; Test accuracy : 68.9\n",
      "Epochs : 798 ; Loss : 0.5906506776809692 ; Accuracy : 69.75 ; Test Loss : 0.6000453233718872 ; Test accuracy : 68.9\n",
      "Epochs : 799 ; Loss : 0.5905865430831909 ; Accuracy : 69.75 ; Test Loss : 0.6000033617019653 ; Test accuracy : 68.9\n",
      "Epochs : 800 ; Loss : 0.5905225872993469 ; Accuracy : 69.725 ; Test Loss : 0.599961519241333 ; Test accuracy : 68.9\n",
      "Epochs : 801 ; Loss : 0.5904587507247925 ; Accuracy : 69.7 ; Test Loss : 0.599919855594635 ; Test accuracy : 69.1\n",
      "Epochs : 802 ; Loss : 0.5903950333595276 ; Accuracy : 69.7 ; Test Loss : 0.599878191947937 ; Test accuracy : 69.1\n",
      "Epochs : 803 ; Loss : 0.5903315544128418 ; Accuracy : 69.7 ; Test Loss : 0.5998367071151733 ; Test accuracy : 69.1\n",
      "Epochs : 804 ; Loss : 0.590268075466156 ; Accuracy : 69.725 ; Test Loss : 0.5997953414916992 ; Test accuracy : 69.1\n",
      "Epochs : 805 ; Loss : 0.5902048349380493 ; Accuracy : 69.75 ; Test Loss : 0.5997540950775146 ; Test accuracy : 69.1\n",
      "Epochs : 806 ; Loss : 0.5901417136192322 ; Accuracy : 69.75 ; Test Loss : 0.5997130274772644 ; Test accuracy : 69.1\n",
      "Epochs : 807 ; Loss : 0.5900787115097046 ; Accuracy : 69.775 ; Test Loss : 0.5996721386909485 ; Test accuracy : 69.1\n",
      "Epochs : 808 ; Loss : 0.5900158882141113 ; Accuracy : 69.75 ; Test Loss : 0.5996311902999878 ; Test accuracy : 69.1\n",
      "Epochs : 809 ; Loss : 0.5899531245231628 ; Accuracy : 69.75 ; Test Loss : 0.5995904803276062 ; Test accuracy : 69.1\n",
      "Epochs : 810 ; Loss : 0.5898905992507935 ; Accuracy : 69.75 ; Test Loss : 0.5995498895645142 ; Test accuracy : 69.1\n",
      "Epochs : 811 ; Loss : 0.5898281335830688 ; Accuracy : 69.8 ; Test Loss : 0.5995094776153564 ; Test accuracy : 69.2\n",
      "Epochs : 812 ; Loss : 0.5897659063339233 ; Accuracy : 69.8 ; Test Loss : 0.5994691252708435 ; Test accuracy : 69.2\n",
      "Epochs : 813 ; Loss : 0.5897036194801331 ; Accuracy : 69.8 ; Test Loss : 0.5994288325309753 ; Test accuracy : 69.2\n",
      "Epochs : 814 ; Loss : 0.5896416306495667 ; Accuracy : 69.8 ; Test Loss : 0.599388837814331 ; Test accuracy : 69.1\n",
      "Epochs : 815 ; Loss : 0.5895797610282898 ; Accuracy : 69.825 ; Test Loss : 0.5993488430976868 ; Test accuracy : 69.1\n",
      "Epochs : 816 ; Loss : 0.5895179510116577 ; Accuracy : 69.825 ; Test Loss : 0.5993089079856873 ; Test accuracy : 69.1\n",
      "Epochs : 817 ; Loss : 0.58945631980896 ; Accuracy : 69.825 ; Test Loss : 0.5992692112922668 ; Test accuracy : 69.1\n",
      "Epochs : 818 ; Loss : 0.5893948078155518 ; Accuracy : 69.85 ; Test Loss : 0.5992295742034912 ; Test accuracy : 69.1\n",
      "Epochs : 819 ; Loss : 0.5893334746360779 ; Accuracy : 69.9 ; Test Loss : 0.5991901159286499 ; Test accuracy : 69.1\n",
      "Epochs : 820 ; Loss : 0.5892722606658936 ; Accuracy : 69.9 ; Test Loss : 0.5991507172584534 ; Test accuracy : 69.1\n",
      "Epochs : 821 ; Loss : 0.5892111659049988 ; Accuracy : 69.875 ; Test Loss : 0.5991114974021912 ; Test accuracy : 69.1\n",
      "Epochs : 822 ; Loss : 0.5891501903533936 ; Accuracy : 69.875 ; Test Loss : 0.599072277545929 ; Test accuracy : 69.1\n",
      "Epochs : 823 ; Loss : 0.5890893936157227 ; Accuracy : 69.875 ; Test Loss : 0.5990333557128906 ; Test accuracy : 69.0\n",
      "Epochs : 824 ; Loss : 0.5890286564826965 ; Accuracy : 69.9 ; Test Loss : 0.5989944338798523 ; Test accuracy : 69.0\n",
      "Epochs : 825 ; Loss : 0.58896803855896 ; Accuracy : 69.9 ; Test Loss : 0.5989556312561035 ; Test accuracy : 69.0\n",
      "Epochs : 826 ; Loss : 0.5889075994491577 ; Accuracy : 69.9 ; Test Loss : 0.5989170074462891 ; Test accuracy : 69.0\n",
      "Epochs : 827 ; Loss : 0.5888473987579346 ; Accuracy : 69.925 ; Test Loss : 0.5988784432411194 ; Test accuracy : 69.0\n",
      "Epochs : 828 ; Loss : 0.5887871384620667 ; Accuracy : 69.925 ; Test Loss : 0.5988399982452393 ; Test accuracy : 69.0\n",
      "Epochs : 829 ; Loss : 0.5887270569801331 ; Accuracy : 69.95 ; Test Loss : 0.5988016724586487 ; Test accuracy : 69.0\n",
      "Epochs : 830 ; Loss : 0.5886671543121338 ; Accuracy : 69.925 ; Test Loss : 0.5987634658813477 ; Test accuracy : 69.0\n",
      "Epochs : 831 ; Loss : 0.5886073708534241 ; Accuracy : 69.925 ; Test Loss : 0.5987254977226257 ; Test accuracy : 69.0\n",
      "Epochs : 832 ; Loss : 0.5885477662086487 ; Accuracy : 69.95 ; Test Loss : 0.598687469959259 ; Test accuracy : 69.0\n",
      "Epochs : 833 ; Loss : 0.5884881615638733 ; Accuracy : 69.95 ; Test Loss : 0.5986496210098267 ; Test accuracy : 68.9\n",
      "Epochs : 834 ; Loss : 0.5884288549423218 ; Accuracy : 69.975 ; Test Loss : 0.5986119508743286 ; Test accuracy : 68.9\n",
      "Epochs : 835 ; Loss : 0.5883695483207703 ; Accuracy : 69.975 ; Test Loss : 0.5985743403434753 ; Test accuracy : 68.9\n",
      "Epochs : 836 ; Loss : 0.5883103013038635 ; Accuracy : 69.975 ; Test Loss : 0.5985367894172668 ; Test accuracy : 68.9\n",
      "Epochs : 837 ; Loss : 0.5882513523101807 ; Accuracy : 70.0 ; Test Loss : 0.5984994173049927 ; Test accuracy : 68.9\n",
      "Epochs : 838 ; Loss : 0.5881924033164978 ; Accuracy : 69.975 ; Test Loss : 0.5984621644020081 ; Test accuracy : 68.8\n",
      "Epochs : 839 ; Loss : 0.588133692741394 ; Accuracy : 70.0 ; Test Loss : 0.598425030708313 ; Test accuracy : 68.8\n",
      "Epochs : 840 ; Loss : 0.5880751013755798 ; Accuracy : 69.975 ; Test Loss : 0.5983879566192627 ; Test accuracy : 68.8\n",
      "Epochs : 841 ; Loss : 0.5880165100097656 ; Accuracy : 69.975 ; Test Loss : 0.598351001739502 ; Test accuracy : 68.8\n",
      "Epochs : 842 ; Loss : 0.5879581570625305 ; Accuracy : 69.975 ; Test Loss : 0.5983142256736755 ; Test accuracy : 68.9\n",
      "Epochs : 843 ; Loss : 0.5878998637199402 ; Accuracy : 69.975 ; Test Loss : 0.5982775092124939 ; Test accuracy : 68.9\n",
      "Epochs : 844 ; Loss : 0.5878416895866394 ; Accuracy : 69.975 ; Test Loss : 0.598240852355957 ; Test accuracy : 68.9\n",
      "Epochs : 845 ; Loss : 0.587783694267273 ; Accuracy : 70.0 ; Test Loss : 0.5982043743133545 ; Test accuracy : 68.9\n",
      "Epochs : 846 ; Loss : 0.5877258777618408 ; Accuracy : 70.0 ; Test Loss : 0.5981680750846863 ; Test accuracy : 68.9\n",
      "Epochs : 847 ; Loss : 0.5876680612564087 ; Accuracy : 70.0 ; Test Loss : 0.5981317162513733 ; Test accuracy : 69.0\n",
      "Epochs : 848 ; Loss : 0.5876103639602661 ; Accuracy : 70.025 ; Test Loss : 0.5980955958366394 ; Test accuracy : 68.9\n",
      "Epochs : 849 ; Loss : 0.5875529050827026 ; Accuracy : 70.05 ; Test Loss : 0.5980595946311951 ; Test accuracy : 68.9\n",
      "Epochs : 850 ; Loss : 0.5874955058097839 ; Accuracy : 70.05 ; Test Loss : 0.5980236530303955 ; Test accuracy : 68.9\n",
      "Epochs : 851 ; Loss : 0.5874382257461548 ; Accuracy : 70.05 ; Test Loss : 0.5979878306388855 ; Test accuracy : 68.9\n",
      "Epochs : 852 ; Loss : 0.5873810648918152 ; Accuracy : 70.05 ; Test Loss : 0.597952127456665 ; Test accuracy : 68.9\n",
      "Epochs : 853 ; Loss : 0.5873240232467651 ; Accuracy : 70.05 ; Test Loss : 0.5979164838790894 ; Test accuracy : 68.9\n",
      "Epochs : 854 ; Loss : 0.5872671008110046 ; Accuracy : 70.05 ; Test Loss : 0.5978809595108032 ; Test accuracy : 68.9\n",
      "Epochs : 855 ; Loss : 0.5872103571891785 ; Accuracy : 70.1 ; Test Loss : 0.5978456139564514 ; Test accuracy : 68.9\n",
      "Epochs : 856 ; Loss : 0.5871536731719971 ; Accuracy : 70.125 ; Test Loss : 0.5978103280067444 ; Test accuracy : 69.0\n",
      "Epochs : 857 ; Loss : 0.5870970487594604 ; Accuracy : 70.175 ; Test Loss : 0.5977750420570374 ; Test accuracy : 69.0\n",
      "Epochs : 858 ; Loss : 0.5870406627655029 ; Accuracy : 70.2 ; Test Loss : 0.5977399945259094 ; Test accuracy : 69.0\n",
      "Epochs : 859 ; Loss : 0.5869843363761902 ; Accuracy : 70.2 ; Test Loss : 0.5977051258087158 ; Test accuracy : 69.0\n",
      "Epochs : 860 ; Loss : 0.586928129196167 ; Accuracy : 70.2 ; Test Loss : 0.5976701974868774 ; Test accuracy : 69.0\n",
      "Epochs : 861 ; Loss : 0.5868721008300781 ; Accuracy : 70.15 ; Test Loss : 0.5976354479789734 ; Test accuracy : 69.0\n",
      "Epochs : 862 ; Loss : 0.5868161916732788 ; Accuracy : 70.15 ; Test Loss : 0.5976008176803589 ; Test accuracy : 69.0\n",
      "Epochs : 863 ; Loss : 0.5867602825164795 ; Accuracy : 70.125 ; Test Loss : 0.5975662469863892 ; Test accuracy : 69.0\n",
      "Epochs : 864 ; Loss : 0.5867046117782593 ; Accuracy : 70.15 ; Test Loss : 0.5975318551063538 ; Test accuracy : 69.0\n",
      "Epochs : 865 ; Loss : 0.5866489410400391 ; Accuracy : 70.175 ; Test Loss : 0.5974975228309631 ; Test accuracy : 69.0\n",
      "Epochs : 866 ; Loss : 0.586593508720398 ; Accuracy : 70.175 ; Test Loss : 0.5974633097648621 ; Test accuracy : 69.0\n",
      "Epochs : 867 ; Loss : 0.5865381360054016 ; Accuracy : 70.175 ; Test Loss : 0.597429096698761 ; Test accuracy : 69.0\n",
      "Epochs : 868 ; Loss : 0.5864828824996948 ; Accuracy : 70.175 ; Test Loss : 0.597395122051239 ; Test accuracy : 69.0\n",
      "Epochs : 869 ; Loss : 0.5864277482032776 ; Accuracy : 70.175 ; Test Loss : 0.5973612070083618 ; Test accuracy : 69.0\n",
      "Epochs : 870 ; Loss : 0.5863727331161499 ; Accuracy : 70.175 ; Test Loss : 0.5973274111747742 ; Test accuracy : 69.0\n",
      "Epochs : 871 ; Loss : 0.5863178372383118 ; Accuracy : 70.175 ; Test Loss : 0.5972936749458313 ; Test accuracy : 69.0\n",
      "Epochs : 872 ; Loss : 0.5862630009651184 ; Accuracy : 70.15 ; Test Loss : 0.597260057926178 ; Test accuracy : 69.0\n",
      "Epochs : 873 ; Loss : 0.5862084031105042 ; Accuracy : 70.15 ; Test Loss : 0.5972265005111694 ; Test accuracy : 69.0\n",
      "Epochs : 874 ; Loss : 0.5861538648605347 ; Accuracy : 70.15 ; Test Loss : 0.5971931219100952 ; Test accuracy : 69.0\n",
      "Epochs : 875 ; Loss : 0.58609938621521 ; Accuracy : 70.175 ; Test Loss : 0.5971598029136658 ; Test accuracy : 69.0\n",
      "Epochs : 876 ; Loss : 0.5860450863838196 ; Accuracy : 70.2 ; Test Loss : 0.5971266031265259 ; Test accuracy : 69.1\n",
      "Epochs : 877 ; Loss : 0.585990846157074 ; Accuracy : 70.2 ; Test Loss : 0.5970935225486755 ; Test accuracy : 69.1\n",
      "Epochs : 878 ; Loss : 0.5859367251396179 ; Accuracy : 70.2 ; Test Loss : 0.5970604419708252 ; Test accuracy : 69.1\n",
      "Epochs : 879 ; Loss : 0.5858827829360962 ; Accuracy : 70.225 ; Test Loss : 0.5970275402069092 ; Test accuracy : 69.1\n",
      "Epochs : 880 ; Loss : 0.5858289003372192 ; Accuracy : 70.225 ; Test Loss : 0.5969947576522827 ; Test accuracy : 69.1\n",
      "Epochs : 881 ; Loss : 0.5857751965522766 ; Accuracy : 70.25 ; Test Loss : 0.596962034702301 ; Test accuracy : 69.1\n",
      "Epochs : 882 ; Loss : 0.585721492767334 ; Accuracy : 70.25 ; Test Loss : 0.5969294905662537 ; Test accuracy : 69.1\n",
      "Epochs : 883 ; Loss : 0.5856679081916809 ; Accuracy : 70.25 ; Test Loss : 0.5968969464302063 ; Test accuracy : 69.1\n",
      "Epochs : 884 ; Loss : 0.5856145620346069 ; Accuracy : 70.25 ; Test Loss : 0.5968645215034485 ; Test accuracy : 68.9\n",
      "Epochs : 885 ; Loss : 0.5855612754821777 ; Accuracy : 70.225 ; Test Loss : 0.5968321561813354 ; Test accuracy : 68.9\n",
      "Epochs : 886 ; Loss : 0.5855081081390381 ; Accuracy : 70.25 ; Test Loss : 0.5967999696731567 ; Test accuracy : 68.8\n",
      "Epochs : 887 ; Loss : 0.5854550004005432 ; Accuracy : 70.25 ; Test Loss : 0.5967678427696228 ; Test accuracy : 68.8\n",
      "Epochs : 888 ; Loss : 0.5854020118713379 ; Accuracy : 70.25 ; Test Loss : 0.5967358946800232 ; Test accuracy : 68.8\n",
      "Epochs : 889 ; Loss : 0.5853490829467773 ; Accuracy : 70.275 ; Test Loss : 0.5967038869857788 ; Test accuracy : 68.7\n",
      "Epochs : 890 ; Loss : 0.5852963924407959 ; Accuracy : 70.275 ; Test Loss : 0.5966721177101135 ; Test accuracy : 68.7\n",
      "Epochs : 891 ; Loss : 0.5852437019348145 ; Accuracy : 70.3 ; Test Loss : 0.596640408039093 ; Test accuracy : 68.7\n",
      "Epochs : 892 ; Loss : 0.5851911902427673 ; Accuracy : 70.325 ; Test Loss : 0.5966086983680725 ; Test accuracy : 68.8\n",
      "Epochs : 893 ; Loss : 0.585138738155365 ; Accuracy : 70.35 ; Test Loss : 0.5965771675109863 ; Test accuracy : 68.8\n",
      "Epochs : 894 ; Loss : 0.585086464881897 ; Accuracy : 70.35 ; Test Loss : 0.5965457558631897 ; Test accuracy : 68.8\n",
      "Epochs : 895 ; Loss : 0.585034191608429 ; Accuracy : 70.35 ; Test Loss : 0.5965144038200378 ; Test accuracy : 68.8\n",
      "Epochs : 896 ; Loss : 0.5849820971488953 ; Accuracy : 70.35 ; Test Loss : 0.5964831113815308 ; Test accuracy : 68.8\n",
      "Epochs : 897 ; Loss : 0.5849300622940063 ; Accuracy : 70.35 ; Test Loss : 0.596451997756958 ; Test accuracy : 68.8\n",
      "Epochs : 898 ; Loss : 0.5848782062530518 ; Accuracy : 70.325 ; Test Loss : 0.5964208841323853 ; Test accuracy : 68.8\n",
      "Epochs : 899 ; Loss : 0.5848264694213867 ; Accuracy : 70.325 ; Test Loss : 0.5963899493217468 ; Test accuracy : 68.8\n",
      "Epochs : 900 ; Loss : 0.5847747921943665 ; Accuracy : 70.325 ; Test Loss : 0.5963590145111084 ; Test accuracy : 68.8\n",
      "Epochs : 901 ; Loss : 0.5847232341766357 ; Accuracy : 70.325 ; Test Loss : 0.5963282585144043 ; Test accuracy : 68.8\n",
      "Epochs : 902 ; Loss : 0.5846717953681946 ; Accuracy : 70.3 ; Test Loss : 0.5962975025177002 ; Test accuracy : 68.8\n",
      "Epochs : 903 ; Loss : 0.5846204161643982 ; Accuracy : 70.325 ; Test Loss : 0.5962669849395752 ; Test accuracy : 68.8\n",
      "Epochs : 904 ; Loss : 0.5845690965652466 ; Accuracy : 70.325 ; Test Loss : 0.5962364673614502 ; Test accuracy : 68.8\n",
      "Epochs : 905 ; Loss : 0.5845180749893188 ; Accuracy : 70.35 ; Test Loss : 0.59620600938797 ; Test accuracy : 68.8\n",
      "Epochs : 906 ; Loss : 0.5844669938087463 ; Accuracy : 70.425 ; Test Loss : 0.5961756706237793 ; Test accuracy : 68.8\n",
      "Epochs : 907 ; Loss : 0.5844160318374634 ; Accuracy : 70.45 ; Test Loss : 0.5961453914642334 ; Test accuracy : 68.8\n",
      "Epochs : 908 ; Loss : 0.5843652486801147 ; Accuracy : 70.45 ; Test Loss : 0.5961153507232666 ; Test accuracy : 68.8\n",
      "Epochs : 909 ; Loss : 0.5843145251274109 ; Accuracy : 70.45 ; Test Loss : 0.596085250377655 ; Test accuracy : 68.8\n",
      "Epochs : 910 ; Loss : 0.5842638611793518 ; Accuracy : 70.5 ; Test Loss : 0.5960553288459778 ; Test accuracy : 68.8\n",
      "Epochs : 911 ; Loss : 0.5842133164405823 ; Accuracy : 70.475 ; Test Loss : 0.5960254073143005 ; Test accuracy : 68.8\n",
      "Epochs : 912 ; Loss : 0.5841630101203918 ; Accuracy : 70.475 ; Test Loss : 0.5959956049919128 ; Test accuracy : 68.7\n",
      "Epochs : 913 ; Loss : 0.5841127038002014 ; Accuracy : 70.475 ; Test Loss : 0.5959659814834595 ; Test accuracy : 68.7\n",
      "Epochs : 914 ; Loss : 0.5840624570846558 ; Accuracy : 70.425 ; Test Loss : 0.5959363579750061 ; Test accuracy : 68.7\n",
      "Epochs : 915 ; Loss : 0.5840123295783997 ; Accuracy : 70.4 ; Test Loss : 0.5959068536758423 ; Test accuracy : 68.7\n",
      "Epochs : 916 ; Loss : 0.5839624404907227 ; Accuracy : 70.4 ; Test Loss : 0.5958773493766785 ; Test accuracy : 68.7\n",
      "Epochs : 917 ; Loss : 0.5839124917984009 ; Accuracy : 70.425 ; Test Loss : 0.595848023891449 ; Test accuracy : 68.7\n",
      "Epochs : 918 ; Loss : 0.5838627219200134 ; Accuracy : 70.45 ; Test Loss : 0.595818817615509 ; Test accuracy : 68.7\n",
      "Epochs : 919 ; Loss : 0.5838130116462708 ; Accuracy : 70.425 ; Test Loss : 0.5957897305488586 ; Test accuracy : 68.7\n",
      "Epochs : 920 ; Loss : 0.5837634801864624 ; Accuracy : 70.375 ; Test Loss : 0.5957605838775635 ; Test accuracy : 68.7\n",
      "Epochs : 921 ; Loss : 0.583713948726654 ; Accuracy : 70.375 ; Test Loss : 0.5957316160202026 ; Test accuracy : 68.7\n",
      "Epochs : 922 ; Loss : 0.58366459608078 ; Accuracy : 70.425 ; Test Loss : 0.5957027077674866 ; Test accuracy : 68.8\n",
      "Epochs : 923 ; Loss : 0.583615243434906 ; Accuracy : 70.425 ; Test Loss : 0.5956739187240601 ; Test accuracy : 68.8\n",
      "Epochs : 924 ; Loss : 0.5835661292076111 ; Accuracy : 70.475 ; Test Loss : 0.5956451892852783 ; Test accuracy : 68.8\n",
      "Epochs : 925 ; Loss : 0.5835170149803162 ; Accuracy : 70.475 ; Test Loss : 0.5956165194511414 ; Test accuracy : 68.8\n",
      "Epochs : 926 ; Loss : 0.5834680199623108 ; Accuracy : 70.475 ; Test Loss : 0.595587968826294 ; Test accuracy : 68.8\n",
      "Epochs : 927 ; Loss : 0.583419144153595 ; Accuracy : 70.475 ; Test Loss : 0.5955595374107361 ; Test accuracy : 68.8\n",
      "Epochs : 928 ; Loss : 0.5833703875541687 ; Accuracy : 70.45 ; Test Loss : 0.595531165599823 ; Test accuracy : 68.8\n",
      "Epochs : 929 ; Loss : 0.5833216905593872 ; Accuracy : 70.45 ; Test Loss : 0.5955028533935547 ; Test accuracy : 68.8\n",
      "Epochs : 930 ; Loss : 0.5832731127738953 ; Accuracy : 70.45 ; Test Loss : 0.5954746603965759 ; Test accuracy : 68.7\n",
      "Epochs : 931 ; Loss : 0.5832245945930481 ; Accuracy : 70.45 ; Test Loss : 0.5954465866088867 ; Test accuracy : 68.7\n",
      "Epochs : 932 ; Loss : 0.5831762552261353 ; Accuracy : 70.45 ; Test Loss : 0.5954185128211975 ; Test accuracy : 68.7\n",
      "Epochs : 933 ; Loss : 0.5831279754638672 ; Accuracy : 70.45 ; Test Loss : 0.5953905582427979 ; Test accuracy : 68.7\n",
      "Epochs : 934 ; Loss : 0.5830797553062439 ; Accuracy : 70.45 ; Test Loss : 0.595362663269043 ; Test accuracy : 68.7\n",
      "Epochs : 935 ; Loss : 0.5830317139625549 ; Accuracy : 70.45 ; Test Loss : 0.5953348875045776 ; Test accuracy : 68.7\n",
      "Epochs : 936 ; Loss : 0.582983672618866 ; Accuracy : 70.475 ; Test Loss : 0.5953071713447571 ; Test accuracy : 68.7\n",
      "Epochs : 937 ; Loss : 0.5829358100891113 ; Accuracy : 70.475 ; Test Loss : 0.5952795743942261 ; Test accuracy : 68.7\n",
      "Epochs : 938 ; Loss : 0.5828879475593567 ; Accuracy : 70.475 ; Test Loss : 0.5952519774436951 ; Test accuracy : 68.7\n",
      "Epochs : 939 ; Loss : 0.5828402638435364 ; Accuracy : 70.45 ; Test Loss : 0.5952244997024536 ; Test accuracy : 68.7\n",
      "Epochs : 940 ; Loss : 0.5827926397323608 ; Accuracy : 70.45 ; Test Loss : 0.5951972007751465 ; Test accuracy : 68.6\n",
      "Epochs : 941 ; Loss : 0.5827451348304749 ; Accuracy : 70.45 ; Test Loss : 0.5951698422431946 ; Test accuracy : 68.6\n",
      "Epochs : 942 ; Loss : 0.5826976299285889 ; Accuracy : 70.45 ; Test Loss : 0.5951427221298218 ; Test accuracy : 68.6\n",
      "Epochs : 943 ; Loss : 0.5826504230499268 ; Accuracy : 70.475 ; Test Loss : 0.5951154828071594 ; Test accuracy : 68.6\n",
      "Epochs : 944 ; Loss : 0.5826031565666199 ; Accuracy : 70.5 ; Test Loss : 0.595088541507721 ; Test accuracy : 68.6\n",
      "Epochs : 945 ; Loss : 0.5825560688972473 ; Accuracy : 70.5 ; Test Loss : 0.5950615406036377 ; Test accuracy : 68.6\n",
      "Epochs : 946 ; Loss : 0.5825090408325195 ; Accuracy : 70.475 ; Test Loss : 0.595034658908844 ; Test accuracy : 68.6\n",
      "Epochs : 947 ; Loss : 0.5824620723724365 ; Accuracy : 70.5 ; Test Loss : 0.5950078368186951 ; Test accuracy : 68.6\n",
      "Epochs : 948 ; Loss : 0.5824151635169983 ; Accuracy : 70.475 ; Test Loss : 0.5949811339378357 ; Test accuracy : 68.6\n",
      "Epochs : 949 ; Loss : 0.5823684334754944 ; Accuracy : 70.475 ; Test Loss : 0.5949544906616211 ; Test accuracy : 68.5\n",
      "Epochs : 950 ; Loss : 0.5823218822479248 ; Accuracy : 70.475 ; Test Loss : 0.5949279069900513 ; Test accuracy : 68.5\n",
      "Epochs : 951 ; Loss : 0.5822752714157104 ; Accuracy : 70.475 ; Test Loss : 0.5949013829231262 ; Test accuracy : 68.5\n",
      "Epochs : 952 ; Loss : 0.5822287797927856 ; Accuracy : 70.5 ; Test Loss : 0.5948750376701355 ; Test accuracy : 68.5\n",
      "Epochs : 953 ; Loss : 0.5821824073791504 ; Accuracy : 70.5 ; Test Loss : 0.5948486924171448 ; Test accuracy : 68.5\n",
      "Epochs : 954 ; Loss : 0.5821361541748047 ; Accuracy : 70.5 ; Test Loss : 0.5948224663734436 ; Test accuracy : 68.5\n",
      "Epochs : 955 ; Loss : 0.582089900970459 ; Accuracy : 70.5 ; Test Loss : 0.5947962999343872 ; Test accuracy : 68.5\n",
      "Epochs : 956 ; Loss : 0.5820438265800476 ; Accuracy : 70.5 ; Test Loss : 0.5947701930999756 ; Test accuracy : 68.5\n",
      "Epochs : 957 ; Loss : 0.581997811794281 ; Accuracy : 70.5 ; Test Loss : 0.5947441458702087 ; Test accuracy : 68.5\n",
      "Epochs : 958 ; Loss : 0.581951916217804 ; Accuracy : 70.475 ; Test Loss : 0.5947182774543762 ; Test accuracy : 68.5\n",
      "Epochs : 959 ; Loss : 0.5819061398506165 ; Accuracy : 70.475 ; Test Loss : 0.5946924090385437 ; Test accuracy : 68.5\n",
      "Epochs : 960 ; Loss : 0.581860363483429 ; Accuracy : 70.525 ; Test Loss : 0.5946666598320007 ; Test accuracy : 68.5\n",
      "Epochs : 961 ; Loss : 0.581814706325531 ; Accuracy : 70.55 ; Test Loss : 0.5946409106254578 ; Test accuracy : 68.5\n",
      "Epochs : 962 ; Loss : 0.5817691683769226 ; Accuracy : 70.55 ; Test Loss : 0.5946153402328491 ; Test accuracy : 68.6\n",
      "Epochs : 963 ; Loss : 0.5817237496376038 ; Accuracy : 70.55 ; Test Loss : 0.5945897698402405 ; Test accuracy : 68.6\n",
      "Epochs : 964 ; Loss : 0.5816783308982849 ; Accuracy : 70.575 ; Test Loss : 0.5945643186569214 ; Test accuracy : 68.6\n",
      "Epochs : 965 ; Loss : 0.5816330909729004 ; Accuracy : 70.575 ; Test Loss : 0.5945389270782471 ; Test accuracy : 68.4\n",
      "Epochs : 966 ; Loss : 0.5815878510475159 ; Accuracy : 70.625 ; Test Loss : 0.5945136547088623 ; Test accuracy : 68.4\n",
      "Epochs : 967 ; Loss : 0.5815427899360657 ; Accuracy : 70.65 ; Test Loss : 0.5944883823394775 ; Test accuracy : 68.4\n",
      "Epochs : 968 ; Loss : 0.5814977884292603 ; Accuracy : 70.675 ; Test Loss : 0.5944631695747375 ; Test accuracy : 68.4\n",
      "Epochs : 969 ; Loss : 0.5814528465270996 ; Accuracy : 70.675 ; Test Loss : 0.5944381356239319 ; Test accuracy : 68.4\n",
      "Epochs : 970 ; Loss : 0.5814079642295837 ; Accuracy : 70.7 ; Test Loss : 0.5944130420684814 ; Test accuracy : 68.4\n",
      "Epochs : 971 ; Loss : 0.581363320350647 ; Accuracy : 70.7 ; Test Loss : 0.5943881273269653 ; Test accuracy : 68.4\n",
      "Epochs : 972 ; Loss : 0.5813186168670654 ; Accuracy : 70.65 ; Test Loss : 0.5943633317947388 ; Test accuracy : 68.4\n",
      "Epochs : 973 ; Loss : 0.5812740921974182 ; Accuracy : 70.65 ; Test Loss : 0.5943385362625122 ; Test accuracy : 68.4\n",
      "Epochs : 974 ; Loss : 0.581229567527771 ; Accuracy : 70.65 ; Test Loss : 0.5943138003349304 ; Test accuracy : 68.4\n",
      "Epochs : 975 ; Loss : 0.5811852216720581 ; Accuracy : 70.65 ; Test Loss : 0.5942891240119934 ; Test accuracy : 68.4\n",
      "Epochs : 976 ; Loss : 0.5811408758163452 ; Accuracy : 70.65 ; Test Loss : 0.594264566898346 ; Test accuracy : 68.4\n",
      "Epochs : 977 ; Loss : 0.5810967087745667 ; Accuracy : 70.65 ; Test Loss : 0.5942400693893433 ; Test accuracy : 68.4\n",
      "Epochs : 978 ; Loss : 0.5810526013374329 ; Accuracy : 70.65 ; Test Loss : 0.5942156314849854 ; Test accuracy : 68.4\n",
      "Epochs : 979 ; Loss : 0.5810085535049438 ; Accuracy : 70.65 ; Test Loss : 0.594191312789917 ; Test accuracy : 68.4\n",
      "Epochs : 980 ; Loss : 0.5809646248817444 ; Accuracy : 70.675 ; Test Loss : 0.5941669940948486 ; Test accuracy : 68.4\n",
      "Epochs : 981 ; Loss : 0.5809206962585449 ; Accuracy : 70.675 ; Test Loss : 0.5941428542137146 ; Test accuracy : 68.4\n",
      "Epochs : 982 ; Loss : 0.5808769464492798 ; Accuracy : 70.675 ; Test Loss : 0.5941187143325806 ; Test accuracy : 68.4\n",
      "Epochs : 983 ; Loss : 0.5808331966400146 ; Accuracy : 70.675 ; Test Loss : 0.5940946340560913 ; Test accuracy : 68.4\n",
      "Epochs : 984 ; Loss : 0.5807896256446838 ; Accuracy : 70.7 ; Test Loss : 0.5940706729888916 ; Test accuracy : 68.4\n",
      "Epochs : 985 ; Loss : 0.5807461142539978 ; Accuracy : 70.7 ; Test Loss : 0.5940467715263367 ; Test accuracy : 68.4\n",
      "Epochs : 986 ; Loss : 0.5807026624679565 ; Accuracy : 70.7 ; Test Loss : 0.5940229296684265 ; Test accuracy : 68.4\n",
      "Epochs : 987 ; Loss : 0.5806593298912048 ; Accuracy : 70.7 ; Test Loss : 0.5939991474151611 ; Test accuracy : 68.4\n",
      "Epochs : 988 ; Loss : 0.5806161165237427 ; Accuracy : 70.7 ; Test Loss : 0.5939754247665405 ; Test accuracy : 68.4\n",
      "Epochs : 989 ; Loss : 0.5805729031562805 ; Accuracy : 70.775 ; Test Loss : 0.5939518213272095 ; Test accuracy : 68.4\n",
      "Epochs : 990 ; Loss : 0.5805298089981079 ; Accuracy : 70.775 ; Test Loss : 0.5939282774925232 ; Test accuracy : 68.4\n",
      "Epochs : 991 ; Loss : 0.5804867744445801 ; Accuracy : 70.775 ; Test Loss : 0.5939046740531921 ; Test accuracy : 68.4\n",
      "Epochs : 992 ; Loss : 0.5804438591003418 ; Accuracy : 70.8 ; Test Loss : 0.593881368637085 ; Test accuracy : 68.4\n",
      "Epochs : 993 ; Loss : 0.5804010033607483 ; Accuracy : 70.8 ; Test Loss : 0.5938579440116882 ; Test accuracy : 68.4\n",
      "Epochs : 994 ; Loss : 0.5803582668304443 ; Accuracy : 70.775 ; Test Loss : 0.5938346982002258 ; Test accuracy : 68.4\n",
      "Epochs : 995 ; Loss : 0.5803155899047852 ; Accuracy : 70.775 ; Test Loss : 0.5938115119934082 ; Test accuracy : 68.4\n",
      "Epochs : 996 ; Loss : 0.5802729725837708 ; Accuracy : 70.8 ; Test Loss : 0.5937883853912354 ; Test accuracy : 68.4\n",
      "Epochs : 997 ; Loss : 0.5802304744720459 ; Accuracy : 70.8 ; Test Loss : 0.5937652587890625 ; Test accuracy : 68.4\n",
      "Epochs : 998 ; Loss : 0.5801880955696106 ; Accuracy : 70.8 ; Test Loss : 0.5937422513961792 ; Test accuracy : 68.3\n",
      "Epochs : 999 ; Loss : 0.5801457166671753 ; Accuracy : 70.825 ; Test Loss : 0.5937192440032959 ; Test accuracy : 68.3\n",
      "Imtafe (other metrics): 6.275\n",
      "Accuracy :  69.2\n",
      "AUC :  0.7492799884798157\n",
      "F1 score :  0.6829920748018701\n",
      "Finished training with parameter: H\n",
      "--- Finding All Unique Particles ---\n",
      "\n",
      "--- Inserting Masses ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:00, 3827.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calculating Momenta and Energies ---\n",
      "\n",
      "--- Calculating Edge Tensors ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10000/10000 [00:16<00:00, 612.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating graphs ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10000/10000 [00:05<00:00, 1923.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====epoch 1\n",
      "5.867082786560059\n",
      "5.331970596313477\n",
      "5.351121520996093\n",
      "UNI :  -1.4789620280265807\n",
      "ALIGN :  0.11280245929956437\n",
      "====epoch 2\n",
      "4.051527214050293\n",
      "3.6777947425842283\n",
      "3.7373250007629393\n",
      "UNI :  -2.7346613883972166\n",
      "ALIGN :  0.19154825210571289\n",
      "====epoch 3\n",
      "3.3027973651885985\n",
      "2.9923587322235106\n",
      "3.104386329650879\n",
      "UNI :  -3.1590551376342773\n",
      "ALIGN :  0.2698493987321854\n",
      "====epoch 4\n",
      "2.8048213481903077\n",
      "2.5336347579956056\n",
      "2.7118658065795898\n",
      "UNI :  -3.3963901519775392\n",
      "ALIGN :  0.3134113192558289\n",
      "====epoch 5\n",
      "2.4711453437805178\n",
      "2.225303030014038\n",
      "2.458423614501953\n",
      "UNI :  -3.5070164680480955\n",
      "ALIGN :  0.31780288815498353\n",
      "====epoch 6\n",
      "2.215739059448242\n",
      "1.989323878288269\n",
      "2.264151763916016\n",
      "UNI :  -3.566619062423706\n",
      "ALIGN :  0.3088909208774567\n",
      "====epoch 7\n",
      "2.023139142990112\n",
      "1.8104968547821045\n",
      "2.1264231204986572\n",
      "UNI :  -3.615413522720337\n",
      "ALIGN :  0.3099763631820679\n",
      "====epoch 8\n",
      "1.8635457277297973\n",
      "1.6626502990722656\n",
      "2.008954405784607\n",
      "UNI :  -3.6452120780944823\n",
      "ALIGN :  0.3039896070957184\n",
      "====epoch 9\n",
      "1.7505218029022216\n",
      "1.557611083984375\n",
      "1.929106855392456\n",
      "UNI :  -3.66477518081665\n",
      "ALIGN :  0.299472314119339\n",
      "====epoch 10\n",
      "1.6103307723999023\n",
      "1.4271634101867676\n",
      "1.8316737413406372\n",
      "UNI :  -3.6787089347839355\n",
      "ALIGN :  0.28767605423927306\n",
      "====epoch 11\n",
      "1.5162361145019532\n",
      "1.3387009620666503\n",
      "1.7753512382507324\n",
      "UNI :  -3.691354179382324\n",
      "ALIGN :  0.2849943995475769\n",
      "====epoch 12\n",
      "1.4300063610076905\n",
      "1.2579599857330321\n",
      "1.7204635858535766\n",
      "UNI :  -3.7013566493988037\n",
      "ALIGN :  0.2801740884780884\n",
      "====epoch 13\n",
      "1.3438227891921997\n",
      "1.1775294542312622\n",
      "1.6629331827163696\n",
      "UNI :  -3.714545965194702\n",
      "ALIGN :  0.27638261914253237\n",
      "====epoch 14\n",
      "1.2777826309204101\n",
      "1.11588716506958\n",
      "1.618954563140869\n",
      "UNI :  -3.7251031398773193\n",
      "ALIGN :  0.27462897896766664\n",
      "====epoch 15\n",
      "1.214965319633484\n",
      "1.05621280670166\n",
      "1.587524962425232\n",
      "UNI :  -3.7351202011108398\n",
      "ALIGN :  0.27432790994644163\n",
      "====epoch 16\n",
      "1.1573214054107666\n",
      "1.0020708322525025\n",
      "1.5525055646896362\n",
      "UNI :  -3.7437329292297363\n",
      "ALIGN :  0.27323357462882997\n",
      "====epoch 17\n",
      "1.0856959819793701\n",
      "0.934704327583313\n",
      "1.5099169731140136\n",
      "UNI :  -3.7528402328491213\n",
      "ALIGN :  0.2682340919971466\n",
      "====epoch 18\n",
      "1.0294315338134765\n",
      "0.8816735029220581\n",
      "1.4775802373886109\n",
      "UNI :  -3.759597158432007\n",
      "ALIGN :  0.26573405265808103\n",
      "====epoch 19\n",
      "0.9635518074035645\n",
      "0.8193720936775207\n",
      "1.4417969703674316\n",
      "UNI :  -3.7657589435577394\n",
      "ALIGN :  0.261219447851181\n",
      "====epoch 20\n",
      "0.931932532787323\n",
      "0.7892805814743042\n",
      "1.4265193462371826\n",
      "UNI :  -3.773255729675293\n",
      "ALIGN :  0.26313711404800416\n",
      "====epoch 21\n",
      "0.8609336733818054\n",
      "0.7225097298622132\n",
      "1.3842394351959229\n",
      "UNI :  -3.7809964179992677\n",
      "ALIGN :  0.2580568492412567\n",
      "====epoch 22\n",
      "0.8217988252639771\n",
      "0.6853495717048645\n",
      "1.3644926309585572\n",
      "UNI :  -3.785239410400391\n",
      "ALIGN :  0.25723044872283934\n",
      "====epoch 23\n",
      "0.783870005607605\n",
      "0.6487572908401489\n",
      "1.3511271715164184\n",
      "UNI :  -3.7898826599121094\n",
      "ALIGN :  0.2556857496500015\n",
      "====epoch 24\n",
      "0.7478490114212036\n",
      "0.615032958984375\n",
      "1.3281604528427124\n",
      "UNI :  -3.793253040313721\n",
      "ALIGN :  0.25400035083293915\n",
      "====epoch 25\n",
      "0.7167139887809754\n",
      "0.5846776247024537\n",
      "1.320363664627075\n",
      "UNI :  -3.796366834640503\n",
      "ALIGN :  0.2533419281244278\n",
      "====epoch 26\n",
      "0.6618420958518982\n",
      "0.5329068303108215\n",
      "1.2893526315689088\n",
      "UNI :  -3.8009154319763185\n",
      "ALIGN :  0.24830879867076874\n",
      "====epoch 27\n",
      "0.647026801109314\n",
      "0.5181691467761993\n",
      "1.2885764122009278\n",
      "UNI :  -3.806082248687744\n",
      "ALIGN :  0.250100639462471\n",
      "====epoch 28\n",
      "0.6046435475349426\n",
      "0.4782203257083893\n",
      "1.264232087135315\n",
      "UNI :  -3.809327220916748\n",
      "ALIGN :  0.2470219224691391\n",
      "====epoch 29\n",
      "0.5843904256820679\n",
      "0.4588793456554413\n",
      "1.2551107168197633\n",
      "UNI :  -3.811178684234619\n",
      "ALIGN :  0.24683341681957244\n",
      "====epoch 30\n",
      "0.5370144784450531\n",
      "0.41354659795761106\n",
      "1.2346786737442017\n",
      "UNI :  -3.8129624843597414\n",
      "ALIGN :  0.2409294456243515\n",
      "====epoch 31\n",
      "0.5189117312431335\n",
      "0.39614694714546206\n",
      "1.2276479959487916\n",
      "UNI :  -3.817740631103516\n",
      "ALIGN :  0.24275703430175782\n",
      "====epoch 32\n",
      "0.471457701921463\n",
      "0.3513036906719208\n",
      "1.2015401363372802\n",
      "UNI :  -3.8200448989868163\n",
      "ALIGN :  0.23704650700092317\n",
      "====epoch 33\n",
      "0.44215267300605776\n",
      "0.3238390862941742\n",
      "1.1831358671188354\n",
      "UNI :  -3.8221209049224854\n",
      "ALIGN :  0.23496606945991516\n",
      "====epoch 34\n",
      "0.4515630006790161\n",
      "0.3315200746059418\n",
      "1.2004292488098145\n",
      "UNI :  -3.8235990047454833\n",
      "ALIGN :  0.23947231471538544\n",
      "====epoch 35\n",
      "0.419548100233078\n",
      "0.3006645917892456\n",
      "1.188835072517395\n",
      "UNI :  -3.82448992729187\n",
      "ALIGN :  0.2349438488483429\n",
      "====epoch 36\n",
      "0.40459591150283813\n",
      "0.28665215373039243\n",
      "1.1794375896453857\n",
      "UNI :  -3.826166534423828\n",
      "ALIGN :  0.2348771721124649\n",
      "====epoch 37\n",
      "0.3831834077835083\n",
      "0.26610165238380434\n",
      "1.1708175182342528\n",
      "UNI :  -3.828082799911499\n",
      "ALIGN :  0.23349928557872773\n",
      "====epoch 38\n",
      "0.37602582573890686\n",
      "0.2585544973611832\n",
      "1.1747133016586304\n",
      "UNI :  -3.82822790145874\n",
      "ALIGN :  0.23464407324790953\n",
      "====epoch 39\n",
      "0.32593994140625\n",
      "0.21113407909870147\n",
      "1.1480586290359498\n",
      "UNI :  -3.8298759937286375\n",
      "ALIGN :  0.22675242125988007\n",
      "====epoch 40\n",
      "0.3197286128997803\n",
      "0.20523292422294617\n",
      "1.1449569463729858\n",
      "UNI :  -3.831135082244873\n",
      "ALIGN :  0.2280161440372467\n",
      "====epoch 41\n",
      "0.3034548759460449\n",
      "0.18979520499706268\n",
      "1.1365967750549317\n",
      "UNI :  -3.83228440284729\n",
      "ALIGN :  0.2269872695207596\n",
      "====epoch 42\n",
      "0.2768915772438049\n",
      "0.16404843628406524\n",
      "1.1284314155578614\n",
      "UNI :  -3.8331469535827636\n",
      "ALIGN :  0.22496703863143921\n",
      "====epoch 43\n",
      "0.2673001527786255\n",
      "0.15408798754215242\n",
      "1.1321216106414795\n",
      "UNI :  -3.8360029220581056\n",
      "ALIGN :  0.22433204650878907\n",
      "====epoch 44\n",
      "0.24825226068496703\n",
      "0.13578513264656067\n",
      "1.1246712684631348\n",
      "UNI :  -3.8380930423736572\n",
      "ALIGN :  0.22304098606109618\n",
      "====epoch 45\n",
      "0.2321184456348419\n",
      "0.12015947252511978\n",
      "1.1195896863937378\n",
      "UNI :  -3.840480375289917\n",
      "ALIGN :  0.223190513253212\n",
      "====epoch 46\n",
      "0.21751330494880677\n",
      "0.1061023935675621\n",
      "1.1141091108322143\n",
      "UNI :  -3.841943550109863\n",
      "ALIGN :  0.22184572219848633\n",
      "====epoch 47\n",
      "0.22286224961280823\n",
      "0.11052513271570205\n",
      "1.123371148109436\n",
      "UNI :  -3.8433881282806395\n",
      "ALIGN :  0.22584183216094972\n",
      "====epoch 48\n",
      "0.21234751343727112\n",
      "0.1000672921538353\n",
      "1.12280216217041\n",
      "UNI :  -3.843254566192627\n",
      "ALIGN :  0.22357246577739714\n",
      "====epoch 49\n",
      "0.20395132303237914\n",
      "0.09150059372186661\n",
      "1.1245073080062866\n",
      "UNI :  -3.844406509399414\n",
      "ALIGN :  0.22387920916080475\n",
      "====epoch 50\n",
      "0.18927928805351257\n",
      "0.07695741951465607\n",
      "1.1232187271118164\n",
      "UNI :  -3.845000982284546\n",
      "ALIGN :  0.22293174862861634\n",
      "--- Finding All Unique Particles ---\n",
      "\n",
      "--- Inserting Masses ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:00, 3832.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calculating Momenta and Energies ---\n",
      "\n",
      "--- Calculating Edge Tensors ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7000/7000 [00:11<00:00, 630.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating graphs ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7000/7000 [00:03<00:00, 2109.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs : 0 ; Loss : 1.0827856063842773 ; Accuracy : 50.25 ; Test Loss : 1.0114569664001465 ; Test accuracy : 52.0\n",
      "Epochs : 1 ; Loss : 1.069650650024414 ; Accuracy : 50.375 ; Test Loss : 0.9993873834609985 ; Test accuracy : 52.4\n",
      "Epochs : 2 ; Loss : 1.0568126440048218 ; Accuracy : 50.225 ; Test Loss : 0.9876288175582886 ; Test accuracy : 51.9\n",
      "Epochs : 3 ; Loss : 1.0442826747894287 ; Accuracy : 50.225 ; Test Loss : 0.9761922359466553 ; Test accuracy : 51.6\n",
      "Epochs : 4 ; Loss : 1.032071828842163 ; Accuracy : 50.125 ; Test Loss : 0.9650881886482239 ; Test accuracy : 51.6\n",
      "Epochs : 5 ; Loss : 1.020190954208374 ; Accuracy : 49.975 ; Test Loss : 0.9543266892433167 ; Test accuracy : 51.6\n",
      "Epochs : 6 ; Loss : 1.0086501836776733 ; Accuracy : 50.125 ; Test Loss : 0.9439175128936768 ; Test accuracy : 51.6\n",
      "Epochs : 7 ; Loss : 0.9974596500396729 ; Accuracy : 50.25 ; Test Loss : 0.9338696599006653 ; Test accuracy : 51.7\n",
      "Epochs : 8 ; Loss : 0.9866284728050232 ; Accuracy : 50.25 ; Test Loss : 0.9241914749145508 ; Test accuracy : 51.9\n",
      "Epochs : 9 ; Loss : 0.9761655330657959 ; Accuracy : 50.2 ; Test Loss : 0.914890468120575 ; Test accuracy : 51.6\n",
      "Epochs : 10 ; Loss : 0.9660784602165222 ; Accuracy : 50.075 ; Test Loss : 0.9059733152389526 ; Test accuracy : 51.8\n",
      "Epochs : 11 ; Loss : 0.9563747048377991 ; Accuracy : 49.75 ; Test Loss : 0.8974458575248718 ; Test accuracy : 51.9\n",
      "Epochs : 12 ; Loss : 0.9470601081848145 ; Accuracy : 49.525 ; Test Loss : 0.8893123865127563 ; Test accuracy : 51.8\n",
      "Epochs : 13 ; Loss : 0.9381400346755981 ; Accuracy : 49.35 ; Test Loss : 0.8815765976905823 ; Test accuracy : 52.2\n",
      "Epochs : 14 ; Loss : 0.9296185970306396 ; Accuracy : 49.3 ; Test Loss : 0.8742407560348511 ; Test accuracy : 52.0\n",
      "Epochs : 15 ; Loss : 0.9214985966682434 ; Accuracy : 49.275 ; Test Loss : 0.8673058152198792 ; Test accuracy : 51.8\n",
      "Epochs : 16 ; Loss : 0.9137818813323975 ; Accuracy : 49.2 ; Test Loss : 0.8607714772224426 ; Test accuracy : 51.8\n",
      "Epochs : 17 ; Loss : 0.90646892786026 ; Accuracy : 49.225 ; Test Loss : 0.8546358942985535 ; Test accuracy : 51.5\n",
      "Epochs : 18 ; Loss : 0.8995586037635803 ; Accuracy : 49.15 ; Test Loss : 0.8488959074020386 ; Test accuracy : 51.7\n",
      "Epochs : 19 ; Loss : 0.8930487036705017 ; Accuracy : 48.775 ; Test Loss : 0.8435469269752502 ; Test accuracy : 51.9\n",
      "Epochs : 20 ; Loss : 0.8869355916976929 ; Accuracy : 48.7 ; Test Loss : 0.8385828137397766 ; Test accuracy : 51.2\n",
      "Epochs : 21 ; Loss : 0.8812140822410583 ; Accuracy : 49.1 ; Test Loss : 0.8339958786964417 ; Test accuracy : 51.1\n",
      "Epochs : 22 ; Loss : 0.8758776783943176 ; Accuracy : 48.75 ; Test Loss : 0.8297773599624634 ; Test accuracy : 50.8\n",
      "Epochs : 23 ; Loss : 0.8709183931350708 ; Accuracy : 48.675 ; Test Loss : 0.825916588306427 ; Test accuracy : 50.4\n",
      "Epochs : 24 ; Loss : 0.8663268089294434 ; Accuracy : 48.65 ; Test Loss : 0.8224020004272461 ; Test accuracy : 50.1\n",
      "Epochs : 25 ; Loss : 0.8620924949645996 ; Accuracy : 48.725 ; Test Loss : 0.8192204833030701 ; Test accuracy : 50.2\n",
      "Epochs : 26 ; Loss : 0.8582033514976501 ; Accuracy : 48.425 ; Test Loss : 0.8163579702377319 ; Test accuracy : 50.4\n",
      "Epochs : 27 ; Loss : 0.8546463251113892 ; Accuracy : 48.225 ; Test Loss : 0.8137990236282349 ; Test accuracy : 50.3\n",
      "Epochs : 28 ; Loss : 0.8514074683189392 ; Accuracy : 48.025 ; Test Loss : 0.8115277886390686 ; Test accuracy : 49.6\n",
      "Epochs : 29 ; Loss : 0.848471462726593 ; Accuracy : 48.025 ; Test Loss : 0.8095270991325378 ; Test accuracy : 49.3\n",
      "Epochs : 30 ; Loss : 0.8458225727081299 ; Accuracy : 47.8 ; Test Loss : 0.8077793121337891 ; Test accuracy : 49.0\n",
      "Epochs : 31 ; Loss : 0.8434441089630127 ; Accuracy : 47.675 ; Test Loss : 0.8062666058540344 ; Test accuracy : 49.1\n",
      "Epochs : 32 ; Loss : 0.8413189053535461 ; Accuracy : 47.5 ; Test Loss : 0.8049702644348145 ; Test accuracy : 49.4\n",
      "Epochs : 33 ; Loss : 0.839429497718811 ; Accuracy : 47.55 ; Test Loss : 0.8038719892501831 ; Test accuracy : 49.2\n",
      "Epochs : 34 ; Loss : 0.8377581834793091 ; Accuracy : 47.475 ; Test Loss : 0.8029531836509705 ; Test accuracy : 49.1\n",
      "Epochs : 35 ; Loss : 0.8362871408462524 ; Accuracy : 47.525 ; Test Loss : 0.8021954894065857 ; Test accuracy : 48.8\n",
      "Epochs : 36 ; Loss : 0.8349988460540771 ; Accuracy : 47.45 ; Test Loss : 0.8015809655189514 ; Test accuracy : 48.8\n",
      "Epochs : 37 ; Loss : 0.8338756561279297 ; Accuracy : 47.275 ; Test Loss : 0.8010922074317932 ; Test accuracy : 49.1\n",
      "Epochs : 38 ; Loss : 0.832900881767273 ; Accuracy : 47.15 ; Test Loss : 0.8007121682167053 ; Test accuracy : 48.8\n",
      "Epochs : 39 ; Loss : 0.832057774066925 ; Accuracy : 47.275 ; Test Loss : 0.800425112247467 ; Test accuracy : 49.3\n",
      "Epochs : 40 ; Loss : 0.8313307166099548 ; Accuracy : 47.175 ; Test Loss : 0.8002155423164368 ; Test accuracy : 49.7\n",
      "Epochs : 41 ; Loss : 0.8307046294212341 ; Accuracy : 47.025 ; Test Loss : 0.8000693917274475 ; Test accuracy : 49.5\n",
      "Epochs : 42 ; Loss : 0.8301655054092407 ; Accuracy : 47.05 ; Test Loss : 0.7999735474586487 ; Test accuracy : 49.4\n",
      "Epochs : 43 ; Loss : 0.8296999931335449 ; Accuracy : 47.175 ; Test Loss : 0.7999157905578613 ; Test accuracy : 49.1\n",
      "Epochs : 44 ; Loss : 0.8292959332466125 ; Accuracy : 46.925 ; Test Loss : 0.7998852729797363 ; Test accuracy : 48.9\n",
      "Epochs : 45 ; Loss : 0.8289421796798706 ; Accuracy : 46.875 ; Test Loss : 0.7998722195625305 ; Test accuracy : 48.7\n",
      "Epochs : 46 ; Loss : 0.8286285996437073 ; Accuracy : 46.875 ; Test Loss : 0.7998678684234619 ; Test accuracy : 48.6\n",
      "Epochs : 47 ; Loss : 0.8283461928367615 ; Accuracy : 46.825 ; Test Loss : 0.7998647689819336 ; Test accuracy : 48.8\n",
      "Epochs : 48 ; Loss : 0.8280868530273438 ; Accuracy : 46.825 ; Test Loss : 0.7998564839363098 ; Test accuracy : 48.5\n",
      "Epochs : 49 ; Loss : 0.8278436660766602 ; Accuracy : 46.9 ; Test Loss : 0.7998377084732056 ; Test accuracy : 48.7\n",
      "Epochs : 50 ; Loss : 0.8276104927062988 ; Accuracy : 46.95 ; Test Loss : 0.7998039126396179 ; Test accuracy : 48.7\n",
      "Epochs : 51 ; Loss : 0.8273825645446777 ; Accuracy : 46.975 ; Test Loss : 0.7997517585754395 ; Test accuracy : 48.8\n",
      "Epochs : 52 ; Loss : 0.8271552920341492 ; Accuracy : 46.975 ; Test Loss : 0.7996786236763 ; Test accuracy : 48.5\n",
      "Epochs : 53 ; Loss : 0.8269255757331848 ; Accuracy : 46.875 ; Test Loss : 0.7995827794075012 ; Test accuracy : 48.6\n",
      "Epochs : 54 ; Loss : 0.8266907334327698 ; Accuracy : 46.925 ; Test Loss : 0.7994629740715027 ; Test accuracy : 48.7\n",
      "Epochs : 55 ; Loss : 0.8264485001564026 ; Accuracy : 46.95 ; Test Loss : 0.799318790435791 ; Test accuracy : 48.7\n",
      "Epochs : 56 ; Loss : 0.8261978030204773 ; Accuracy : 46.85 ; Test Loss : 0.799150288105011 ; Test accuracy : 48.6\n",
      "Epochs : 57 ; Loss : 0.8259376883506775 ; Accuracy : 46.85 ; Test Loss : 0.7989580631256104 ; Test accuracy : 48.7\n",
      "Epochs : 58 ; Loss : 0.8256675004959106 ; Accuracy : 46.85 ; Test Loss : 0.7987428307533264 ; Test accuracy : 48.8\n",
      "Epochs : 59 ; Loss : 0.8253874778747559 ; Accuracy : 46.825 ; Test Loss : 0.798505961894989 ; Test accuracy : 48.9\n",
      "Epochs : 60 ; Loss : 0.8250975608825684 ; Accuracy : 46.875 ; Test Loss : 0.7982487082481384 ; Test accuracy : 48.9\n",
      "Epochs : 61 ; Loss : 0.824798583984375 ; Accuracy : 46.875 ; Test Loss : 0.7979728579521179 ; Test accuracy : 48.8\n",
      "Epochs : 62 ; Loss : 0.8244909048080444 ; Accuracy : 46.85 ; Test Loss : 0.7976800799369812 ; Test accuracy : 48.8\n",
      "Epochs : 63 ; Loss : 0.8241754174232483 ; Accuracy : 46.875 ; Test Loss : 0.7973721027374268 ; Test accuracy : 48.8\n",
      "Epochs : 64 ; Loss : 0.823853075504303 ; Accuracy : 46.85 ; Test Loss : 0.797050952911377 ; Test accuracy : 48.9\n",
      "Epochs : 65 ; Loss : 0.8235247135162354 ; Accuracy : 46.95 ; Test Loss : 0.7967183589935303 ; Test accuracy : 48.8\n",
      "Epochs : 66 ; Loss : 0.8231913447380066 ; Accuracy : 46.975 ; Test Loss : 0.7963759899139404 ; Test accuracy : 48.9\n",
      "Epochs : 67 ; Loss : 0.8228538036346436 ; Accuracy : 47.025 ; Test Loss : 0.7960256934165955 ; Test accuracy : 48.9\n",
      "Epochs : 68 ; Loss : 0.8225131034851074 ; Accuracy : 47.05 ; Test Loss : 0.7956689596176147 ; Test accuracy : 48.9\n",
      "Epochs : 69 ; Loss : 0.822170078754425 ; Accuracy : 47.05 ; Test Loss : 0.7953073382377625 ; Test accuracy : 48.9\n",
      "Epochs : 70 ; Loss : 0.821825385093689 ; Accuracy : 47.1 ; Test Loss : 0.794942319393158 ; Test accuracy : 48.9\n",
      "Epochs : 71 ; Loss : 0.8214796781539917 ; Accuracy : 47.05 ; Test Loss : 0.7945748567581177 ; Test accuracy : 48.8\n",
      "Epochs : 72 ; Loss : 0.8211336731910706 ; Accuracy : 47.1 ; Test Loss : 0.7942063212394714 ; Test accuracy : 48.8\n",
      "Epochs : 73 ; Loss : 0.8207876086235046 ; Accuracy : 47.175 ; Test Loss : 0.7938376665115356 ; Test accuracy : 48.7\n",
      "Epochs : 74 ; Loss : 0.8204421997070312 ; Accuracy : 47.175 ; Test Loss : 0.7934696674346924 ; Test accuracy : 48.7\n",
      "Epochs : 75 ; Loss : 0.8200976252555847 ; Accuracy : 47.175 ; Test Loss : 0.793103039264679 ; Test accuracy : 48.8\n",
      "Epochs : 76 ; Loss : 0.8197540640830994 ; Accuracy : 47.15 ; Test Loss : 0.7927384972572327 ; Test accuracy : 49.0\n",
      "Epochs : 77 ; Loss : 0.8194116353988647 ; Accuracy : 47.2 ; Test Loss : 0.7923763990402222 ; Test accuracy : 49.0\n",
      "Epochs : 78 ; Loss : 0.8190704584121704 ; Accuracy : 47.2 ; Test Loss : 0.7920172214508057 ; Test accuracy : 48.9\n",
      "Epochs : 79 ; Loss : 0.8187307715415955 ; Accuracy : 47.25 ; Test Loss : 0.7916613221168518 ; Test accuracy : 48.8\n",
      "Epochs : 80 ; Loss : 0.8183922171592712 ; Accuracy : 47.375 ; Test Loss : 0.7913086414337158 ; Test accuracy : 48.8\n",
      "Epochs : 81 ; Loss : 0.8180547952651978 ; Accuracy : 47.35 ; Test Loss : 0.7909597158432007 ; Test accuracy : 48.8\n",
      "Epochs : 82 ; Loss : 0.8177185654640198 ; Accuracy : 47.3 ; Test Loss : 0.7906143069267273 ; Test accuracy : 48.9\n",
      "Epochs : 83 ; Loss : 0.8173832297325134 ; Accuracy : 47.3 ; Test Loss : 0.7902725338935852 ; Test accuracy : 49.0\n",
      "Epochs : 84 ; Loss : 0.8170486092567444 ; Accuracy : 47.25 ; Test Loss : 0.7899344563484192 ; Test accuracy : 49.1\n",
      "Epochs : 85 ; Loss : 0.8167147040367126 ; Accuracy : 47.225 ; Test Loss : 0.7896000146865845 ; Test accuracy : 49.1\n",
      "Epochs : 86 ; Loss : 0.8163812756538391 ; Accuracy : 47.325 ; Test Loss : 0.7892690300941467 ; Test accuracy : 49.2\n",
      "Epochs : 87 ; Loss : 0.8160481452941895 ; Accuracy : 47.3 ; Test Loss : 0.7889413833618164 ; Test accuracy : 49.2\n",
      "Epochs : 88 ; Loss : 0.8157150745391846 ; Accuracy : 47.375 ; Test Loss : 0.788616955280304 ; Test accuracy : 49.2\n",
      "Epochs : 89 ; Loss : 0.8153820037841797 ; Accuracy : 47.375 ; Test Loss : 0.7882957458496094 ; Test accuracy : 49.2\n",
      "Epochs : 90 ; Loss : 0.8150487542152405 ; Accuracy : 47.4 ; Test Loss : 0.7879774570465088 ; Test accuracy : 49.1\n",
      "Epochs : 91 ; Loss : 0.8147151470184326 ; Accuracy : 47.375 ; Test Loss : 0.7876619100570679 ; Test accuracy : 49.0\n",
      "Epochs : 92 ; Loss : 0.8143811225891113 ; Accuracy : 47.35 ; Test Loss : 0.7873490452766418 ; Test accuracy : 49.0\n",
      "Epochs : 93 ; Loss : 0.8140466809272766 ; Accuracy : 47.35 ; Test Loss : 0.7870386242866516 ; Test accuracy : 49.0\n",
      "Epochs : 94 ; Loss : 0.8137116432189941 ; Accuracy : 47.35 ; Test Loss : 0.7867304682731628 ; Test accuracy : 49.0\n",
      "Epochs : 95 ; Loss : 0.8133758902549744 ; Accuracy : 47.375 ; Test Loss : 0.786424458026886 ; Test accuracy : 49.0\n",
      "Epochs : 96 ; Loss : 0.8130394816398621 ; Accuracy : 47.4 ; Test Loss : 0.7861204147338867 ; Test accuracy : 49.0\n",
      "Epochs : 97 ; Loss : 0.8127022981643677 ; Accuracy : 47.375 ; Test Loss : 0.7858182191848755 ; Test accuracy : 49.0\n",
      "Epochs : 98 ; Loss : 0.812364399433136 ; Accuracy : 47.4 ; Test Loss : 0.7855177521705627 ; Test accuracy : 49.0\n",
      "Epochs : 99 ; Loss : 0.8120256662368774 ; Accuracy : 47.4 ; Test Loss : 0.7852187752723694 ; Test accuracy : 49.0\n",
      "Epochs : 100 ; Loss : 0.8116862773895264 ; Accuracy : 47.4 ; Test Loss : 0.7849211692810059 ; Test accuracy : 49.0\n",
      "Epochs : 101 ; Loss : 0.8113461136817932 ; Accuracy : 47.45 ; Test Loss : 0.7846249341964722 ; Test accuracy : 49.0\n",
      "Epochs : 102 ; Loss : 0.811005175113678 ; Accuracy : 47.5 ; Test Loss : 0.7843297719955444 ; Test accuracy : 49.0\n",
      "Epochs : 103 ; Loss : 0.8106635808944702 ; Accuracy : 47.525 ; Test Loss : 0.7840355634689331 ; Test accuracy : 49.0\n",
      "Epochs : 104 ; Loss : 0.8103212714195251 ; Accuracy : 47.55 ; Test Loss : 0.7837422490119934 ; Test accuracy : 49.0\n",
      "Epochs : 105 ; Loss : 0.8099783658981323 ; Accuracy : 47.55 ; Test Loss : 0.7834497690200806 ; Test accuracy : 49.0\n",
      "Epochs : 106 ; Loss : 0.809634804725647 ; Accuracy : 47.55 ; Test Loss : 0.7831578254699707 ; Test accuracy : 49.0\n",
      "Epochs : 107 ; Loss : 0.8092908263206482 ; Accuracy : 47.575 ; Test Loss : 0.7828664779663086 ; Test accuracy : 49.1\n",
      "Epochs : 108 ; Loss : 0.8089461326599121 ; Accuracy : 47.6 ; Test Loss : 0.7825755476951599 ; Test accuracy : 49.2\n",
      "Epochs : 109 ; Loss : 0.8086011409759521 ; Accuracy : 47.625 ; Test Loss : 0.7822849154472351 ; Test accuracy : 49.2\n",
      "Epochs : 110 ; Loss : 0.8082555532455444 ; Accuracy : 47.675 ; Test Loss : 0.7819944620132446 ; Test accuracy : 49.2\n",
      "Epochs : 111 ; Loss : 0.8079096078872681 ; Accuracy : 47.7 ; Test Loss : 0.7817041277885437 ; Test accuracy : 49.2\n",
      "Epochs : 112 ; Loss : 0.8075631260871887 ; Accuracy : 47.675 ; Test Loss : 0.7814137935638428 ; Test accuracy : 49.2\n",
      "Epochs : 113 ; Loss : 0.8072163462638855 ; Accuracy : 47.7 ; Test Loss : 0.7811235189437866 ; Test accuracy : 49.2\n",
      "Epochs : 114 ; Loss : 0.8068693280220032 ; Accuracy : 47.7 ; Test Loss : 0.7808330655097961 ; Test accuracy : 49.2\n",
      "Epochs : 115 ; Loss : 0.8065218329429626 ; Accuracy : 47.725 ; Test Loss : 0.780542254447937 ; Test accuracy : 49.2\n",
      "Epochs : 116 ; Loss : 0.806174099445343 ; Accuracy : 47.775 ; Test Loss : 0.7802512645721436 ; Test accuracy : 49.2\n",
      "Epochs : 117 ; Loss : 0.8058260679244995 ; Accuracy : 47.75 ; Test Loss : 0.7799598574638367 ; Test accuracy : 49.1\n",
      "Epochs : 118 ; Loss : 0.8054777383804321 ; Accuracy : 47.725 ; Test Loss : 0.7796681523323059 ; Test accuracy : 49.2\n",
      "Epochs : 119 ; Loss : 0.8051291704177856 ; Accuracy : 47.725 ; Test Loss : 0.7793759107589722 ; Test accuracy : 49.2\n",
      "Epochs : 120 ; Loss : 0.8047803044319153 ; Accuracy : 47.7 ; Test Loss : 0.7790831923484802 ; Test accuracy : 49.2\n",
      "Epochs : 121 ; Loss : 0.8044312596321106 ; Accuracy : 47.7 ; Test Loss : 0.7787898778915405 ; Test accuracy : 49.3\n",
      "Epochs : 122 ; Loss : 0.8040819764137268 ; Accuracy : 47.675 ; Test Loss : 0.7784961462020874 ; Test accuracy : 49.3\n",
      "Epochs : 123 ; Loss : 0.8037323355674744 ; Accuracy : 47.7 ; Test Loss : 0.7782016396522522 ; Test accuracy : 49.3\n",
      "Epochs : 124 ; Loss : 0.8033826351165771 ; Accuracy : 47.775 ; Test Loss : 0.777906596660614 ; Test accuracy : 49.3\n",
      "Epochs : 125 ; Loss : 0.8030325770378113 ; Accuracy : 47.8 ; Test Loss : 0.7776110172271729 ; Test accuracy : 49.3\n",
      "Epochs : 126 ; Loss : 0.8026824593544006 ; Accuracy : 47.8 ; Test Loss : 0.7773146629333496 ; Test accuracy : 49.3\n",
      "Epochs : 127 ; Loss : 0.8023320436477661 ; Accuracy : 47.8 ; Test Loss : 0.7770177721977234 ; Test accuracy : 49.3\n",
      "Epochs : 128 ; Loss : 0.801981508731842 ; Accuracy : 47.775 ; Test Loss : 0.7767202258110046 ; Test accuracy : 49.2\n",
      "Epochs : 129 ; Loss : 0.8016307950019836 ; Accuracy : 47.775 ; Test Loss : 0.7764221429824829 ; Test accuracy : 49.2\n",
      "Epochs : 130 ; Loss : 0.8012798428535461 ; Accuracy : 47.75 ; Test Loss : 0.7761234641075134 ; Test accuracy : 49.2\n",
      "Epochs : 131 ; Loss : 0.8009288311004639 ; Accuracy : 47.725 ; Test Loss : 0.7758241891860962 ; Test accuracy : 49.3\n",
      "Epochs : 132 ; Loss : 0.8005776405334473 ; Accuracy : 47.75 ; Test Loss : 0.775524377822876 ; Test accuracy : 49.3\n",
      "Epochs : 133 ; Loss : 0.8002262115478516 ; Accuracy : 47.825 ; Test Loss : 0.7752240896224976 ; Test accuracy : 49.3\n",
      "Epochs : 134 ; Loss : 0.7998746633529663 ; Accuracy : 47.85 ; Test Loss : 0.7749233245849609 ; Test accuracy : 49.2\n",
      "Epochs : 135 ; Loss : 0.799523115158081 ; Accuracy : 47.825 ; Test Loss : 0.7746220231056213 ; Test accuracy : 49.0\n",
      "Epochs : 136 ; Loss : 0.7991713881492615 ; Accuracy : 47.825 ; Test Loss : 0.7743203639984131 ; Test accuracy : 49.0\n",
      "Epochs : 137 ; Loss : 0.7988194823265076 ; Accuracy : 47.825 ; Test Loss : 0.7740183472633362 ; Test accuracy : 49.1\n",
      "Epochs : 138 ; Loss : 0.7984675765037537 ; Accuracy : 47.85 ; Test Loss : 0.7737160921096802 ; Test accuracy : 49.2\n",
      "Epochs : 139 ; Loss : 0.7981154918670654 ; Accuracy : 47.825 ; Test Loss : 0.773413360118866 ; Test accuracy : 49.1\n",
      "Epochs : 140 ; Loss : 0.7977634072303772 ; Accuracy : 47.8 ; Test Loss : 0.7731105089187622 ; Test accuracy : 49.1\n",
      "Epochs : 141 ; Loss : 0.7974112033843994 ; Accuracy : 47.775 ; Test Loss : 0.7728073596954346 ; Test accuracy : 49.1\n",
      "Epochs : 142 ; Loss : 0.7970589995384216 ; Accuracy : 47.75 ; Test Loss : 0.7725040912628174 ; Test accuracy : 49.2\n",
      "Epochs : 143 ; Loss : 0.7967066764831543 ; Accuracy : 47.8 ; Test Loss : 0.7722005248069763 ; Test accuracy : 49.1\n",
      "Epochs : 144 ; Loss : 0.7963544130325317 ; Accuracy : 47.875 ; Test Loss : 0.77189701795578 ; Test accuracy : 49.0\n",
      "Epochs : 145 ; Loss : 0.7960020303726196 ; Accuracy : 47.875 ; Test Loss : 0.7715932726860046 ; Test accuracy : 49.1\n",
      "Epochs : 146 ; Loss : 0.7956497669219971 ; Accuracy : 47.9 ; Test Loss : 0.771289587020874 ; Test accuracy : 49.2\n",
      "Epochs : 147 ; Loss : 0.795297384262085 ; Accuracy : 47.95 ; Test Loss : 0.7709859013557434 ; Test accuracy : 49.1\n",
      "Epochs : 148 ; Loss : 0.7949450016021729 ; Accuracy : 47.975 ; Test Loss : 0.7706822156906128 ; Test accuracy : 49.0\n",
      "Epochs : 149 ; Loss : 0.7945926785469055 ; Accuracy : 47.95 ; Test Loss : 0.770378589630127 ; Test accuracy : 48.9\n",
      "Epochs : 150 ; Loss : 0.7942403554916382 ; Accuracy : 47.925 ; Test Loss : 0.7700749635696411 ; Test accuracy : 49.0\n",
      "Epochs : 151 ; Loss : 0.7938879728317261 ; Accuracy : 47.875 ; Test Loss : 0.7697715163230896 ; Test accuracy : 49.0\n",
      "Epochs : 152 ; Loss : 0.7935358285903931 ; Accuracy : 47.875 ; Test Loss : 0.7694681882858276 ; Test accuracy : 49.0\n",
      "Epochs : 153 ; Loss : 0.7931835055351257 ; Accuracy : 47.875 ; Test Loss : 0.7691649794578552 ; Test accuracy : 49.0\n",
      "Epochs : 154 ; Loss : 0.7928313612937927 ; Accuracy : 47.85 ; Test Loss : 0.7688619494438171 ; Test accuracy : 48.9\n",
      "Epochs : 155 ; Loss : 0.7924792766571045 ; Accuracy : 47.95 ; Test Loss : 0.7685590386390686 ; Test accuracy : 48.9\n",
      "Epochs : 156 ; Loss : 0.792127251625061 ; Accuracy : 47.9 ; Test Loss : 0.7682563662528992 ; Test accuracy : 48.9\n",
      "Epochs : 157 ; Loss : 0.7917752265930176 ; Accuracy : 47.95 ; Test Loss : 0.7679538726806641 ; Test accuracy : 48.9\n",
      "Epochs : 158 ; Loss : 0.7914233803749084 ; Accuracy : 47.975 ; Test Loss : 0.7676516771316528 ; Test accuracy : 49.0\n",
      "Epochs : 159 ; Loss : 0.7910716533660889 ; Accuracy : 48.0 ; Test Loss : 0.7673496603965759 ; Test accuracy : 49.0\n",
      "Epochs : 160 ; Loss : 0.7907199263572693 ; Accuracy : 47.975 ; Test Loss : 0.7670478820800781 ; Test accuracy : 49.0\n",
      "Epochs : 161 ; Loss : 0.790368378162384 ; Accuracy : 48.0 ; Test Loss : 0.7667464017868042 ; Test accuracy : 49.0\n",
      "Epochs : 162 ; Loss : 0.7900168895721436 ; Accuracy : 48.075 ; Test Loss : 0.7664451003074646 ; Test accuracy : 49.1\n",
      "Epochs : 163 ; Loss : 0.7896655797958374 ; Accuracy : 48.075 ; Test Loss : 0.7661440968513489 ; Test accuracy : 49.2\n",
      "Epochs : 164 ; Loss : 0.7893143892288208 ; Accuracy : 48.1 ; Test Loss : 0.7658433318138123 ; Test accuracy : 49.2\n",
      "Epochs : 165 ; Loss : 0.7889633178710938 ; Accuracy : 48.075 ; Test Loss : 0.7655428647994995 ; Test accuracy : 49.2\n",
      "Epochs : 166 ; Loss : 0.7886123061180115 ; Accuracy : 48.075 ; Test Loss : 0.7652426362037659 ; Test accuracy : 49.2\n",
      "Epochs : 167 ; Loss : 0.7882615327835083 ; Accuracy : 48.125 ; Test Loss : 0.7649427056312561 ; Test accuracy : 49.2\n",
      "Epochs : 168 ; Loss : 0.7879109382629395 ; Accuracy : 48.125 ; Test Loss : 0.7646429538726807 ; Test accuracy : 49.3\n",
      "Epochs : 169 ; Loss : 0.7875604033470154 ; Accuracy : 48.15 ; Test Loss : 0.7643436789512634 ; Test accuracy : 49.3\n",
      "Epochs : 170 ; Loss : 0.7872100472450256 ; Accuracy : 48.175 ; Test Loss : 0.764044463634491 ; Test accuracy : 49.4\n",
      "Epochs : 171 ; Loss : 0.786859929561615 ; Accuracy : 48.2 ; Test Loss : 0.7637456655502319 ; Test accuracy : 49.4\n",
      "Epochs : 172 ; Loss : 0.7865099906921387 ; Accuracy : 48.25 ; Test Loss : 0.7634470462799072 ; Test accuracy : 49.4\n",
      "Epochs : 173 ; Loss : 0.7861601710319519 ; Accuracy : 48.225 ; Test Loss : 0.7631487250328064 ; Test accuracy : 49.4\n",
      "Epochs : 174 ; Loss : 0.785810649394989 ; Accuracy : 48.325 ; Test Loss : 0.7628506422042847 ; Test accuracy : 49.5\n",
      "Epochs : 175 ; Loss : 0.7854612469673157 ; Accuracy : 48.325 ; Test Loss : 0.7625529170036316 ; Test accuracy : 49.5\n",
      "Epochs : 176 ; Loss : 0.7851120829582214 ; Accuracy : 48.325 ; Test Loss : 0.7622553706169128 ; Test accuracy : 49.4\n",
      "Epochs : 177 ; Loss : 0.7847630977630615 ; Accuracy : 48.325 ; Test Loss : 0.7619580626487732 ; Test accuracy : 49.4\n",
      "Epochs : 178 ; Loss : 0.7844143509864807 ; Accuracy : 48.3 ; Test Loss : 0.7616610527038574 ; Test accuracy : 49.4\n",
      "Epochs : 179 ; Loss : 0.784065842628479 ; Accuracy : 48.3 ; Test Loss : 0.7613643407821655 ; Test accuracy : 49.3\n",
      "Epochs : 180 ; Loss : 0.7837175726890564 ; Accuracy : 48.3 ; Test Loss : 0.7610679268836975 ; Test accuracy : 49.2\n",
      "Epochs : 181 ; Loss : 0.7833694815635681 ; Accuracy : 48.325 ; Test Loss : 0.7607716917991638 ; Test accuracy : 49.2\n",
      "Epochs : 182 ; Loss : 0.7830216288566589 ; Accuracy : 48.325 ; Test Loss : 0.760475754737854 ; Test accuracy : 49.2\n",
      "Epochs : 183 ; Loss : 0.7826740741729736 ; Accuracy : 48.375 ; Test Loss : 0.7601800560951233 ; Test accuracy : 49.4\n",
      "Epochs : 184 ; Loss : 0.7823266983032227 ; Accuracy : 48.375 ; Test Loss : 0.7598845958709717 ; Test accuracy : 49.4\n",
      "Epochs : 185 ; Loss : 0.7819796800613403 ; Accuracy : 48.4 ; Test Loss : 0.7595894932746887 ; Test accuracy : 49.4\n",
      "Epochs : 186 ; Loss : 0.7816328406333923 ; Accuracy : 48.45 ; Test Loss : 0.7592945694923401 ; Test accuracy : 49.4\n",
      "Epochs : 187 ; Loss : 0.7812862992286682 ; Accuracy : 48.5 ; Test Loss : 0.7589999437332153 ; Test accuracy : 49.5\n",
      "Epochs : 188 ; Loss : 0.780940055847168 ; Accuracy : 48.55 ; Test Loss : 0.7587056756019592 ; Test accuracy : 49.5\n",
      "Epochs : 189 ; Loss : 0.7805940508842468 ; Accuracy : 48.625 ; Test Loss : 0.7584115266799927 ; Test accuracy : 49.4\n",
      "Epochs : 190 ; Loss : 0.7802482843399048 ; Accuracy : 48.65 ; Test Loss : 0.7581177353858948 ; Test accuracy : 49.4\n",
      "Epochs : 191 ; Loss : 0.7799028754234314 ; Accuracy : 48.7 ; Test Loss : 0.757824182510376 ; Test accuracy : 49.3\n",
      "Epochs : 192 ; Loss : 0.7795576453208923 ; Accuracy : 48.75 ; Test Loss : 0.7575309872627258 ; Test accuracy : 49.3\n",
      "Epochs : 193 ; Loss : 0.7792128324508667 ; Accuracy : 48.825 ; Test Loss : 0.7572380304336548 ; Test accuracy : 49.3\n",
      "Epochs : 194 ; Loss : 0.7788681983947754 ; Accuracy : 48.85 ; Test Loss : 0.7569453716278076 ; Test accuracy : 49.3\n",
      "Epochs : 195 ; Loss : 0.7785240411758423 ; Accuracy : 48.9 ; Test Loss : 0.7566529512405396 ; Test accuracy : 49.3\n",
      "Epochs : 196 ; Loss : 0.7781800031661987 ; Accuracy : 48.9 ; Test Loss : 0.7563608288764954 ; Test accuracy : 49.5\n",
      "Epochs : 197 ; Loss : 0.7778363823890686 ; Accuracy : 49.0 ; Test Loss : 0.7560690641403198 ; Test accuracy : 49.6\n",
      "Epochs : 198 ; Loss : 0.7774930596351624 ; Accuracy : 49.0 ; Test Loss : 0.7557775974273682 ; Test accuracy : 49.7\n",
      "Epochs : 199 ; Loss : 0.7771500945091248 ; Accuracy : 48.975 ; Test Loss : 0.7554863691329956 ; Test accuracy : 49.7\n",
      "Epochs : 200 ; Loss : 0.776807427406311 ; Accuracy : 49.0 ; Test Loss : 0.7551956176757812 ; Test accuracy : 49.7\n",
      "Epochs : 201 ; Loss : 0.776465117931366 ; Accuracy : 49.0 ; Test Loss : 0.7549049854278564 ; Test accuracy : 49.7\n",
      "Epochs : 202 ; Loss : 0.7761231064796448 ; Accuracy : 49.05 ; Test Loss : 0.7546147704124451 ; Test accuracy : 49.7\n",
      "Epochs : 203 ; Loss : 0.7757813334465027 ; Accuracy : 49.05 ; Test Loss : 0.7543248534202576 ; Test accuracy : 49.7\n",
      "Epochs : 204 ; Loss : 0.775439977645874 ; Accuracy : 49.1 ; Test Loss : 0.7540352940559387 ; Test accuracy : 49.9\n",
      "Epochs : 205 ; Loss : 0.7750990390777588 ; Accuracy : 49.15 ; Test Loss : 0.7537460923194885 ; Test accuracy : 49.9\n",
      "Epochs : 206 ; Loss : 0.7747583985328674 ; Accuracy : 49.125 ; Test Loss : 0.7534571886062622 ; Test accuracy : 49.9\n",
      "Epochs : 207 ; Loss : 0.7744181156158447 ; Accuracy : 49.1 ; Test Loss : 0.7531686425209045 ; Test accuracy : 49.9\n",
      "Epochs : 208 ; Loss : 0.7740781903266907 ; Accuracy : 49.075 ; Test Loss : 0.7528803944587708 ; Test accuracy : 49.9\n",
      "Epochs : 209 ; Loss : 0.7737385630607605 ; Accuracy : 49.025 ; Test Loss : 0.7525925636291504 ; Test accuracy : 49.9\n",
      "Epochs : 210 ; Loss : 0.7733993530273438 ; Accuracy : 49.025 ; Test Loss : 0.7523050904273987 ; Test accuracy : 49.8\n",
      "Epochs : 211 ; Loss : 0.7730604410171509 ; Accuracy : 49.075 ; Test Loss : 0.7520179152488708 ; Test accuracy : 49.8\n",
      "Epochs : 212 ; Loss : 0.7727220058441162 ; Accuracy : 49.1 ; Test Loss : 0.7517310976982117 ; Test accuracy : 49.7\n",
      "Epochs : 213 ; Loss : 0.7723838686943054 ; Accuracy : 49.125 ; Test Loss : 0.7514447569847107 ; Test accuracy : 49.7\n",
      "Epochs : 214 ; Loss : 0.7720462083816528 ; Accuracy : 49.15 ; Test Loss : 0.7511586546897888 ; Test accuracy : 49.7\n",
      "Epochs : 215 ; Loss : 0.7717087864875793 ; Accuracy : 49.225 ; Test Loss : 0.7508730292320251 ; Test accuracy : 49.7\n",
      "Epochs : 216 ; Loss : 0.7713717818260193 ; Accuracy : 49.275 ; Test Loss : 0.7505877017974854 ; Test accuracy : 49.7\n",
      "Epochs : 217 ; Loss : 0.7710352540016174 ; Accuracy : 49.275 ; Test Loss : 0.750302791595459 ; Test accuracy : 49.7\n",
      "Epochs : 218 ; Loss : 0.7706990242004395 ; Accuracy : 49.25 ; Test Loss : 0.7500182390213013 ; Test accuracy : 49.6\n",
      "Epochs : 219 ; Loss : 0.7703632712364197 ; Accuracy : 49.25 ; Test Loss : 0.749734103679657 ; Test accuracy : 49.6\n",
      "Epochs : 220 ; Loss : 0.770027756690979 ; Accuracy : 49.225 ; Test Loss : 0.7494503259658813 ; Test accuracy : 49.6\n",
      "Epochs : 221 ; Loss : 0.7696927785873413 ; Accuracy : 49.325 ; Test Loss : 0.7491669654846191 ; Test accuracy : 49.7\n",
      "Epochs : 222 ; Loss : 0.7693581581115723 ; Accuracy : 49.35 ; Test Loss : 0.7488840222358704 ; Test accuracy : 49.8\n",
      "Epochs : 223 ; Loss : 0.7690239548683167 ; Accuracy : 49.4 ; Test Loss : 0.7486013770103455 ; Test accuracy : 49.8\n",
      "Epochs : 224 ; Loss : 0.7686901092529297 ; Accuracy : 49.4 ; Test Loss : 0.7483192086219788 ; Test accuracy : 49.8\n",
      "Epochs : 225 ; Loss : 0.7683567404747009 ; Accuracy : 49.45 ; Test Loss : 0.7480373978614807 ; Test accuracy : 49.8\n",
      "Epochs : 226 ; Loss : 0.7680237293243408 ; Accuracy : 49.45 ; Test Loss : 0.7477560043334961 ; Test accuracy : 49.9\n",
      "Epochs : 227 ; Loss : 0.7676911354064941 ; Accuracy : 49.475 ; Test Loss : 0.7474750280380249 ; Test accuracy : 50.0\n",
      "Epochs : 228 ; Loss : 0.7673589587211609 ; Accuracy : 49.45 ; Test Loss : 0.7471943497657776 ; Test accuracy : 50.2\n",
      "Epochs : 229 ; Loss : 0.7670272588729858 ; Accuracy : 49.45 ; Test Loss : 0.7469142079353333 ; Test accuracy : 50.2\n",
      "Epochs : 230 ; Loss : 0.7666959762573242 ; Accuracy : 49.45 ; Test Loss : 0.7466344237327576 ; Test accuracy : 50.2\n",
      "Epochs : 231 ; Loss : 0.7663650512695312 ; Accuracy : 49.475 ; Test Loss : 0.7463549971580505 ; Test accuracy : 50.2\n",
      "Epochs : 232 ; Loss : 0.7660345435142517 ; Accuracy : 49.45 ; Test Loss : 0.7460761070251465 ; Test accuracy : 50.2\n",
      "Epochs : 233 ; Loss : 0.7657045125961304 ; Accuracy : 49.425 ; Test Loss : 0.7457975149154663 ; Test accuracy : 50.4\n",
      "Epochs : 234 ; Loss : 0.7653748989105225 ; Accuracy : 49.425 ; Test Loss : 0.7455193400382996 ; Test accuracy : 50.4\n",
      "Epochs : 235 ; Loss : 0.765045702457428 ; Accuracy : 49.425 ; Test Loss : 0.745241641998291 ; Test accuracy : 50.4\n",
      "Epochs : 236 ; Loss : 0.7647169828414917 ; Accuracy : 49.475 ; Test Loss : 0.7449642419815063 ; Test accuracy : 50.4\n",
      "Epochs : 237 ; Loss : 0.7643885612487793 ; Accuracy : 49.475 ; Test Loss : 0.7446873784065247 ; Test accuracy : 50.4\n",
      "Epochs : 238 ; Loss : 0.7640607953071594 ; Accuracy : 49.45 ; Test Loss : 0.7444109320640564 ; Test accuracy : 50.4\n",
      "Epochs : 239 ; Loss : 0.7637333273887634 ; Accuracy : 49.45 ; Test Loss : 0.744134783744812 ; Test accuracy : 50.4\n",
      "Epochs : 240 ; Loss : 0.7634062767028809 ; Accuracy : 49.425 ; Test Loss : 0.7438591718673706 ; Test accuracy : 50.5\n",
      "Epochs : 241 ; Loss : 0.7630797624588013 ; Accuracy : 49.425 ; Test Loss : 0.7435839176177979 ; Test accuracy : 50.5\n",
      "Epochs : 242 ; Loss : 0.7627537250518799 ; Accuracy : 49.45 ; Test Loss : 0.7433090806007385 ; Test accuracy : 50.4\n",
      "Epochs : 243 ; Loss : 0.7624279856681824 ; Accuracy : 49.45 ; Test Loss : 0.7430346608161926 ; Test accuracy : 50.4\n",
      "Epochs : 244 ; Loss : 0.7621028423309326 ; Accuracy : 49.475 ; Test Loss : 0.7427607178688049 ; Test accuracy : 50.4\n",
      "Epochs : 245 ; Loss : 0.7617781162261963 ; Accuracy : 49.45 ; Test Loss : 0.7424871325492859 ; Test accuracy : 50.6\n",
      "Epochs : 246 ; Loss : 0.7614537477493286 ; Accuracy : 49.475 ; Test Loss : 0.7422139644622803 ; Test accuracy : 50.7\n",
      "Epochs : 247 ; Loss : 0.7611299157142639 ; Accuracy : 49.55 ; Test Loss : 0.7419413328170776 ; Test accuracy : 50.7\n",
      "Epochs : 248 ; Loss : 0.7608065605163574 ; Accuracy : 49.575 ; Test Loss : 0.7416690587997437 ; Test accuracy : 50.7\n",
      "Epochs : 249 ; Loss : 0.7604836821556091 ; Accuracy : 49.55 ; Test Loss : 0.7413972020149231 ; Test accuracy : 50.7\n",
      "Epochs : 250 ; Loss : 0.7601611614227295 ; Accuracy : 49.55 ; Test Loss : 0.741125762462616 ; Test accuracy : 50.9\n",
      "Epochs : 251 ; Loss : 0.7598391771316528 ; Accuracy : 49.575 ; Test Loss : 0.7408547401428223 ; Test accuracy : 51.0\n",
      "Epochs : 252 ; Loss : 0.7595176100730896 ; Accuracy : 49.575 ; Test Loss : 0.740584135055542 ; Test accuracy : 51.1\n",
      "Epochs : 253 ; Loss : 0.7591965794563293 ; Accuracy : 49.6 ; Test Loss : 0.7403140068054199 ; Test accuracy : 51.2\n",
      "Epochs : 254 ; Loss : 0.7588760256767273 ; Accuracy : 49.625 ; Test Loss : 0.7400442957878113 ; Test accuracy : 51.2\n",
      "Epochs : 255 ; Loss : 0.7585558295249939 ; Accuracy : 49.675 ; Test Loss : 0.7397750616073608 ; Test accuracy : 51.2\n",
      "Epochs : 256 ; Loss : 0.7582362294197083 ; Accuracy : 49.65 ; Test Loss : 0.7395061254501343 ; Test accuracy : 51.2\n",
      "Epochs : 257 ; Loss : 0.7579169869422913 ; Accuracy : 49.675 ; Test Loss : 0.7392377853393555 ; Test accuracy : 51.4\n",
      "Epochs : 258 ; Loss : 0.7575982213020325 ; Accuracy : 49.725 ; Test Loss : 0.7389697432518005 ; Test accuracy : 51.4\n",
      "Epochs : 259 ; Loss : 0.7572800517082214 ; Accuracy : 49.775 ; Test Loss : 0.7387022376060486 ; Test accuracy : 51.4\n",
      "Epochs : 260 ; Loss : 0.7569621801376343 ; Accuracy : 49.8 ; Test Loss : 0.7384352087974548 ; Test accuracy : 51.4\n",
      "Epochs : 261 ; Loss : 0.7566449046134949 ; Accuracy : 49.8 ; Test Loss : 0.738168478012085 ; Test accuracy : 51.4\n",
      "Epochs : 262 ; Loss : 0.7563281059265137 ; Accuracy : 49.8 ; Test Loss : 0.7379023432731628 ; Test accuracy : 51.4\n",
      "Epochs : 263 ; Loss : 0.7560117840766907 ; Accuracy : 49.8 ; Test Loss : 0.7376365065574646 ; Test accuracy : 51.4\n",
      "Epochs : 264 ; Loss : 0.7556958794593811 ; Accuracy : 49.8 ; Test Loss : 0.7373711466789246 ; Test accuracy : 51.8\n",
      "Epochs : 265 ; Loss : 0.7553804516792297 ; Accuracy : 49.9 ; Test Loss : 0.7371062636375427 ; Test accuracy : 51.8\n",
      "Epochs : 266 ; Loss : 0.7550655603408813 ; Accuracy : 49.9 ; Test Loss : 0.7368417382240295 ; Test accuracy : 51.8\n",
      "Epochs : 267 ; Loss : 0.7547512054443359 ; Accuracy : 49.925 ; Test Loss : 0.7365778088569641 ; Test accuracy : 51.9\n",
      "Epochs : 268 ; Loss : 0.754437267780304 ; Accuracy : 49.9 ; Test Loss : 0.7363141179084778 ; Test accuracy : 51.9\n",
      "Epochs : 269 ; Loss : 0.7541238069534302 ; Accuracy : 49.95 ; Test Loss : 0.736051082611084 ; Test accuracy : 51.9\n",
      "Epochs : 270 ; Loss : 0.7538108229637146 ; Accuracy : 49.975 ; Test Loss : 0.7357882857322693 ; Test accuracy : 52.0\n",
      "Epochs : 271 ; Loss : 0.7534983158111572 ; Accuracy : 49.95 ; Test Loss : 0.7355260252952576 ; Test accuracy : 52.0\n",
      "Epochs : 272 ; Loss : 0.7531862854957581 ; Accuracy : 50.075 ; Test Loss : 0.735264241695404 ; Test accuracy : 51.9\n",
      "Epochs : 273 ; Loss : 0.7528747916221619 ; Accuracy : 50.125 ; Test Loss : 0.735002875328064 ; Test accuracy : 52.1\n",
      "Epochs : 274 ; Loss : 0.7525637745857239 ; Accuracy : 50.175 ; Test Loss : 0.7347419857978821 ; Test accuracy : 52.2\n",
      "Epochs : 275 ; Loss : 0.7522532939910889 ; Accuracy : 50.175 ; Test Loss : 0.7344814538955688 ; Test accuracy : 52.1\n",
      "Epochs : 276 ; Loss : 0.7519432306289673 ; Accuracy : 50.2 ; Test Loss : 0.7342214584350586 ; Test accuracy : 52.1\n",
      "Epochs : 277 ; Loss : 0.7516336441040039 ; Accuracy : 50.25 ; Test Loss : 0.7339618802070618 ; Test accuracy : 52.2\n",
      "Epochs : 278 ; Loss : 0.7513245940208435 ; Accuracy : 50.225 ; Test Loss : 0.7337027192115784 ; Test accuracy : 52.4\n",
      "Epochs : 279 ; Loss : 0.7510160207748413 ; Accuracy : 50.25 ; Test Loss : 0.7334439754486084 ; Test accuracy : 52.4\n",
      "Epochs : 280 ; Loss : 0.7507079243659973 ; Accuracy : 50.25 ; Test Loss : 0.7331857085227966 ; Test accuracy : 52.4\n",
      "Epochs : 281 ; Loss : 0.7504003047943115 ; Accuracy : 50.275 ; Test Loss : 0.7329279780387878 ; Test accuracy : 52.4\n",
      "Epochs : 282 ; Loss : 0.7500932216644287 ; Accuracy : 50.325 ; Test Loss : 0.7326705455780029 ; Test accuracy : 52.4\n",
      "Epochs : 283 ; Loss : 0.7497866749763489 ; Accuracy : 50.4 ; Test Loss : 0.7324137091636658 ; Test accuracy : 52.4\n",
      "Epochs : 284 ; Loss : 0.7494805455207825 ; Accuracy : 50.4 ; Test Loss : 0.7321571707725525 ; Test accuracy : 52.4\n",
      "Epochs : 285 ; Loss : 0.749174952507019 ; Accuracy : 50.425 ; Test Loss : 0.731901228427887 ; Test accuracy : 52.4\n",
      "Epochs : 286 ; Loss : 0.7488698363304138 ; Accuracy : 50.45 ; Test Loss : 0.7316455841064453 ; Test accuracy : 52.4\n",
      "Epochs : 287 ; Loss : 0.7485651969909668 ; Accuracy : 50.4 ; Test Loss : 0.7313904762268066 ; Test accuracy : 52.4\n",
      "Epochs : 288 ; Loss : 0.7482610940933228 ; Accuracy : 50.425 ; Test Loss : 0.7311358451843262 ; Test accuracy : 52.3\n",
      "Epochs : 289 ; Loss : 0.7479574084281921 ; Accuracy : 50.45 ; Test Loss : 0.7308816313743591 ; Test accuracy : 52.4\n",
      "Epochs : 290 ; Loss : 0.7476543188095093 ; Accuracy : 50.4 ; Test Loss : 0.7306278347969055 ; Test accuracy : 52.4\n",
      "Epochs : 291 ; Loss : 0.7473517060279846 ; Accuracy : 50.45 ; Test Loss : 0.7303743958473206 ; Test accuracy : 52.3\n",
      "Epochs : 292 ; Loss : 0.7470495700836182 ; Accuracy : 50.5 ; Test Loss : 0.7301214933395386 ; Test accuracy : 52.3\n",
      "Epochs : 293 ; Loss : 0.7467479705810547 ; Accuracy : 50.475 ; Test Loss : 0.7298690676689148 ; Test accuracy : 52.2\n",
      "Epochs : 294 ; Loss : 0.7464467883110046 ; Accuracy : 50.475 ; Test Loss : 0.7296171188354492 ; Test accuracy : 52.3\n",
      "Epochs : 295 ; Loss : 0.7461461424827576 ; Accuracy : 50.5 ; Test Loss : 0.7293655872344971 ; Test accuracy : 52.2\n",
      "Epochs : 296 ; Loss : 0.7458460330963135 ; Accuracy : 50.5 ; Test Loss : 0.7291144132614136 ; Test accuracy : 52.2\n",
      "Epochs : 297 ; Loss : 0.7455464005470276 ; Accuracy : 50.575 ; Test Loss : 0.7288637161254883 ; Test accuracy : 52.3\n",
      "Epochs : 298 ; Loss : 0.7452472448348999 ; Accuracy : 50.55 ; Test Loss : 0.728613555431366 ; Test accuracy : 52.2\n",
      "Epochs : 299 ; Loss : 0.7449486255645752 ; Accuracy : 50.7 ; Test Loss : 0.7283638119697571 ; Test accuracy : 52.2\n",
      "Epochs : 300 ; Loss : 0.7446504831314087 ; Accuracy : 50.75 ; Test Loss : 0.7281144261360168 ; Test accuracy : 52.2\n",
      "Epochs : 301 ; Loss : 0.7443528175354004 ; Accuracy : 50.775 ; Test Loss : 0.7278655767440796 ; Test accuracy : 52.2\n",
      "Epochs : 302 ; Loss : 0.7440556883811951 ; Accuracy : 50.85 ; Test Loss : 0.727617084980011 ; Test accuracy : 52.3\n",
      "Epochs : 303 ; Loss : 0.7437590956687927 ; Accuracy : 50.875 ; Test Loss : 0.7273691892623901 ; Test accuracy : 52.3\n",
      "Epochs : 304 ; Loss : 0.7434629201889038 ; Accuracy : 50.9 ; Test Loss : 0.7271215319633484 ; Test accuracy : 52.3\n",
      "Epochs : 305 ; Loss : 0.7431672811508179 ; Accuracy : 50.875 ; Test Loss : 0.7268744707107544 ; Test accuracy : 52.3\n",
      "Epochs : 306 ; Loss : 0.7428721189498901 ; Accuracy : 50.875 ; Test Loss : 0.7266278266906738 ; Test accuracy : 52.3\n",
      "Epochs : 307 ; Loss : 0.7425775527954102 ; Accuracy : 50.95 ; Test Loss : 0.7263815402984619 ; Test accuracy : 52.3\n",
      "Epochs : 308 ; Loss : 0.7422833442687988 ; Accuracy : 50.925 ; Test Loss : 0.726135790348053 ; Test accuracy : 52.3\n",
      "Epochs : 309 ; Loss : 0.7419897317886353 ; Accuracy : 50.925 ; Test Loss : 0.7258905172348022 ; Test accuracy : 52.3\n",
      "Epochs : 310 ; Loss : 0.7416966557502747 ; Accuracy : 50.925 ; Test Loss : 0.7256455421447754 ; Test accuracy : 52.2\n",
      "Epochs : 311 ; Loss : 0.7414038777351379 ; Accuracy : 50.9 ; Test Loss : 0.7254011631011963 ; Test accuracy : 52.2\n",
      "Epochs : 312 ; Loss : 0.7411118149757385 ; Accuracy : 50.925 ; Test Loss : 0.7251571416854858 ; Test accuracy : 52.2\n",
      "Epochs : 313 ; Loss : 0.7408202290534973 ; Accuracy : 50.9 ; Test Loss : 0.7249135971069336 ; Test accuracy : 52.2\n",
      "Epochs : 314 ; Loss : 0.7405290603637695 ; Accuracy : 50.9 ; Test Loss : 0.7246704697608948 ; Test accuracy : 52.3\n",
      "Epochs : 315 ; Loss : 0.7402384281158447 ; Accuracy : 50.9 ; Test Loss : 0.7244277596473694 ; Test accuracy : 52.3\n",
      "Epochs : 316 ; Loss : 0.7399482727050781 ; Accuracy : 50.9 ; Test Loss : 0.7241855263710022 ; Test accuracy : 52.4\n",
      "Epochs : 317 ; Loss : 0.7396585941314697 ; Accuracy : 50.9 ; Test Loss : 0.7239437699317932 ; Test accuracy : 52.4\n",
      "Epochs : 318 ; Loss : 0.7393693923950195 ; Accuracy : 50.95 ; Test Loss : 0.7237023115158081 ; Test accuracy : 52.5\n",
      "Epochs : 319 ; Loss : 0.7390808463096619 ; Accuracy : 50.95 ; Test Loss : 0.7234614491462708 ; Test accuracy : 52.5\n",
      "Epochs : 320 ; Loss : 0.7387927770614624 ; Accuracy : 50.95 ; Test Loss : 0.723220944404602 ; Test accuracy : 52.5\n",
      "Epochs : 321 ; Loss : 0.7385050654411316 ; Accuracy : 51.025 ; Test Loss : 0.7229808568954468 ; Test accuracy : 52.5\n",
      "Epochs : 322 ; Loss : 0.7382179498672485 ; Accuracy : 51.05 ; Test Loss : 0.7227412462234497 ; Test accuracy : 52.5\n",
      "Epochs : 323 ; Loss : 0.7379312515258789 ; Accuracy : 51.075 ; Test Loss : 0.7225021123886108 ; Test accuracy : 52.5\n",
      "Epochs : 324 ; Loss : 0.7376450896263123 ; Accuracy : 51.075 ; Test Loss : 0.7222633361816406 ; Test accuracy : 52.6\n",
      "Epochs : 325 ; Loss : 0.7373594641685486 ; Accuracy : 51.075 ; Test Loss : 0.7220250368118286 ; Test accuracy : 52.6\n",
      "Epochs : 326 ; Loss : 0.7370743751525879 ; Accuracy : 51.05 ; Test Loss : 0.7217872142791748 ; Test accuracy : 52.6\n",
      "Epochs : 327 ; Loss : 0.7367896437644958 ; Accuracy : 51.025 ; Test Loss : 0.7215496897697449 ; Test accuracy : 52.6\n",
      "Epochs : 328 ; Loss : 0.7365055084228516 ; Accuracy : 51.025 ; Test Loss : 0.7213127613067627 ; Test accuracy : 52.7\n",
      "Epochs : 329 ; Loss : 0.7362219095230103 ; Accuracy : 51.05 ; Test Loss : 0.7210761904716492 ; Test accuracy : 52.6\n",
      "Epochs : 330 ; Loss : 0.7359386086463928 ; Accuracy : 51.15 ; Test Loss : 0.7208400368690491 ; Test accuracy : 52.7\n",
      "Epochs : 331 ; Loss : 0.7356560230255127 ; Accuracy : 51.225 ; Test Loss : 0.7206043601036072 ; Test accuracy : 52.7\n",
      "Epochs : 332 ; Loss : 0.735373854637146 ; Accuracy : 51.25 ; Test Loss : 0.7203690409660339 ; Test accuracy : 52.6\n",
      "Epochs : 333 ; Loss : 0.7350922226905823 ; Accuracy : 51.225 ; Test Loss : 0.7201343178749084 ; Test accuracy : 52.6\n",
      "Epochs : 334 ; Loss : 0.7348109483718872 ; Accuracy : 51.225 ; Test Loss : 0.7198998332023621 ; Test accuracy : 52.6\n",
      "Epochs : 335 ; Loss : 0.7345303297042847 ; Accuracy : 51.225 ; Test Loss : 0.7196658849716187 ; Test accuracy : 52.6\n",
      "Epochs : 336 ; Loss : 0.734250009059906 ; Accuracy : 51.225 ; Test Loss : 0.7194322943687439 ; Test accuracy : 52.6\n",
      "Epochs : 337 ; Loss : 0.7339703440666199 ; Accuracy : 51.3 ; Test Loss : 0.7191992402076721 ; Test accuracy : 52.7\n",
      "Epochs : 338 ; Loss : 0.7336912155151367 ; Accuracy : 51.325 ; Test Loss : 0.718966543674469 ; Test accuracy : 52.7\n",
      "Epochs : 339 ; Loss : 0.733412504196167 ; Accuracy : 51.3 ; Test Loss : 0.7187342643737793 ; Test accuracy : 52.7\n",
      "Epochs : 340 ; Loss : 0.7331342101097107 ; Accuracy : 51.325 ; Test Loss : 0.7185024619102478 ; Test accuracy : 52.7\n",
      "Epochs : 341 ; Loss : 0.7328564524650574 ; Accuracy : 51.325 ; Test Loss : 0.718271017074585 ; Test accuracy : 52.8\n",
      "Epochs : 342 ; Loss : 0.732579231262207 ; Accuracy : 51.325 ; Test Loss : 0.7180400490760803 ; Test accuracy : 52.9\n",
      "Epochs : 343 ; Loss : 0.7323025465011597 ; Accuracy : 51.375 ; Test Loss : 0.7178094983100891 ; Test accuracy : 53.0\n",
      "Epochs : 344 ; Loss : 0.732026219367981 ; Accuracy : 51.4 ; Test Loss : 0.7175793647766113 ; Test accuracy : 53.2\n",
      "Epochs : 345 ; Loss : 0.73175048828125 ; Accuracy : 51.475 ; Test Loss : 0.717349648475647 ; Test accuracy : 53.2\n",
      "Epochs : 346 ; Loss : 0.7314751148223877 ; Accuracy : 51.5 ; Test Loss : 0.717120349407196 ; Test accuracy : 53.1\n",
      "Epochs : 347 ; Loss : 0.7312003374099731 ; Accuracy : 51.5 ; Test Loss : 0.7168915271759033 ; Test accuracy : 53.3\n",
      "Epochs : 348 ; Loss : 0.7309260368347168 ; Accuracy : 51.525 ; Test Loss : 0.716663122177124 ; Test accuracy : 53.5\n",
      "Epochs : 349 ; Loss : 0.7306522727012634 ; Accuracy : 51.55 ; Test Loss : 0.7164350152015686 ; Test accuracy : 53.5\n",
      "Epochs : 350 ; Loss : 0.7303789258003235 ; Accuracy : 51.6 ; Test Loss : 0.7162074446678162 ; Test accuracy : 53.7\n",
      "Epochs : 351 ; Loss : 0.7301061153411865 ; Accuracy : 51.7 ; Test Loss : 0.7159802317619324 ; Test accuracy : 53.7\n",
      "Epochs : 352 ; Loss : 0.729833722114563 ; Accuracy : 51.85 ; Test Loss : 0.7157534956932068 ; Test accuracy : 53.7\n",
      "Epochs : 353 ; Loss : 0.7295618057250977 ; Accuracy : 51.9 ; Test Loss : 0.7155271172523499 ; Test accuracy : 54.0\n",
      "Epochs : 354 ; Loss : 0.7292904257774353 ; Accuracy : 51.975 ; Test Loss : 0.7153011560440063 ; Test accuracy : 54.0\n",
      "Epochs : 355 ; Loss : 0.7290195226669312 ; Accuracy : 51.975 ; Test Loss : 0.7150757312774658 ; Test accuracy : 54.0\n",
      "Epochs : 356 ; Loss : 0.72874915599823 ; Accuracy : 51.975 ; Test Loss : 0.7148506045341492 ; Test accuracy : 54.0\n",
      "Epochs : 357 ; Loss : 0.7284791469573975 ; Accuracy : 52.075 ; Test Loss : 0.7146259546279907 ; Test accuracy : 54.0\n",
      "Epochs : 358 ; Loss : 0.7282097339630127 ; Accuracy : 52.05 ; Test Loss : 0.7144016623497009 ; Test accuracy : 54.0\n",
      "Epochs : 359 ; Loss : 0.7279408574104309 ; Accuracy : 52.125 ; Test Loss : 0.7141778469085693 ; Test accuracy : 54.0\n",
      "Epochs : 360 ; Loss : 0.727672278881073 ; Accuracy : 52.1 ; Test Loss : 0.7139543890953064 ; Test accuracy : 54.1\n",
      "Epochs : 361 ; Loss : 0.7274042963981628 ; Accuracy : 52.1 ; Test Loss : 0.7137313485145569 ; Test accuracy : 54.1\n",
      "Epochs : 362 ; Loss : 0.7271366715431213 ; Accuracy : 52.15 ; Test Loss : 0.7135087251663208 ; Test accuracy : 54.1\n",
      "Epochs : 363 ; Loss : 0.7268696427345276 ; Accuracy : 52.175 ; Test Loss : 0.7132865190505981 ; Test accuracy : 54.3\n",
      "Epochs : 364 ; Loss : 0.726603090763092 ; Accuracy : 52.275 ; Test Loss : 0.7130646705627441 ; Test accuracy : 54.3\n",
      "Epochs : 365 ; Loss : 0.7263369560241699 ; Accuracy : 52.35 ; Test Loss : 0.7128432989120483 ; Test accuracy : 54.2\n",
      "Epochs : 366 ; Loss : 0.726071298122406 ; Accuracy : 52.4 ; Test Loss : 0.712622344493866 ; Test accuracy : 54.2\n",
      "Epochs : 367 ; Loss : 0.7258061766624451 ; Accuracy : 52.4 ; Test Loss : 0.7124017477035522 ; Test accuracy : 54.2\n",
      "Epochs : 368 ; Loss : 0.7255415320396423 ; Accuracy : 52.4 ; Test Loss : 0.712181568145752 ; Test accuracy : 54.3\n",
      "Epochs : 369 ; Loss : 0.725277304649353 ; Accuracy : 52.425 ; Test Loss : 0.7119618058204651 ; Test accuracy : 54.3\n",
      "Epochs : 370 ; Loss : 0.7250136137008667 ; Accuracy : 52.45 ; Test Loss : 0.7117424607276917 ; Test accuracy : 54.2\n",
      "Epochs : 371 ; Loss : 0.724750280380249 ; Accuracy : 52.475 ; Test Loss : 0.7115234732627869 ; Test accuracy : 54.2\n",
      "Epochs : 372 ; Loss : 0.7244875431060791 ; Accuracy : 52.5 ; Test Loss : 0.7113049626350403 ; Test accuracy : 54.4\n",
      "Epochs : 373 ; Loss : 0.7242252826690674 ; Accuracy : 52.6 ; Test Loss : 0.7110868096351624 ; Test accuracy : 54.4\n",
      "Epochs : 374 ; Loss : 0.7239634394645691 ; Accuracy : 52.625 ; Test Loss : 0.7108690738677979 ; Test accuracy : 54.4\n",
      "Epochs : 375 ; Loss : 0.723702073097229 ; Accuracy : 52.65 ; Test Loss : 0.7106516361236572 ; Test accuracy : 54.5\n",
      "Epochs : 376 ; Loss : 0.7234411239624023 ; Accuracy : 52.65 ; Test Loss : 0.7104347348213196 ; Test accuracy : 54.5\n",
      "Epochs : 377 ; Loss : 0.7231807112693787 ; Accuracy : 52.65 ; Test Loss : 0.7102181911468506 ; Test accuracy : 54.5\n",
      "Epochs : 378 ; Loss : 0.7229207754135132 ; Accuracy : 52.7 ; Test Loss : 0.7100020051002502 ; Test accuracy : 54.7\n",
      "Epochs : 379 ; Loss : 0.7226613163948059 ; Accuracy : 52.725 ; Test Loss : 0.7097862958908081 ; Test accuracy : 54.6\n",
      "Epochs : 380 ; Loss : 0.7224022746086121 ; Accuracy : 52.725 ; Test Loss : 0.7095708847045898 ; Test accuracy : 54.6\n",
      "Epochs : 381 ; Loss : 0.7221437096595764 ; Accuracy : 52.7 ; Test Loss : 0.7093559503555298 ; Test accuracy : 54.7\n",
      "Epochs : 382 ; Loss : 0.721885621547699 ; Accuracy : 52.7 ; Test Loss : 0.7091413736343384 ; Test accuracy : 54.7\n",
      "Epochs : 383 ; Loss : 0.721627950668335 ; Accuracy : 52.75 ; Test Loss : 0.7089272141456604 ; Test accuracy : 54.8\n",
      "Epochs : 384 ; Loss : 0.7213707566261292 ; Accuracy : 52.775 ; Test Loss : 0.7087134122848511 ; Test accuracy : 54.8\n",
      "Epochs : 385 ; Loss : 0.7211140394210815 ; Accuracy : 52.8 ; Test Loss : 0.7085000276565552 ; Test accuracy : 54.7\n",
      "Epochs : 386 ; Loss : 0.7208577990531921 ; Accuracy : 52.8 ; Test Loss : 0.7082870006561279 ; Test accuracy : 54.7\n",
      "Epochs : 387 ; Loss : 0.7206020951271057 ; Accuracy : 52.8 ; Test Loss : 0.7080743908882141 ; Test accuracy : 54.7\n",
      "Epochs : 388 ; Loss : 0.7203466892242432 ; Accuracy : 52.8 ; Test Loss : 0.7078621983528137 ; Test accuracy : 54.7\n",
      "Epochs : 389 ; Loss : 0.7200918197631836 ; Accuracy : 52.825 ; Test Loss : 0.7076503038406372 ; Test accuracy : 54.7\n",
      "Epochs : 390 ; Loss : 0.7198374271392822 ; Accuracy : 52.8 ; Test Loss : 0.7074388861656189 ; Test accuracy : 54.8\n",
      "Epochs : 391 ; Loss : 0.7195835113525391 ; Accuracy : 52.875 ; Test Loss : 0.7072278261184692 ; Test accuracy : 54.6\n",
      "Epochs : 392 ; Loss : 0.7193300127983093 ; Accuracy : 52.875 ; Test Loss : 0.7070171236991882 ; Test accuracy : 54.4\n",
      "Epochs : 393 ; Loss : 0.719076931476593 ; Accuracy : 52.975 ; Test Loss : 0.7068068981170654 ; Test accuracy : 54.5\n",
      "Epochs : 394 ; Loss : 0.7188243865966797 ; Accuracy : 53.0 ; Test Loss : 0.7065969705581665 ; Test accuracy : 54.8\n",
      "Epochs : 395 ; Loss : 0.7185723185539246 ; Accuracy : 52.95 ; Test Loss : 0.706387460231781 ; Test accuracy : 54.9\n",
      "Epochs : 396 ; Loss : 0.7183206081390381 ; Accuracy : 52.95 ; Test Loss : 0.7061783075332642 ; Test accuracy : 55.0\n",
      "Epochs : 397 ; Loss : 0.7180693745613098 ; Accuracy : 52.975 ; Test Loss : 0.705969512462616 ; Test accuracy : 55.0\n",
      "Epochs : 398 ; Loss : 0.7178186178207397 ; Accuracy : 53.0 ; Test Loss : 0.705761194229126 ; Test accuracy : 55.1\n",
      "Epochs : 399 ; Loss : 0.7175682783126831 ; Accuracy : 53.025 ; Test Loss : 0.7055531144142151 ; Test accuracy : 55.1\n",
      "Epochs : 400 ; Loss : 0.7173184156417847 ; Accuracy : 53.1 ; Test Loss : 0.7053455710411072 ; Test accuracy : 55.1\n",
      "Epochs : 401 ; Loss : 0.7170690298080444 ; Accuracy : 53.05 ; Test Loss : 0.7051383256912231 ; Test accuracy : 55.3\n",
      "Epochs : 402 ; Loss : 0.7168200612068176 ; Accuracy : 53.0 ; Test Loss : 0.7049314379692078 ; Test accuracy : 55.3\n",
      "Epochs : 403 ; Loss : 0.716571569442749 ; Accuracy : 53.05 ; Test Loss : 0.7047249674797058 ; Test accuracy : 55.3\n",
      "Epochs : 404 ; Loss : 0.7163234949111938 ; Accuracy : 53.025 ; Test Loss : 0.7045188546180725 ; Test accuracy : 55.3\n",
      "Epochs : 405 ; Loss : 0.7160758376121521 ; Accuracy : 53.025 ; Test Loss : 0.7043131589889526 ; Test accuracy : 55.3\n",
      "Epochs : 406 ; Loss : 0.7158286571502686 ; Accuracy : 53.05 ; Test Loss : 0.7041077017784119 ; Test accuracy : 55.3\n",
      "Epochs : 407 ; Loss : 0.7155819535255432 ; Accuracy : 53.1 ; Test Loss : 0.7039027214050293 ; Test accuracy : 55.3\n",
      "Epochs : 408 ; Loss : 0.7153356075286865 ; Accuracy : 53.125 ; Test Loss : 0.7036981582641602 ; Test accuracy : 55.3\n",
      "Epochs : 409 ; Loss : 0.715089738368988 ; Accuracy : 53.2 ; Test Loss : 0.7034939527511597 ; Test accuracy : 55.5\n",
      "Epochs : 410 ; Loss : 0.7148444056510925 ; Accuracy : 53.175 ; Test Loss : 0.7032900452613831 ; Test accuracy : 55.5\n",
      "Epochs : 411 ; Loss : 0.7145993709564209 ; Accuracy : 53.25 ; Test Loss : 0.7030865550041199 ; Test accuracy : 55.5\n",
      "Epochs : 412 ; Loss : 0.7143548130989075 ; Accuracy : 53.275 ; Test Loss : 0.7028834819793701 ; Test accuracy : 55.5\n",
      "Epochs : 413 ; Loss : 0.7141107320785522 ; Accuracy : 53.35 ; Test Loss : 0.7026805877685547 ; Test accuracy : 55.5\n",
      "Epochs : 414 ; Loss : 0.7138671278953552 ; Accuracy : 53.35 ; Test Loss : 0.7024782299995422 ; Test accuracy : 55.6\n",
      "Epochs : 415 ; Loss : 0.7136239409446716 ; Accuracy : 53.325 ; Test Loss : 0.7022761702537537 ; Test accuracy : 55.6\n",
      "Epochs : 416 ; Loss : 0.7133811116218567 ; Accuracy : 53.325 ; Test Loss : 0.7020744681358337 ; Test accuracy : 55.7\n",
      "Epochs : 417 ; Loss : 0.7131387591362 ; Accuracy : 53.325 ; Test Loss : 0.7018731832504272 ; Test accuracy : 55.7\n",
      "Epochs : 418 ; Loss : 0.7128968834877014 ; Accuracy : 53.325 ; Test Loss : 0.7016722559928894 ; Test accuracy : 55.7\n",
      "Epochs : 419 ; Loss : 0.7126554250717163 ; Accuracy : 53.4 ; Test Loss : 0.7014716863632202 ; Test accuracy : 55.6\n",
      "Epochs : 420 ; Loss : 0.7124143838882446 ; Accuracy : 53.425 ; Test Loss : 0.7012714743614197 ; Test accuracy : 55.6\n",
      "Epochs : 421 ; Loss : 0.7121737599372864 ; Accuracy : 53.45 ; Test Loss : 0.7010716199874878 ; Test accuracy : 55.6\n",
      "Epochs : 422 ; Loss : 0.7119335532188416 ; Accuracy : 53.475 ; Test Loss : 0.7008721232414246 ; Test accuracy : 55.7\n",
      "Epochs : 423 ; Loss : 0.7116938233375549 ; Accuracy : 53.55 ; Test Loss : 0.70067298412323 ; Test accuracy : 55.9\n",
      "Epochs : 424 ; Loss : 0.7114545106887817 ; Accuracy : 53.6 ; Test Loss : 0.700474202632904 ; Test accuracy : 55.9\n",
      "Epochs : 425 ; Loss : 0.711215615272522 ; Accuracy : 53.625 ; Test Loss : 0.7002757787704468 ; Test accuracy : 55.9\n",
      "Epochs : 426 ; Loss : 0.7109771370887756 ; Accuracy : 53.65 ; Test Loss : 0.7000776529312134 ; Test accuracy : 56.0\n",
      "Epochs : 427 ; Loss : 0.7107390761375427 ; Accuracy : 53.7 ; Test Loss : 0.6998800039291382 ; Test accuracy : 56.1\n",
      "Epochs : 428 ; Loss : 0.710501492023468 ; Accuracy : 53.675 ; Test Loss : 0.6996826529502869 ; Test accuracy : 56.0\n",
      "Epochs : 429 ; Loss : 0.7102643251419067 ; Accuracy : 53.675 ; Test Loss : 0.6994855999946594 ; Test accuracy : 56.1\n",
      "Epochs : 430 ; Loss : 0.7100275754928589 ; Accuracy : 53.7 ; Test Loss : 0.6992889642715454 ; Test accuracy : 56.1\n",
      "Epochs : 431 ; Loss : 0.7097911834716797 ; Accuracy : 53.7 ; Test Loss : 0.6990926861763 ; Test accuracy : 56.2\n",
      "Epochs : 432 ; Loss : 0.7095553278923035 ; Accuracy : 53.725 ; Test Loss : 0.6988967061042786 ; Test accuracy : 56.3\n",
      "Epochs : 433 ; Loss : 0.7093197703361511 ; Accuracy : 53.7 ; Test Loss : 0.6987011432647705 ; Test accuracy : 56.3\n",
      "Epochs : 434 ; Loss : 0.7090847492218018 ; Accuracy : 53.675 ; Test Loss : 0.6985058784484863 ; Test accuracy : 56.4\n",
      "Epochs : 435 ; Loss : 0.708850085735321 ; Accuracy : 53.725 ; Test Loss : 0.6983109712600708 ; Test accuracy : 56.5\n",
      "Epochs : 436 ; Loss : 0.7086158990859985 ; Accuracy : 53.775 ; Test Loss : 0.6981164813041687 ; Test accuracy : 56.6\n",
      "Epochs : 437 ; Loss : 0.7083820104598999 ; Accuracy : 53.825 ; Test Loss : 0.6979222297668457 ; Test accuracy : 56.5\n",
      "Epochs : 438 ; Loss : 0.7081485986709595 ; Accuracy : 53.825 ; Test Loss : 0.6977283954620361 ; Test accuracy : 56.4\n",
      "Epochs : 439 ; Loss : 0.7079156041145325 ; Accuracy : 53.825 ; Test Loss : 0.6975347995758057 ; Test accuracy : 56.6\n",
      "Epochs : 440 ; Loss : 0.7076830267906189 ; Accuracy : 53.85 ; Test Loss : 0.6973416209220886 ; Test accuracy : 56.5\n",
      "Epochs : 441 ; Loss : 0.7074509263038635 ; Accuracy : 53.775 ; Test Loss : 0.697148859500885 ; Test accuracy : 56.5\n",
      "Epochs : 442 ; Loss : 0.707219123840332 ; Accuracy : 53.8 ; Test Loss : 0.6969563961029053 ; Test accuracy : 56.5\n",
      "Epochs : 443 ; Loss : 0.7069877982139587 ; Accuracy : 53.8 ; Test Loss : 0.6967641711235046 ; Test accuracy : 56.5\n",
      "Epochs : 444 ; Loss : 0.7067568898200989 ; Accuracy : 53.85 ; Test Loss : 0.696572482585907 ; Test accuracy : 56.5\n",
      "Epochs : 445 ; Loss : 0.7065263986587524 ; Accuracy : 53.875 ; Test Loss : 0.6963810324668884 ; Test accuracy : 56.5\n",
      "Epochs : 446 ; Loss : 0.7062963247299194 ; Accuracy : 53.9 ; Test Loss : 0.6961898803710938 ; Test accuracy : 56.5\n",
      "Epochs : 447 ; Loss : 0.7060665488243103 ; Accuracy : 53.975 ; Test Loss : 0.6959990859031677 ; Test accuracy : 56.5\n",
      "Epochs : 448 ; Loss : 0.7058373093605042 ; Accuracy : 54.05 ; Test Loss : 0.6958087086677551 ; Test accuracy : 56.5\n",
      "Epochs : 449 ; Loss : 0.7056084275245667 ; Accuracy : 54.05 ; Test Loss : 0.6956185698509216 ; Test accuracy : 56.5\n",
      "Epochs : 450 ; Loss : 0.7053799033164978 ; Accuracy : 54.075 ; Test Loss : 0.695428729057312 ; Test accuracy : 56.6\n",
      "Epochs : 451 ; Loss : 0.7051519751548767 ; Accuracy : 54.125 ; Test Loss : 0.6952393651008606 ; Test accuracy : 56.6\n",
      "Epochs : 452 ; Loss : 0.7049242258071899 ; Accuracy : 54.15 ; Test Loss : 0.6950502395629883 ; Test accuracy : 56.6\n",
      "Epochs : 453 ; Loss : 0.7046969532966614 ; Accuracy : 54.225 ; Test Loss : 0.6948615312576294 ; Test accuracy : 56.6\n",
      "Epochs : 454 ; Loss : 0.7044700980186462 ; Accuracy : 54.25 ; Test Loss : 0.6946730017662048 ; Test accuracy : 56.6\n",
      "Epochs : 455 ; Loss : 0.7042436599731445 ; Accuracy : 54.25 ; Test Loss : 0.6944850087165833 ; Test accuracy : 56.6\n",
      "Epochs : 456 ; Loss : 0.7040176391601562 ; Accuracy : 54.25 ; Test Loss : 0.694297194480896 ; Test accuracy : 56.7\n",
      "Epochs : 457 ; Loss : 0.7037919759750366 ; Accuracy : 54.275 ; Test Loss : 0.6941097974777222 ; Test accuracy : 56.8\n",
      "Epochs : 458 ; Loss : 0.7035666704177856 ; Accuracy : 54.275 ; Test Loss : 0.6939226984977722 ; Test accuracy : 56.9\n",
      "Epochs : 459 ; Loss : 0.7033418416976929 ; Accuracy : 54.275 ; Test Loss : 0.6937359571456909 ; Test accuracy : 57.0\n",
      "Epochs : 460 ; Loss : 0.7031174302101135 ; Accuracy : 54.25 ; Test Loss : 0.6935494542121887 ; Test accuracy : 57.0\n",
      "Epochs : 461 ; Loss : 0.7028933167457581 ; Accuracy : 54.25 ; Test Loss : 0.6933633089065552 ; Test accuracy : 57.1\n",
      "Epochs : 462 ; Loss : 0.7026695609092712 ; Accuracy : 54.275 ; Test Loss : 0.6931775212287903 ; Test accuracy : 57.0\n",
      "Epochs : 463 ; Loss : 0.7024463415145874 ; Accuracy : 54.225 ; Test Loss : 0.692992091178894 ; Test accuracy : 57.0\n",
      "Epochs : 464 ; Loss : 0.702223539352417 ; Accuracy : 54.275 ; Test Loss : 0.6928068995475769 ; Test accuracy : 57.0\n",
      "Epochs : 465 ; Loss : 0.7020010352134705 ; Accuracy : 54.3 ; Test Loss : 0.6926221251487732 ; Test accuracy : 57.0\n",
      "Epochs : 466 ; Loss : 0.7017789483070374 ; Accuracy : 54.35 ; Test Loss : 0.6924375891685486 ; Test accuracy : 57.2\n",
      "Epochs : 467 ; Loss : 0.7015572786331177 ; Accuracy : 54.35 ; Test Loss : 0.6922534704208374 ; Test accuracy : 57.2\n",
      "Epochs : 468 ; Loss : 0.7013359069824219 ; Accuracy : 54.375 ; Test Loss : 0.6920695900917053 ; Test accuracy : 57.1\n",
      "Epochs : 469 ; Loss : 0.7011150121688843 ; Accuracy : 54.475 ; Test Loss : 0.6918860673904419 ; Test accuracy : 57.1\n",
      "Epochs : 470 ; Loss : 0.7008944749832153 ; Accuracy : 54.5 ; Test Loss : 0.6917028427124023 ; Test accuracy : 57.1\n",
      "Epochs : 471 ; Loss : 0.700674295425415 ; Accuracy : 54.55 ; Test Loss : 0.6915199756622314 ; Test accuracy : 57.2\n",
      "Epochs : 472 ; Loss : 0.7004545331001282 ; Accuracy : 54.625 ; Test Loss : 0.6913374066352844 ; Test accuracy : 57.3\n",
      "Epochs : 473 ; Loss : 0.70023512840271 ; Accuracy : 54.7 ; Test Loss : 0.691155195236206 ; Test accuracy : 57.4\n",
      "Epochs : 474 ; Loss : 0.7000161409378052 ; Accuracy : 54.775 ; Test Loss : 0.6909732222557068 ; Test accuracy : 57.4\n",
      "Epochs : 475 ; Loss : 0.6997975707054138 ; Accuracy : 54.825 ; Test Loss : 0.6907916069030762 ; Test accuracy : 57.4\n",
      "Epochs : 476 ; Loss : 0.6995793581008911 ; Accuracy : 54.9 ; Test Loss : 0.6906102895736694 ; Test accuracy : 57.4\n",
      "Epochs : 477 ; Loss : 0.6993615627288818 ; Accuracy : 54.9 ; Test Loss : 0.6904293298721313 ; Test accuracy : 57.5\n",
      "Epochs : 478 ; Loss : 0.6991440653800964 ; Accuracy : 54.925 ; Test Loss : 0.6902486681938171 ; Test accuracy : 57.5\n",
      "Epochs : 479 ; Loss : 0.6989269852638245 ; Accuracy : 54.975 ; Test Loss : 0.690068244934082 ; Test accuracy : 57.5\n",
      "Epochs : 480 ; Loss : 0.6987102627754211 ; Accuracy : 55.0 ; Test Loss : 0.6898882389068604 ; Test accuracy : 57.5\n",
      "Epochs : 481 ; Loss : 0.698494017124176 ; Accuracy : 55.0 ; Test Loss : 0.6897085309028625 ; Test accuracy : 57.5\n",
      "Epochs : 482 ; Loss : 0.69827800989151 ; Accuracy : 55.05 ; Test Loss : 0.6895290613174438 ; Test accuracy : 57.6\n",
      "Epochs : 483 ; Loss : 0.6980624198913574 ; Accuracy : 55.0 ; Test Loss : 0.6893500089645386 ; Test accuracy : 57.5\n",
      "Epochs : 484 ; Loss : 0.6978472471237183 ; Accuracy : 55.05 ; Test Loss : 0.6891711950302124 ; Test accuracy : 57.6\n",
      "Epochs : 485 ; Loss : 0.6976324915885925 ; Accuracy : 55.125 ; Test Loss : 0.6889926791191101 ; Test accuracy : 57.4\n",
      "Epochs : 486 ; Loss : 0.6974179744720459 ; Accuracy : 55.225 ; Test Loss : 0.6888144612312317 ; Test accuracy : 57.4\n",
      "Epochs : 487 ; Loss : 0.6972039341926575 ; Accuracy : 55.225 ; Test Loss : 0.6886366009712219 ; Test accuracy : 57.4\n",
      "Epochs : 488 ; Loss : 0.6969902515411377 ; Accuracy : 55.2 ; Test Loss : 0.6884590983390808 ; Test accuracy : 57.4\n",
      "Epochs : 489 ; Loss : 0.6967768669128418 ; Accuracy : 55.2 ; Test Loss : 0.688281774520874 ; Test accuracy : 57.3\n",
      "Epochs : 490 ; Loss : 0.6965640187263489 ; Accuracy : 55.225 ; Test Loss : 0.6881048083305359 ; Test accuracy : 57.2\n",
      "Epochs : 491 ; Loss : 0.6963514089584351 ; Accuracy : 55.3 ; Test Loss : 0.6879281997680664 ; Test accuracy : 57.2\n",
      "Epochs : 492 ; Loss : 0.6961392164230347 ; Accuracy : 55.325 ; Test Loss : 0.6877518892288208 ; Test accuracy : 57.2\n",
      "Epochs : 493 ; Loss : 0.6959273815155029 ; Accuracy : 55.425 ; Test Loss : 0.6875758171081543 ; Test accuracy : 57.3\n",
      "Epochs : 494 ; Loss : 0.6957158446311951 ; Accuracy : 55.475 ; Test Loss : 0.6874000430107117 ; Test accuracy : 57.3\n",
      "Epochs : 495 ; Loss : 0.6955047845840454 ; Accuracy : 55.525 ; Test Loss : 0.6872245669364929 ; Test accuracy : 57.3\n",
      "Epochs : 496 ; Loss : 0.6952940821647644 ; Accuracy : 55.525 ; Test Loss : 0.6870494484901428 ; Test accuracy : 57.2\n",
      "Epochs : 497 ; Loss : 0.6950836777687073 ; Accuracy : 55.5 ; Test Loss : 0.6868746280670166 ; Test accuracy : 57.3\n",
      "Epochs : 498 ; Loss : 0.6948736310005188 ; Accuracy : 55.5 ; Test Loss : 0.6867001056671143 ; Test accuracy : 57.3\n",
      "Epochs : 499 ; Loss : 0.6946640610694885 ; Accuracy : 55.475 ; Test Loss : 0.686525821685791 ; Test accuracy : 57.3\n",
      "Epochs : 500 ; Loss : 0.6944547295570374 ; Accuracy : 55.475 ; Test Loss : 0.6863519549369812 ; Test accuracy : 57.2\n",
      "Epochs : 501 ; Loss : 0.6942458152770996 ; Accuracy : 55.5 ; Test Loss : 0.6861782670021057 ; Test accuracy : 57.3\n",
      "Epochs : 502 ; Loss : 0.6940372586250305 ; Accuracy : 55.5 ; Test Loss : 0.6860049366950989 ; Test accuracy : 57.3\n",
      "Epochs : 503 ; Loss : 0.6938289999961853 ; Accuracy : 55.5 ; Test Loss : 0.6858319044113159 ; Test accuracy : 57.3\n",
      "Epochs : 504 ; Loss : 0.6936212778091431 ; Accuracy : 55.55 ; Test Loss : 0.6856591105461121 ; Test accuracy : 57.3\n",
      "Epochs : 505 ; Loss : 0.6934137344360352 ; Accuracy : 55.525 ; Test Loss : 0.6854866743087769 ; Test accuracy : 57.2\n",
      "Epochs : 506 ; Loss : 0.6932066082954407 ; Accuracy : 55.55 ; Test Loss : 0.6853144764900208 ; Test accuracy : 57.3\n",
      "Epochs : 507 ; Loss : 0.6929998397827148 ; Accuracy : 55.575 ; Test Loss : 0.6851426362991333 ; Test accuracy : 57.4\n",
      "Epochs : 508 ; Loss : 0.6927934288978577 ; Accuracy : 55.575 ; Test Loss : 0.684971034526825 ; Test accuracy : 57.4\n",
      "Epochs : 509 ; Loss : 0.6925873756408691 ; Accuracy : 55.6 ; Test Loss : 0.6847997307777405 ; Test accuracy : 57.5\n",
      "Epochs : 510 ; Loss : 0.692381739616394 ; Accuracy : 55.575 ; Test Loss : 0.6846288442611694 ; Test accuracy : 57.6\n",
      "Epochs : 511 ; Loss : 0.692176342010498 ; Accuracy : 55.6 ; Test Loss : 0.6844580173492432 ; Test accuracy : 57.6\n",
      "Epochs : 512 ; Loss : 0.6919713616371155 ; Accuracy : 55.675 ; Test Loss : 0.6842876076698303 ; Test accuracy : 57.7\n",
      "Epochs : 513 ; Loss : 0.6917667388916016 ; Accuracy : 55.675 ; Test Loss : 0.6841174960136414 ; Test accuracy : 57.8\n",
      "Epochs : 514 ; Loss : 0.6915624141693115 ; Accuracy : 55.7 ; Test Loss : 0.6839476823806763 ; Test accuracy : 57.8\n",
      "Epochs : 515 ; Loss : 0.6913585066795349 ; Accuracy : 55.8 ; Test Loss : 0.6837781071662903 ; Test accuracy : 57.7\n",
      "Epochs : 516 ; Loss : 0.691154956817627 ; Accuracy : 55.8 ; Test Loss : 0.6836088299751282 ; Test accuracy : 57.6\n",
      "Epochs : 517 ; Loss : 0.6909517049789429 ; Accuracy : 55.85 ; Test Loss : 0.6834399104118347 ; Test accuracy : 57.6\n",
      "Epochs : 518 ; Loss : 0.6907488107681274 ; Accuracy : 55.925 ; Test Loss : 0.6832712292671204 ; Test accuracy : 57.6\n",
      "Epochs : 519 ; Loss : 0.6905462741851807 ; Accuracy : 55.9 ; Test Loss : 0.6831027865409851 ; Test accuracy : 57.7\n",
      "Epochs : 520 ; Loss : 0.6903440952301025 ; Accuracy : 56.0 ; Test Loss : 0.6829346418380737 ; Test accuracy : 57.7\n",
      "Epochs : 521 ; Loss : 0.6901422739028931 ; Accuracy : 55.95 ; Test Loss : 0.682766854763031 ; Test accuracy : 57.7\n",
      "Epochs : 522 ; Loss : 0.6899406909942627 ; Accuracy : 55.925 ; Test Loss : 0.6825992465019226 ; Test accuracy : 57.9\n",
      "Epochs : 523 ; Loss : 0.6897395253181458 ; Accuracy : 55.925 ; Test Loss : 0.6824320554733276 ; Test accuracy : 58.0\n",
      "Epochs : 524 ; Loss : 0.6895387172698975 ; Accuracy : 55.975 ; Test Loss : 0.682265043258667 ; Test accuracy : 58.0\n",
      "Epochs : 525 ; Loss : 0.6893382668495178 ; Accuracy : 56.1 ; Test Loss : 0.682098388671875 ; Test accuracy : 58.0\n",
      "Epochs : 526 ; Loss : 0.6891381740570068 ; Accuracy : 56.1 ; Test Loss : 0.6819319128990173 ; Test accuracy : 58.0\n",
      "Epochs : 527 ; Loss : 0.6889383792877197 ; Accuracy : 56.175 ; Test Loss : 0.6817657947540283 ; Test accuracy : 58.0\n",
      "Epochs : 528 ; Loss : 0.6887389421463013 ; Accuracy : 56.225 ; Test Loss : 0.6815999746322632 ; Test accuracy : 58.0\n",
      "Epochs : 529 ; Loss : 0.6885398030281067 ; Accuracy : 56.225 ; Test Loss : 0.6814343333244324 ; Test accuracy : 58.1\n",
      "Epochs : 530 ; Loss : 0.6883410215377808 ; Accuracy : 56.25 ; Test Loss : 0.6812690496444702 ; Test accuracy : 58.1\n",
      "Epochs : 531 ; Loss : 0.6881425976753235 ; Accuracy : 56.25 ; Test Loss : 0.6811040639877319 ; Test accuracy : 58.1\n",
      "Epochs : 532 ; Loss : 0.6879444718360901 ; Accuracy : 56.25 ; Test Loss : 0.6809393167495728 ; Test accuracy : 58.2\n",
      "Epochs : 533 ; Loss : 0.6877467632293701 ; Accuracy : 56.275 ; Test Loss : 0.6807748675346375 ; Test accuracy : 58.2\n",
      "Epochs : 534 ; Loss : 0.687549352645874 ; Accuracy : 56.275 ; Test Loss : 0.680610716342926 ; Test accuracy : 58.3\n",
      "Epochs : 535 ; Loss : 0.687352180480957 ; Accuracy : 56.25 ; Test Loss : 0.6804467439651489 ; Test accuracy : 58.2\n",
      "Epochs : 536 ; Loss : 0.6871554851531982 ; Accuracy : 56.275 ; Test Loss : 0.6802831292152405 ; Test accuracy : 58.2\n",
      "Epochs : 537 ; Loss : 0.6869590878486633 ; Accuracy : 56.275 ; Test Loss : 0.6801196932792664 ; Test accuracy : 58.2\n",
      "Epochs : 538 ; Loss : 0.6867629885673523 ; Accuracy : 56.275 ; Test Loss : 0.6799566149711609 ; Test accuracy : 58.1\n",
      "Epochs : 539 ; Loss : 0.6865672469139099 ; Accuracy : 56.3 ; Test Loss : 0.6797937750816345 ; Test accuracy : 58.1\n",
      "Epochs : 540 ; Loss : 0.6863718032836914 ; Accuracy : 56.325 ; Test Loss : 0.679631233215332 ; Test accuracy : 58.1\n",
      "Epochs : 541 ; Loss : 0.6861767172813416 ; Accuracy : 56.35 ; Test Loss : 0.6794689893722534 ; Test accuracy : 58.2\n",
      "Epochs : 542 ; Loss : 0.6859819889068604 ; Accuracy : 56.375 ; Test Loss : 0.6793070435523987 ; Test accuracy : 58.2\n",
      "Epochs : 543 ; Loss : 0.6857874989509583 ; Accuracy : 56.4 ; Test Loss : 0.6791452169418335 ; Test accuracy : 58.4\n",
      "Epochs : 544 ; Loss : 0.6855934262275696 ; Accuracy : 56.475 ; Test Loss : 0.6789838075637817 ; Test accuracy : 58.5\n",
      "Epochs : 545 ; Loss : 0.6853997111320496 ; Accuracy : 56.575 ; Test Loss : 0.6788226366043091 ; Test accuracy : 58.5\n",
      "Epochs : 546 ; Loss : 0.6852062344551086 ; Accuracy : 56.6 ; Test Loss : 0.6786617040634155 ; Test accuracy : 58.4\n",
      "Epochs : 547 ; Loss : 0.6850131154060364 ; Accuracy : 56.625 ; Test Loss : 0.6785010099411011 ; Test accuracy : 58.3\n",
      "Epochs : 548 ; Loss : 0.6848203539848328 ; Accuracy : 56.675 ; Test Loss : 0.6783406734466553 ; Test accuracy : 58.3\n",
      "Epochs : 549 ; Loss : 0.6846278309822083 ; Accuracy : 56.675 ; Test Loss : 0.6781805753707886 ; Test accuracy : 58.3\n",
      "Epochs : 550 ; Loss : 0.6844356656074524 ; Accuracy : 56.7 ; Test Loss : 0.678020715713501 ; Test accuracy : 58.2\n",
      "Epochs : 551 ; Loss : 0.68424391746521 ; Accuracy : 56.65 ; Test Loss : 0.6778610944747925 ; Test accuracy : 58.1\n",
      "Epochs : 552 ; Loss : 0.6840524077415466 ; Accuracy : 56.725 ; Test Loss : 0.6777018308639526 ; Test accuracy : 58.1\n",
      "Epochs : 553 ; Loss : 0.683861255645752 ; Accuracy : 56.725 ; Test Loss : 0.6775427460670471 ; Test accuracy : 58.0\n",
      "Epochs : 554 ; Loss : 0.6836703419685364 ; Accuracy : 56.725 ; Test Loss : 0.6773839592933655 ; Test accuracy : 58.1\n",
      "Epochs : 555 ; Loss : 0.6834797859191895 ; Accuracy : 56.75 ; Test Loss : 0.6772254109382629 ; Test accuracy : 58.2\n",
      "Epochs : 556 ; Loss : 0.6832895874977112 ; Accuracy : 56.725 ; Test Loss : 0.6770671606063843 ; Test accuracy : 58.3\n",
      "Epochs : 557 ; Loss : 0.6830996870994568 ; Accuracy : 56.75 ; Test Loss : 0.6769092082977295 ; Test accuracy : 58.4\n",
      "Epochs : 558 ; Loss : 0.6829100847244263 ; Accuracy : 56.775 ; Test Loss : 0.676751434803009 ; Test accuracy : 58.6\n",
      "Epochs : 559 ; Loss : 0.6827208399772644 ; Accuracy : 56.8 ; Test Loss : 0.6765939593315125 ; Test accuracy : 58.7\n",
      "Epochs : 560 ; Loss : 0.6825318932533264 ; Accuracy : 56.825 ; Test Loss : 0.676436722278595 ; Test accuracy : 58.9\n",
      "Epochs : 561 ; Loss : 0.6823433041572571 ; Accuracy : 56.825 ; Test Loss : 0.6762798428535461 ; Test accuracy : 58.9\n",
      "Epochs : 562 ; Loss : 0.6821549534797668 ; Accuracy : 56.85 ; Test Loss : 0.6761230826377869 ; Test accuracy : 59.0\n",
      "Epochs : 563 ; Loss : 0.6819669604301453 ; Accuracy : 56.85 ; Test Loss : 0.6759666800498962 ; Test accuracy : 59.0\n",
      "Epochs : 564 ; Loss : 0.6817793250083923 ; Accuracy : 56.95 ; Test Loss : 0.6758105754852295 ; Test accuracy : 59.0\n",
      "Epochs : 565 ; Loss : 0.6815918684005737 ; Accuracy : 56.975 ; Test Loss : 0.6756545901298523 ; Test accuracy : 59.0\n",
      "Epochs : 566 ; Loss : 0.6814048290252686 ; Accuracy : 56.975 ; Test Loss : 0.6754989624023438 ; Test accuracy : 59.0\n",
      "Epochs : 567 ; Loss : 0.6812180280685425 ; Accuracy : 57.025 ; Test Loss : 0.6753435134887695 ; Test accuracy : 59.0\n",
      "Epochs : 568 ; Loss : 0.6810316443443298 ; Accuracy : 57.075 ; Test Loss : 0.6751883625984192 ; Test accuracy : 58.9\n",
      "Epochs : 569 ; Loss : 0.6808454990386963 ; Accuracy : 57.1 ; Test Loss : 0.6750335693359375 ; Test accuracy : 59.0\n",
      "Epochs : 570 ; Loss : 0.6806597113609314 ; Accuracy : 57.1 ; Test Loss : 0.6748789548873901 ; Test accuracy : 59.1\n",
      "Epochs : 571 ; Loss : 0.6804742217063904 ; Accuracy : 57.125 ; Test Loss : 0.6747245192527771 ; Test accuracy : 59.1\n",
      "Epochs : 572 ; Loss : 0.6802890300750732 ; Accuracy : 57.15 ; Test Loss : 0.6745703816413879 ; Test accuracy : 59.1\n",
      "Epochs : 573 ; Loss : 0.68010413646698 ; Accuracy : 57.2 ; Test Loss : 0.6744166016578674 ; Test accuracy : 59.0\n",
      "Epochs : 574 ; Loss : 0.6799196004867554 ; Accuracy : 57.2 ; Test Loss : 0.6742628812789917 ; Test accuracy : 59.0\n",
      "Epochs : 575 ; Loss : 0.6797352433204651 ; Accuracy : 57.225 ; Test Loss : 0.6741095781326294 ; Test accuracy : 58.9\n",
      "Epochs : 576 ; Loss : 0.6795513033866882 ; Accuracy : 57.275 ; Test Loss : 0.6739565134048462 ; Test accuracy : 58.9\n",
      "Epochs : 577 ; Loss : 0.6793676614761353 ; Accuracy : 57.325 ; Test Loss : 0.6738036274909973 ; Test accuracy : 58.8\n",
      "Epochs : 578 ; Loss : 0.6791843771934509 ; Accuracy : 57.325 ; Test Loss : 0.6736510396003723 ; Test accuracy : 58.9\n",
      "Epochs : 579 ; Loss : 0.6790012717247009 ; Accuracy : 57.4 ; Test Loss : 0.6734986901283264 ; Test accuracy : 59.0\n",
      "Epochs : 580 ; Loss : 0.6788185238838196 ; Accuracy : 57.45 ; Test Loss : 0.6733465790748596 ; Test accuracy : 58.7\n",
      "Epochs : 581 ; Loss : 0.6786360144615173 ; Accuracy : 57.475 ; Test Loss : 0.6731947064399719 ; Test accuracy : 58.7\n",
      "Epochs : 582 ; Loss : 0.6784538626670837 ; Accuracy : 57.55 ; Test Loss : 0.6730431914329529 ; Test accuracy : 58.8\n",
      "Epochs : 583 ; Loss : 0.6782721281051636 ; Accuracy : 57.55 ; Test Loss : 0.6728918552398682 ; Test accuracy : 58.8\n",
      "Epochs : 584 ; Loss : 0.6780905723571777 ; Accuracy : 57.6 ; Test Loss : 0.6727407574653625 ; Test accuracy : 58.8\n",
      "Epochs : 585 ; Loss : 0.677909255027771 ; Accuracy : 57.575 ; Test Loss : 0.672589898109436 ; Test accuracy : 58.8\n",
      "Epochs : 586 ; Loss : 0.6777283549308777 ; Accuracy : 57.575 ; Test Loss : 0.6724392771720886 ; Test accuracy : 58.7\n",
      "Epochs : 587 ; Loss : 0.6775476932525635 ; Accuracy : 57.625 ; Test Loss : 0.6722889542579651 ; Test accuracy : 58.6\n",
      "Epochs : 588 ; Loss : 0.6773673295974731 ; Accuracy : 57.65 ; Test Loss : 0.6721388101577759 ; Test accuracy : 58.5\n",
      "Epochs : 589 ; Loss : 0.6771872639656067 ; Accuracy : 57.675 ; Test Loss : 0.6719889640808105 ; Test accuracy : 58.5\n",
      "Epochs : 590 ; Loss : 0.6770076155662537 ; Accuracy : 57.725 ; Test Loss : 0.6718394160270691 ; Test accuracy : 58.5\n",
      "Epochs : 591 ; Loss : 0.676828145980835 ; Accuracy : 57.725 ; Test Loss : 0.6716901063919067 ; Test accuracy : 58.6\n",
      "Epochs : 592 ; Loss : 0.6766489744186401 ; Accuracy : 57.8 ; Test Loss : 0.6715409159660339 ; Test accuracy : 58.6\n",
      "Epochs : 593 ; Loss : 0.6764701008796692 ; Accuracy : 57.775 ; Test Loss : 0.6713920831680298 ; Test accuracy : 58.6\n",
      "Epochs : 594 ; Loss : 0.6762914657592773 ; Accuracy : 57.85 ; Test Loss : 0.67124342918396 ; Test accuracy : 58.6\n",
      "Epochs : 595 ; Loss : 0.6761132478713989 ; Accuracy : 57.925 ; Test Loss : 0.6710950136184692 ; Test accuracy : 58.6\n",
      "Epochs : 596 ; Loss : 0.6759352684020996 ; Accuracy : 57.95 ; Test Loss : 0.6709468364715576 ; Test accuracy : 58.7\n",
      "Epochs : 597 ; Loss : 0.6757575273513794 ; Accuracy : 57.95 ; Test Loss : 0.6707989573478699 ; Test accuracy : 58.7\n",
      "Epochs : 598 ; Loss : 0.6755801439285278 ; Accuracy : 57.95 ; Test Loss : 0.6706512570381165 ; Test accuracy : 58.6\n",
      "Epochs : 599 ; Loss : 0.6754031181335449 ; Accuracy : 58.0 ; Test Loss : 0.6705038547515869 ; Test accuracy : 58.6\n",
      "Epochs : 600 ; Loss : 0.6752262115478516 ; Accuracy : 58.1 ; Test Loss : 0.6703567504882812 ; Test accuracy : 58.7\n",
      "Epochs : 601 ; Loss : 0.6750497221946716 ; Accuracy : 58.125 ; Test Loss : 0.6702098250389099 ; Test accuracy : 58.7\n",
      "Epochs : 602 ; Loss : 0.6748734712600708 ; Accuracy : 58.125 ; Test Loss : 0.6700631380081177 ; Test accuracy : 58.7\n",
      "Epochs : 603 ; Loss : 0.6746975183486938 ; Accuracy : 58.1 ; Test Loss : 0.6699166297912598 ; Test accuracy : 58.7\n",
      "Epochs : 604 ; Loss : 0.6745218634605408 ; Accuracy : 58.1 ; Test Loss : 0.6697704195976257 ; Test accuracy : 58.7\n",
      "Epochs : 605 ; Loss : 0.6743464469909668 ; Accuracy : 58.1 ; Test Loss : 0.6696245074272156 ; Test accuracy : 58.6\n",
      "Epochs : 606 ; Loss : 0.6741714477539062 ; Accuracy : 58.1 ; Test Loss : 0.669478714466095 ; Test accuracy : 58.7\n",
      "Epochs : 607 ; Loss : 0.67399662733078 ; Accuracy : 58.125 ; Test Loss : 0.6693332195281982 ; Test accuracy : 58.8\n",
      "Epochs : 608 ; Loss : 0.6738220453262329 ; Accuracy : 58.125 ; Test Loss : 0.6691879630088806 ; Test accuracy : 58.8\n",
      "Epochs : 609 ; Loss : 0.6736478805541992 ; Accuracy : 58.2 ; Test Loss : 0.6690430045127869 ; Test accuracy : 58.8\n",
      "Epochs : 610 ; Loss : 0.6734738945960999 ; Accuracy : 58.2 ; Test Loss : 0.6688982248306274 ; Test accuracy : 58.9\n",
      "Epochs : 611 ; Loss : 0.6733002066612244 ; Accuracy : 58.275 ; Test Loss : 0.6687535643577576 ; Test accuracy : 58.8\n",
      "Epochs : 612 ; Loss : 0.6731268763542175 ; Accuracy : 58.325 ; Test Loss : 0.6686092615127563 ; Test accuracy : 58.8\n",
      "Epochs : 613 ; Loss : 0.6729537844657898 ; Accuracy : 58.35 ; Test Loss : 0.668465256690979 ; Test accuracy : 58.8\n",
      "Epochs : 614 ; Loss : 0.6727809309959412 ; Accuracy : 58.35 ; Test Loss : 0.6683213710784912 ; Test accuracy : 58.8\n",
      "Epochs : 615 ; Loss : 0.6726084351539612 ; Accuracy : 58.375 ; Test Loss : 0.6681777834892273 ; Test accuracy : 58.8\n",
      "Epochs : 616 ; Loss : 0.6724361777305603 ; Accuracy : 58.475 ; Test Loss : 0.6680343747138977 ; Test accuracy : 58.8\n",
      "Epochs : 617 ; Loss : 0.6722642183303833 ; Accuracy : 58.475 ; Test Loss : 0.667891263961792 ; Test accuracy : 58.9\n",
      "Epochs : 618 ; Loss : 0.6720925569534302 ; Accuracy : 58.475 ; Test Loss : 0.6677483916282654 ; Test accuracy : 59.0\n",
      "Epochs : 619 ; Loss : 0.6719211339950562 ; Accuracy : 58.475 ; Test Loss : 0.6676057577133179 ; Test accuracy : 58.9\n",
      "Epochs : 620 ; Loss : 0.6717499494552612 ; Accuracy : 58.5 ; Test Loss : 0.6674632430076599 ; Test accuracy : 58.9\n",
      "Epochs : 621 ; Loss : 0.671579122543335 ; Accuracy : 58.55 ; Test Loss : 0.6673210859298706 ; Test accuracy : 59.1\n",
      "Epochs : 622 ; Loss : 0.6714085340499878 ; Accuracy : 58.6 ; Test Loss : 0.6671791076660156 ; Test accuracy : 59.1\n",
      "Epochs : 623 ; Loss : 0.6712382435798645 ; Accuracy : 58.625 ; Test Loss : 0.667037308216095 ; Test accuracy : 59.1\n",
      "Epochs : 624 ; Loss : 0.6710681915283203 ; Accuracy : 58.65 ; Test Loss : 0.666895866394043 ; Test accuracy : 59.0\n",
      "Epochs : 625 ; Loss : 0.6708984971046448 ; Accuracy : 58.775 ; Test Loss : 0.6667545437812805 ; Test accuracy : 59.0\n",
      "Epochs : 626 ; Loss : 0.6707290410995483 ; Accuracy : 58.775 ; Test Loss : 0.6666135191917419 ; Test accuracy : 59.0\n",
      "Epochs : 627 ; Loss : 0.6705597639083862 ; Accuracy : 58.9 ; Test Loss : 0.6664726734161377 ; Test accuracy : 59.1\n",
      "Epochs : 628 ; Loss : 0.6703909039497375 ; Accuracy : 58.95 ; Test Loss : 0.6663321256637573 ; Test accuracy : 59.1\n",
      "Epochs : 629 ; Loss : 0.6702222228050232 ; Accuracy : 58.925 ; Test Loss : 0.6661916971206665 ; Test accuracy : 59.2\n",
      "Epochs : 630 ; Loss : 0.6700537800788879 ; Accuracy : 58.925 ; Test Loss : 0.6660515666007996 ; Test accuracy : 59.2\n",
      "Epochs : 631 ; Loss : 0.6698857545852661 ; Accuracy : 58.925 ; Test Loss : 0.6659116744995117 ; Test accuracy : 59.2\n",
      "Epochs : 632 ; Loss : 0.6697179079055786 ; Accuracy : 58.975 ; Test Loss : 0.665772020816803 ; Test accuracy : 59.2\n",
      "Epochs : 633 ; Loss : 0.6695502996444702 ; Accuracy : 59.1 ; Test Loss : 0.6656325459480286 ; Test accuracy : 59.2\n",
      "Epochs : 634 ; Loss : 0.6693831086158752 ; Accuracy : 59.125 ; Test Loss : 0.6654933094978333 ; Test accuracy : 59.4\n",
      "Epochs : 635 ; Loss : 0.669215977191925 ; Accuracy : 59.125 ; Test Loss : 0.6653542518615723 ; Test accuracy : 59.5\n",
      "Epochs : 636 ; Loss : 0.6690492033958435 ; Accuracy : 59.125 ; Test Loss : 0.6652155518531799 ; Test accuracy : 59.5\n",
      "Epochs : 637 ; Loss : 0.6688827276229858 ; Accuracy : 59.125 ; Test Loss : 0.6650769710540771 ; Test accuracy : 59.4\n",
      "Epochs : 638 ; Loss : 0.668716549873352 ; Accuracy : 59.15 ; Test Loss : 0.6649386882781982 ; Test accuracy : 59.4\n",
      "Epochs : 639 ; Loss : 0.6685505509376526 ; Accuracy : 59.175 ; Test Loss : 0.6648005843162537 ; Test accuracy : 59.5\n",
      "Epochs : 640 ; Loss : 0.6683849096298218 ; Accuracy : 59.2 ; Test Loss : 0.664662778377533 ; Test accuracy : 59.4\n",
      "Epochs : 641 ; Loss : 0.6682195067405701 ; Accuracy : 59.25 ; Test Loss : 0.664525032043457 ; Test accuracy : 59.4\n",
      "Epochs : 642 ; Loss : 0.6680543422698975 ; Accuracy : 59.275 ; Test Loss : 0.6643876433372498 ; Test accuracy : 59.4\n",
      "Epochs : 643 ; Loss : 0.667889416217804 ; Accuracy : 59.3 ; Test Loss : 0.664250373840332 ; Test accuracy : 59.3\n",
      "Epochs : 644 ; Loss : 0.6677248477935791 ; Accuracy : 59.45 ; Test Loss : 0.664113461971283 ; Test accuracy : 59.3\n",
      "Epochs : 645 ; Loss : 0.6675604581832886 ; Accuracy : 59.525 ; Test Loss : 0.6639767289161682 ; Test accuracy : 59.3\n",
      "Epochs : 646 ; Loss : 0.6673963665962219 ; Accuracy : 59.525 ; Test Loss : 0.663840115070343 ; Test accuracy : 59.2\n",
      "Epochs : 647 ; Loss : 0.6672325730323792 ; Accuracy : 59.575 ; Test Loss : 0.6637039184570312 ; Test accuracy : 59.2\n",
      "Epochs : 648 ; Loss : 0.6670690178871155 ; Accuracy : 59.575 ; Test Loss : 0.6635677814483643 ; Test accuracy : 59.2\n",
      "Epochs : 649 ; Loss : 0.6669056415557861 ; Accuracy : 59.625 ; Test Loss : 0.6634319424629211 ; Test accuracy : 59.2\n",
      "Epochs : 650 ; Loss : 0.6667426228523254 ; Accuracy : 59.65 ; Test Loss : 0.6632962226867676 ; Test accuracy : 59.1\n",
      "Epochs : 651 ; Loss : 0.6665798425674438 ; Accuracy : 59.725 ; Test Loss : 0.6631608009338379 ; Test accuracy : 59.1\n",
      "Epochs : 652 ; Loss : 0.6664173603057861 ; Accuracy : 59.75 ; Test Loss : 0.6630256772041321 ; Test accuracy : 59.2\n",
      "Epochs : 653 ; Loss : 0.6662551164627075 ; Accuracy : 59.75 ; Test Loss : 0.662890613079071 ; Test accuracy : 59.4\n",
      "Epochs : 654 ; Loss : 0.666093111038208 ; Accuracy : 59.7 ; Test Loss : 0.6627559065818787 ; Test accuracy : 59.5\n",
      "Epochs : 655 ; Loss : 0.6659313440322876 ; Accuracy : 59.7 ; Test Loss : 0.6626213788986206 ; Test accuracy : 59.5\n",
      "Epochs : 656 ; Loss : 0.6657699346542358 ; Accuracy : 59.7 ; Test Loss : 0.6624869704246521 ; Test accuracy : 59.5\n",
      "Epochs : 657 ; Loss : 0.6656086444854736 ; Accuracy : 59.75 ; Test Loss : 0.6623528003692627 ; Test accuracy : 59.6\n",
      "Epochs : 658 ; Loss : 0.6654476523399353 ; Accuracy : 59.775 ; Test Loss : 0.6622189879417419 ; Test accuracy : 59.6\n",
      "Epochs : 659 ; Loss : 0.6652870178222656 ; Accuracy : 59.775 ; Test Loss : 0.6620852947235107 ; Test accuracy : 59.6\n",
      "Epochs : 660 ; Loss : 0.6651265025138855 ; Accuracy : 59.8 ; Test Loss : 0.6619518399238586 ; Test accuracy : 59.7\n",
      "Epochs : 661 ; Loss : 0.664966344833374 ; Accuracy : 59.9 ; Test Loss : 0.6618185639381409 ; Test accuracy : 59.8\n",
      "Epochs : 662 ; Loss : 0.6648064255714417 ; Accuracy : 59.95 ; Test Loss : 0.661685585975647 ; Test accuracy : 59.7\n",
      "Epochs : 663 ; Loss : 0.6646467447280884 ; Accuracy : 59.95 ; Test Loss : 0.6615527868270874 ; Test accuracy : 59.7\n",
      "Epochs : 664 ; Loss : 0.6644873023033142 ; Accuracy : 60.0 ; Test Loss : 0.6614200472831726 ; Test accuracy : 59.7\n",
      "Epochs : 665 ; Loss : 0.6643280982971191 ; Accuracy : 60.1 ; Test Loss : 0.6612877249717712 ; Test accuracy : 59.7\n",
      "Epochs : 666 ; Loss : 0.664169192314148 ; Accuracy : 60.075 ; Test Loss : 0.6611555218696594 ; Test accuracy : 59.7\n",
      "Epochs : 667 ; Loss : 0.6640105247497559 ; Accuracy : 60.1 ; Test Loss : 0.6610236167907715 ; Test accuracy : 59.7\n",
      "Epochs : 668 ; Loss : 0.6638520956039429 ; Accuracy : 60.025 ; Test Loss : 0.6608918905258179 ; Test accuracy : 59.7\n",
      "Epochs : 669 ; Loss : 0.6636939644813538 ; Accuracy : 60.1 ; Test Loss : 0.6607602834701538 ; Test accuracy : 59.7\n",
      "Epochs : 670 ; Loss : 0.6635360717773438 ; Accuracy : 60.125 ; Test Loss : 0.6606290340423584 ; Test accuracy : 59.8\n",
      "Epochs : 671 ; Loss : 0.6633782982826233 ; Accuracy : 60.125 ; Test Loss : 0.6604979634284973 ; Test accuracy : 59.8\n",
      "Epochs : 672 ; Loss : 0.6632209420204163 ; Accuracy : 60.175 ; Test Loss : 0.6603670716285706 ; Test accuracy : 59.8\n",
      "Epochs : 673 ; Loss : 0.6630638241767883 ; Accuracy : 60.2 ; Test Loss : 0.6602363586425781 ; Test accuracy : 59.9\n",
      "Epochs : 674 ; Loss : 0.6629068851470947 ; Accuracy : 60.225 ; Test Loss : 0.6601058840751648 ; Test accuracy : 59.9\n",
      "Epochs : 675 ; Loss : 0.662750244140625 ; Accuracy : 60.225 ; Test Loss : 0.6599757075309753 ; Test accuracy : 60.0\n",
      "Epochs : 676 ; Loss : 0.6625937819480896 ; Accuracy : 60.225 ; Test Loss : 0.6598455905914307 ; Test accuracy : 60.0\n",
      "Epochs : 677 ; Loss : 0.6624376773834229 ; Accuracy : 60.25 ; Test Loss : 0.6597157716751099 ; Test accuracy : 60.0\n",
      "Epochs : 678 ; Loss : 0.6622816920280457 ; Accuracy : 60.225 ; Test Loss : 0.6595861315727234 ; Test accuracy : 60.0\n",
      "Epochs : 679 ; Loss : 0.6621260046958923 ; Accuracy : 60.25 ; Test Loss : 0.659456729888916 ; Test accuracy : 59.9\n",
      "Epochs : 680 ; Loss : 0.6619706153869629 ; Accuracy : 60.25 ; Test Loss : 0.6593275666236877 ; Test accuracy : 60.0\n",
      "Epochs : 681 ; Loss : 0.6618154644966125 ; Accuracy : 60.25 ; Test Loss : 0.6591985821723938 ; Test accuracy : 60.0\n",
      "Epochs : 682 ; Loss : 0.6616604924201965 ; Accuracy : 60.275 ; Test Loss : 0.6590697169303894 ; Test accuracy : 60.0\n",
      "Epochs : 683 ; Loss : 0.6615057587623596 ; Accuracy : 60.3 ; Test Loss : 0.6589412689208984 ; Test accuracy : 60.0\n",
      "Epochs : 684 ; Loss : 0.6613513231277466 ; Accuracy : 60.3 ; Test Loss : 0.6588128209114075 ; Test accuracy : 60.0\n",
      "Epochs : 685 ; Loss : 0.6611971855163574 ; Accuracy : 60.325 ; Test Loss : 0.6586847305297852 ; Test accuracy : 60.0\n",
      "Epochs : 686 ; Loss : 0.6610431671142578 ; Accuracy : 60.325 ; Test Loss : 0.6585566997528076 ; Test accuracy : 60.0\n",
      "Epochs : 687 ; Loss : 0.6608895659446716 ; Accuracy : 60.35 ; Test Loss : 0.658428966999054 ; Test accuracy : 60.0\n",
      "Epochs : 688 ; Loss : 0.6607359647750854 ; Accuracy : 60.4 ; Test Loss : 0.6583014130592346 ; Test accuracy : 60.2\n",
      "Epochs : 689 ; Loss : 0.6605828404426575 ; Accuracy : 60.425 ; Test Loss : 0.6581740975379944 ; Test accuracy : 60.3\n",
      "Epochs : 690 ; Loss : 0.660429835319519 ; Accuracy : 60.475 ; Test Loss : 0.6580470204353333 ; Test accuracy : 60.3\n",
      "Epochs : 691 ; Loss : 0.6602770686149597 ; Accuracy : 60.5 ; Test Loss : 0.6579200625419617 ; Test accuracy : 60.3\n",
      "Epochs : 692 ; Loss : 0.6601245999336243 ; Accuracy : 60.475 ; Test Loss : 0.6577933430671692 ; Test accuracy : 60.2\n",
      "Epochs : 693 ; Loss : 0.6599723100662231 ; Accuracy : 60.5 ; Test Loss : 0.6576669216156006 ; Test accuracy : 60.2\n",
      "Epochs : 694 ; Loss : 0.6598202586174011 ; Accuracy : 60.55 ; Test Loss : 0.6575406193733215 ; Test accuracy : 60.2\n",
      "Epochs : 695 ; Loss : 0.659668505191803 ; Accuracy : 60.6 ; Test Loss : 0.657414436340332 ; Test accuracy : 60.1\n",
      "Epochs : 696 ; Loss : 0.6595169305801392 ; Accuracy : 60.65 ; Test Loss : 0.6572886109352112 ; Test accuracy : 60.1\n",
      "Epochs : 697 ; Loss : 0.6593656539916992 ; Accuracy : 60.7 ; Test Loss : 0.6571629047393799 ; Test accuracy : 60.1\n",
      "Epochs : 698 ; Loss : 0.6592145562171936 ; Accuracy : 60.725 ; Test Loss : 0.6570373773574829 ; Test accuracy : 60.2\n",
      "Epochs : 699 ; Loss : 0.6590637564659119 ; Accuracy : 60.7 ; Test Loss : 0.6569121479988098 ; Test accuracy : 60.1\n",
      "Epochs : 700 ; Loss : 0.6589131355285645 ; Accuracy : 60.725 ; Test Loss : 0.6567870378494263 ; Test accuracy : 60.3\n",
      "Epochs : 701 ; Loss : 0.6587628126144409 ; Accuracy : 60.75 ; Test Loss : 0.6566622257232666 ; Test accuracy : 60.4\n",
      "Epochs : 702 ; Loss : 0.6586127281188965 ; Accuracy : 60.725 ; Test Loss : 0.6565375924110413 ; Test accuracy : 60.4\n",
      "Epochs : 703 ; Loss : 0.6584628224372864 ; Accuracy : 60.75 ; Test Loss : 0.6564131379127502 ; Test accuracy : 60.4\n",
      "Epochs : 704 ; Loss : 0.6583131551742554 ; Accuracy : 60.85 ; Test Loss : 0.6562888026237488 ; Test accuracy : 60.4\n",
      "Epochs : 705 ; Loss : 0.6581636667251587 ; Accuracy : 60.925 ; Test Loss : 0.6561647653579712 ; Test accuracy : 60.3\n",
      "Epochs : 706 ; Loss : 0.6580145359039307 ; Accuracy : 60.875 ; Test Loss : 0.6560408473014832 ; Test accuracy : 60.4\n",
      "Epochs : 707 ; Loss : 0.657865583896637 ; Accuracy : 60.925 ; Test Loss : 0.655917227268219 ; Test accuracy : 60.3\n",
      "Epochs : 708 ; Loss : 0.6577168107032776 ; Accuracy : 60.95 ; Test Loss : 0.6557937264442444 ; Test accuracy : 60.3\n",
      "Epochs : 709 ; Loss : 0.6575683951377869 ; Accuracy : 60.975 ; Test Loss : 0.6556704640388489 ; Test accuracy : 60.3\n",
      "Epochs : 710 ; Loss : 0.6574201583862305 ; Accuracy : 61.05 ; Test Loss : 0.6555474400520325 ; Test accuracy : 60.3\n",
      "Epochs : 711 ; Loss : 0.6572721004486084 ; Accuracy : 61.15 ; Test Loss : 0.6554245948791504 ; Test accuracy : 60.3\n",
      "Epochs : 712 ; Loss : 0.6571242809295654 ; Accuracy : 61.15 ; Test Loss : 0.6553019285202026 ; Test accuracy : 60.4\n",
      "Epochs : 713 ; Loss : 0.6569766998291016 ; Accuracy : 61.15 ; Test Loss : 0.655179500579834 ; Test accuracy : 60.4\n",
      "Epochs : 714 ; Loss : 0.6568294167518616 ; Accuracy : 61.125 ; Test Loss : 0.6550571322441101 ; Test accuracy : 60.4\n",
      "Epochs : 715 ; Loss : 0.6566824316978455 ; Accuracy : 61.15 ; Test Loss : 0.6549350619316101 ; Test accuracy : 60.4\n",
      "Epochs : 716 ; Loss : 0.6565355658531189 ; Accuracy : 61.2 ; Test Loss : 0.654813289642334 ; Test accuracy : 60.3\n",
      "Epochs : 717 ; Loss : 0.6563888788223267 ; Accuracy : 61.2 ; Test Loss : 0.6546915769577026 ; Test accuracy : 60.4\n",
      "Epochs : 718 ; Loss : 0.6562424898147583 ; Accuracy : 61.225 ; Test Loss : 0.6545701026916504 ; Test accuracy : 60.5\n",
      "Epochs : 719 ; Loss : 0.6560962796211243 ; Accuracy : 61.325 ; Test Loss : 0.6544488072395325 ; Test accuracy : 60.5\n",
      "Epochs : 720 ; Loss : 0.6559503674507141 ; Accuracy : 61.4 ; Test Loss : 0.6543278098106384 ; Test accuracy : 60.5\n",
      "Epochs : 721 ; Loss : 0.6558045744895935 ; Accuracy : 61.425 ; Test Loss : 0.6542068719863892 ; Test accuracy : 60.6\n",
      "Epochs : 722 ; Loss : 0.6556591391563416 ; Accuracy : 61.425 ; Test Loss : 0.6540861129760742 ; Test accuracy : 60.6\n",
      "Epochs : 723 ; Loss : 0.6555138230323792 ; Accuracy : 61.45 ; Test Loss : 0.6539657115936279 ; Test accuracy : 60.6\n",
      "Epochs : 724 ; Loss : 0.6553688049316406 ; Accuracy : 61.475 ; Test Loss : 0.6538453698158264 ; Test accuracy : 60.6\n",
      "Epochs : 725 ; Loss : 0.6552240252494812 ; Accuracy : 61.55 ; Test Loss : 0.653725266456604 ; Test accuracy : 60.7\n",
      "Epochs : 726 ; Loss : 0.6550793647766113 ; Accuracy : 61.525 ; Test Loss : 0.6536054015159607 ; Test accuracy : 60.7\n",
      "Epochs : 727 ; Loss : 0.6549350619316101 ; Accuracy : 61.525 ; Test Loss : 0.6534856557846069 ; Test accuracy : 60.7\n",
      "Epochs : 728 ; Loss : 0.6547909379005432 ; Accuracy : 61.6 ; Test Loss : 0.6533661484718323 ; Test accuracy : 60.9\n",
      "Epochs : 729 ; Loss : 0.6546469926834106 ; Accuracy : 61.65 ; Test Loss : 0.6532468199729919 ; Test accuracy : 60.9\n",
      "Epochs : 730 ; Loss : 0.654503345489502 ; Accuracy : 61.65 ; Test Loss : 0.6531276702880859 ; Test accuracy : 60.9\n",
      "Epochs : 731 ; Loss : 0.6543598771095276 ; Accuracy : 61.7 ; Test Loss : 0.6530088186264038 ; Test accuracy : 60.9\n",
      "Epochs : 732 ; Loss : 0.6542166471481323 ; Accuracy : 61.725 ; Test Loss : 0.6528900265693665 ; Test accuracy : 60.9\n",
      "Epochs : 733 ; Loss : 0.6540736556053162 ; Accuracy : 61.725 ; Test Loss : 0.6527714729309082 ; Test accuracy : 60.9\n",
      "Epochs : 734 ; Loss : 0.6539308428764343 ; Accuracy : 61.75 ; Test Loss : 0.6526530981063843 ; Test accuracy : 61.0\n",
      "Epochs : 735 ; Loss : 0.6537882685661316 ; Accuracy : 61.775 ; Test Loss : 0.6525349617004395 ; Test accuracy : 61.0\n",
      "Epochs : 736 ; Loss : 0.6536458730697632 ; Accuracy : 61.8 ; Test Loss : 0.652417004108429 ; Test accuracy : 61.1\n",
      "Epochs : 737 ; Loss : 0.6535037159919739 ; Accuracy : 61.8 ; Test Loss : 0.652299165725708 ; Test accuracy : 61.2\n",
      "Epochs : 738 ; Loss : 0.6533618569374084 ; Accuracy : 61.8 ; Test Loss : 0.6521816253662109 ; Test accuracy : 61.2\n",
      "Epochs : 739 ; Loss : 0.6532201766967773 ; Accuracy : 61.875 ; Test Loss : 0.6520642638206482 ; Test accuracy : 61.2\n",
      "Epochs : 740 ; Loss : 0.6530786156654358 ; Accuracy : 61.925 ; Test Loss : 0.6519469618797302 ; Test accuracy : 61.3\n",
      "Epochs : 741 ; Loss : 0.6529374122619629 ; Accuracy : 61.925 ; Test Loss : 0.6518299579620361 ; Test accuracy : 61.3\n",
      "Epochs : 742 ; Loss : 0.6527964472770691 ; Accuracy : 61.95 ; Test Loss : 0.6517131924629211 ; Test accuracy : 61.4\n",
      "Epochs : 743 ; Loss : 0.6526555418968201 ; Accuracy : 62.0 ; Test Loss : 0.6515965461730957 ; Test accuracy : 61.4\n",
      "Epochs : 744 ; Loss : 0.6525149345397949 ; Accuracy : 62.0 ; Test Loss : 0.6514801383018494 ; Test accuracy : 61.4\n",
      "Epochs : 745 ; Loss : 0.6523745656013489 ; Accuracy : 62.05 ; Test Loss : 0.6513638496398926 ; Test accuracy : 61.4\n",
      "Epochs : 746 ; Loss : 0.6522344350814819 ; Accuracy : 62.075 ; Test Loss : 0.6512477993965149 ; Test accuracy : 61.4\n",
      "Epochs : 747 ; Loss : 0.6520945429801941 ; Accuracy : 62.1 ; Test Loss : 0.6511318683624268 ; Test accuracy : 61.4\n",
      "Epochs : 748 ; Loss : 0.6519547700881958 ; Accuracy : 62.175 ; Test Loss : 0.651016116142273 ; Test accuracy : 61.4\n",
      "Epochs : 749 ; Loss : 0.6518152356147766 ; Accuracy : 62.15 ; Test Loss : 0.650900661945343 ; Test accuracy : 61.3\n",
      "Epochs : 750 ; Loss : 0.6516759395599365 ; Accuracy : 62.175 ; Test Loss : 0.6507853865623474 ; Test accuracy : 61.5\n",
      "Epochs : 751 ; Loss : 0.6515368819236755 ; Accuracy : 62.175 ; Test Loss : 0.6506701707839966 ; Test accuracy : 61.4\n",
      "Epochs : 752 ; Loss : 0.6513980031013489 ; Accuracy : 62.225 ; Test Loss : 0.6505553126335144 ; Test accuracy : 61.3\n",
      "Epochs : 753 ; Loss : 0.6512593030929565 ; Accuracy : 62.225 ; Test Loss : 0.650440514087677 ; Test accuracy : 61.3\n",
      "Epochs : 754 ; Loss : 0.6511209011077881 ; Accuracy : 62.225 ; Test Loss : 0.6503259539604187 ; Test accuracy : 61.3\n",
      "Epochs : 755 ; Loss : 0.650982677936554 ; Accuracy : 62.225 ; Test Loss : 0.6502115726470947 ; Test accuracy : 61.3\n",
      "Epochs : 756 ; Loss : 0.6508446335792542 ; Accuracy : 62.25 ; Test Loss : 0.6500973701477051 ; Test accuracy : 61.4\n",
      "Epochs : 757 ; Loss : 0.6507068872451782 ; Accuracy : 62.275 ; Test Loss : 0.6499834060668945 ; Test accuracy : 61.4\n",
      "Epochs : 758 ; Loss : 0.6505692601203918 ; Accuracy : 62.275 ; Test Loss : 0.6498695611953735 ; Test accuracy : 61.4\n",
      "Epochs : 759 ; Loss : 0.6504319310188293 ; Accuracy : 62.3 ; Test Loss : 0.6497558951377869 ; Test accuracy : 61.4\n",
      "Epochs : 760 ; Loss : 0.6502947211265564 ; Accuracy : 62.325 ; Test Loss : 0.6496424674987793 ; Test accuracy : 61.5\n",
      "Epochs : 761 ; Loss : 0.6501577496528625 ; Accuracy : 62.325 ; Test Loss : 0.649529218673706 ; Test accuracy : 61.5\n",
      "Epochs : 762 ; Loss : 0.6500210165977478 ; Accuracy : 62.325 ; Test Loss : 0.6494160890579224 ; Test accuracy : 61.5\n",
      "Epochs : 763 ; Loss : 0.6498845815658569 ; Accuracy : 62.3 ; Test Loss : 0.6493032574653625 ; Test accuracy : 61.6\n",
      "Epochs : 764 ; Loss : 0.6497482061386108 ; Accuracy : 62.375 ; Test Loss : 0.6491904854774475 ; Test accuracy : 61.6\n",
      "Epochs : 765 ; Loss : 0.6496120691299438 ; Accuracy : 62.45 ; Test Loss : 0.6490779519081116 ; Test accuracy : 61.6\n",
      "Epochs : 766 ; Loss : 0.6494762301445007 ; Accuracy : 62.475 ; Test Loss : 0.64896559715271 ; Test accuracy : 61.7\n",
      "Epochs : 767 ; Loss : 0.6493405103683472 ; Accuracy : 62.475 ; Test Loss : 0.6488534808158875 ; Test accuracy : 61.7\n",
      "Epochs : 768 ; Loss : 0.6492049694061279 ; Accuracy : 62.475 ; Test Loss : 0.6487414836883545 ; Test accuracy : 61.8\n",
      "Epochs : 769 ; Loss : 0.6490697860717773 ; Accuracy : 62.5 ; Test Loss : 0.6486296653747559 ; Test accuracy : 61.8\n",
      "Epochs : 770 ; Loss : 0.6489347219467163 ; Accuracy : 62.5 ; Test Loss : 0.6485180854797363 ; Test accuracy : 61.7\n",
      "Epochs : 771 ; Loss : 0.6487998366355896 ; Accuracy : 62.55 ; Test Loss : 0.6484065651893616 ; Test accuracy : 61.7\n",
      "Epochs : 772 ; Loss : 0.648665189743042 ; Accuracy : 62.55 ; Test Loss : 0.6482954621315002 ; Test accuracy : 61.7\n",
      "Epochs : 773 ; Loss : 0.6485307216644287 ; Accuracy : 62.55 ; Test Loss : 0.6481842994689941 ; Test accuracy : 61.8\n",
      "Epochs : 774 ; Loss : 0.6483964920043945 ; Accuracy : 62.55 ; Test Loss : 0.6480733752250671 ; Test accuracy : 61.8\n",
      "Epochs : 775 ; Loss : 0.6482625007629395 ; Accuracy : 62.65 ; Test Loss : 0.6479626893997192 ; Test accuracy : 61.9\n",
      "Epochs : 776 ; Loss : 0.6481286287307739 ; Accuracy : 62.675 ; Test Loss : 0.6478521227836609 ; Test accuracy : 61.9\n",
      "Epochs : 777 ; Loss : 0.6479950547218323 ; Accuracy : 62.7 ; Test Loss : 0.6477418541908264 ; Test accuracy : 61.9\n",
      "Epochs : 778 ; Loss : 0.6478615999221802 ; Accuracy : 62.725 ; Test Loss : 0.6476316452026367 ; Test accuracy : 61.9\n",
      "Epochs : 779 ; Loss : 0.647728443145752 ; Accuracy : 62.725 ; Test Loss : 0.6475216150283813 ; Test accuracy : 61.9\n",
      "Epochs : 780 ; Loss : 0.6475953459739685 ; Accuracy : 62.85 ; Test Loss : 0.6474118232727051 ; Test accuracy : 61.8\n",
      "Epochs : 781 ; Loss : 0.6474625468254089 ; Accuracy : 62.75 ; Test Loss : 0.6473022103309631 ; Test accuracy : 61.8\n",
      "Epochs : 782 ; Loss : 0.6473299860954285 ; Accuracy : 62.725 ; Test Loss : 0.6471927762031555 ; Test accuracy : 61.8\n",
      "Epochs : 783 ; Loss : 0.6471975445747375 ; Accuracy : 62.725 ; Test Loss : 0.6470835208892822 ; Test accuracy : 61.8\n",
      "Epochs : 784 ; Loss : 0.6470653414726257 ; Accuracy : 62.75 ; Test Loss : 0.6469743847846985 ; Test accuracy : 61.9\n",
      "Epochs : 785 ; Loss : 0.646933376789093 ; Accuracy : 62.775 ; Test Loss : 0.6468654870986938 ; Test accuracy : 62.0\n",
      "Epochs : 786 ; Loss : 0.6468015909194946 ; Accuracy : 62.775 ; Test Loss : 0.6467567682266235 ; Test accuracy : 62.0\n",
      "Epochs : 787 ; Loss : 0.6466699838638306 ; Accuracy : 62.8 ; Test Loss : 0.6466481685638428 ; Test accuracy : 61.9\n",
      "Epochs : 788 ; Loss : 0.6465386152267456 ; Accuracy : 62.825 ; Test Loss : 0.6465398073196411 ; Test accuracy : 62.0\n",
      "Epochs : 789 ; Loss : 0.6464073657989502 ; Accuracy : 62.775 ; Test Loss : 0.6464316248893738 ; Test accuracy : 62.0\n",
      "Epochs : 790 ; Loss : 0.6462764143943787 ; Accuracy : 62.775 ; Test Loss : 0.6463235020637512 ; Test accuracy : 62.0\n",
      "Epochs : 791 ; Loss : 0.6461456418037415 ; Accuracy : 62.825 ; Test Loss : 0.6462157368659973 ; Test accuracy : 62.0\n",
      "Epochs : 792 ; Loss : 0.6460151076316833 ; Accuracy : 62.825 ; Test Loss : 0.646108090877533 ; Test accuracy : 62.1\n",
      "Epochs : 793 ; Loss : 0.6458846926689148 ; Accuracy : 62.875 ; Test Loss : 0.6460005044937134 ; Test accuracy : 62.0\n",
      "Epochs : 794 ; Loss : 0.6457545757293701 ; Accuracy : 62.9 ; Test Loss : 0.6458932161331177 ; Test accuracy : 62.0\n",
      "Epochs : 795 ; Loss : 0.6456245183944702 ; Accuracy : 62.95 ; Test Loss : 0.6457860469818115 ; Test accuracy : 62.3\n",
      "Epochs : 796 ; Loss : 0.6454946994781494 ; Accuracy : 62.95 ; Test Loss : 0.6456791162490845 ; Test accuracy : 62.3\n",
      "Epochs : 797 ; Loss : 0.6453651189804077 ; Accuracy : 62.975 ; Test Loss : 0.645572304725647 ; Test accuracy : 62.3\n",
      "Epochs : 798 ; Loss : 0.6452357769012451 ; Accuracy : 63.0 ; Test Loss : 0.6454656720161438 ; Test accuracy : 62.4\n",
      "Epochs : 799 ; Loss : 0.6451066136360168 ; Accuracy : 63.0 ; Test Loss : 0.645359218120575 ; Test accuracy : 62.4\n",
      "Epochs : 800 ; Loss : 0.6449775695800781 ; Accuracy : 63.025 ; Test Loss : 0.6452529430389404 ; Test accuracy : 62.4\n",
      "Epochs : 801 ; Loss : 0.6448487043380737 ; Accuracy : 63.075 ; Test Loss : 0.645146906375885 ; Test accuracy : 62.5\n",
      "Epochs : 802 ; Loss : 0.6447201371192932 ; Accuracy : 63.1 ; Test Loss : 0.6450409293174744 ; Test accuracy : 62.5\n",
      "Epochs : 803 ; Loss : 0.6445916891098022 ; Accuracy : 63.05 ; Test Loss : 0.6449351906776428 ; Test accuracy : 62.6\n",
      "Epochs : 804 ; Loss : 0.6444635391235352 ; Accuracy : 63.075 ; Test Loss : 0.6448296308517456 ; Test accuracy : 62.7\n",
      "Epochs : 805 ; Loss : 0.6443355083465576 ; Accuracy : 63.075 ; Test Loss : 0.6447241902351379 ; Test accuracy : 62.7\n",
      "Epochs : 806 ; Loss : 0.6442076563835144 ; Accuracy : 63.075 ; Test Loss : 0.6446189284324646 ; Test accuracy : 62.7\n",
      "Epochs : 807 ; Loss : 0.6440799832344055 ; Accuracy : 63.075 ; Test Loss : 0.6445139050483704 ; Test accuracy : 62.7\n",
      "Epochs : 808 ; Loss : 0.6439526081085205 ; Accuracy : 63.15 ; Test Loss : 0.6444089412689209 ; Test accuracy : 62.6\n",
      "Epochs : 809 ; Loss : 0.6438252925872803 ; Accuracy : 63.175 ; Test Loss : 0.6443042755126953 ; Test accuracy : 62.6\n",
      "Epochs : 810 ; Loss : 0.6436982750892639 ; Accuracy : 63.175 ; Test Loss : 0.6441997289657593 ; Test accuracy : 62.6\n",
      "Epochs : 811 ; Loss : 0.6435714364051819 ; Accuracy : 63.2 ; Test Loss : 0.6440953612327576 ; Test accuracy : 62.6\n",
      "Epochs : 812 ; Loss : 0.6434447169303894 ; Accuracy : 63.275 ; Test Loss : 0.6439911127090454 ; Test accuracy : 62.6\n",
      "Epochs : 813 ; Loss : 0.6433183550834656 ; Accuracy : 63.25 ; Test Loss : 0.6438871026039124 ; Test accuracy : 62.6\n",
      "Epochs : 814 ; Loss : 0.6431920528411865 ; Accuracy : 63.275 ; Test Loss : 0.6437832117080688 ; Test accuracy : 62.6\n",
      "Epochs : 815 ; Loss : 0.6430659294128418 ; Accuracy : 63.275 ; Test Loss : 0.6436796188354492 ; Test accuracy : 62.7\n",
      "Epochs : 816 ; Loss : 0.6429400444030762 ; Accuracy : 63.275 ; Test Loss : 0.6435760855674744 ; Test accuracy : 62.7\n",
      "Epochs : 817 ; Loss : 0.6428142786026001 ; Accuracy : 63.325 ; Test Loss : 0.6434726715087891 ; Test accuracy : 62.7\n",
      "Epochs : 818 ; Loss : 0.6426888108253479 ; Accuracy : 63.325 ; Test Loss : 0.6433695554733276 ; Test accuracy : 62.7\n",
      "Epochs : 819 ; Loss : 0.6425634622573853 ; Accuracy : 63.35 ; Test Loss : 0.643266499042511 ; Test accuracy : 62.7\n",
      "Epochs : 820 ; Loss : 0.6424383521080017 ; Accuracy : 63.375 ; Test Loss : 0.6431636810302734 ; Test accuracy : 62.8\n",
      "Epochs : 821 ; Loss : 0.6423133611679077 ; Accuracy : 63.4 ; Test Loss : 0.6430609226226807 ; Test accuracy : 62.8\n",
      "Epochs : 822 ; Loss : 0.6421886086463928 ; Accuracy : 63.45 ; Test Loss : 0.6429584622383118 ; Test accuracy : 62.7\n",
      "Epochs : 823 ; Loss : 0.6420640349388123 ; Accuracy : 63.4 ; Test Loss : 0.6428561210632324 ; Test accuracy : 62.7\n",
      "Epochs : 824 ; Loss : 0.6419396996498108 ; Accuracy : 63.4 ; Test Loss : 0.6427539587020874 ; Test accuracy : 62.7\n",
      "Epochs : 825 ; Loss : 0.6418155431747437 ; Accuracy : 63.425 ; Test Loss : 0.6426519751548767 ; Test accuracy : 62.7\n",
      "Epochs : 826 ; Loss : 0.6416915059089661 ; Accuracy : 63.425 ; Test Loss : 0.6425501108169556 ; Test accuracy : 62.7\n",
      "Epochs : 827 ; Loss : 0.6415676474571228 ; Accuracy : 63.45 ; Test Loss : 0.6424484848976135 ; Test accuracy : 62.7\n",
      "Epochs : 828 ; Loss : 0.6414440870285034 ; Accuracy : 63.45 ; Test Loss : 0.642346978187561 ; Test accuracy : 62.7\n",
      "Epochs : 829 ; Loss : 0.6413205862045288 ; Accuracy : 63.45 ; Test Loss : 0.6422456502914429 ; Test accuracy : 62.6\n",
      "Epochs : 830 ; Loss : 0.6411973834037781 ; Accuracy : 63.5 ; Test Loss : 0.6421444416046143 ; Test accuracy : 62.7\n",
      "Epochs : 831 ; Loss : 0.6410742402076721 ; Accuracy : 63.525 ; Test Loss : 0.6420434713363647 ; Test accuracy : 62.7\n",
      "Epochs : 832 ; Loss : 0.6409514546394348 ; Accuracy : 63.5 ; Test Loss : 0.6419426798820496 ; Test accuracy : 62.7\n",
      "Epochs : 833 ; Loss : 0.6408287286758423 ; Accuracy : 63.55 ; Test Loss : 0.6418419480323792 ; Test accuracy : 62.7\n",
      "Epochs : 834 ; Loss : 0.6407061815261841 ; Accuracy : 63.55 ; Test Loss : 0.6417415142059326 ; Test accuracy : 62.6\n",
      "Epochs : 835 ; Loss : 0.640583872795105 ; Accuracy : 63.6 ; Test Loss : 0.6416411399841309 ; Test accuracy : 62.6\n",
      "Epochs : 836 ; Loss : 0.6404617428779602 ; Accuracy : 63.625 ; Test Loss : 0.6415409445762634 ; Test accuracy : 62.6\n",
      "Epochs : 837 ; Loss : 0.640339732170105 ; Accuracy : 63.675 ; Test Loss : 0.6414409279823303 ; Test accuracy : 62.6\n",
      "Epochs : 838 ; Loss : 0.6402180194854736 ; Accuracy : 63.6 ; Test Loss : 0.6413410902023315 ; Test accuracy : 62.6\n",
      "Epochs : 839 ; Loss : 0.6400964856147766 ; Accuracy : 63.625 ; Test Loss : 0.6412414312362671 ; Test accuracy : 62.6\n",
      "Epochs : 840 ; Loss : 0.6399750113487244 ; Accuracy : 63.65 ; Test Loss : 0.6411418914794922 ; Test accuracy : 62.7\n",
      "Epochs : 841 ; Loss : 0.6398537755012512 ; Accuracy : 63.625 ; Test Loss : 0.6410425305366516 ; Test accuracy : 62.7\n",
      "Epochs : 842 ; Loss : 0.6397327780723572 ; Accuracy : 63.65 ; Test Loss : 0.6409434080123901 ; Test accuracy : 62.7\n",
      "Epochs : 843 ; Loss : 0.6396118998527527 ; Accuracy : 63.625 ; Test Loss : 0.6408443450927734 ; Test accuracy : 62.6\n",
      "Epochs : 844 ; Loss : 0.6394912600517273 ; Accuracy : 63.65 ; Test Loss : 0.6407455205917358 ; Test accuracy : 62.6\n",
      "Epochs : 845 ; Loss : 0.6393707394599915 ; Accuracy : 63.675 ; Test Loss : 0.640646755695343 ; Test accuracy : 62.6\n",
      "Epochs : 846 ; Loss : 0.6392504572868347 ; Accuracy : 63.675 ; Test Loss : 0.6405482292175293 ; Test accuracy : 62.6\n",
      "Epochs : 847 ; Loss : 0.6391302943229675 ; Accuracy : 63.7 ; Test Loss : 0.6404498815536499 ; Test accuracy : 62.6\n",
      "Epochs : 848 ; Loss : 0.6390104293823242 ; Accuracy : 63.75 ; Test Loss : 0.6403516530990601 ; Test accuracy : 62.6\n",
      "Epochs : 849 ; Loss : 0.6388906240463257 ; Accuracy : 63.75 ; Test Loss : 0.6402536034584045 ; Test accuracy : 62.5\n",
      "Epochs : 850 ; Loss : 0.6387709379196167 ; Accuracy : 63.75 ; Test Loss : 0.6401557326316833 ; Test accuracy : 62.5\n",
      "Epochs : 851 ; Loss : 0.6386516690254211 ; Accuracy : 63.75 ; Test Loss : 0.6400580406188965 ; Test accuracy : 62.5\n",
      "Epochs : 852 ; Loss : 0.6385324001312256 ; Accuracy : 63.775 ; Test Loss : 0.6399604082107544 ; Test accuracy : 62.5\n",
      "Epochs : 853 ; Loss : 0.6384133696556091 ; Accuracy : 63.775 ; Test Loss : 0.6398630738258362 ; Test accuracy : 62.4\n",
      "Epochs : 854 ; Loss : 0.6382943987846375 ; Accuracy : 63.825 ; Test Loss : 0.6397658586502075 ; Test accuracy : 62.4\n",
      "Epochs : 855 ; Loss : 0.6381757259368896 ; Accuracy : 63.8 ; Test Loss : 0.6396687030792236 ; Test accuracy : 62.4\n",
      "Epochs : 856 ; Loss : 0.638057291507721 ; Accuracy : 63.825 ; Test Loss : 0.6395717859268188 ; Test accuracy : 62.5\n",
      "Epochs : 857 ; Loss : 0.637938916683197 ; Accuracy : 63.825 ; Test Loss : 0.6394749879837036 ; Test accuracy : 62.5\n",
      "Epochs : 858 ; Loss : 0.6378207206726074 ; Accuracy : 63.85 ; Test Loss : 0.6393784284591675 ; Test accuracy : 62.5\n",
      "Epochs : 859 ; Loss : 0.6377027630805969 ; Accuracy : 63.85 ; Test Loss : 0.6392819881439209 ; Test accuracy : 62.5\n",
      "Epochs : 860 ; Loss : 0.6375849843025208 ; Accuracy : 63.85 ; Test Loss : 0.6391857266426086 ; Test accuracy : 62.5\n",
      "Epochs : 861 ; Loss : 0.6374673247337341 ; Accuracy : 63.875 ; Test Loss : 0.6390896439552307 ; Test accuracy : 62.5\n",
      "Epochs : 862 ; Loss : 0.6373499035835266 ; Accuracy : 63.875 ; Test Loss : 0.6389936208724976 ; Test accuracy : 62.7\n",
      "Epochs : 863 ; Loss : 0.6372326016426086 ; Accuracy : 63.875 ; Test Loss : 0.6388978362083435 ; Test accuracy : 62.7\n",
      "Epochs : 864 ; Loss : 0.6371155381202698 ; Accuracy : 63.875 ; Test Loss : 0.638802170753479 ; Test accuracy : 62.7\n",
      "Epochs : 865 ; Loss : 0.6369985938072205 ; Accuracy : 63.85 ; Test Loss : 0.6387066841125488 ; Test accuracy : 62.7\n",
      "Epochs : 866 ; Loss : 0.6368818879127502 ; Accuracy : 63.85 ; Test Loss : 0.638611376285553 ; Test accuracy : 62.7\n",
      "Epochs : 867 ; Loss : 0.6367653012275696 ; Accuracy : 63.825 ; Test Loss : 0.6385161876678467 ; Test accuracy : 62.7\n",
      "Epochs : 868 ; Loss : 0.6366488933563232 ; Accuracy : 63.875 ; Test Loss : 0.6384211778640747 ; Test accuracy : 62.7\n",
      "Epochs : 869 ; Loss : 0.6365326046943665 ; Accuracy : 63.875 ; Test Loss : 0.6383263468742371 ; Test accuracy : 62.7\n",
      "Epochs : 870 ; Loss : 0.6364166736602783 ; Accuracy : 63.9 ; Test Loss : 0.6382315754890442 ; Test accuracy : 62.7\n",
      "Epochs : 871 ; Loss : 0.636300802230835 ; Accuracy : 63.925 ; Test Loss : 0.6381370425224304 ; Test accuracy : 62.8\n",
      "Epochs : 872 ; Loss : 0.6361851096153259 ; Accuracy : 63.95 ; Test Loss : 0.638042688369751 ; Test accuracy : 62.8\n",
      "Epochs : 873 ; Loss : 0.6360694766044617 ; Accuracy : 64.0 ; Test Loss : 0.6379483938217163 ; Test accuracy : 62.8\n",
      "Epochs : 874 ; Loss : 0.6359542012214661 ; Accuracy : 64.025 ; Test Loss : 0.6378543972969055 ; Test accuracy : 62.8\n",
      "Epochs : 875 ; Loss : 0.63583904504776 ; Accuracy : 64.025 ; Test Loss : 0.6377604007720947 ; Test accuracy : 62.9\n",
      "Epochs : 876 ; Loss : 0.6357240080833435 ; Accuracy : 64.05 ; Test Loss : 0.637666642665863 ; Test accuracy : 62.9\n",
      "Epochs : 877 ; Loss : 0.6356091499328613 ; Accuracy : 64.05 ; Test Loss : 0.6375730633735657 ; Test accuracy : 62.9\n",
      "Epochs : 878 ; Loss : 0.6354944705963135 ; Accuracy : 64.1 ; Test Loss : 0.6374796628952026 ; Test accuracy : 62.9\n",
      "Epochs : 879 ; Loss : 0.6353800296783447 ; Accuracy : 64.125 ; Test Loss : 0.6373863816261292 ; Test accuracy : 62.9\n",
      "Epochs : 880 ; Loss : 0.6352656483650208 ; Accuracy : 64.125 ; Test Loss : 0.6372931599617004 ; Test accuracy : 63.0\n",
      "Epochs : 881 ; Loss : 0.6351515054702759 ; Accuracy : 64.175 ; Test Loss : 0.6372001767158508 ; Test accuracy : 63.1\n",
      "Epochs : 882 ; Loss : 0.6350375413894653 ; Accuracy : 64.3 ; Test Loss : 0.6371073126792908 ; Test accuracy : 63.1\n",
      "Epochs : 883 ; Loss : 0.6349237561225891 ; Accuracy : 64.325 ; Test Loss : 0.637014627456665 ; Test accuracy : 63.1\n",
      "Epochs : 884 ; Loss : 0.6348100900650024 ; Accuracy : 64.35 ; Test Loss : 0.6369221210479736 ; Test accuracy : 63.1\n",
      "Epochs : 885 ; Loss : 0.6346966624259949 ; Accuracy : 64.375 ; Test Loss : 0.6368297934532166 ; Test accuracy : 63.2\n",
      "Epochs : 886 ; Loss : 0.6345833539962769 ; Accuracy : 64.4 ; Test Loss : 0.6367375254631042 ; Test accuracy : 63.2\n",
      "Epochs : 887 ; Loss : 0.6344701647758484 ; Accuracy : 64.375 ; Test Loss : 0.636645495891571 ; Test accuracy : 63.2\n",
      "Epochs : 888 ; Loss : 0.634357213973999 ; Accuracy : 64.4 ; Test Loss : 0.6365535855293274 ; Test accuracy : 63.2\n",
      "Epochs : 889 ; Loss : 0.634244441986084 ; Accuracy : 64.425 ; Test Loss : 0.6364617943763733 ; Test accuracy : 63.2\n",
      "Epochs : 890 ; Loss : 0.6341318488121033 ; Accuracy : 64.475 ; Test Loss : 0.6363701224327087 ; Test accuracy : 63.2\n",
      "Epochs : 891 ; Loss : 0.6340193748474121 ; Accuracy : 64.475 ; Test Loss : 0.6362786889076233 ; Test accuracy : 63.2\n",
      "Epochs : 892 ; Loss : 0.6339070796966553 ; Accuracy : 64.475 ; Test Loss : 0.6361874341964722 ; Test accuracy : 63.2\n",
      "Epochs : 893 ; Loss : 0.6337949633598328 ; Accuracy : 64.475 ; Test Loss : 0.6360962986946106 ; Test accuracy : 63.1\n",
      "Epochs : 894 ; Loss : 0.6336830258369446 ; Accuracy : 64.475 ; Test Loss : 0.6360052824020386 ; Test accuracy : 63.2\n",
      "Epochs : 895 ; Loss : 0.633571207523346 ; Accuracy : 64.45 ; Test Loss : 0.6359143853187561 ; Test accuracy : 63.2\n",
      "Epochs : 896 ; Loss : 0.6334596276283264 ; Accuracy : 64.45 ; Test Loss : 0.635823667049408 ; Test accuracy : 63.2\n",
      "Epochs : 897 ; Loss : 0.6333481669425964 ; Accuracy : 64.45 ; Test Loss : 0.6357331871986389 ; Test accuracy : 63.2\n",
      "Epochs : 898 ; Loss : 0.633236825466156 ; Accuracy : 64.475 ; Test Loss : 0.6356427073478699 ; Test accuracy : 63.2\n",
      "Epochs : 899 ; Loss : 0.6331257224082947 ; Accuracy : 64.45 ; Test Loss : 0.6355525255203247 ; Test accuracy : 63.3\n",
      "Epochs : 900 ; Loss : 0.6330147385597229 ; Accuracy : 64.45 ; Test Loss : 0.6354623436927795 ; Test accuracy : 63.3\n",
      "Epochs : 901 ; Loss : 0.6329039335250854 ; Accuracy : 64.45 ; Test Loss : 0.6353724002838135 ; Test accuracy : 63.2\n",
      "Epochs : 902 ; Loss : 0.6327933669090271 ; Accuracy : 64.475 ; Test Loss : 0.6352826356887817 ; Test accuracy : 63.1\n",
      "Epochs : 903 ; Loss : 0.6326829195022583 ; Accuracy : 64.475 ; Test Loss : 0.6351930499076843 ; Test accuracy : 63.2\n",
      "Epochs : 904 ; Loss : 0.6325725317001343 ; Accuracy : 64.525 ; Test Loss : 0.6351034045219421 ; Test accuracy : 63.1\n",
      "Epochs : 905 ; Loss : 0.6324624419212341 ; Accuracy : 64.525 ; Test Loss : 0.6350141167640686 ; Test accuracy : 63.1\n",
      "Epochs : 906 ; Loss : 0.6323524713516235 ; Accuracy : 64.575 ; Test Loss : 0.6349248886108398 ; Test accuracy : 63.1\n",
      "Epochs : 907 ; Loss : 0.6322426795959473 ; Accuracy : 64.575 ; Test Loss : 0.6348358392715454 ; Test accuracy : 63.2\n",
      "Epochs : 908 ; Loss : 0.6321330070495605 ; Accuracy : 64.6 ; Test Loss : 0.6347469687461853 ; Test accuracy : 63.2\n",
      "Epochs : 909 ; Loss : 0.6320235133171082 ; Accuracy : 64.625 ; Test Loss : 0.6346582174301147 ; Test accuracy : 63.2\n",
      "Epochs : 910 ; Loss : 0.6319141983985901 ; Accuracy : 64.7 ; Test Loss : 0.6345695853233337 ; Test accuracy : 63.2\n",
      "Epochs : 911 ; Loss : 0.6318050026893616 ; Accuracy : 64.675 ; Test Loss : 0.6344811320304871 ; Test accuracy : 63.1\n",
      "Epochs : 912 ; Loss : 0.6316960453987122 ; Accuracy : 64.75 ; Test Loss : 0.6343927979469299 ; Test accuracy : 63.1\n",
      "Epochs : 913 ; Loss : 0.6315872073173523 ; Accuracy : 64.8 ; Test Loss : 0.6343046426773071 ; Test accuracy : 63.1\n",
      "Epochs : 914 ; Loss : 0.6314785480499268 ; Accuracy : 64.85 ; Test Loss : 0.6342166066169739 ; Test accuracy : 63.1\n",
      "Epochs : 915 ; Loss : 0.6313700079917908 ; Accuracy : 64.875 ; Test Loss : 0.6341286897659302 ; Test accuracy : 63.4\n",
      "Epochs : 916 ; Loss : 0.6312617063522339 ; Accuracy : 64.875 ; Test Loss : 0.6340410709381104 ; Test accuracy : 63.4\n",
      "Epochs : 917 ; Loss : 0.6311534643173218 ; Accuracy : 64.9 ; Test Loss : 0.6339533925056458 ; Test accuracy : 63.6\n",
      "Epochs : 918 ; Loss : 0.6310454607009888 ; Accuracy : 64.9 ; Test Loss : 0.633866012096405 ; Test accuracy : 63.6\n",
      "Epochs : 919 ; Loss : 0.6309375762939453 ; Accuracy : 64.95 ; Test Loss : 0.6337786912918091 ; Test accuracy : 63.7\n",
      "Epochs : 920 ; Loss : 0.6308298707008362 ; Accuracy : 64.925 ; Test Loss : 0.6336914896965027 ; Test accuracy : 63.7\n",
      "Epochs : 921 ; Loss : 0.6307223439216614 ; Accuracy : 64.925 ; Test Loss : 0.6336045265197754 ; Test accuracy : 63.8\n",
      "Epochs : 922 ; Loss : 0.6306149363517761 ; Accuracy : 64.925 ; Test Loss : 0.6335176825523376 ; Test accuracy : 63.8\n",
      "Epochs : 923 ; Loss : 0.6305077075958252 ; Accuracy : 64.925 ; Test Loss : 0.6334309577941895 ; Test accuracy : 63.8\n",
      "Epochs : 924 ; Loss : 0.6304006576538086 ; Accuracy : 64.925 ; Test Loss : 0.6333444118499756 ; Test accuracy : 63.8\n",
      "Epochs : 925 ; Loss : 0.6302937865257263 ; Accuracy : 64.95 ; Test Loss : 0.6332579851150513 ; Test accuracy : 63.8\n",
      "Epochs : 926 ; Loss : 0.6301869750022888 ; Accuracy : 64.975 ; Test Loss : 0.6331717371940613 ; Test accuracy : 63.8\n",
      "Epochs : 927 ; Loss : 0.6300804018974304 ; Accuracy : 64.975 ; Test Loss : 0.6330856084823608 ; Test accuracy : 63.8\n",
      "Epochs : 928 ; Loss : 0.6299739480018616 ; Accuracy : 64.975 ; Test Loss : 0.6329995393753052 ; Test accuracy : 63.8\n",
      "Epochs : 929 ; Loss : 0.6298677325248718 ; Accuracy : 64.975 ; Test Loss : 0.6329137086868286 ; Test accuracy : 63.8\n",
      "Epochs : 930 ; Loss : 0.6297615766525269 ; Accuracy : 65.0 ; Test Loss : 0.6328279972076416 ; Test accuracy : 63.8\n",
      "Epochs : 931 ; Loss : 0.6296555995941162 ; Accuracy : 65.025 ; Test Loss : 0.6327424645423889 ; Test accuracy : 63.8\n",
      "Epochs : 932 ; Loss : 0.6295498013496399 ; Accuracy : 65.05 ; Test Loss : 0.632656991481781 ; Test accuracy : 63.8\n",
      "Epochs : 933 ; Loss : 0.6294441223144531 ; Accuracy : 65.05 ; Test Loss : 0.632571816444397 ; Test accuracy : 63.8\n",
      "Epochs : 934 ; Loss : 0.6293386816978455 ; Accuracy : 65.075 ; Test Loss : 0.6324865818023682 ; Test accuracy : 63.8\n",
      "Epochs : 935 ; Loss : 0.6292333006858826 ; Accuracy : 65.075 ; Test Loss : 0.6324016451835632 ; Test accuracy : 63.8\n",
      "Epochs : 936 ; Loss : 0.629128098487854 ; Accuracy : 65.075 ; Test Loss : 0.6323168277740479 ; Test accuracy : 63.8\n",
      "Epochs : 937 ; Loss : 0.629023015499115 ; Accuracy : 65.1 ; Test Loss : 0.6322320699691772 ; Test accuracy : 63.8\n",
      "Epochs : 938 ; Loss : 0.6289182305335999 ; Accuracy : 65.1 ; Test Loss : 0.6321475505828857 ; Test accuracy : 63.7\n",
      "Epochs : 939 ; Loss : 0.6288134455680847 ; Accuracy : 65.1 ; Test Loss : 0.6320631504058838 ; Test accuracy : 63.8\n",
      "Epochs : 940 ; Loss : 0.6287088990211487 ; Accuracy : 65.1 ; Test Loss : 0.6319788694381714 ; Test accuracy : 63.8\n",
      "Epochs : 941 ; Loss : 0.628604531288147 ; Accuracy : 65.1 ; Test Loss : 0.6318947076797485 ; Test accuracy : 63.9\n",
      "Epochs : 942 ; Loss : 0.6285002827644348 ; Accuracy : 65.1 ; Test Loss : 0.63181072473526 ; Test accuracy : 63.9\n",
      "Epochs : 943 ; Loss : 0.6283960938453674 ; Accuracy : 65.125 ; Test Loss : 0.631726861000061 ; Test accuracy : 63.9\n",
      "Epochs : 944 ; Loss : 0.6282921433448792 ; Accuracy : 65.125 ; Test Loss : 0.6316431760787964 ; Test accuracy : 63.9\n",
      "Epochs : 945 ; Loss : 0.6281883716583252 ; Accuracy : 65.125 ; Test Loss : 0.6315595507621765 ; Test accuracy : 64.0\n",
      "Epochs : 946 ; Loss : 0.6280847191810608 ; Accuracy : 65.15 ; Test Loss : 0.631476104259491 ; Test accuracy : 63.9\n",
      "Epochs : 947 ; Loss : 0.6279812455177307 ; Accuracy : 65.125 ; Test Loss : 0.631392776966095 ; Test accuracy : 63.9\n",
      "Epochs : 948 ; Loss : 0.6278778910636902 ; Accuracy : 65.15 ; Test Loss : 0.6313096880912781 ; Test accuracy : 63.9\n",
      "Epochs : 949 ; Loss : 0.627774715423584 ; Accuracy : 65.175 ; Test Loss : 0.6312265992164612 ; Test accuracy : 64.0\n",
      "Epochs : 950 ; Loss : 0.6276716589927673 ; Accuracy : 65.175 ; Test Loss : 0.6311437487602234 ; Test accuracy : 64.0\n",
      "Epochs : 951 ; Loss : 0.6275688409805298 ; Accuracy : 65.2 ; Test Loss : 0.6310610175132751 ; Test accuracy : 64.0\n",
      "Epochs : 952 ; Loss : 0.627466082572937 ; Accuracy : 65.2 ; Test Loss : 0.6309784054756165 ; Test accuracy : 64.0\n",
      "Epochs : 953 ; Loss : 0.6273635029792786 ; Accuracy : 65.175 ; Test Loss : 0.6308959722518921 ; Test accuracy : 64.0\n",
      "Epochs : 954 ; Loss : 0.6272611021995544 ; Accuracy : 65.2 ; Test Loss : 0.6308136582374573 ; Test accuracy : 64.0\n",
      "Epochs : 955 ; Loss : 0.6271588206291199 ; Accuracy : 65.225 ; Test Loss : 0.630731463432312 ; Test accuracy : 64.1\n",
      "Epochs : 956 ; Loss : 0.6270566582679749 ; Accuracy : 65.225 ; Test Loss : 0.6306494474411011 ; Test accuracy : 64.2\n",
      "Epochs : 957 ; Loss : 0.6269546747207642 ; Accuracy : 65.25 ; Test Loss : 0.6305675506591797 ; Test accuracy : 64.2\n",
      "Epochs : 958 ; Loss : 0.626852810382843 ; Accuracy : 65.25 ; Test Loss : 0.6304857730865479 ; Test accuracy : 64.2\n",
      "Epochs : 959 ; Loss : 0.626751184463501 ; Accuracy : 65.2 ; Test Loss : 0.6304040551185608 ; Test accuracy : 64.2\n",
      "Epochs : 960 ; Loss : 0.6266496777534485 ; Accuracy : 65.225 ; Test Loss : 0.6303225755691528 ; Test accuracy : 64.2\n",
      "Epochs : 961 ; Loss : 0.6265482902526855 ; Accuracy : 65.225 ; Test Loss : 0.6302412152290344 ; Test accuracy : 64.2\n",
      "Epochs : 962 ; Loss : 0.6264470219612122 ; Accuracy : 65.25 ; Test Loss : 0.6301600933074951 ; Test accuracy : 64.4\n",
      "Epochs : 963 ; Loss : 0.6263459920883179 ; Accuracy : 65.3 ; Test Loss : 0.630078911781311 ; Test accuracy : 64.4\n",
      "Epochs : 964 ; Loss : 0.6262450218200684 ; Accuracy : 65.325 ; Test Loss : 0.629997968673706 ; Test accuracy : 64.5\n",
      "Epochs : 965 ; Loss : 0.6261442303657532 ; Accuracy : 65.35 ; Test Loss : 0.6299171447753906 ; Test accuracy : 64.5\n",
      "Epochs : 966 ; Loss : 0.6260436177253723 ; Accuracy : 65.375 ; Test Loss : 0.6298364400863647 ; Test accuracy : 64.5\n",
      "Epochs : 967 ; Loss : 0.625943124294281 ; Accuracy : 65.375 ; Test Loss : 0.6297559142112732 ; Test accuracy : 64.5\n",
      "Epochs : 968 ; Loss : 0.625842809677124 ; Accuracy : 65.35 ; Test Loss : 0.629675567150116 ; Test accuracy : 64.7\n",
      "Epochs : 969 ; Loss : 0.6257425546646118 ; Accuracy : 65.425 ; Test Loss : 0.6295952200889587 ; Test accuracy : 64.8\n",
      "Epochs : 970 ; Loss : 0.6256425976753235 ; Accuracy : 65.45 ; Test Loss : 0.6295151114463806 ; Test accuracy : 64.8\n",
      "Epochs : 971 ; Loss : 0.6255426406860352 ; Accuracy : 65.45 ; Test Loss : 0.6294350624084473 ; Test accuracy : 64.8\n",
      "Epochs : 972 ; Loss : 0.6254429221153259 ; Accuracy : 65.45 ; Test Loss : 0.629355251789093 ; Test accuracy : 64.9\n",
      "Epochs : 973 ; Loss : 0.6253432631492615 ; Accuracy : 65.475 ; Test Loss : 0.6292754411697388 ; Test accuracy : 64.9\n",
      "Epochs : 974 ; Loss : 0.6252437829971313 ; Accuracy : 65.475 ; Test Loss : 0.6291958093643188 ; Test accuracy : 64.9\n",
      "Epochs : 975 ; Loss : 0.6251444816589355 ; Accuracy : 65.475 ; Test Loss : 0.629116415977478 ; Test accuracy : 64.9\n",
      "Epochs : 976 ; Loss : 0.6250452995300293 ; Accuracy : 65.525 ; Test Loss : 0.629037082195282 ; Test accuracy : 64.9\n",
      "Epochs : 977 ; Loss : 0.6249462962150574 ; Accuracy : 65.575 ; Test Loss : 0.6289579272270203 ; Test accuracy : 64.9\n",
      "Epochs : 978 ; Loss : 0.624847412109375 ; Accuracy : 65.625 ; Test Loss : 0.6288788318634033 ; Test accuracy : 64.9\n",
      "Epochs : 979 ; Loss : 0.624748706817627 ; Accuracy : 65.625 ; Test Loss : 0.6287998557090759 ; Test accuracy : 64.9\n",
      "Epochs : 980 ; Loss : 0.6246500611305237 ; Accuracy : 65.675 ; Test Loss : 0.6287211179733276 ; Test accuracy : 64.9\n",
      "Epochs : 981 ; Loss : 0.6245516538619995 ; Accuracy : 65.675 ; Test Loss : 0.6286423802375793 ; Test accuracy : 64.9\n",
      "Epochs : 982 ; Loss : 0.6244534254074097 ; Accuracy : 65.7 ; Test Loss : 0.6285638809204102 ; Test accuracy : 64.9\n",
      "Epochs : 983 ; Loss : 0.6243552565574646 ; Accuracy : 65.75 ; Test Loss : 0.6284855008125305 ; Test accuracy : 64.9\n",
      "Epochs : 984 ; Loss : 0.6242572069168091 ; Accuracy : 65.775 ; Test Loss : 0.6284071207046509 ; Test accuracy : 64.9\n",
      "Epochs : 985 ; Loss : 0.6241593360900879 ; Accuracy : 65.8 ; Test Loss : 0.6283290386199951 ; Test accuracy : 64.9\n",
      "Epochs : 986 ; Loss : 0.6240615844726562 ; Accuracy : 65.825 ; Test Loss : 0.6282510161399841 ; Test accuracy : 64.9\n",
      "Epochs : 987 ; Loss : 0.6239640116691589 ; Accuracy : 65.825 ; Test Loss : 0.6281731724739075 ; Test accuracy : 64.9\n",
      "Epochs : 988 ; Loss : 0.623866617679596 ; Accuracy : 65.85 ; Test Loss : 0.6280954480171204 ; Test accuracy : 64.9\n",
      "Epochs : 989 ; Loss : 0.6237693428993225 ; Accuracy : 65.85 ; Test Loss : 0.6280178427696228 ; Test accuracy : 64.9\n",
      "Epochs : 990 ; Loss : 0.6236721277236938 ; Accuracy : 65.8 ; Test Loss : 0.6279403567314148 ; Test accuracy : 64.9\n",
      "Epochs : 991 ; Loss : 0.6235750913619995 ; Accuracy : 65.8 ; Test Loss : 0.6278629302978516 ; Test accuracy : 64.9\n",
      "Epochs : 992 ; Loss : 0.6234782934188843 ; Accuracy : 65.85 ; Test Loss : 0.6277857422828674 ; Test accuracy : 64.9\n",
      "Epochs : 993 ; Loss : 0.623381495475769 ; Accuracy : 65.825 ; Test Loss : 0.6277086734771729 ; Test accuracy : 64.9\n",
      "Epochs : 994 ; Loss : 0.6232849359512329 ; Accuracy : 65.825 ; Test Loss : 0.627631664276123 ; Test accuracy : 64.9\n",
      "Epochs : 995 ; Loss : 0.6231884956359863 ; Accuracy : 65.875 ; Test Loss : 0.6275548934936523 ; Test accuracy : 64.8\n",
      "Epochs : 996 ; Loss : 0.6230921745300293 ; Accuracy : 65.875 ; Test Loss : 0.6274781823158264 ; Test accuracy : 64.8\n",
      "Epochs : 997 ; Loss : 0.6229959726333618 ; Accuracy : 65.9 ; Test Loss : 0.62740159034729 ; Test accuracy : 64.8\n",
      "Epochs : 998 ; Loss : 0.6228999495506287 ; Accuracy : 65.9 ; Test Loss : 0.627325177192688 ; Test accuracy : 64.8\n",
      "Epochs : 999 ; Loss : 0.6228041052818298 ; Accuracy : 65.875 ; Test Loss : 0.6272488832473755 ; Test accuracy : 64.9\n",
      "Imtafe (other metrics): 5.053191489361702\n",
      "Accuracy :  64.9\n",
      "AUC :  0.702107268170426\n",
      "F1 score :  0.648921007226626\n",
      "Finished training with parameter: Phase\n"
     ]
    }
   ],
   "source": [
    "# encoding type\n",
    "\n",
    "parameters = ['H','Phase']\n",
    "\n",
    "for paramx in parameters:\n",
    "    # Set up model\n",
    "    device = 'cuda'\n",
    "    num_layer_gnn = 2\n",
    "    num_layer_gnn_est = 2\n",
    "    qnn_layers = 3\n",
    "    emb_dim = 128\n",
    "    in_dim = 8\n",
    "    inter_dim = 256\n",
    "    out_dim = 128\n",
    "    JK = 'last'\n",
    "    dropout_ratio = 0.1 \n",
    "    gnn_type = 'gat'\n",
    "    lr = 0.001\n",
    "    decay = 0\n",
    "    aug_ratio = 0.1\n",
    "    batch_size = 2000\n",
    "    loss_temp = 0.1\n",
    "    lamda = 0.1\n",
    "    node_est = 'quantum'\n",
    "    entanglement_type = 'CNOT'\n",
    "    encoding_type = paramx #'RY'\n",
    "    \n",
    "    # Dataset\n",
    "    qg_dataset = QuarkGluonGraphDataset(dataset_name='Quark Gluon', raw_dir=main_dir, save_dir='/content',\n",
    "                                        data_folder_name=jet_folder_path, datafile_name=jet_file_path, labelsfile_name=jet_file_path,\n",
    "                                        datatype='particles', dataset_size=10000, nodes_per_graph=nodes_per_graph_original,\n",
    "                                        spectral_augmentation=False, irc_safety_aug=True, device='cuda')\n",
    "    \n",
    "    # Model\n",
    "    gnn = ParticleNetTagger1Path(in_dim, 2)\n",
    "    if node_est == 'classical':\n",
    "        node_imp_estimator = GNN_imp_estimator(num_layer=num_layer_gnn_est, emb_dim=emb_dim, in_dim=in_dim, JK=JK, drop_ratio=dropout_ratio)\n",
    "    if node_est == 'quantum':\n",
    "        node_imp_estimator = QGNN_node_estimator(nodes_per_graph_original, qnn_layers, in_dim, device=device,\n",
    "                                                 entanglement_type=entanglement_type, encoding_type=encoding_type)\n",
    "    \n",
    "    model = graphcl(gnn, node_imp_estimator, emb_dim, out_dim)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Optimizer with current learning rate\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=decay)\n",
    "\n",
    "\n",
    "############## after training ###############\n",
    "    epochs = 50\n",
    "    con_loss = []\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(\"====epoch \" + str(epoch))\n",
    "        qg_dataset.augment = False\n",
    "        train_loss, ra_loss, cp_loss, uni_loss, al_loss = train(epoch, model=model, device=device, dataset=qg_dataset, optimizer=optimizer, batch_size=batch_size,\n",
    "                                          nodes_per_graph=qg_dataset.nodes_per_graph, aug_ratio=aug_ratio, loss_temp=loss_temp, lamda=lamda,\n",
    "                                          irc_safety=True, q_edge_attr=True, node_est=node_est)\n",
    "        con_loss.append(train_loss)\n",
    "        print(train_loss)\n",
    "        print(ra_loss)\n",
    "        print(cp_loss)\n",
    "        print('UNI : ', uni_loss)\n",
    "        print('ALIGN : ', al_loss)\n",
    "\n",
    "    # nodes_per_graph_original = 10\n",
    "    test_dataset = QuarkGluonGraphDataset(dataset_name='Quark Gluon', raw_dir=main_dir, save_dir='/content',\n",
    "                                        data_folder_name=jet_folder_path, datafile_name=jet_file_path, labelsfile_name=jet_file_path,\n",
    "                                        datatype='particles', dataset_size=7000, nodes_per_graph=nodes_per_graph_original, spectral_augmentation=False, irc_safety_aug=True,\n",
    "                                        device='cuda')\n",
    "\n",
    "    test_samples = torch.tensor(np.arange(2000,7000).astype('int32'))\n",
    "    test_sampler = SubsetRandomSampler(test_samples)\n",
    "\n",
    "    test_dataloader = GraphDataLoader(\n",
    "        test_dataset, sampler=test_sampler, batch_size=500, drop_last=False\n",
    "    )\n",
    "\n",
    "    cls_embds = torch.Tensor([])\n",
    "    cls_labels = torch.Tensor([])\n",
    "\n",
    "    for batched_graph, labels in test_dataloader:\n",
    "          graphs = []\n",
    "          unbatched_graph = dgl.unbatch(batched_graph)\n",
    "          for graph in unbatched_graph:\n",
    "            graphs.append(dgl.add_self_loop(graph))\n",
    "          batched_graph = dgl.batch(graphs)\n",
    "          batch_t = torch.arange(0, batched_graph.batch_size).reshape(-1,1).expand(batched_graph.batch_size, test_dataset.nodes_per_graph).reshape(-1,)\n",
    "\n",
    "          ## For custom GNN\n",
    "          # cls_emb = gnn.forward(batched_graph.ndata[\"node_attr\"].float(), torch.stack(batched_graph.edges()), batched_graph.edata[\"edge_attr\"].float())\n",
    "\n",
    "          ## For ParticleNet\n",
    "          pf_feats = batched_graph.ndata[\"node_attr\"].reshape(len(unbatched_graph), nodes_per_graph_original, -1).float()\n",
    "          points = pf_feats[:,:,1:3]\n",
    "          cls_emb = gnn.forward(points.reshape(points.shape[0], points.shape[2], points.shape[1])\n",
    "                             , pf_feats.reshape(pf_feats.shape[0], pf_feats.shape[2], pf_feats.shape[1]), None)\n",
    "          cls_emb = cls_emb.reshape(cls_emb.shape[0], cls_emb.shape[2], cls_emb.shape[1])\n",
    "          cls_emb = cls_emb.reshape(cls_emb.shape[0]*cls_emb.shape[1], cls_emb.shape[2])\n",
    "\n",
    "          # cls_emb = batched_graph.ndata[\"node_attr\"].float()\n",
    "          cls_emb = global_mean_pool(cls_emb, batch_t)\n",
    "          cls_embds = torch.cat((cls_embds, cls_emb.detach()), 0)     #cls_emb\n",
    "          cls_labels = torch.cat((cls_labels, labels))\n",
    "\n",
    "    cls_epochs = 1000\n",
    "    cls_train_data = cls_embds[ : int(0.8*len(cls_embds))]\n",
    "    targets = cls_labels[ : int(0.8*len(cls_embds))]\n",
    "    cls_test_data = cls_embds[int(0.8*len(cls_embds)) : ]\n",
    "    testtargets = cls_labels[int(0.8*len(cls_embds)) : ]\n",
    "\n",
    "    cls_loss, cls_accuracy, test_cls_loss, test_cls_accuracy, fpr, tpr, auc, eB, eS, f1_score, imtafe = train_classifier(cls_epochs, classifier, cls_train_data, targets, cls_test_data, testtargets)\n",
    "\n",
    "    # Print the performance metrics\n",
    "    print(f'Imtafe (other metrics): {imtafe}')\n",
    "\n",
    "    print('Accuracy : ', max(test_cls_accuracy))\n",
    "    print('AUC : ', auc)\n",
    "    print('F1 score : ', f1_score)\n",
    "    # Print or log results for comparison\n",
    "    print(f\"Finished training with parameter: {paramx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "77c61b0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T10:16:29.580739Z",
     "iopub.status.busy": "2024-10-15T10:16:29.580340Z",
     "iopub.status.idle": "2024-10-15T10:16:29.589736Z",
     "shell.execute_reply": "2024-10-15T10:16:29.588877Z"
    },
    "papermill": {
     "duration": 0.149982,
     "end_time": "2024-10-15T10:16:29.591515",
     "exception": false,
     "start_time": "2024-10-15T10:16:29.441533",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Example Hyperparameter Search for Learning Rate\n",
    "\n",
    "# # Set up different learning rates to try\n",
    "# learning_rates = [1e-4, 1e-2, 3e-3, 5e-3]\n",
    "\n",
    "# for lr in learning_rates:\n",
    "#     # Set up model\n",
    "#     device = 'cuda'\n",
    "#     num_layer_gnn = 2\n",
    "#     num_layer_gnn_est = 2\n",
    "#     qnn_layers = 3\n",
    "#     emb_dim = 128\n",
    "#     in_dim = 8\n",
    "#     inter_dim = 256\n",
    "#     out_dim = 128\n",
    "#     JK = 'last'\n",
    "#     dropout_ratio = 0.1 \n",
    "#     gnn_type = 'gat'\n",
    "#     decay = 0\n",
    "#     aug_ratio = 0.1\n",
    "#     batch_size = 2000\n",
    "#     loss_temp = 0.1\n",
    "#     lamda = 0.1\n",
    "#     node_est = 'quantum'\n",
    "#     entanglement_type = 'CNOT'\n",
    "#     encoding_type = 'RY'\n",
    "    \n",
    "#     # Dataset\n",
    "#     qg_dataset = QuarkGluonGraphDataset(dataset_name='Quark Gluon', raw_dir=main_dir, save_dir='/content',\n",
    "#                                         data_folder_name=jet_folder_path, datafile_name=jet_file_path, labelsfile_name=jet_file_path,\n",
    "#                                         datatype='particles', dataset_size=10000, nodes_per_graph=nodes_per_graph_original,\n",
    "#                                         spectral_augmentation=False, irc_safety_aug=True, device='cuda')\n",
    "    \n",
    "#     # Model\n",
    "#     gnn = ParticleNetTagger1Path(in_dim, 2)\n",
    "#     if node_est == 'classical':\n",
    "#         node_imp_estimator = GNN_imp_estimator(num_layer=num_layer_gnn_est, emb_dim=emb_dim, in_dim=in_dim, JK=JK, drop_ratio=dropout_ratio)\n",
    "#     if node_est == 'quantum':\n",
    "#         node_imp_estimator = QGNN_node_estimator(nodes_per_graph_original, qnn_layers, in_dim, device=device,\n",
    "#                                                  entanglement_type=entanglement_type, encoding_type=encoding_type)\n",
    "    \n",
    "#     model = graphcl(gnn, node_imp_estimator, emb_dim, out_dim)\n",
    "#     model.to(device)\n",
    "    \n",
    "#     # Optimizer with current learning rate\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=decay)\n",
    "\n",
    "\n",
    "# ############## after training ###############\n",
    "#     epochs = 50\n",
    "#     con_loss = []\n",
    "\n",
    "#     for epoch in range(1, epochs + 1):\n",
    "#         print(\"====epoch \" + str(epoch))\n",
    "#         qg_dataset.augment = False\n",
    "#         train_loss, ra_loss, cp_loss, uni_loss, al_loss = train(epoch, model=model, device=device, dataset=qg_dataset, optimizer=optimizer, batch_size=batch_size,\n",
    "#                                           nodes_per_graph=qg_dataset.nodes_per_graph, aug_ratio=aug_ratio, loss_temp=loss_temp, lamda=lamda,\n",
    "#                                           irc_safety=True, q_edge_attr=True, node_est=node_est)\n",
    "#         con_loss.append(train_loss)\n",
    "#         print(train_loss)\n",
    "#         print(ra_loss)\n",
    "#         print(cp_loss)\n",
    "#         print('UNI : ', uni_loss)\n",
    "#         print('ALIGN : ', al_loss)\n",
    "\n",
    "#     # nodes_per_graph_original = 10\n",
    "#     test_dataset = QuarkGluonGraphDataset(dataset_name='Quark Gluon', raw_dir=main_dir, save_dir='/content',\n",
    "#                                         data_folder_name=jet_folder_path, datafile_name=jet_file_path, labelsfile_name=jet_file_path,\n",
    "#                                         datatype='particles', dataset_size=7000, nodes_per_graph=nodes_per_graph_original, spectral_augmentation=False, irc_safety_aug=True,\n",
    "#                                         device='cuda')\n",
    "\n",
    "#     test_samples = torch.tensor(np.arange(2000,7000).astype('int32'))\n",
    "#     test_sampler = SubsetRandomSampler(test_samples)\n",
    "\n",
    "#     test_dataloader = test_dataloader = GraphDataLoader(\n",
    "#         test_dataset, sampler=test_sampler, batch_size=500, drop_last=False\n",
    "#     )\n",
    "\n",
    "#     cls_embds = torch.Tensor([])\n",
    "#     cls_labels = torch.Tensor([])\n",
    "\n",
    "#     for batched_graph, labels in test_dataloader:\n",
    "#           graphs = []\n",
    "#           unbatched_graph = dgl.unbatch(batched_graph)\n",
    "#           for graph in unbatched_graph:\n",
    "#             graphs.append(dgl.add_self_loop(graph))\n",
    "#           batched_graph = dgl.batch(graphs)\n",
    "#           batch_t = torch.arange(0, batched_graph.batch_size).reshape(-1,1).expand(batched_graph.batch_size, test_dataset.nodes_per_graph).reshape(-1,)\n",
    "\n",
    "#           ## For custom GNN\n",
    "#           # cls_emb = gnn.forward(batched_graph.ndata[\"node_attr\"].float(), torch.stack(batched_graph.edges()), batched_graph.edata[\"edge_attr\"].float())\n",
    "\n",
    "#           ## For ParticleNet\n",
    "#           pf_feats = batched_graph.ndata[\"node_attr\"].reshape(len(unbatched_graph), nodes_per_graph_original, -1).float()\n",
    "#           points = pf_feats[:,:,1:3]\n",
    "#           cls_emb = gnn.forward(points.reshape(points.shape[0], points.shape[2], points.shape[1])\n",
    "#                              , pf_feats.reshape(pf_feats.shape[0], pf_feats.shape[2], pf_feats.shape[1]), None)\n",
    "#           cls_emb = cls_emb.reshape(cls_emb.shape[0], cls_emb.shape[2], cls_emb.shape[1])\n",
    "#           cls_emb = cls_emb.reshape(cls_emb.shape[0]*cls_emb.shape[1], cls_emb.shape[2])\n",
    "\n",
    "#           # cls_emb = batched_graph.ndata[\"node_attr\"].float()\n",
    "#           cls_emb = global_mean_pool(cls_emb, batch_t)\n",
    "#           cls_embds = torch.cat((cls_embds, cls_emb.detach()), 0)     #cls_emb\n",
    "#           cls_labels = torch.cat((cls_labels, labels))\n",
    "\n",
    "#     cls_epochs = 1000\n",
    "#     cls_train_data = cls_embds[ : int(0.8*len(cls_embds))]\n",
    "#     targets = cls_labels[ : int(0.8*len(cls_embds))]\n",
    "#     cls_test_data = cls_embds[int(0.8*len(cls_embds)) : ]\n",
    "#     testtargets = cls_labels[int(0.8*len(cls_embds)) : ]\n",
    "\n",
    "#     cls_loss, cls_accuracy, test_cls_loss, test_cls_accuracy, fpr, tpr, auc, eB, eS, f1_score, imtafe = train_classifier(cls_epochs, classifier, cls_train_data, targets, cls_test_data, testtargets)\n",
    "\n",
    "#     # Print the performance metrics\n",
    "#     print(f'Imtafe (other metrics): {imtafe}')\n",
    "\n",
    "#     print('Accuracy : ', max(test_cls_accuracy))\n",
    "#     print('AUC : ', auc)\n",
    "#     print('F1 score : ', f1_score)\n",
    "#     # Print or log results for comparison\n",
    "#     print(f\"Finished training with learning rate: {lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef3384a",
   "metadata": {
    "papermill": {
     "duration": 0.137686,
     "end_time": "2024-10-15T10:16:29.863908",
     "exception": false,
     "start_time": "2024-10-15T10:16:29.726222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Lx1VcRhVX9tg"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3292.29436,
   "end_time": "2024-10-15T10:16:33.180091",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-15T09:21:40.885731",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
