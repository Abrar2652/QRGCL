{"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["EjdpTpoY4eel","Lx1VcRhVX9tg"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from IPython.display import clear_output\n!pip install torch==2.2.0\n!pip install torch_geometric\n!pip install particle\n!pip install pennylane\n!pip install pennylane-lightning\n!pip install pennylane-torch\n!pip install torchdata==0.7.1\n!pip install torchvision==0.17.0\n!pip install qiskit==0.46.0\n!pip install torchquantum\n!pip install qiskit-ibm-runtime==0.18.0\n!pip install qiskit-aer==0.13.2\n!pip install dgl -f https://data.dgl.ai/wheels/cu121/repo.html\n!pip install dglgo -f https://data.dgl.ai/wheels-test/repo.html\n!pip install energyflow\nclear_output()","metadata":{"id":"-LvCO-zQ2nmU","scrolled":true,"execution":{"iopub.status.busy":"2024-10-16T11:27:11.015423Z","iopub.execute_input":"2024-10-16T11:27:11.016175Z","iopub.status.idle":"2024-10-16T11:33:08.203215Z","shell.execute_reply.started":"2024-10-16T11:27:11.016127Z","shell.execute_reply":"2024-10-16T11:33:08.202094Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"\n!pip list","metadata":{"id":"gt_ntIZ7S00B","colab":{"base_uri":"https://localhost:8080/"},"outputId":"95bc74c4-ceaf-47c7-f0d6-62a814a2c167","scrolled":true,"execution":{"iopub.status.busy":"2024-10-16T11:33:08.205331Z","iopub.execute_input":"2024-10-16T11:33:08.205658Z","iopub.status.idle":"2024-10-16T11:33:11.015148Z","shell.execute_reply.started":"2024-10-16T11:33:08.205623Z","shell.execute_reply":"2024-10-16T11:33:11.013965Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Package                                  Version            Editable project location\n---------------------------------------- ------------------ -------------------------\nabsl-py                                  1.4.0\naccelerate                               0.34.2\naiobotocore                              2.15.1\naiofiles                                 22.1.0\naiohttp                                  3.9.5\naioitertools                             0.12.0\naiosignal                                1.3.1\naiosqlite                                0.20.0\nalabaster                                1.0.0\nalbucore                                 0.0.17\nalbumentations                           1.4.17\nalembic                                  1.13.3\naltair                                   5.4.1\nannotated-types                          0.7.0\nannoy                                    1.17.3\nansicolors                               1.1.8\nanyio                                    4.4.0\napache-beam                              2.46.0\nappdirs                                  1.4.4\narchspec                                 0.2.3\nargon2-cffi                              23.1.0\nargon2-cffi-bindings                     21.2.0\narray_record                             0.5.1\narrow                                    1.3.0\narviz                                    0.20.0\nastroid                                  3.3.4\nasttokens                                2.4.1\nastunparse                               1.6.3\nasync-lru                                2.0.4\nasync-timeout                            4.0.3\natpublic                                 4.1.0\nattrs                                    23.2.0\naudioread                                3.0.1\nautograd                                 1.7.0\nautopep8                                 2.0.4\nautoray                                  0.6.12\nBabel                                    2.15.0\nbackports.tarfile                        1.2.0\nbayesian-optimization                    1.5.1\nbeatrix_jupyterlab                       2024.66.154055\nbeautifulsoup4                           4.12.3\nbidict                                   0.23.1\nbigframes                                0.22.0\nbleach                                   6.1.0\nblessed                                  1.20.0\nblinker                                  1.8.2\nblis                                     0.7.10\nblosc2                                   2.7.1\nbokeh                                    3.5.2\nboltons                                  24.0.0\nBoruta                                   0.4.3\nboto3                                    1.26.100\nbotocore                                 1.35.23\nbq_helper                                0.4.1              /root/src/BigQuery_Helper\nbqplot                                   0.12.43\nbranca                                   0.8.0\nBrotli                                   1.1.0\nbrotlipy                                 0.7.0\ncached-property                          1.5.2\ncachetools                               4.2.4\nCartopy                                  0.23.0\ncatalogue                                2.0.10\ncatboost                                 1.2.7\ncategory-encoders                        2.6.4\ncertifi                                  2024.8.30\ncesium                                   0.12.3\ncffi                                     1.16.0\ncharset-normalizer                       3.3.2\nchex                                     0.1.86\nclick                                    8.1.7\nclick-plugins                            1.1.1\ncligj                                    0.7.2\ncloud-tpu-client                         0.10\ncloud-tpu-profiler                       2.4.0\ncloudpathlib                             0.19.0\ncloudpickle                              3.0.0\ncmdstanpy                                1.2.4\ncolorama                                 0.4.6\ncolorcet                                 3.1.0\ncolorful                                 0.5.6\ncolorlog                                 6.8.2\ncolorlover                               0.3.0\ncomm                                     0.2.2\ncommonmark                               0.9.1\nconda                                    24.9.0\nconda-content-trust                      0+unknown\nconda-libmamba-solver                    23.12.0\nconda-package-handling                   2.3.0\nconda_package_streaming                  0.10.0\nconfection                               0.1.4\ncontourpy                                1.2.1\ncrcmod                                   1.7\ncryptography                             42.0.8\ncuda-python                              12.6.0\ncudf                                     24.8.3\ncufflinks                                0.17.3\ncuml                                     24.8.0\ncupy                                     13.3.0\nCVXcanon                                 0.1.2\ncycler                                   0.12.1\ncymem                                    2.0.8\nCython                                   3.0.10\ncytoolz                                  0.12.3\ndaal                                     2024.7.0\ndaal4py                                  2024.7.0\ndacite                                   1.8.1\ndask                                     2024.9.1\ndask-cuda                                24.8.2\ndask-cudf                                24.8.3\ndask-expr                                1.1.15\ndataclasses-json                         0.6.7\ndataproc_jupyter_plugin                  0.1.79\ndatasets                                 3.0.1\ndatashader                               0.16.3\ndatatile                                 1.0.3\ndb-dtypes                                1.2.0\ndeap                                     1.4.1\ndebugpy                                  1.8.1\ndecorator                                5.1.1\ndeepdiff                                 8.0.1\ndefusedxml                               0.7.1\nDeprecated                               1.2.14\ndgl                                      2.1.0+cu121\ndglgo                                    0.0.2\ndill                                     0.3.4\ndipy                                     1.9.0\ndistlib                                  0.3.8\ndistributed                              2024.7.1\ndistributed-ucxx                         0.39.1\ndistro                                   1.9.0\ndm-tree                                  0.1.8\ndnspython                                2.6.1\ndocker                                   7.1.0\ndocker-pycreds                           0.4.0\ndocopt                                   0.6.2\ndocstring_parser                         0.16\ndocstring-to-markdown                    0.15\ndocutils                                 0.21.2\nearthengine-api                          1.1.2\neasyocr                                  1.7.2\necos                                     2.0.14\neli5                                     0.13.0\nemail_validator                          2.1.1\nemoji                                    2.13.2\nen-core-web-lg                           3.7.1\nen-core-web-sm                           3.7.1\nEnergyFlow                               1.3.2\nentrypoints                              0.4\net-xmlfile                               1.1.0\netils                                    1.7.0\neval_type_backport                       0.2.0\nexceptiongroup                           1.2.0\nexecnb                                   0.1.6\nexecuting                                2.0.1\nexplainable-ai-sdk                       1.3.3\nFarama-Notifications                     0.0.4\nfastai                                   2.7.17\nfastapi                                  0.111.0\nfastapi-cli                              0.0.4\nfastavro                                 1.9.4\nfastcore                                 1.7.10\nfastdownload                             0.0.7\nfasteners                                0.19\nfastjsonschema                           2.19.1\nfastprogress                             1.0.3\nfastrlock                                0.8.2\nfasttext                                 0.9.3\nfeaturetools                             1.31.0\nfilelock                                 3.15.1\nfiona                                    1.9.6\nflake8                                   7.1.1\nFlask                                    3.0.3\nflatbuffers                              24.3.25\nflax                                     0.8.4\nfolium                                   0.17.0\nfonttools                                4.53.0\nfqdn                                     1.5.1\nfrozendict                               2.4.4\nfrozenlist                               1.4.1\nfsspec                                   2024.6.1\nfuncy                                    2.0\nfury                                     0.11.0\nfuture                                   1.0.0\nfuzzywuzzy                               0.18.0\ngast                                     0.5.4\ngatspy                                   0.3\ngcsfs                                    2024.6.1\ngensim                                   4.3.3\ngeographiclib                            2.0\ngeojson                                  3.1.0\ngeopandas                                0.14.4\ngeopy                                    2.4.1\nghapi                                    1.0.6\ngitdb                                    4.0.11\nGitPython                                3.1.43\ngoogle-ai-generativelanguage             0.6.10\ngoogle-api-core                          2.11.1\ngoogle-api-python-client                 2.147.0\ngoogle-apitools                          0.5.31\ngoogle-auth                              2.30.0\ngoogle-auth-httplib2                     0.2.0\ngoogle-auth-oauthlib                     1.2.0\ngoogle-cloud-aiplatform                  0.6.0a1\ngoogle-cloud-artifact-registry           1.11.3\ngoogle-cloud-automl                      1.0.1\ngoogle-cloud-bigquery                    2.34.4\ngoogle-cloud-bigquery-connection         1.15.3\ngoogle-cloud-bigtable                    1.7.3\ngoogle-cloud-core                        2.4.1\ngoogle-cloud-datastore                   2.20.1\ngoogle-cloud-dlp                         3.18.0\ngoogle-cloud-functions                   1.16.3\ngoogle-cloud-iam                         2.15.0\ngoogle-cloud-jupyter-config              0.0.10\ngoogle-cloud-language                    2.14.0\ngoogle-cloud-monitoring                  2.21.0\ngoogle-cloud-pubsub                      2.21.3\ngoogle-cloud-pubsublite                  1.10.0\ngoogle-cloud-recommendations-ai          0.7.1\ngoogle-cloud-resource-manager            1.12.3\ngoogle-cloud-spanner                     3.47.0\ngoogle-cloud-storage                     1.44.0\ngoogle-cloud-translate                   3.12.1\ngoogle-cloud-videointelligence           2.13.5\ngoogle-cloud-vision                      2.8.0\ngoogle-crc32c                            1.5.0\ngoogle-generativeai                      0.8.2\ngoogle-pasta                             0.2.0\ngoogle-resumable-media                   2.7.1\ngoogleapis-common-protos                 1.63.1\ngpustat                                  1.0.0\ngpxpy                                    1.6.2\ngraphviz                                 0.20.3\ngreenlet                                 3.0.3\ngrpc-google-iam-v1                       0.12.7\ngrpc-interceptor                         0.15.4\ngrpcio                                   1.62.2\ngrpcio-status                            1.48.0\ngviz-api                                 1.10.0\ngym                                      0.26.2\ngym-notices                              0.0.8\ngymnasium                                0.29.0\nh11                                      0.14.0\nh2o                                      3.46.0.5\nh5netcdf                                 1.3.0\nh5py                                     3.11.0\nhaversine                                2.8.1\nhdfs                                     2.7.3\nhep-ml                                   0.7.2\nhepunits                                 2.3.5\nholidays                                 0.57\nholoviews                                1.19.1\nhtml5lib                                 1.1\nhtmlmin                                  0.1.12\nhttpcore                                 1.0.5\nhttplib2                                 0.21.0\nhttptools                                0.6.1\nhttpx                                    0.27.0\nhuggingface-hub                          0.25.1\nhumanize                                 4.9.0\nhyperopt                                 0.2.7\nibis-framework                           7.1.0\nibm-cloud-sdk-core                       3.22.0\nibm-platform-services                    0.57.1\nidna                                     3.7\nigraph                                   0.11.6\nImageHash                                4.3.1\nimageio                                  2.34.1\nimagesize                                1.4.1\nimbalanced-learn                         0.12.3\nimgaug                                   0.4.0\nimmutabledict                            4.2.0\nimportlib-metadata                       7.0.0\nimportlib_resources                      6.4.0\niniconfig                                2.0.0\nipykernel                                6.29.4\nipympl                                   0.7.0\nipython                                  8.21.0\nipython-genutils                         0.2.0\nipython-sql                              0.5.0\nipywidgets                               7.7.1\nisoduration                              20.11.0\nisort                                    5.13.2\nisoweek                                  1.3.3\nitsdangerous                             2.2.0\nJanome                                   0.5.0\njaraco.classes                           3.4.0\njaraco.context                           5.3.0\njaraco.functools                         4.0.1\njax                                      0.4.26\njax-jumpy                                1.0.0\njaxlib                                   0.4.26.dev20240620\njedi                                     0.19.1\njeepney                                  0.8.0\njieba                                    0.42.1\nJinja2                                   3.1.4\njmespath                                 1.0.1\njoblib                                   1.4.2\njson5                                    0.9.25\njsonpatch                                1.33\njsonpointer                              2.4\njsonschema                               4.22.0\njsonschema-specifications                2023.12.1\njupyter_client                           7.4.9\njupyter-console                          6.6.3\njupyter_core                             5.7.2\njupyter-events                           0.10.0\njupyter-http-over-ws                     0.0.8\njupyter-lsp                              1.5.1\njupyter_server                           2.12.5\njupyter_server_fileid                    0.9.2\njupyter-server-mathjax                   0.2.6\njupyter_server_proxy                     4.2.0\njupyter_server_terminals                 0.5.3\njupyter_server_ydoc                      0.8.0\njupyter-ydoc                             0.2.5\njupyterlab                               4.2.5\njupyterlab_git                           0.44.0\njupyterlab-lsp                           5.1.0\njupyterlab_pygments                      0.3.0\njupyterlab_server                        2.27.2\njupyterlab_widgets                       3.0.11\njupytext                                 1.16.2\nkaggle                                   1.6.17\nkaggle-environments                      1.14.15\nkagglehub                                0.3.1\nkeras                                    3.3.3\nkeras-core                               0.1.7\nkeras-cv                                 0.9.0\nkeras-nlp                                0.15.1\nkeras-tuner                              1.4.7\nkernels-mixer                            0.0.13\nkeyring                                  25.2.1\nkeyrings.google-artifactregistry-auth    1.1.2\nkfp                                      2.5.0\nkfp-pipeline-spec                        0.2.2\nkfp-server-api                           2.0.5\nkiwisolver                               1.4.5\nkornia                                   0.7.3\nkornia_rs                                0.1.5\nkt-legacy                                1.0.5\nkubernetes                               26.1.0\nlangcodes                                3.4.1\nlangid                                   1.1.6\nlanguage_data                            1.2.0\nlazy_loader                              0.4\nlearntools                               0.3.4\nleven                                    1.0.4\nlibclang                                 18.1.1\nlibmambapy                               1.5.10\nlibpysal                                 4.9.2\nlibrosa                                  0.10.2.post1\nlightgbm                                 4.2.0\nlightning-utilities                      0.11.7\nlime                                     0.2.0.1\nline_profiler                            4.1.3\nlinkify-it-py                            2.0.3\nlittleutils                              0.2.4\nllvmlite                                 0.43.0\nlml                                      0.1.0\nlocket                                   1.0.0\nloguru                                   0.7.2\nlxml                                     5.3.0\nlz4                                      4.3.3\nMako                                     1.3.5\nmamba                                    1.5.10\nmarisa-trie                              1.1.0\nMarkdown                                 3.6\nmarkdown-it-py                           3.0.0\nMarkupSafe                               2.1.5\nmarshmallow                              3.22.0\nmatplotlib                               3.7.5\nmatplotlib-inline                        0.1.7\nmatplotlib-venn                          1.1.1\nmccabe                                   0.7.0\nmdit-py-plugins                          0.4.1\nmdurl                                    0.1.2\nmemory-profiler                          0.61.0\nmemray                                   1.12.0\nmenuinst                                 2.1.1\nmissingno                                0.5.2\nmistune                                  0.8.4\nmizani                                   0.11.4\nml-dtypes                                0.3.2\nmlcrate                                  0.2.0\nmlxtend                                  0.23.1\nmne                                      1.8.0\nmore-itertools                           10.3.0\nmpld3                                    0.5.10\nmpmath                                   1.3.0\nmsgpack                                  1.0.8\nmsgpack-numpy                            0.4.8\nmultidict                                6.0.5\nmultimethod                              1.11.2\nmultipledispatch                         1.0.0\nmultiprocess                             0.70.12.2\nmunkres                                  1.1.4\nmurmurhash                               1.0.10\nmypy-extensions                          1.0.0\nnamex                                    0.0.8\nnarwhals                                 1.9.0\nnb_conda                                 2.2.1\nnb_conda_kernels                         2.5.1\nnbclassic                                1.1.0\nnbclient                                 0.5.13\nnbconvert                                6.4.5\nnbdev                                    2.3.31\nnbdime                                   3.2.0\nnbformat                                 5.10.4\nnbsphinx                                 0.9.5\nndindex                                  1.9.2\nnest-asyncio                             1.6.0\nnetworkx                                 3.3\nnibabel                                  5.2.1\nnilearn                                  0.10.4\nninja                                    1.11.1.1\nnltk                                     3.2.4\nnose                                     1.3.7\nnotebook                                 6.5.7\nnotebook_executor                        0.2\nnotebook_shim                            0.2.4\nnumba                                    0.60.0\nnumexpr                                  2.10.1\nnumpy                                    1.26.4\nnumpydoc                                 1.8.0\nnvidia-cublas-cu12                       12.1.3.1\nnvidia-cuda-cupti-cu12                   12.1.105\nnvidia-cuda-nvrtc-cu12                   12.1.105\nnvidia-cuda-runtime-cu12                 12.1.105\nnvidia-cudnn-cu12                        8.9.2.26\nnvidia-cufft-cu12                        11.0.2.54\nnvidia-curand-cu12                       10.3.2.106\nnvidia-cusolver-cu12                     11.4.5.107\nnvidia-cusparse-cu12                     12.1.0.106\nnvidia-ml-py                             11.495.46\nnvidia-nccl-cu12                         2.19.3\nnvidia-nvjitlink-cu12                    12.6.77\nnvidia-nvtx-cu12                         12.1.105\nnvtx                                     0.2.10\noauth2client                             4.1.3\noauthlib                                 3.2.2\nobjsize                                  0.6.1\nodfpy                                    1.4.1\nogb                                      1.3.6\nolefile                                  0.47\nonnx                                     1.17.0\nopencensus                               0.11.4\nopencensus-context                       0.1.3\nopencv-contrib-python                    4.10.0.84\nopencv-python                            4.10.0.84\nopencv-python-headless                   4.10.0.84\nopenpyxl                                 3.1.5\nopenslide-python                         1.3.1\nopentelemetry-api                        1.25.0\nopentelemetry-exporter-otlp              1.25.0\nopentelemetry-exporter-otlp-proto-common 1.25.0\nopentelemetry-exporter-otlp-proto-grpc   1.25.0\nopentelemetry-exporter-otlp-proto-http   1.25.0\nopentelemetry-proto                      1.25.0\nopentelemetry-sdk                        1.25.0\nopentelemetry-semantic-conventions       0.46b0\nopt-einsum                               3.3.0\noptax                                    0.2.2\noptree                                   0.11.0\noptuna                                   4.0.0\norbax-checkpoint                         0.6.4\norderly-set                              5.2.2\norjson                                   3.10.4\noutdated                                 0.2.2\noverrides                                7.7.0\npackaging                                24.1\npandas                                   2.2.2\npandas-datareader                        0.10.0\npandas-profiling                         3.6.6\npandas-summary                           0.2.0\npandasql                                 0.7.3\npandocfilters                            1.5.0\npanel                                    1.5.1\npapermill                                2.6.0\nparam                                    2.1.1\nparso                                    0.8.4\nparsy                                    2.1\npartd                                    1.4.2\nparticle                                 0.25.2\npath                                     17.0.0\npath.py                                  12.5.0\npathos                                   0.2.8\npatsy                                    0.5.6\npbr                                      6.1.0\npdf2image                                1.17.0\npendulum                                 3.0.0\nPennyLane                                0.38.0\nPennyLane_Lightning                      0.38.0\npettingzoo                               1.24.0\npexpect                                  4.9.0\nphik                                     0.12.4\npickleshare                              0.7.5\npillow                                   10.3.0\npins                                     0.8.6\npip                                      24.0\npkgutil_resolve_name                     1.3.10\nplatformdirs                             3.11.0\nplotly                                   5.22.0\nplotly-express                           0.4.1\nplotnine                                 0.13.6\npluggy                                   1.5.0\nply                                      3.11\npolars                                   1.9.0\npooch                                    1.8.2\npox                                      0.3.5\nppft                                     1.7.6.9\npreprocessing                            0.1.13\npreshed                                  3.0.9\nprettytable                              3.10.0\nprometheus_client                        0.20.0\npromise                                  2.3\nprompt_toolkit                           3.0.47\nprophet                                  1.1.5\nproto-plus                               1.23.0\nprotobuf                                 3.20.3\npsutil                                   5.9.3\nptyprocess                               0.7.0\npudb                                     2024.1.2\npure-eval                                0.2.2\npy-cpuinfo                               9.0.0\npy-spy                                   0.3.14\npy4j                                     0.10.9.7\npyaml                                    24.9.0\nPyArabic                                 0.6.15\npyarrow                                  16.1.0\npyarrow-hotfix                           0.6\npyasn1                                   0.6.0\npyasn1_modules                           0.4.0\npybind11                                 2.13.6\npyclipper                                1.3.0.post5\npycodestyle                              2.12.1\npycosat                                  0.6.6\npycparser                                2.22\npycryptodome                             3.20.0\npyct                                     0.5.0\npycuda                                   2024.1.2\npydantic                                 2.9.2\npydantic_core                            2.23.4\npydata-google-auth                       1.8.2\npydegensac                               0.1.2\npydicom                                  3.0.1\npydocstyle                               6.3.0\npydot                                    1.4.2\npydub                                    0.25.1\npyemd                                    1.0.0\npyexcel-io                               0.6.6\npyexcel-ods                              0.6.0\npyflakes                                 3.2.0\npygltflib                                1.16.2\nPygments                                 2.18.0\nPyJWT                                    2.8.0\npylatexenc                               2.10\npyLDAvis                                 3.4.1\npylibraft                                24.8.1\npylint                                   3.3.1\npymc3                                    3.11.4\npymongo                                  3.13.0\nPympler                                  1.1\npynvjitlink-cu12                         0.3.0\npynvml                                   11.4.1\npynvrtc                                  9.2\npyOpenSSL                                24.0.0\npyparsing                                3.1.2\npypdf                                    5.0.1\npyproj                                   3.6.1\npyscf                                    2.7.0\npyshp                                    2.3.1\nPySocks                                  1.7.1\npyspnego                                 0.11.1\npytesseract                              0.3.13\npytest                                   8.3.3\npython-bidi                              0.6.0\npython-dateutil                          2.9.0.post0\npython-dotenv                            1.0.1\npython-json-logger                       2.0.7\npython-louvain                           0.16\npython-lsp-jsonrpc                       1.1.2\npython-lsp-server                        1.12.0\npython-multipart                         0.0.9\npython-slugify                           8.0.4\npytoolconfig                             1.3.1\npytools                                  2024.1.14\npytorch-ignite                           0.5.1\npytorch-lightning                        2.4.0\npytz                                     2024.1\npyu2f                                    0.1.5\nPyUpSet                                  0.1.1.post7\npyviz_comms                              3.0.3\nPyWavelets                               1.6.0\nPyYAML                                   6.0.2\npyzmq                                    26.0.3\nqgrid                                    1.3.1\nqiskit                                   0.46.0\nqiskit-aer                               0.13.2\nqiskit-ibm-provider                      0.11.0\nqiskit-ibm-runtime                       0.18.0\nqiskit-terra                             0.46.0\nqtconsole                                5.6.0\nQtPy                                     2.4.1\nraft-dask                                24.8.1\nrapids-dask-dependency                   24.8.0a0\nray                                      2.24.0\nray-cpp                                  2.24.0\nrdkit-pypi                               2022.9.5\nrecommonmark                             0.7.1\nreferencing                              0.35.1\nregex                                    2024.5.15\nrequests                                 2.32.3\nrequests_ntlm                            1.3.0\nrequests-oauthlib                        2.0.0\nrequests-toolbelt                        0.10.1\nretrying                                 1.3.3\nrfc3339-validator                        0.1.4\nrfc3986-validator                        0.1.1\nrgf-python                               3.12.0\nrich                                     13.7.1\nrmm                                      24.8.2\nrope                                     1.13.0\nrpds-py                                  0.18.1\nrsa                                      4.9\nRtree                                    1.3.0\nruamel.yaml                              0.18.6\nruamel.yaml.clib                         0.2.8\nruamel-yaml-conda                        0.15.100\nrustworkx                                0.15.1\ns3fs                                     2024.6.1\ns3transfer                               0.6.2\nsafetensors                              0.4.5\nscikit-image                             0.23.2\nscikit-learn                             1.2.2\nscikit-learn-intelex                     2024.7.0\nscikit-multilearn                        0.2.0\nscikit-optimize                          0.10.2\nscikit-plot                              0.3.7\nscikit-surprise                          1.1.4\nscipy                                    1.14.1\nseaborn                                  0.12.2\nSecretStorage                            3.3.3\nsegment_anything                         1.0\nsemver                                   3.0.2\nSend2Trash                               1.8.3\nsentencepiece                            0.2.0\nsentry-sdk                               2.15.0\nsetproctitle                             1.3.3\nsetuptools                               70.0.0\nsetuptools-scm                           8.1.0\nshap                                     0.44.1\nShapely                                  1.8.5.post1\nshellingham                              1.5.4\nShimmy                                   1.3.0\nsimpervisor                              1.0.0\nsimple_parsing                           0.1.5\nSimpleITK                                2.4.0\nsix                                      1.16.0\nsklearn-pandas                           2.2.0\nslicer                                   0.0.7\nsmart_open                               7.0.4\nsmmap                                    5.0.1\nsniffio                                  1.3.1\nsnowballstemmer                          2.2.0\nsortedcontainers                         2.4.0\nsoundfile                                0.12.1\nsoupsieve                                2.5\nsoxr                                     0.5.0.post1\nspacy                                    3.7.6\nspacy-legacy                             3.0.12\nspacy-loggers                            1.0.5\nSphinx                                   8.1.3\nsphinx-rtd-theme                         0.2.4\nsphinxcontrib-applehelp                  2.0.0\nsphinxcontrib-devhelp                    2.0.0\nsphinxcontrib-htmlhelp                   2.1.0\nsphinxcontrib-jsmath                     1.0.1\nsphinxcontrib-qthelp                     2.0.0\nsphinxcontrib-serializinghtml            2.0.0\nSQLAlchemy                               2.0.30\nsqlglot                                  19.9.0\nsqlparse                                 0.5.0\nsquarify                                 0.4.4\nsrsly                                    2.4.8\nstable-baselines3                        2.1.0\nstack-data                               0.6.2\nstanio                                   0.5.1\nstarlette                                0.37.2\nstatsmodels                              0.14.2\nstevedore                                5.3.0\nstopit                                   1.1.2\nstumpy                                   1.13.0\nsymengine                                0.13.0\nsympy                                    1.13.3\ntables                                   3.10.1\ntabulate                                 0.9.0\ntangled-up-in-unicode                    0.2.0\ntbb                                      2021.13.1\ntblib                                    3.0.0\ntenacity                                 8.3.0\ntensorboard                              2.16.2\ntensorboard-data-server                  0.7.2\ntensorboard_plugin_profile               2.15.1\ntensorboardX                             2.6.2.2\ntensorflow                               2.16.1\ntensorflow-cloud                         0.1.16\ntensorflow-datasets                      4.9.6\ntensorflow_decision_forests              1.9.1\ntensorflow-estimator                     2.15.0\ntensorflow-hub                           0.16.1\ntensorflow-io                            0.37.0\ntensorflow-io-gcs-filesystem             0.37.0\ntensorflow-metadata                      0.14.0\ntensorflow-probability                   0.24.0\ntensorflow-serving-api                   2.16.1\ntensorflow-text                          2.16.1\ntensorflow-transform                     0.14.0\ntensorpack                               0.11\ntensorstore                              0.1.66\ntermcolor                                2.4.0\nterminado                                0.18.1\ntestpath                                 0.6.0\ntext-unidecode                           1.3\ntextblob                                 0.18.0.post0\ntexttable                                1.7.0\ntextual                                  0.67.1\ntf_keras                                 2.16.0\nTheano                                   1.0.5\nTheano-PyMC                              1.1.2\nthinc                                    8.2.5\nthreadpoolctl                            3.5.0\ntifffile                                 2024.5.22\ntime-machine                             2.14.1\ntimm                                     1.0.9\ntinycss2                                 1.3.0\ntokenizers                               0.20.0\ntoml                                     0.10.2\ntomli                                    2.0.1\ntomlkit                                  0.13.2\ntoolz                                    0.12.1\ntorch                                    2.2.0\ntorch-geometric                          2.6.1\ntorchaudio                               2.4.0\ntorchdata                                0.7.1\ntorchdiffeq                              0.2.4\ntorchinfo                                1.8.0\ntorchmetrics                             1.4.2\ntorchpack                                0.3.1\ntorchquantum                             0.1.8\ntorchvision                              0.17.0\ntornado                                  6.4.1\nTPOT                                     0.12.1\ntqdm                                     4.66.4\ntraceml                                  1.0.8\ntraitlets                                5.14.3\ntraittypes                               0.2.1\ntransformers                             4.45.1\ntreelite                                 4.3.0\ntriton                                   2.2.0\ntruststore                               0.8.0\ntrx-python                               0.3\ntsfresh                                  0.20.3\ntypeguard                                4.3.0\ntyper                                    0.12.3\ntyper-slim                               0.12.5\ntypes-python-dateutil                    2.9.0.20240316\ntyping_extensions                        4.12.2\ntyping-inspect                           0.9.0\ntyping-utils                             0.1.0\ntzdata                                   2024.1\nuc-micro-py                              1.0.3\nucx-py                                   0.39.2\nucxx                                     0.39.1\nujson                                    5.10.0\nunicodedata2                             15.1.0\nupdate-checker                           0.18.0\nuri-template                             1.3.0\nuritemplate                              3.0.1\nurllib3                                  2.2.1\nurwid                                    2.6.15\nurwid_readline                           0.15.1\nuvicorn                                  0.30.1\nuvloop                                   0.19.0\nvec_noise                                1.1.4\nvirtualenv                               20.21.0\nvisions                                  0.7.5\nvtk                                      9.3.1\nWand                                     0.6.13\nwandb                                    0.18.3\nwasabi                                   1.1.2\nwasserstein                              1.1.0\nwatchdog                                 5.0.3\nwatchfiles                               0.22.0\nwavio                                    0.0.9\nwcwidth                                  0.2.13\nweasel                                   0.4.1\nwebcolors                                24.6.0\nwebencodings                             0.5.1\nwebsocket-client                         1.8.0\nwebsockets                               12.0\nWerkzeug                                 3.0.4\nwhatthepatch                             1.0.6\nwheel                                    0.43.0\nwidgetsnbextension                       3.6.9\nwitwidget                                1.8.1\nwoodwork                                 0.31.0\nwordcloud                                1.9.3\nwrapt                                    1.16.0\nwurlitzer                                3.1.1\nxarray                                   2024.9.0\nxarray-einstats                          0.8.0\nxgboost                                  2.0.3\nxvfbwrapper                              0.2.9\nxxhash                                   3.4.1\nxyzservices                              2024.9.0\ny-py                                     0.6.2\nyapf                                     0.40.2\nyarl                                     1.9.4\nydata-profiling                          4.10.0\nydf                                      0.8.0\nyellowbrick                              1.5\nypy-websocket                            0.8.4\nzict                                     3.0.0\nzipp                                     3.19.2\nzstandard                                0.23.0\n","output_type":"stream"}]},{"cell_type":"code","source":"nodes_per_graph = nodes_per_graph_original = 7","metadata":{"id":"0p0ze4Qe2How","execution":{"iopub.status.busy":"2024-10-16T11:33:11.016708Z","iopub.execute_input":"2024-10-16T11:33:11.017047Z","iopub.status.idle":"2024-10-16T11:33:11.021707Z","shell.execute_reply.started":"2024-10-16T11:33:11.017011Z","shell.execute_reply":"2024-10-16T11:33:11.020816Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchdata\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchquantum as tq\nfrom torchquantum.layer.entanglement.op2_layer import Op2QAllLayer\nfrom torchquantum.layer.layers.layers import Op1QAllLayer, Op2QAllLayer\nfrom torchquantum.measurement import measure\n\nimport numpy as np\nimport os\nfrom tqdm import tqdm\nimport scipy\nimport warnings\nimport dgl\nfrom dgl.data import DGLDataset\nfrom dgl.dataloading import GraphDataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\n\nfrom sklearn import metrics\nfrom sklearn.preprocessing import normalize\n\nimport scipy.sparse as sp\nimport csv\nimport time\nimport pandas as pd\nfrom collections import OrderedDict\nfrom functools import partial\nimport pickle\nimport multiprocessing\nimport joblib\n\nimport torch_geometric\nfrom torch_geometric.nn import global_mean_pool\nfrom torch_geometric.utils import add_self_loops, degree, softmax\nimport torch.optim as optim\n\nfrom copy import deepcopy\nimport gc\n\nfrom particle import Particle\nimport pennylane as qml\nimport matplotlib.pyplot as plt\n%matplotlib inline\n","metadata":{"id":"kDgEhsePTK1h","colab":{"base_uri":"https://localhost:8080/"},"outputId":"24b14d7f-919e-4d88-e515-c63a5a4a6675","execution":{"iopub.status.busy":"2024-10-16T11:33:11.024052Z","iopub.execute_input":"2024-10-16T11:33:11.024356Z","iopub.status.idle":"2024-10-16T11:33:22.380518Z","shell.execute_reply.started":"2024-10-16T11:33:11.024319Z","shell.execute_reply":"2024-10-16T11:33:22.379741Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"DGL backend not selected or invalid.  Assuming PyTorch for now.\n","output_type":"stream"},{"name":"stdout","text":"Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n","output_type":"stream"}]},{"cell_type":"code","source":"## Download the jets along with storing them in a folder for future use, eliminating the need to download them again\nmain_dir = '/content/'\n\nimport energyflow\ndata = energyflow.qg_jets.load(num_data=20000, pad=True, ncol=4, generator='pythia',\n                        with_bc=False, cache_dir=main_dir+'/energyflow')","metadata":{"id":"aCmapYGUTWG4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ae427c23-09da-477f-bf9a-1959c64d7292","execution":{"iopub.status.busy":"2024-10-16T11:33:22.381822Z","iopub.execute_input":"2024-10-16T11:33:22.382962Z","iopub.status.idle":"2024-10-16T11:36:13.407109Z","shell.execute_reply.started":"2024-10-16T11:33:22.382916Z","shell.execute_reply":"2024-10-16T11:36:13.406088Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading QG_jets.npz from https://www.dropbox.com/s/fclsl7pukcpobsb/QG_jets.npz?dl=1 to /content//energyflow/datasets\nURL fetch failure on https://www.dropbox.com/s/fclsl7pukcpobsb/QG_jets.npz?dl=1: None -- Bad Request\nFailed to download QG_jets.npz from source 'dropbox', trying next source...\nDownloading QG_jets.npz from https://zenodo.org/record/3164691/files/QG_jets.npz?download=1 to /content//energyflow/datasets\n","output_type":"stream"}]},{"cell_type":"code","source":"jet_file_path = '/content/energyflow/datasets/QG_jets.npz'\ndata = np.load(jet_file_path)","metadata":{"id":"IZJZuPAvUJ-c","execution":{"iopub.status.busy":"2024-10-16T11:36:13.408473Z","iopub.execute_input":"2024-10-16T11:36:13.409335Z","iopub.status.idle":"2024-10-16T11:36:13.415657Z","shell.execute_reply.started":"2024-10-16T11:36:13.409298Z","shell.execute_reply":"2024-10-16T11:36:13.414654Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# @title\n### Reference - https://github.com/ML4SCI/QMLHEP/blob/main/Quantum_GNN_for_HEP_Roy_Forestano/utils/preprocess.py\n\ndef preprocess_fixed_nodes(x_data,y_data,nodes_per_graph=10): #,masses):\n    print('--- Finding All Unique Particles ---')\n    unique_particles = np.unique(x_data[:,:,3])\n    x_data = torch.tensor(x_data)\n    y_data = torch.tensor(y_data)\n    print()\n    print('--- Inserting Masses ---')\n    masses = torch.zeros((x_data.shape[0],x_data.shape[1]))\n    for i,particle in tqdm(enumerate(unique_particles)):\n        if particle!=0:\n            mass = Particle.from_pdgid(particle).mass/1000\n            inds = torch.where(particle==x_data[:,:,3])\n            masses[inds]=mass # GeV\n    print()\n    print('--- Calculating Momenta and Energies ---')\n    #theta = torch.arctan(torch.exp(-X[:,:,1]))*2 # polar angle\n    pt        = x_data[:,:,0]     # transverse momentum\n    rapidity  = x_data[:,:,1]     # rapidity\n    phi       = x_data[:,:,2]     # azimuthal angle\n\n    mt        = (pt**2+masses**2).sqrt() # Transverse mass\n    energy    = mt*torch.cosh(rapidity) # Energy per multiplicity bin\n    e_per_jet = energy.sum(axis=1)  # total energy per jet summed across multiplicity bins\n\n    px = pt*torch.cos(phi)  # momentum in x\n    py = pt*torch.sin(phi)  # momentum in y\n    pz = mt*torch.sinh(rapidity)  # momentum in z\n\n    # three momentum\n    p  = torch.cat(( px[:,:,None],\n                     py[:,:,None],\n                     pz[:,:,None]), dim=2 )\n\n    p_per_jet        = (p).sum(axis=1)  # total componet momentum per jet\n    pt_per_Mbin      = (p_per_jet[:,:2]**2).sum(axis=1).sqrt()  # transverse momentum per jet\n    mass_per_jet     = (e_per_jet**2-(p_per_jet**2).sum(axis=1)).sqrt() # mass per jet\n    rapidity_per_jet = torch.log( (e_per_jet+p_per_jet[:,2])/(e_per_jet-p_per_jet[:,2]) )/2  # rapidity per jet from analytical formula\n    end_multiplicity_indx_per_jet = (pt!=0).sum(axis=1).int() # see where the jet (graph) ends\n\n    x_data = torch.cat( ( x_data[:,:,:3],\n                          x_data[:,:,4:],\n                          masses[:,:,None],\n                          energy[:,:,None],\n                          p), dim=2)\n\n    x_data_max = (x_data.max(dim=1).values).max(dim=0).values\n    x_data = x_data/x_data_max\n\n    print()\n    print('--- Calculating Edge Tensors ---')\n    N = x_data[:,0,3].shape[0]  # number of jets (graphs)\n    M = nodes_per_graph #x_data[0,:,3].shape[0]  # number of max multiplicty\n    connections = nodes_per_graph\n    edge_tensor = torch.zeros((N,M,M))\n    edge_indx_tensor = torch.zeros((N,2,connections*(connections-1) )) # M*(connections-1) is the max number of edges we allow per jet\n    edge_attr_matrix = torch.zeros((N,connections*(connections-1),1))\n#     fixed_edges_list = torch.tensor([ [i,j] for i in range(connections) for j in range(connections) if i!=j]).reshape(2,90)\n\n    for jet in tqdm(range(N)):\n        stop_indx = end_multiplicity_indx_per_jet[jet] #connections # stop finding edges once we hit zeros -> when we hit 10\n        if end_multiplicity_indx_per_jet[jet]>=connections:\n            for m in range(connections):\n#                 inds_edge = np.argsort((energy[jet,m]+energy[jet,:stop_indx])**2-torch.sum((p[jet,m,:stop_indx]+p[jet,:stop_indx,:])**2,axis=1))[:connections]\n#                 edge_tensor[jet,m,:] = (energy[jet,m]+energy[jet,:connections])**2-torch.sum((p[jet,m,:]+p[jet,:connections,:])**2,axis=1)\n#                 edge_tensor[jet,m,m] = 0.\n#                 edge_tensor[jet,m,m]=((energy[jet,m]+energy[jet,m])**2-torch.sum((p[jet,m,:]+p[jet,m,:])**2,axis=0))\n                # inds_edge = torch.sqrt( (phi[jet,m]-phi[jet,:])**2 + (rapidity[jet,m]-rapidity[jet,:])**2 ).argsort()[:connections]\n                # edge_tensor[jet,m,:] = torch.sqrt( (phi[jet,m]-phi[jet,inds_edge])**2 + (rapidity[jet,m]-rapidity[jet,inds_edge])**2 )\n                edge_tensor[jet,m,:] = torch.sqrt( (phi[jet,m]-phi[jet,:connections])**2 + (rapidity[jet,m]-rapidity[jet,:connections])**2 )\n#                 inds_edge = np.argsort( (energy[jet,m]+energy[jet,:stop_indx])**2-torch.sum((p[jet,m,:stop_indx]+p[jet,:stop_indx,:])**2,axis=1) )[:connections]\n#                 edge_tensor[jet,m,inds_edge] = (energy[jet,m]+energy[jet,inds_edge])**2-torch.sum((p[jet,m,:]+p[jet,inds_edge,:])**2,axis=1)\n            edges_exist_at = torch.where(edge_tensor[jet,:,:].abs()>0)\n\n#             edge_indx_tensor[jet,:,:(edge_tensor[jet,:,:].abs()>0).sum()] = fixed_edges_list\n            edge_indx_tensor[jet,:,:(edge_tensor[jet,:,:].abs()>0).sum()] = torch.cat((edges_exist_at[0][None,:],edges_exist_at[1][None,:]),dim=0).reshape((2,edges_exist_at[0].shape[0]))\n            edge_attr_matrix[jet,:(edge_tensor[jet,:,:].abs()>0).sum(),0]  =  edge_tensor[jet,edges_exist_at[0],edges_exist_at[1]].flatten()\n\n    end_edges_indx_per_jet = (edge_attr_matrix!=0).sum(axis=1).int()\n    keep_inds =  torch.where(end_edges_indx_per_jet>=connections)[0]\n\n    edge_tensor = edge_tensor/edge_tensor.max()\n    edge_attr_matrix = edge_attr_matrix/edge_attr_matrix.max()\n\n    graph_help = torch.cat( ( (energy.max(axis=1).values/e_per_jet).reshape(x_data[:,0,3].shape[0],1),\n                              (mass_per_jet).reshape(x_data[:,0,3].shape[0],1),\n                              (end_multiplicity_indx_per_jet).reshape(x_data[:,0,3].shape[0],1).int(),\n                              (end_edges_indx_per_jet).reshape(x_data[:,0,3].shape[0],1).int() ), dim=1)\n\n    return x_data[keep_inds,:nodes_per_graph], y_data[keep_inds].long(), edge_tensor[keep_inds], edge_indx_tensor[keep_inds].long(), edge_attr_matrix[keep_inds], graph_help[keep_inds], masses\n","metadata":{"id":"lhY05LBQUeYY","execution":{"iopub.status.busy":"2024-10-16T11:36:13.417328Z","iopub.execute_input":"2024-10-16T11:36:13.417720Z","iopub.status.idle":"2024-10-16T11:36:13.443463Z","shell.execute_reply.started":"2024-10-16T11:36:13.417652Z","shell.execute_reply":"2024-10-16T11:36:13.442597Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# @title\n### Reference - https://github.com/bmdillon/JetCLR/blob/main/scripts/modules/jet_augs.py\n\ndef distort_jets( batch, strength=0.1, pT_clip_min=0.1 ):\n    '''\n    Input: batch of jets, shape (batchsize, 3, n_constit)\n    dim 1 ordering: (pT, eta, phi)\n    Output: batch of jets with each constituents position shifted independently, shifts drawn from normal with mean 0, std strength/pT, same shape as input\n    '''\n    pT = batch[:,0]   # (batchsize, n_constit)\n    shift_eta = np.nan_to_num( strength * np.random.randn(batch.shape[0], batch.shape[2]) / pT.clip(min=pT_clip_min), posinf = 0.0, neginf = 0.0 )# * mask\n    shift_phi = np.nan_to_num( strength * np.random.randn(batch.shape[0], batch.shape[2]) / pT.clip(min=pT_clip_min), posinf = 0.0, neginf = 0.0 )# * mask\n    shift = np.stack( [ np.zeros( (batch.shape[0], batch.shape[2]) ), shift_eta, shift_phi ], 1)\n    return batch + shift\n\ndef collinear_fill_jets( batch ):\n    '''\n    Input: batch of jets, shape (batchsize, 3, n_constit)\n    dim 1 ordering: (pT, eta, phi)\n    Output: batch of jets with collinear splittings, the function attempts to fill as many of the zero-padded args.nconstit\n    entries with collinear splittings of the constituents by splitting each constituent at most once, same shape as input\n    '''\n    batchb = batch.copy()\n    nc = batch.shape[2]\n    nzs = np.array( [ np.where( batch[:,0,:][i]>0.0)[0].shape[0] for i in range(len(batch)) ] )\n\n    for k in range(len(batch)):\n        nzs1 = np.max( [ nzs[k], int(nc/2) ] )\n        zs1 = int(nc-nzs1)\n        els = np.random.choice( np.linspace(0,nzs1-1,nzs1), size=zs1, replace=False )\n        rs = np.random.uniform( size=zs1 )\n        for j in range(zs1):\n            batchb[k,0,int(els[j])] = rs[j]*batch[k,0,int(els[j])]\n            batchb[k,0,int(nzs[k]+j)] = (1-rs[j])*batch[k,0,int(els[j])]\n            batchb[k,1,int(nzs[k]+j)] = batch[k,1,int(els[j])]\n            batchb[k,2,int(nzs[k]+j)] = batch[k,2,int(els[j])]\n\n    return batchb","metadata":{"id":"-uyS1h4zU4XB","cellView":"form","execution":{"iopub.status.busy":"2024-10-16T11:36:13.444766Z","iopub.execute_input":"2024-10-16T11:36:13.445347Z","iopub.status.idle":"2024-10-16T11:36:13.460716Z","shell.execute_reply.started":"2024-10-16T11:36:13.445302Z","shell.execute_reply":"2024-10-16T11:36:13.459897Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# @title\nclass QuarkGluonGraphDataset(dgl.data.dgl_dataset.DGLDataset):\n\n  def __init__(self, dataset_name, raw_dir, save_dir, data_folder_name, datafile_name, labelsfile_name, datatype='particles', dataset_size=12500,\n               nodes_per_graph = 5, spectral_augmentation=False, irc_safety_aug=False, url=None, hash_key=..., force_reload=False, verbose=False, transform=None,\n              device='cpu'):\n    self.data_folder = data_folder_name\n    self.datafile_name = datafile_name\n    self.labelsfile_name = labelsfile_name\n    self.datatype = datatype\n    self.nodes_per_graph = nodes_per_graph\n    self.spectral_augmentation = spectral_augmentation\n    self.drop_ra_nodes = False\n    self.drop_cp_nodes = False\n    self.aug_ratio = None\n    self.irc_safety_aug = irc_safety_aug\n    self.device = device\n    self.dataset_size = dataset_size\n    self.augment = False\n    self.nodes_per_aug_graph = None\n    super().__init__(dataset_name, url, raw_dir, save_dir, hash_key, force_reload, verbose, transform)\n\n  @property\n  def data_folder_name(self):\n    return self.data_folder\n\n  @property\n  def raw_path(self):\n    return os.path.join(self.raw_dir, self.data_folder_name)\n\n  @property\n  def save_path(self):\n    return os.path.join(self.save_dir, self.data_folder_name)\n\n  @property\n  def graph_path(self):\n    return os.path.join(self.save_path, 'graphs_and_labels')\n\n  @property\n  def info_path(self):\n    return os.path.join(self.save_path, 'graphs_and_labels')\n\n  def load(self):\n    graphs, label_dict = dgl.load_graphs(str(self.graph_path))\n    info_dict = dgl.data.utils.load_info(str(self.info_path))\n\n    self.graph_lists = graphs\n    self.graph_labels = label_dict[\"labels\"]\n    self.max_num_node = info_dict[\"max_num_node\"]\n    self.num_labels = info_dict[\"num_labels\"]\n\n  # def save(self,):\n  #   label_dict = {\"labels\": self.graph_labels}\n  #   info_dict = {\n  #           \"max_num_node\": self.max_num_node,\n  #           \"num_labels\": self.num_labels,\n  #       }\n  #   dgl.save_graphs(str(self.graph_path), self.graph_lists, label_dict)\n  #   dgl.data.utils.save_info(str(self.info_path), info_dict)\n\n  def process(self,):\n    data = np.load(os.path.join(self.raw_path, self.datafile_name))\n    X = data['X']\n    y = data['y']\n    X_l, y_l = [], []\n    i = 0\n\n    while len(X_l)!=self.dataset_size:\n        if np.unique(X[i].sum(axis=1).nonzero()).shape[0] >= self.nodes_per_graph:\n            sorted_inds = np.argsort(X[i,:,0])[::-1]\n            x = X[i][sorted_inds]\n            X_l.append(x[:self.nodes_per_graph, :])\n            y_l.append(y[i])\n        i += 1\n    X = np.array(X_l)\n    y = np.array(y_l)\n\n\n    if self.datatype == 'particles':\n      self.graph_lists = []\n      self.rationale_augmented_graph_lists_1 = []\n      self.rationale_augmented_graph_lists_2 = []\n      self.complement_augmented_graph_lists = []\n      x_data_proc, y_data_proc, edge_tensor, edge_indx_tensor, edge_attr_matrix, graph_help, masses = preprocess_fixed_nodes(X,y,nodes_per_graph = self.nodes_per_graph) #,masses[:N])\n      self.max_num_node = x_data_proc.shape[1]\n      self.graph_labels = y_data_proc\n      self.num_labels = y_data_proc.shape[0]\n\n      print('--- Creating graphs ---')\n      for i in tqdm(range(x_data_proc.shape[0])):\n        g = dgl.graph((edge_indx_tensor[i][0], edge_indx_tensor[i][1]))\n        g.ndata['node_attr'] = x_data_proc[i]\n        g.ndata['node_indices'] = torch.arange(x_data_proc[i].shape[0]).reshape(-1,1)\n        g.ndata['node_mass'] = masses[i][:self.nodes_per_graph]\n        g.edata['edge_attr'] = edge_attr_matrix[i].view(-1,)\n        g.to(self.device)\n        self.graph_lists.append(g)\n        self.rationale_augmented_graph_lists_1.append(g)\n        self.rationale_augmented_graph_lists_2.append(g)\n        self.complement_augmented_graph_lists.append(g)\n\n      if self.spectral_augmentation:\n        self.spectral_graph_lists = []\n        print('--- Creating spectral graphs ---')\n        for i in tqdm(range(x_data_proc.shape[0])):\n          g = SpectralGraph((edge_indx_tensor[i][0], edge_indx_tensor[i][1]), theta=0.1, delta_origin=0.05, edge_weights_matrix=edge_tensor[i])\n          g.ndata['node_attr'] = x_data_proc[i]\n          g.edata['edge_attr'] = edge_attr_matrix[i].view(-1,)\n          self.spectral_graph_lists.append(g)\n        # print(self.graph_lists)\n\n      if self.irc_safety_aug:\n        for idx in range(len(self.graph_lists)):\n          g = self.graph_lists[idx]\n          g.ndata['node_attr_irc'] = g.ndata['node_attr'].clone()\n          if self.device=='cuda':\n            g.ndata['node_attr_irc'][:,:3] = torch.Tensor(distort_jets(collinear_fill_jets(g.ndata['node_attr'][:,:3].T.unsqueeze(0).cpu().numpy()))).squeeze(0).T.cuda()\n          else:\n            g.ndata['node_attr_irc'][:,:3] = torch.Tensor(distort_jets(collinear_fill_jets(g.ndata['node_attr'][:,:3].T.unsqueeze(0).numpy()))).squeeze(0).T\n          pt, rapidity, phi = g.ndata['node_attr_irc'][:, 0], g.ndata['node_attr_irc'][:, 1], g.ndata['node_attr_irc'][:, 2]\n          mt = (pt**2+g.ndata['node_mass']**2).sqrt()\n          energy = mt*torch.cosh(rapidity)\n          px, py, pz = pt*torch.cos(phi), pt*torch.sin(phi), mt*torch.sinh(rapidity)\n          g.ndata['node_attr_irc'][:,3] =  mt\n          g.ndata['node_attr_irc'][:,4] = energy\n          g.ndata['node_attr_irc'][:,5] = px\n          g.ndata['node_attr_irc'][:,6] = py\n          g.ndata['node_attr_irc'][:,7] = pz\n\n  def has_cache(self):\n    if os.path.exists(self.graph_path) and os.path.exists(self.info_path):\n      return True\n    return False\n\n  def __len__(self,):\n    return len(self.graph_lists)\n\n  def augment_dataset(self, type, batched_graph, batch_size):\n    self.augment = True\n\n    if type == 'rationale':\n      return drop_nodes_prob_batch(batched_graph, batch_size), drop_nodes_prob_batch(batched_graph, batch_size)\n\n    if type == 'complement':\n      return drop_nodes_cp_batch(batched_graph, batch_size)\n\n  def __getitem__(self, idx):\n    if self.spectral_augmentation:\n      g1 = self.graph_lists[idx]\n      g2 = self.spectral_graph_lists[idx]\n      if self._transform is not None:\n        g1 = self._transform(g1)\n        g2 = self._transform(g2)\n      return g1, g2, self.graph_labels[idx]\n\n    else:\n      g = self.graph_lists[idx]\n      if self._transform is not None:\n        g = self._transform(g)\n      return g, self.graph_labels[idx]\n\n  @property\n  def num_classes(self):\n    return int(self.num_labels)","metadata":{"id":"Ym9AH6-SVLr-","cellView":"form","execution":{"iopub.status.busy":"2024-10-16T11:36:13.461876Z","iopub.execute_input":"2024-10-16T11:36:13.462198Z","iopub.status.idle":"2024-10-16T11:36:13.495521Z","shell.execute_reply.started":"2024-10-16T11:36:13.462167Z","shell.execute_reply":"2024-10-16T11:36:13.494645Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"main_dir = '/content/'\njet_folder_path = '/content/energyflow/'\n\nqg_dataset = QuarkGluonGraphDataset(dataset_name='Quark Gluon', raw_dir=main_dir, save_dir='/content',\n                                    data_folder_name=jet_folder_path, datafile_name=jet_file_path, labelsfile_name=jet_file_path,\n                                    datatype='particles', dataset_size=10000, nodes_per_graph=nodes_per_graph, spectral_augmentation=False, irc_safety_aug=True,\n                                   device='cuda')","metadata":{"id":"lTcJqvhaVYQU","colab":{"base_uri":"https://localhost:8080/"},"outputId":"86201fd8-eec2-4886-edc4-059eb19b3f12","execution":{"iopub.status.busy":"2024-10-16T11:36:13.499626Z","iopub.execute_input":"2024-10-16T11:36:13.499994Z","iopub.status.idle":"2024-10-16T11:36:32.307815Z","shell.execute_reply.started":"2024-10-16T11:36:13.499964Z","shell.execute_reply":"2024-10-16T11:36:32.306825Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"--- Finding All Unique Particles ---\n\n--- Inserting Masses ---\n","output_type":"stream"},{"name":"stderr","text":"14it [00:00, 1878.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n--- Calculating Momenta and Energies ---\n\n--- Calculating Edge Tensors ---\n","output_type":"stream"},{"name":"stderr","text":"100%|| 10000/10000 [00:05<00:00, 1803.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"--- Creating graphs ---\n","output_type":"stream"},{"name":"stderr","text":"100%|| 10000/10000 [00:04<00:00, 2130.92it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# @title\nclass GNN_imp_estimator(torch.nn.Module):\n    \"\"\"\n\n    Args:\n        num_layer (int): the number of GNN layers\n        emb_dim (int): dimensionality of embeddings\n        JK (str): last, concat, max or sum.\n        max_pool_layer (int): the layer from which we use max pool rather than add pool for neighbor aggregation\n        drop_ratio (float): dropout rate\n        gnn_type: gin, gcn, graphsage, gat\n\n    Output:\n        node representations\n\n    \"\"\"\n\n    def __init__(self, num_layer, emb_dim, in_dim, JK=\"last\", drop_ratio=0):\n        super(GNN_imp_estimator, self).__init__()\n        self.num_layer = num_layer\n        self.drop_ratio = drop_ratio\n        self.JK = JK\n\n        if self.num_layer < 2:\n            raise ValueError(\"Number of GNN layers must be greater than 1.\")\n\n\n        ###List of MLPs\n        self.gnns = torch.nn.ModuleList()\n        # self.gnns.append(torch_geometric.nn.conv.GCNConv(in_dim, 32))\n        # self.gnns.append(torch_geometric.nn.conv.GCNConv(32, 16))\n        # self.gnns.append(torch_geometric.nn.conv.GCNConv(16, 8))\n\n        self.gnns.append(dgl.nn.GraphConv(in_dim, 32, weight=True, bias=True))\n        self.gnns.append(dgl.nn.GraphConv(32, 16, weight=True, bias=True))\n        self.gnns.append(dgl.nn.GraphConv(16, 8, weight=True, bias=True))\n\n        ###List of batchnorms\n        self.batch_norms = torch.nn.ModuleList()\n        self.batch_norms.append(torch.nn.BatchNorm1d(32))\n        self.batch_norms.append(torch.nn.BatchNorm1d(16))\n        self.batch_norms.append(torch.nn.BatchNorm1d(8))\n\n        self.linear = torch.nn.Linear(8, 1)\n\n    def forward(self, *argv):\n        if len(argv) == 4:\n            x, edge_index, edge_attr, batch = argv[0], argv[1], argv[2], argv[3]\n            # Ensure edge_index is a 2D tensor (shape: [2, num_edges])\n            if edge_index.dim() != 2 or edge_index.size(0) != 2:\n                raise ValueError(\"edge_index must be a 2D tensor with shape [2, num_edges].\")\n\n            # Create the graph using DGL\n            graph = dgl.graph((edge_index[0], edge_index[1]))  # Create the graph from edge indices\n            graph.ndata['node_attr'] = x   # Assign node features\n            graph.edata['edge_attr'] = edge_attr  # Assign edge attributes\n\n        elif len(argv) == 2:\n            graph, batch = argv[0], argv[1]\n            x, edge_index, edge_attr = graph.ndata['node_attr'], graph.edges(), graph.edata['edge_attr']\n        else:\n            raise ValueError(\"unmatched number of arguments.\")\n\n\n        # x = self.x_embedding1(x[:, 0]) + self.x_embedding2(x[:, 1])\n\n        # h_list = [x]\n        # for layer in range(len(self.gnns)):\n        #     print('Layer : ',layer)\n        #     h = self.gnns[layer](graph, h_list[layer].float(), edge_weight=edge_attr)   #\n        #     h = self.batch_norms[layer](h)\n        #     if layer == len(self.gnns) - 1:\n        #         # remove relu for the last layer\n        #         h = F.dropout(h, self.drop_ratio, training=self.training)\n        #     else:\n        #         h = F.dropout(nn.ReLU()(h), self.drop_ratio, training=self.training)\n        #     h_list.append(h)\n\n        h0 = self.gnns[0](graph, x.float(), edge_weight=edge_attr) # self.gnns[layer](h, edge_index, edge_attr)\n        h0 = self.batch_norms[0](h0)\n        h0 = F.dropout(nn.ReLU()(h0), self.drop_ratio, training=self.training)\n        h1 = self.gnns[1](graph, h0, edge_weight=edge_attr)\n        h1 = self.batch_norms[1](h1)\n        h1 = F.dropout(nn.ReLU()(h1), self.drop_ratio, training=self.training)\n        h2 = self.gnns[2](graph, h1, edge_weight=edge_attr)\n        h2 = self.batch_norms[2](h2)\n        h2 = F.dropout(h2, self.drop_ratio, training=self.training)\n\n        node_representation = h2  #h_list[-1]\n        node_representation = self.linear(node_representation)\n        node_representation = softmax(node_representation, batch)\n\n        return node_representation","metadata":{"id":"iwFoIOb2XdjG","cellView":"form","execution":{"iopub.status.busy":"2024-10-16T11:36:32.309382Z","iopub.execute_input":"2024-10-16T11:36:32.309795Z","iopub.status.idle":"2024-10-16T11:36:32.329062Z","shell.execute_reply.started":"2024-10-16T11:36:32.309749Z","shell.execute_reply":"2024-10-16T11:36:32.328163Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# @title\nclass GNN(torch.nn.Module):\n    \"\"\"\n\n\n\n    Args:\n        num_layer (int): the number of GNN layers\n        emb_dim (int): dimensionality of embeddings\n        JK (str): last, concat, max or sum.\n        max_pool_layer (int): the layer from which we use max pool rather than add pool for neighbor aggregation\n        drop_ratio (float): dropout rate\n        gnn_type: gin, gcn, graphsage, gat\n\n    Output:\n        node representations\n\n    \"\"\"\n    def __init__(self, num_layer, in_dim, emb_dim, inter_dim, JK = \"last\", drop_ratio=0, gnn_type = \"gin\"):\n        super(GNN, self).__init__()\n        self.num_layer = num_layer\n        self.drop_ratio = drop_ratio\n        self.JK = JK\n\n        if self.num_layer < 2:\n            raise ValueError(\"Number of GNN layers must be greater than 1.\")\n\n        ###List of MLPs\n        self.gnns = torch.nn.ModuleList()\n        self.batch_norms = torch.nn.ModuleList()\n        # self.gnns.append(torch_geometric.nn.conv.GCNConv(in_dim, emb_dim))\n        if gnn_type == \"gin\":\n            self.gnns.append(GINConv(in_dim, aggr=\"add\"))\n            self.batch_norms.append(torch.nn.BatchNorm1d(inter_dim))\n        elif gnn_type == \"gcn\":\n            self.gnns.append(torch_geometric.nn.conv.GCNConv(in_dim, inter_dim))\n            self.batch_norms.append(torch.nn.BatchNorm1d(inter_dim))\n        elif gnn_type == \"gat\":\n            self.gnns.append(torch_geometric.nn.conv.GATConv(in_dim, inter_dim, heads=3, concat=False))\n            self.batch_norms.append(torch.nn.BatchNorm1d(inter_dim))\n        elif gnn_type == \"graphsage\":\n            self.gnns.append(GraphSAGEConv(in_dim))\n            self.batch_norms.append(torch.nn.BatchNorm1d(inter_dim))\n\n        for layer in range(num_layer):\n            if gnn_type == \"gin\":\n                self.gnns.append(GINConv(inter_dim, aggr=\"add\"))\n                self.batch_norms.append(torch.nn.BatchNorm1d(inter_dim))\n            elif gnn_type == \"gcn\":\n                self.gnns.append(torch_geometric.nn.conv.GCNConv(inter_dim, inter_dim))\n                self.batch_norms.append(torch.nn.BatchNorm1d(inter_dim))\n            elif gnn_type == \"gat\":\n                self.gnns.append(torch_geometric.nn.conv.GATConv(inter_dim, inter_dim, heads=3, concat=False))\n                self.batch_norms.append(torch.nn.BatchNorm1d(inter_dim))\n            elif gnn_type == \"graphsage\":\n                self.gnns.append(GraphSAGEConv(inter_dim))\n                self.batch_norms.append(torch.nn.BatchNorm1d(inter_dim))\n\n        if gnn_type == \"gin\":\n            self.gnns.append(GINConv(emb_dim, aggr=\"add\"))\n            self.batch_norms.append(torch.nn.BatchNorm1d(emb_dim))\n        elif gnn_type == \"gcn\":\n            self.gnns.append(torch_geometric.nn.conv.GCNConv(inter_dim, emb_dim))\n            self.batch_norms.append(torch.nn.BatchNorm1d(emb_dim))\n        elif gnn_type == \"gat\":\n            self.gnns.append(torch_geometric.nn.conv.GATConv(inter_dim, emb_dim, heads=3, concat=False))\n            self.batch_norms.append(torch.nn.BatchNorm1d(emb_dim))\n        elif gnn_type == \"graphsage\":\n            self.gnns.append(GraphSAGEConv(emb_dim))\n            self.batch_norms.append(torch.nn.BatchNorm1d(emb_dim))\n\n\n    #def forward(self, x, edge_index, edge_attr):\n    def forward(self, *argv):\n        if len(argv) == 3:\n            x, edge_index, edge_attr = argv[0], argv[1], argv[2]\n        elif len(argv) == 1:\n            # data = argv[0]\n            # x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n            graph = argv[0]\n            x, edge_index, edge_attr = graph.ndata['node_attr'], graph.edges(), graph.edata['edge_attr']\n        else:\n            raise ValueError(\"unmatched number of arguments.\")\n\n        # print(x)\n        # h_list = [x]\n        h = x\n        for layer in range(self.num_layer+2):\n            h = self.gnns[layer](h, edge_index, edge_attr)   #h_list[layer]\n            h = self.batch_norms[layer](h)\n            #h = F.dropout(F.relu(h), self.drop_ratio, training = self.training)\n            if layer == self.num_layer+1:\n                #remove relu for the last layer\n                h = F.dropout(h, self.drop_ratio, training = self.training)\n            else:\n                h = F.dropout(F.relu(h), self.drop_ratio, training = self.training)\n            # h_list.append(h)\n\n        ### Different implementations of Jk-concat\n        if self.JK == \"concat\":\n            node_representation = torch.cat(h_list, dim = 1)\n        elif self.JK == \"last\":\n            node_representation = h   #h_list[-1]\n        elif self.JK == \"max\":\n            h_list = [h.unsqueeze(0) for h in h_list]\n            node_representation = torch.max(torch.cat(h_list, dim = 0), dim = 0)[0]\n        elif self.JK == \"sum\":\n            h_list = [h.unsqueeze(0) for h in h_list]\n            node_representation = torch.sum(torch.cat(h_list, dim = 0), dim = 0)[0]\n\n        return node_representation\n\n    def forward_gradc(self, *argv):\n        if len(argv) == 3:\n            x, edge_index, edge_attr = argv[0], argv[1], argv[2]\n        elif len(argv) == 1:\n            data = argv[0]\n            x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n        else:\n            raise ValueError(\"unmatched number of arguments.\")\n\n        h_list = [x]\n        for layer in range(self.num_layer+2):\n            h = self.gnns[layer](h_list[layer], edge_index, edge_attr)\n            h = self.batch_norms[layer](h)\n            h = F.dropout(F.relu(h), self.drop_ratio, training = self.training)\n            if layer == self.num_layer - 1:\n                #remove relu for the last layer\n                h = F.dropout(h, self.drop_ratio, training = self.training)\n            else:\n                h = F.dropout(F.relu(h), self.drop_ratio, training = self.training)\n            h_list.append(h)\n\n        ### Different implementations of Jk-concat\n        if self.JK == \"concat\":\n            node_representation = torch.cat(h_list, dim = 1)\n        elif self.JK == \"last\":\n            node_representation = h_list[-1]\n        elif self.JK == \"max\":\n            h_list = [h.unsqueeze(0) for h in h_list]\n            node_representation = torch.max(torch.cat(h_list, dim = 0), dim = 0)[0]\n        elif self.JK == \"sum\":\n            h_list = [h.unsqueeze(0) for h in h_list]\n            node_representation = torch.sum(torch.cat(h_list, dim = 0), dim = 0)[0]\n\n        return node_representation","metadata":{"id":"zGuASKZx4Vxm","cellView":"form","execution":{"iopub.status.busy":"2024-10-16T11:36:32.330337Z","iopub.execute_input":"2024-10-16T11:36:32.330712Z","iopub.status.idle":"2024-10-16T11:36:32.361953Z","shell.execute_reply.started":"2024-10-16T11:36:32.330650Z","shell.execute_reply":"2024-10-16T11:36:32.361045Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"#### Quantum circuit","metadata":{"id":"EjdpTpoY4eel"}},{"cell_type":"code","source":"# !pip install pennylane qiskit pennylane-qiskit pylatexenc  ## new version","metadata":{"id":"dFzB3NOrZQpl","execution":{"iopub.status.busy":"2024-10-16T11:36:32.363125Z","iopub.execute_input":"2024-10-16T11:36:32.363697Z","iopub.status.idle":"2024-10-16T11:36:32.375784Z","shell.execute_reply.started":"2024-10-16T11:36:32.363642Z","shell.execute_reply":"2024-10-16T11:36:32.374919Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# import pennylane as qml\n# from pennylane import numpy as np\n# import qiskit\n# print(qml.__version__)\n# print(qiskit.__version__)\n# import pennylane_qiskit\n# print(pennylane_qiskit.__version__)","metadata":{"id":"379UNbDaYw3_","execution":{"iopub.status.busy":"2024-10-16T11:36:32.376754Z","iopub.execute_input":"2024-10-16T11:36:32.377043Z","iopub.status.idle":"2024-10-16T11:36:32.385549Z","shell.execute_reply.started":"2024-10-16T11:36:32.377013Z","shell.execute_reply":"2024-10-16T11:36:32.384740Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"\n# # Define the quantum device using Qiskit Aer simulator backend\n# dev = qml.device(\"qiskit.aer\", wires=nodes_per_graph)\n\n# class BetterBetterPennyLaneLayer(torch.nn.Module):\n#     def __init__(self, nodes_per_graph, num_layers, input_dim, device, entanglement_type='SWAP', encoding_type='RY'):\n#         super(BetterBetterPennyLaneLayer, self).__init__()\n#         self.device = device\n#         self.num_qubits = nodes_per_graph\n#         self.entanglement_type = entanglement_type\n#         self.encoding_type = encoding_type\n\n#         self.num_layers = num_layers\n#         self.input_dim = input_dim\n\n#         # Define the QNode for applying the quantum circuit\n#         self.qnode = qml.QNode(self.quantum_circuit, dev, interface=\"torch\")\n\n#     def quantum_circuit(self, inputs, weights):\n#         # Encoding the input features using the selected encoding method\n#         if self.encoding_type == 'Amplitude':\n#             # Amplitude Embedding (requires input size to be a power of 2 and normalized)\n#             qml.AmplitudeEmbedding(features=inputs, wires=range(self.num_qubits), normalize=True, pad_with=False)\n\n#         elif self.encoding_type == 'IQP':\n#             # IQP Embedding\n#             qml.IQPEmbedding(features=inputs, wires=range(self.num_qubits), n_repeats=2)\n\n#         elif self.encoding_type == 'Displacement':\n#             # Displacement Embedding (for continuous-variable quantum circuits)\n#             qml.DisplacementEmbedding(features=inputs, wires=range(self.num_qubits), method=\"amplitude\")\n\n#         else:\n#             # Encoding with rotation gates\n#             for q in range(self.num_qubits):\n#                 if self.encoding_type == 'RY':\n#                     qml.RY(inputs[q], wires=q)\n#                 elif self.encoding_type == 'RZ':\n#                     qml.RZ(inputs[q], wires=q)\n#                 elif self.encoding_type == 'RX':\n#                     qml.RX(inputs[q], wires=q)\n#                 elif self.encoding_type == 'H':\n#                     qml.Hadamard(wires=q)\n#                 elif self.encoding_type == 'Phase':\n#                     qml.PhaseShift(inputs[q], wires=q)\n\n#         # Apply quantum layers\n#         weight_idx = 0\n#         for l in range(self.num_layers):\n#             for q in range(self.num_qubits):\n#                 # Apply rotation gates with trainable parameters (weights)\n#                 qml.RX(weights[weight_idx], wires=q)\n#                 qml.RY(weights[weight_idx + 1], wires=q)\n#                 qml.RZ(weights[weight_idx + 2], wires=q)\n#                 weight_idx += 3\n\n#             # Apply entanglement based on the selected type\n#             if self.entanglement_type == 'CNOT':\n#                 for q in range(self.num_qubits - 1):\n#                     qml.CNOT(wires=[q, q + 1])\n#             elif self.entanglement_type == 'CZ':\n#                 for q in range(self.num_qubits - 1):\n#                     qml.CZ(wires=[q, q + 1])\n#             elif self.entanglement_type == 'SWAP':\n#                 for q in range(self.num_qubits - 1):\n#                     qml.SWAP(wires=[q, q + 1])\n\n#         # Measure the expectation value of the PauliZ operator for each qubit\n#         return [qml.expval(qml.PauliZ(q)) for q in range(self.num_qubits)]\n\n#     def forward(self, inputs):\n#         # Randomly initialize weights for the quantum circuit\n#         weights = torch.rand(self.num_layers * 3 * self.num_qubits, requires_grad=True)\n\n#         # Compute the quantum circuit\n#         return self.qnode(inputs, weights)\n\n# # Instantiate the quantum model\n# nodes_per_graph = 7\n# pl_model = BetterBetterPennyLaneLayer(nodes_per_graph, num_layers=3, input_dim = 8, device='cpu', entanglement_type='SWAP', encoding_type='IQP')\n\n# # Example input for the quantum circuit (random inputs)\n# inputs = torch.rand(nodes_per_graph)\n\n# # Forward pass through the model\n# # output = pl_model(inputs)\n\n# pl_model(inputs)\n# # # Extract the Qiskit circuit from the PennyLane QNode\n# # qiskit_circuit = load(pl_model.qnode)\n\n# # # Now draw the Qiskit circuit using the `mpl` format and styles\n# # qiskit_circuit.draw('mpl',\n# #                     plot_barriers=True,\n# #                     reverse_bits=True,\n# #                     style='iqp',        # You can choose 'iqp', 'iqp-dark', 'clifford'\n# #                     idle_wires=True,\n# #                     vertical_compression='high')\n# # Drawing the quantum circuit\n","metadata":{"id":"-rIqSzOWbEzu","execution":{"iopub.status.busy":"2024-10-16T11:36:32.386511Z","iopub.execute_input":"2024-10-16T11:36:32.386805Z","iopub.status.idle":"2024-10-16T11:36:32.396627Z","shell.execute_reply.started":"2024-10-16T11:36:32.386759Z","shell.execute_reply":"2024-10-16T11:36:32.395949Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# drawer = qml.draw(pl_model.qnode)\n# print(drawer(inputs, torch.rand(pl_model.num_layers * 3 * pl_model.num_qubits)))","metadata":{"id":"uOhqABVik7k1","execution":{"iopub.status.busy":"2024-10-16T11:36:32.397990Z","iopub.execute_input":"2024-10-16T11:36:32.398326Z","iopub.status.idle":"2024-10-16T11:36:32.409340Z","shell.execute_reply.started":"2024-10-16T11:36:32.398286Z","shell.execute_reply":"2024-10-16T11:36:32.408482Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# dev._circuit.draw('mpl',\n#                   plot_barriers=True,\n#                   reverse_bits=True,\n#                   style = 'iqp',       # 'iqp-dark', 'clifford',\n#                   idle_wires=True,\n#                   vertical_compression='high',\n#                   # fold=-1,\n#                   )","metadata":{"id":"bOXBrr-Ndhy7","execution":{"iopub.status.busy":"2024-10-16T11:36:32.412195Z","iopub.execute_input":"2024-10-16T11:36:32.412450Z","iopub.status.idle":"2024-10-16T11:36:32.419888Z","shell.execute_reply.started":"2024-10-16T11:36:32.412422Z","shell.execute_reply":"2024-10-16T11:36:32.419037Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchquantum as tq\nimport torchquantum.functional as tqf\nfrom itertools import combinations\n\nclass IQPEmbedding(tq.QuantumModule):\n    def __init__(self, wires, n_repeats=1, pattern=None):\n        \"\"\"\n        Initialize the IQPEmbedding with specified number of qubits and repetitions.\n\n        Args:\n            wires (list[int]): List of qubits (wires) to apply the operations on.\n            n_repeats (int): Number of repetitions of the embedding circuit.\n            pattern (list[tuple]): Optional custom pattern for entanglement.\n        \"\"\"\n        super().__init__()\n        self.wires = wires  # The number of qubits (wires)\n        self.n_repeats = n_repeats  # Number of repetitions for the embedding\n        if pattern is None:\n            # Default to an all-to-all entanglement pattern\n            self.pattern = list(combinations(wires, 2))\n        else:\n            self.pattern = pattern  # Custom entanglement pattern\n\n    def forward(self, q_device, features):\n        \"\"\"\n        Apply the IQPEmbedding on the quantum device.\n\n        Args:\n            q_device (tq.QuantumDevice): The quantum device (simulator).\n            features (torch.Tensor): Tensor of features to encode.\n                Shape: (batch_size, num_wires, feature_dim)\n        \"\"\"\n        batch_size = features.shape[0]\n        n_wires = len(self.wires)\n        n_features = features.shape[-1]\n\n        if n_wires != features.shape[1]:\n            raise ValueError(f\"Feature dimension ({features.shape[1]}) must match number of wires ({n_wires}).\")\n\n        for batch_idx in range(batch_size):\n            feature_batch = features[batch_idx]\n            # print(feature_batch.shape)\n            for _ in range(self.n_repeats):\n                # Apply Hadamard gates and RZ rotations for each wire\n                for i, wire in enumerate(self.wires):\n                    tqf.hadamard(q_device, wires=wire)\n                    # Ensure we pass a scalar for the RZ gate (e.g., the first feature in feature_batch)\n                    tqf.rz(q_device, wires=wire, params=feature_batch[i, 0])  # Pick the first feature value\n\n                # Apply ZZ entanglement according to the pattern\n                for (wire1, wire2) in self.pattern:\n                    # Multiply the selected feature scalars for the interaction\n                    tqf.multirz(q_device, n_wires=2, wires=[wire1, wire2],\n                                params=feature_batch[self.wires.index(wire1), 0] * feature_batch[self.wires.index(wire2), 0])\n\n\n# Example usage\nn_qubit = 10\n\n# Sample input data for embedding\ndata = torch.rand((20, n_qubit, 8))  # Batch of size 2000, 4 wires, 8 features per wire\n\n# Instantiate the quantum device and the circuit\nqdev = tq.QuantumDevice(n_wires=n_qubit, bsz=data.shape[0], device='cpu')\n\n# Initialize the circuit\nencoder = IQPEmbedding(wires=range(n_qubit), n_repeats=3)\n\n# Apply the circuit to the quantum device\nencoder(qdev, data)\n\n# Get the quantum state\nquantum_state = qdev.get_states_1d()\nprint(quantum_state)\n","metadata":{"scrolled":true,"id":"Tqj-QZ6c2HpL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"020798fc-b676-46e0-b0a7-b2c6850d0345","execution":{"iopub.status.busy":"2024-10-16T11:36:32.421195Z","iopub.execute_input":"2024-10-16T11:36:32.421550Z","iopub.status.idle":"2024-10-16T11:36:34.117268Z","shell.execute_reply.started":"2024-10-16T11:36:32.421509Z","shell.execute_reply":"2024-10-16T11:36:34.116307Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"tensor([[-0.0096+0.0003j, -0.0423+0.0174j, -0.0143-0.0110j,  ...,\n          0.0437-0.0161j, -0.0016+0.0427j,  0.0076+0.0125j],\n        [-0.0096+0.0003j, -0.0423+0.0174j, -0.0143-0.0110j,  ...,\n          0.0437-0.0161j, -0.0016+0.0427j,  0.0076+0.0125j],\n        [-0.0096+0.0003j, -0.0423+0.0174j, -0.0143-0.0110j,  ...,\n          0.0437-0.0161j, -0.0016+0.0427j,  0.0076+0.0125j],\n        ...,\n        [-0.0096+0.0003j, -0.0423+0.0174j, -0.0143-0.0110j,  ...,\n          0.0437-0.0161j, -0.0016+0.0427j,  0.0076+0.0125j],\n        [-0.0096+0.0003j, -0.0423+0.0174j, -0.0143-0.0110j,  ...,\n          0.0437-0.0161j, -0.0016+0.0427j,  0.0076+0.0125j],\n        [-0.0096+0.0003j, -0.0423+0.0174j, -0.0143-0.0110j,  ...,\n          0.0437-0.0161j, -0.0016+0.0427j,  0.0076+0.0125j]])\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torchquantum as tq\nimport torchquantum.functional as tqf\n\nclass DisplacementEmbedding(tq.QuantumModule):\n    \"\"\"\n    Encodes features into the displacement amplitudes or phases of quantum states\n    in a way similar to PennyLane's DisplacementEmbedding but using TorchQuantum.\n    \"\"\"\n    def __init__(self, n_features, wires, method=\"amplitude\", c=0.1):\n        super().__init__()\n        self.n_features = n_features\n        self.wires = wires\n        self.method = method\n        self.c = c\n\n        if self.method not in [\"amplitude\", \"phase\"]:\n            raise ValueError(f\"Method must be 'amplitude' or 'phase', but got {self.method}.\")\n\n    def forward(self, q_device, features):\n        \"\"\"\n        Process the input features and apply the displacement embedding to each wire of the quantum device.\n\n        Args:\n            q_device (tq.QuantumDevice): Quantum device (simulator).\n            features (torch.Tensor): Input features of shape (batch_size, num_wires, num_features).\n                                     For example, (20, 10, 8).\n        \"\"\"\n        batch_size, n_wires, n_features = features.shape\n\n        # Ensure that the number of wires matches the input dimension\n        if n_wires != len(self.wires):\n            raise ValueError(f\"Number of wires ({len(self.wires)}) does not match feature dimension ({n_wires}).\")\n\n        for batch_idx in range(batch_size):\n            # Extract the features for this batch\n            feature_batch = features[batch_idx]\n\n            for i, wire in enumerate(self.wires):\n                for j in range(n_features):\n                    if self.method == \"amplitude\":\n                        # Encode into displacement amplitudes using the j-th feature\n                        displacement_amp = feature_batch[i, j]\n                        displacement_phase = self.c\n                    elif self.method == \"phase\":\n                        # Encode into displacement phases using the j-th feature\n                        displacement_amp = self.c\n                        displacement_phase = feature_batch[i, j]\n\n                    # Apply the displacement operation on the quantum device\n                    # Assuming tqf.rx and tqf.rz simulate the behavior of displacement for this illustration\n                    tqf.rx(q_device, wires=wire, params=displacement_amp)\n                    tqf.rz(q_device, wires=wire, params=displacement_phase)\n\n# Usage Example:\n\n# Create a quantum device with the necessary wires\nn_wires = 10  # The number of wires must match the second dimension of the input data\n\n# Create features with shape (20, 10, 8) - 20 batches, 10 wires, and 8 features per wire\nfeatures = torch.rand((256, n_wires, 8))\n\nq_device = tq.QuantumDevice(n_wires=n_wires, bsz=features.shape[0], device='cpu')\n# Initialize the DisplacementEmbedding\nembedding = DisplacementEmbedding(n_features=n_wires, wires=list(range(n_wires)), method=\"amplitude\") # \"amplitude\", \"phase\"\n\n# Apply the embedding\nembedding(q_device, features)\n\n# Print the quantum state to check the result\nprint(q_device.get_states_1d())\n","metadata":{"id":"nn9RSM-82HpO","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ff72670e-d64d-43d5-c965-de9a2847cfa0","execution":{"iopub.status.busy":"2024-10-16T11:36:34.119599Z","iopub.execute_input":"2024-10-16T11:36:34.119987Z","iopub.status.idle":"2024-10-16T11:36:53.067385Z","shell.execute_reply.started":"2024-10-16T11:36:34.119946Z","shell.execute_reply":"2024-10-16T11:36:53.066459Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"tensor([[-0.0518-0.0485j,  0.0339+0.0661j,  0.0352+0.0275j,  ...,\n          0.0048-0.0046j,  0.0014-0.0037j, -0.0027+0.0032j],\n        [-0.0518-0.0485j,  0.0339+0.0661j,  0.0352+0.0275j,  ...,\n          0.0048-0.0046j,  0.0014-0.0037j, -0.0027+0.0032j],\n        [-0.0518-0.0485j,  0.0339+0.0661j,  0.0352+0.0275j,  ...,\n          0.0048-0.0046j,  0.0014-0.0037j, -0.0027+0.0032j],\n        ...,\n        [-0.0518-0.0485j,  0.0339+0.0661j,  0.0352+0.0275j,  ...,\n          0.0048-0.0046j,  0.0014-0.0037j, -0.0027+0.0032j],\n        [-0.0518-0.0485j,  0.0339+0.0661j,  0.0352+0.0275j,  ...,\n          0.0048-0.0046j,  0.0014-0.0037j, -0.0027+0.0032j],\n        [-0.0518-0.0485j,  0.0339+0.0661j,  0.0352+0.0275j,  ...,\n          0.0048-0.0046j,  0.0014-0.0037j, -0.0027+0.0032j]])\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\n\ndef pad_or_truncate_to_power_of_two(data, pad_with=0):\n    \"\"\"\n    Convert input data into a size of 2^n by padding or truncating.\n\n    Parameters:\n    - data: torch.Tensor of shape (batch_size, input_size, features)\n    - pad_with: Value to pad with if the data needs to be padded.\n\n    Returns:\n    - padded_data: torch.Tensor of shape (batch_size, target_size, features)\n    \"\"\"\n    print(data.shape)\n    batch_size, input_size, features = data.shape\n\n    # Calculate the next power of 2 for the input_size\n    n = torch.ceil(torch.log2(torch.tensor(input_size, dtype=torch.float))).int().item()\n    target_size = 2 ** n\n\n    # If input size is less than target size, pad with `pad_with`\n    if input_size < target_size:\n        padded_data = F.pad(data, (0, 0, 0, target_size - input_size), mode='constant', value=pad_with)\n    # If input size is greater than target size, truncate the extra elements\n    else:\n        padded_data = data[:, :target_size, :]\n\n    return padded_data\n\ndef normalize_data(data):\n    \"\"\"\n    Normalize input data such that the sum of squares of each sample is 1.\n\n    Parameters:\n    - data: torch.Tensor of shape (batch_size, N, features)\n\n    Returns:\n    - normalized_data: torch.Tensor of shape (batch_size, N, features)\n    \"\"\"\n    # Calculate the L2 norm (sum of squares) for each sample in the batch along the last two dimensions\n    norm = torch.sqrt(torch.sum(data ** 2, dim=(1, 2), keepdim=True))\n\n    # Normalize each sample by dividing by its norm\n    normalized_data = data / (norm + 1e-10)\n\n    return normalized_data\n\n# # Example usage:\n# # Sample input data of size (2000, 10, 8)\n# data = torch.rand((2000, 10, 8))\n\n# # Convert to a size that is a power of 2\n# converted_data = pad_or_truncate_to_power_of_two(data)\n\n# # Normalize the data\n# normalized_data = normalize_data(converted_data)\n\n# print(\"Converted Data Shape:\", converted_data.shape)\n# print(\"Normalized Data Shape:\", normalized_data.shape)\n\n# # Apply amplitude encoding (assuming `amplitude_encoder` is defined elsewhere)\n# # amplitude_encoder(qdev, normalized_data)\n","metadata":{"id":"9LTkuQziJqtu","jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2024-10-16T11:36:53.068763Z","iopub.execute_input":"2024-10-16T11:36:53.069066Z","iopub.status.idle":"2024-10-16T11:36:53.078309Z","shell.execute_reply.started":"2024-10-16T11:36:53.069034Z","shell.execute_reply":"2024-10-16T11:36:53.077462Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import torchquantum as tq\nimport torch\nimport torch.nn.functional as F\nimport torch.nn as nn\n\nTOLERANCE = 1e-10\n\nclass AmplitudeEmbedding(tq.QuantumModule):\n    def __init__(self, num_qubits, pad_with=None, normalize=True):\n        super(AmplitudeEmbedding, self).__init__()\n        self.num_qubits = num_qubits\n        self.pad_with = pad_with\n        self.normalize = normalize\n\n    def forward(self, qdev, data):\n        \"\"\"Amplitude embedding using torchquantum basic gates.\"\"\"\n        # Calculate the required number of amplitudes\n        required_size = 2 ** self.num_qubits\n\n        # Reshape data to ensure proper dimensionality for padding\n        if data.ndim == 3:\n            batch_size, input_size, features = data.shape\n            # Flatten the features dimension\n            data = data.view(batch_size, input_size * features)\n        else:\n            raise ValueError(\"Input data must be of shape (batch_size, input_size, features).\")\n\n        # Pad the data if necessary\n        if data.shape[1] < required_size:\n            if self.pad_with is not None:\n                pad_size = required_size - data.shape[1]\n                data = F.pad(data, (0, pad_size), mode='constant', value=self.pad_with)\n            else:\n                raise ValueError(\"Input data must have a size of 2^n or provide pad_with value.\")\n\n        # Normalize the data if required\n        if self.normalize:\n            data = F.normalize(data, p=2, dim=1)\n\n        # Check if the data is properly normalized\n        norm = torch.sum(data ** 2, dim=1)\n        # print(\"Norm:\", norm)\n        # Check if the norm is close enough to 1 for all samples in the batch\n        if not torch.allclose(norm, torch.ones_like(norm), atol=TOLERANCE):\n            raise ValueError(\"Input data must be normalized such that the sum of squares is 1.\")\n\n        # Reset quantum device states before encoding (Pass the batch size)\n        qdev.reset_states(bsz=qdev.bsz)\n\n        # Amplitude encoding: Decompose the amplitude preparation into basic gates\n        self._apply_amplitude_encoding(qdev, data.view(-1, required_size))  # Ensure the data shape matches the encoding requirement\n\n    def _apply_amplitude_encoding(self, qdev, data):\n        \"\"\"Apply amplitude encoding using basic gates.\"\"\"\n        batch_size = data.shape[0]\n\n        # Thetas for RY gates are calculated from the data amplitudes\n        for i in range(self.num_qubits):\n            for b in range(batch_size):\n                theta = 2 * torch.acos(data[b, i])  # Ensure you are accessing the right element\n\n                # Wrap theta as a torch.nn.Parameter\n                theta_param = nn.Parameter(theta, requires_grad=False)\n\n                # Apply the RY gate for the ith qubit\n                tq.RY(has_params=True, trainable=False)(qdev, wires=i, params=theta_param)\n\n        # Apply CNOT gates for entanglement between qubits\n        for i in range(self.num_qubits - 1):\n            tq.CNOT()(qdev, wires=[i, i + 1])\n\n# Example usage:\n# Initialize a 2-qubit quantum device\nn_qubit = 10\n\n# Sample input data for amplitude embedding\ndata = torch.rand((20, n_qubit, 8))  # Should be of size (2000, 10, 8)\n\nqdev = tq.QuantumDevice(n_wires=n_qubit, bsz=data.shape[0], device='cpu')\n\n# Convert to a size that is a power of 2\nconverted_data = pad_or_truncate_to_power_of_two(data)  # You need to define this function\n\n# Normalize the data\nnormalized_data = normalize_data(converted_data)  # You need to define this function\n\n# Initialize the amplitude embedding layer\namplitude_encoder = AmplitudeEmbedding(num_qubits=n_qubit, normalize=True, pad_with=0.0)\n\n# Apply amplitude encoding\namplitude_encoder(qdev, normalized_data)\n\n# Get the quantum state\nquantum_state = qdev.get_states_1d()\nprint(quantum_state)\n","metadata":{"id":"KMtqZdOeBxvp","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d549ae1a-a579-4cdc-e441-528f9e2849ea","jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2024-10-16T11:36:53.079964Z","iopub.execute_input":"2024-10-16T11:36:53.080419Z","iopub.status.idle":"2024-10-16T11:36:53.218480Z","shell.execute_reply.started":"2024-10-16T11:36:53.080374Z","shell.execute_reply":"2024-10-16T11:36:53.217577Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"torch.Size([20, 10, 8])\ntensor([[5.3732e-05+0.j, 1.0775e-04+0.j, 7.4130e-04+0.j,  ..., 1.2132e-03+0.j,\n         1.7635e-04+0.j, 8.7938e-05+0.j],\n        [5.3732e-05+0.j, 1.0775e-04+0.j, 7.4130e-04+0.j,  ..., 1.2132e-03+0.j,\n         1.7635e-04+0.j, 8.7938e-05+0.j],\n        [5.3732e-05+0.j, 1.0775e-04+0.j, 7.4130e-04+0.j,  ..., 1.2132e-03+0.j,\n         1.7635e-04+0.j, 8.7938e-05+0.j],\n        ...,\n        [5.3732e-05+0.j, 1.0775e-04+0.j, 7.4130e-04+0.j,  ..., 1.2132e-03+0.j,\n         1.7635e-04+0.j, 8.7938e-05+0.j],\n        [5.3732e-05+0.j, 1.0775e-04+0.j, 7.4130e-04+0.j,  ..., 1.2132e-03+0.j,\n         1.7635e-04+0.j, 8.7938e-05+0.j],\n        [5.3732e-05+0.j, 1.0775e-04+0.j, 7.4130e-04+0.j,  ..., 1.2132e-03+0.j,\n         1.7635e-04+0.j, 8.7938e-05+0.j]])\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torchquantum as tq\n\nclass BetterBetterTorchLayer(torch.nn.Module):\n    def __init__(self, nodes_per_graph, num_layers, input_dim, device, entanglement_type='CNOT', encoding_type='RY'):\n        super(BetterBetterTorchLayer, self).__init__()\n        self.device = device\n        self.num_qubits = nodes_per_graph\n        self.entanglement_type = entanglement_type\n        self.encoding_type = encoding_type  # Encoding type\n        inputs = []\n        self.node_attr_count = 0\n        self.amplitude_encoding = False\n        self.IQP_encoding = False\n        self.displacement_encoding = False\n\n        # Choose the type of encoding\n        if self.encoding_type == 'AmplitudeEncoding':\n            self.amplitude_encoding = True\n        elif self.encoding_type == 'IQPEncoding':\n            self.IQP_encoding = True\n        elif self.encoding_type == 'DisplacementEncoding':\n            self.displacement_encoding = True\n        else:\n            self.amplitude_encoding = False\n            self.IQP_encoding = False\n            self.displacement_encoding = False\n\n        # Standard gate encoding for node attributes\n        q_control = 0  # Define the control qubit as the first qubit (you can modify this as needed)\n        q2 = 1  # Define a second qubit for gates like SWAP (you can modify this as well)\n        theta, phi, lambda_ = 0.5, 0.3, 0.1  # Example values for U3 gate parameters (adjustable)\n\n        if not self.amplitude_encoding and not self.IQP_encoding and not self.displacement_encoding:\n            for q in range(self.num_qubits):\n                for d in range(input_dim):\n                    if self.encoding_type == 'RY':\n                        # Y-axis rotation encoding\n                        inputs.append({'input_idx': self.node_attr_count, 'func': 'ry', 'wires': [q]})\n\n                    elif self.encoding_type == 'RZ':\n                        # Z-axis rotation encoding\n                        inputs.append({'input_idx': self.node_attr_count, 'func': 'rz', 'wires': [q]})\n\n                    elif self.encoding_type == 'RX':\n                        # X-axis rotation encoding\n                        inputs.append({'input_idx': self.node_attr_count, 'func': 'rx', 'wires': [q]})\n\n                    elif self.encoding_type == 'H':\n                        # Hadamard gate encoding for superposition\n                        inputs.append({'input_idx': self.node_attr_count, 'func': 'h', 'wires': [q]})\n\n                    elif self.encoding_type == 'Phase':\n                        # Phase gate encoding\n                        inputs.append({'input_idx': self.node_attr_count, 'func': 'p', 'wires': [q]})\n\n                    self.node_attr_count += 1\n\n            # Prepare edge inputs\n            self.edge_attr_count = self.node_attr_count + 1\n            for q in range(self.num_qubits):\n                for e in range(q + 1, self.num_qubits):\n                    inputs.append({'input_idx': self.edge_attr_count, 'func': 'crz', 'wires': [q, e]})\n                    self.edge_attr_count += 1\n            self.edge_attr_count -= self.node_attr_count\n\n        self.encoder = tq.GeneralEncoder(inputs)\n        self.q_layers = tq.QuantumModuleList()\n\n        # Build quantum layers with entanglement\n        for layer in range(num_layers):\n            self.q_layers.append(\n                tq.Op1QAllLayer(op=tq.RX, n_wires=self.num_qubits, has_params=True, trainable=True)\n            )\n            self.q_layers.append(\n                tq.Op1QAllLayer(op=tq.RY, n_wires=self.num_qubits, has_params=True, trainable=True)\n            )\n            self.q_layers.append(\n                tq.Op1QAllLayer(op=tq.RZ, n_wires=self.num_qubits, has_params=True, trainable=True)\n            )\n\n            # Apply entanglement layer based on selected type\n            if self.entanglement_type == 'CNOT':\n                self.q_layers.append(\n                    tq.Op2QAllLayer(op=tq.CNOT, n_wires=self.num_qubits, jump=(layer + 1) % (self.num_qubits - 1), circular=True)\n                )\n            elif self.entanglement_type == 'CZ':\n                self.q_layers.append(\n                    tq.Op2QAllLayer(op=tq.CZ, n_wires=self.num_qubits, jump=(layer + 1) % (self.num_qubits - 1), circular=True)\n                )\n            elif self.entanglement_type == 'SWAP':\n                self.q_layers.append(\n                    tq.Op2QAllLayer(op=tq.SWAP, n_wires=self.num_qubits, jump=(layer + 1) % (self.num_qubits - 1), circular=True)\n                )\n            elif self.entanglement_type == 'CNOTbutterfly':\n                self.q_layers.append(\n                    tq.Op2QButterflyLayer(op=tq.CNOT, n_wires=self.num_qubits, has_params=False, trainable=False, wire_reverse=False)\n                )\n            elif self.entanglement_type == 'CZbutterfly':\n                self.q_layers.append(\n                    tq.Op2QButterflyLayer(op=tq.CZ, n_wires=self.num_qubits, has_params=False, trainable=False, wire_reverse=False)\n                )\n            elif self.entanglement_type == 'SWAPbutterfly':\n                self.q_layers.append(\n                    tq.Op2QButterflyLayer(op=tq.SWAP, n_wires=self.num_qubits, has_params=False, trainable=False, wire_reverse=False)\n                )\n\n\n    def forward(self, node_inputs, node_indices, edge_inputs):\n        qdev = tq.QuantumDevice(n_wires=self.num_qubits, bsz=node_inputs.shape[0], device=self.device, record_op=True)\n\n        if self.amplitude_encoding:\n            # Convert to a size that is a power of 2\n            converted_data = pad_or_truncate_to_power_of_two(node_inputs)\n            # Normalize the data\n            normalized_data = normalize_data(converted_data)\n            # Initialize the amplitude embedding layer\n            amplitude_encoder = AmplitudeEmbedding(num_qubits=self.num_qubits, normalize=False, pad_with=0.0)\n            # Apply amplitude encoding\n            amplitude_encoder(qdev, normalized_data)\n\n        elif self.IQP_encoding:\n            # Initialize the circuit\n            encoder = IQPEmbedding(wires=range(self.num_qubits), n_repeats=3)\n            # Apply the circuit to the quantum device\n            encoder(qdev, node_inputs)\n\n        elif self.displacement_encoding:\n            # Initialize the circuit\n            encoder = DisplacementEmbedding(n_features=self.num_qubits, wires=list(range(self.num_qubits)), method=\"phase\") # \"amplitude\", \"phase\"\n            # Apply the circuit to the quantum device\n            encoder(qdev, node_inputs)\n\n        else:\n            # Default to gate encoding\n            self.encoder(qdev, torch.cat((node_inputs.reshape(node_inputs.shape[0], -1), edge_inputs.reshape(edge_inputs.shape[0], -1)), dim=1))\n\n        # Apply quantum layers\n        for l in range(len(self.q_layers)):\n            self.q_layers[l](qdev)\n\n        # Return the squared amplitude of the final quantum state\n        return torch.abs(qdev.get_states_1d()) ** 2\n","metadata":{"id":"B0JvK_rRKGtR","execution":{"iopub.status.busy":"2024-10-16T11:36:53.219698Z","iopub.execute_input":"2024-10-16T11:36:53.219992Z","iopub.status.idle":"2024-10-16T11:36:53.248020Z","shell.execute_reply.started":"2024-10-16T11:36:53.219961Z","shell.execute_reply":"2024-10-16T11:36:53.247162Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# @title\nclass QGNN_node_estimator(torch.nn.Module):\n  def __init__(self, nodes_per_graph, num_layers, input_dim=None, device='cpu', entanglement_type='CNOT', encoding_type='RY'):\n    super(QGNN_node_estimator, self).__init__()\n    self.device = device\n    self.nodes_per_graph = nodes_per_graph\n    self.num_layers = num_layers\n    self.input_dim = input_dim\n    self.entanglement_type = entanglement_type\n    self.encoding_type = encoding_type\n    self.quantum_nn = BetterBetterTorchLayer(self.nodes_per_graph, self.num_layers, self.input_dim, self.device, self.entanglement_type, self.encoding_type)\n\n\n  def edge_attr_relevant(self, edge_attr, edge_attr_r):\n    count=0\n    for n in range(edge_attr.shape[0]):\n        for e in range(n+1, edge_attr.shape[1]):\n          edge_attr_r[count] = edge_attr[n, e]\n          count += 1\n    return edge_attr_r\n\n  def forward(self, x, node_indices, edge_attr=None):\n    if edge_attr is not None:\n      edge_attr_r = torch.zeros((edge_attr.shape[0], int(edge_attr.shape[1]*edge_attr.shape[2]/2 + 1)), device=self.device)\n      edge_attr = torch.vmap(self.edge_attr_relevant)(edge_attr, edge_attr_r)\n    output = self.quantum_nn(x, node_indices, edge_attr)\n    output = output[:, [2**i for i in range(self.nodes_per_graph)]]\n    return torch.vmap(lambda out, ind: out[ind])(output, node_indices)","metadata":{"id":"_Ky_BkEUXiYJ","cellView":"form","execution":{"iopub.status.busy":"2024-10-16T11:36:53.249036Z","iopub.execute_input":"2024-10-16T11:36:53.249328Z","iopub.status.idle":"2024-10-16T11:36:53.263372Z","shell.execute_reply.started":"2024-10-16T11:36:53.249282Z","shell.execute_reply":"2024-10-16T11:36:53.262522Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"#### Convolutional","metadata":{"id":"Lx1VcRhVX9tg"}},{"cell_type":"code","source":"# @title\n### Reference - https://github.com/colizz/weaver-benchmark/blob/main/top_tagging/networks/particlenet_pf.py\n\n'''Based on https://github.com/WangYueFt/dgcnn/blob/master/pytorch/model.py.'''\n\n\ndef knn(x, k):\n    inner = -2 * torch.matmul(x.transpose(2, 1), x)\n    xx = torch.sum(x ** 2, dim=1, keepdim=True)\n    pairwise_distance = -xx - inner - xx.transpose(2, 1)\n    idx = pairwise_distance.topk(k=k + 1, dim=-1)[1][:, :, 1:]  # (batch_size, num_points, k)\n    return idx\n\n\n# v1 is faster on GPU\ndef get_graph_feature_v1(x, k, idx):\n    batch_size, num_dims, num_points = x.size()\n\n\n    idx_base = torch.arange(0, batch_size, device=x.device).view(-1, 1, 1) * num_points\n    idx = idx + idx_base\n    idx = idx.view(-1)\n\n    fts = x.transpose(2, 1).reshape(-1, num_dims)  # -> (batch_size, num_points, num_dims) -> (batch_size*num_points, num_dims)\n    fts = fts[idx, :].view(batch_size, num_points, k, num_dims)  # neighbors: -> (batch_size*num_points*k, num_dims) -> ...\n    fts = fts.permute(0, 3, 1, 2).contiguous()  # (batch_size, num_dims, num_points, k)\n    x = x.view(batch_size, num_dims, num_points, 1).repeat(1, 1, 1, k)\n    fts = torch.cat((x, fts - x), dim=1)  # ->(batch_size, 2*num_dims, num_points, k)\n    return fts\n\n\n# v2 is faster on CPU\ndef get_graph_feature_v2(x, k, idx):\n    batch_size, num_dims, num_points = x.size()\n\n    idx_base = torch.arange(0, batch_size, device=x.device).view(-1, 1, 1) * num_points\n    idx = idx + idx_base\n    idx = idx.view(-1)\n\n    fts = x.transpose(0, 1).reshape(num_dims, -1)  # -> (num_dims, batch_size, num_points) -> (num_dims, batch_size*num_points)\n    fts = fts[:, idx].view(num_dims, batch_size, num_points, k)  # neighbors: -> (num_dims, batch_size*num_points*k) -> ...\n    fts = fts.transpose(1, 0).contiguous()  # (batch_size, num_dims, num_points, k)\n\n    x = x.view(batch_size, num_dims, num_points, 1).repeat(1, 1, 1, k)\n    fts = torch.cat((x, fts - x), dim=1)  # ->(batch_size, 2*num_dims, num_points, k)\n\n    return fts\n\n\nclass EdgeConvBlock(nn.Module):\n    r\"\"\"EdgeConv layer.\n    Introduced in \"`Dynamic Graph CNN for Learning on Point Clouds\n    <https://arxiv.org/pdf/1801.07829>`__\".  Can be described as follows:\n    .. math::\n       x_i^{(l+1)} = \\max_{j \\in \\mathcal{N}(i)} \\mathrm{ReLU}(\n       \\Theta \\cdot (x_j^{(l)} - x_i^{(l)}) + \\Phi \\cdot x_i^{(l)})\n    where :math:`\\mathcal{N}(i)` is the neighbor of :math:`i`.\n    Parameters\n    ----------\n    in_feat : int\n        Input feature size.\n    out_feat : int\n        Output feature size.\n    batch_norm : bool\n        Whether to include batch normalization on messages.\n    \"\"\"\n\n    def __init__(self, k, in_feat, out_feats, batch_norm=True, activation=True, cpu_mode=False):\n        super(EdgeConvBlock, self).__init__()\n        self.k = k\n        self.batch_norm = batch_norm\n        self.activation = activation\n        self.num_layers = len(out_feats)\n        self.get_graph_feature = get_graph_feature_v2 if cpu_mode else get_graph_feature_v1\n\n        self.convs = nn.ModuleList()\n        for i in range(self.num_layers):\n            self.convs.append(nn.Conv2d(2 * in_feat if i == 0 else out_feats[i - 1], out_feats[i], kernel_size=1, bias=False if self.batch_norm else True))\n\n        if batch_norm:\n            self.bns = nn.ModuleList()\n            for i in range(self.num_layers):\n                self.bns.append(nn.BatchNorm2d(out_feats[i]))\n\n        if activation:\n            self.acts = nn.ModuleList()\n            for i in range(self.num_layers):\n                self.acts.append(nn.ReLU())\n\n        if in_feat == out_feats[-1]:\n            self.sc = None\n        else:\n            self.sc = nn.Conv1d(in_feat, out_feats[-1], kernel_size=1, bias=False)\n            self.sc_bn = nn.BatchNorm1d(out_feats[-1])\n\n        if activation:\n            self.sc_act = nn.ReLU()\n\n    def forward(self, points, features):\n\n        topk_indices = knn(points, self.k)\n        x = self.get_graph_feature(features, self.k, topk_indices)\n\n        for conv, bn, act in zip(self.convs, self.bns, self.acts):\n            x = conv(x)  # (N, C', P, K)\n            if bn:\n                x = bn(x)\n            if act:\n                x = act(x)\n\n        fts = x.mean(dim=-1)  # (N, C, P)\n\n        # shortcut\n        if self.sc:\n            sc = self.sc(features)  # (N, C_out, P)\n            sc = self.sc_bn(sc)\n        else:\n            sc = features\n\n        return self.sc_act(sc + fts)  # (N, C_out, P)\n\n\nclass ParticleNet(nn.Module):\n\n    def __init__(self,\n                 input_dims,\n                 num_classes,\n                 conv_params=[(7, (32, 32, 32)), (7, (64, 64, 64))],\n                 fc_params=[(128, 0.1)],\n                 use_fusion=True,\n                 use_fts_bn=True,\n                 use_counts=True,\n                 for_inference=False,\n                 for_segmentation=True,\n                 **kwargs):\n        super(ParticleNet, self).__init__(**kwargs)\n\n        self.use_fts_bn = use_fts_bn\n        if self.use_fts_bn:\n            self.bn_fts = nn.BatchNorm1d(input_dims)\n\n        self.use_counts = use_counts\n\n        self.edge_convs = nn.ModuleList()\n        for idx, layer_param in enumerate(conv_params):\n            k, channels = layer_param\n            in_feat = input_dims if idx == 0 else conv_params[idx - 1][1][-1]\n            self.edge_convs.append(EdgeConvBlock(k=k, in_feat=in_feat, out_feats=channels, cpu_mode=for_inference))\n\n        self.use_fusion = use_fusion\n        if self.use_fusion:\n            in_chn = sum(x[-1] for _, x in conv_params)\n            out_chn = np.clip((in_chn // 128) * 128, 128, 1024)\n            self.fusion_block = nn.Sequential(nn.Conv1d(in_chn, out_chn, kernel_size=1, bias=False), nn.BatchNorm1d(out_chn), nn.ReLU())\n\n        self.for_segmentation = for_segmentation\n\n        fcs = []\n        for idx, layer_param in enumerate(fc_params):\n            channels, drop_rate = layer_param\n            if idx == 0:\n                in_chn = out_chn if self.use_fusion else conv_params[-1][1][-1]\n            else:\n                in_chn = fc_params[idx - 1][0]\n            if self.for_segmentation:\n                fcs.append(nn.Sequential(nn.Conv1d(in_chn, channels, kernel_size=1, bias=False),\n                                         nn.BatchNorm1d(channels), nn.ReLU(), nn.Dropout(drop_rate)))\n            else:\n                fcs.append(nn.Sequential(nn.Linear(in_chn, channels), nn.ReLU(), nn.Dropout(drop_rate)))\n        # if self.for_segmentation:\n        #     fcs.append(nn.Conv1d(fc_params[-1][0], num_classes, kernel_size=1))\n        # else:\n        #     fcs.append(nn.Linear(fc_params[-1][0], num_classes))\n        self.fc = nn.Sequential(*fcs)\n\n        self.for_inference = for_inference\n\n    def forward(self, points, features, mask=None):\n#         print('points:\\n', points)\n#         print('features:\\n', features)\n        if mask is None:\n            mask = (features.abs().sum(dim=1, keepdim=True) != 0)  # (N, 1, P)\n            # print(mask)\n            # print(mask.shape)\n        points *= mask\n        features *= mask\n        coord_shift = (mask == 0) * 1e9\n        if self.use_counts:\n            counts = mask.float().sum(dim=-1)\n            counts = torch.max(counts, torch.ones_like(counts))  # >=1\n\n        if self.use_fts_bn:\n            fts = self.bn_fts(features) * mask\n        else:\n            fts = features\n        outputs = []\n        for idx, conv in enumerate(self.edge_convs):\n            pts = (points if idx == 0 else fts) + coord_shift\n            fts = conv(pts, fts) * mask\n            if self.use_fusion:\n                outputs.append(fts)\n        if self.use_fusion:\n            fts = self.fusion_block(torch.cat(outputs, dim=1)) * mask\n\n#         assert(((fts.abs().sum(dim=1, keepdim=True) != 0).float() - mask.float()).abs().sum().item() == 0)\n\n        if self.for_segmentation:\n            x = fts\n        else:\n            if self.use_counts:\n                x = fts.sum(dim=-1) / counts  # divide by the real counts\n            else:\n                x = fts.mean(dim=-1)\n\n        output =  self.fc(x)\n\n        if self.for_inference:\n            output = torch.softmax(output, dim=1)\n        # print('output:\\n', output)\n        return output\n\n\nclass FeatureConv(nn.Module):\n\n    def __init__(self, in_chn, out_chn, **kwargs):\n        super(FeatureConv, self).__init__(**kwargs)\n        self.conv = nn.Sequential(\n            nn.BatchNorm1d(in_chn),\n            nn.Conv1d(in_chn, out_chn, kernel_size=1, bias=False),\n            nn.BatchNorm1d(out_chn),\n            nn.ReLU()\n            )\n\n    def forward(self, x):\n        return self.conv(x)\n\n\nclass ParticleNetTagger1Path(nn.Module):\n\n    def __init__(self,\n                 pf_features_dims,\n                 num_classes,\n                 conv_params= [(6, (32, 32, 32)), (6, (64, 64, 64)), (6, (128, 128, 128))],   #[(7, (32, 32, 32)), (7, (64, 64, 64))],  #\n                 fc_params=[(128, 0.1)],\n                 use_fusion=False,\n                 use_fts_bn=False,\n                 use_counts=True,\n                 pf_input_dropout=None,\n                 for_inference=False,\n                 **kwargs):\n        super(ParticleNetTagger1Path, self).__init__(**kwargs)\n        self.pf_input_dropout = nn.Dropout(pf_input_dropout) if pf_input_dropout else None\n        # self.pf_conv = FeatureConv(pf_features_dims, 32)\n        self.gnn = ParticleNet(input_dims=pf_features_dims,\n                              num_classes=num_classes,\n                              conv_params=conv_params,\n                              fc_params=fc_params,\n                              use_fusion=use_fusion,\n                              use_fts_bn=use_fts_bn,\n                              use_counts=use_counts,\n                              for_inference=for_inference)\n\n    def forward(self, pf_points, pf_features, pf_mask):\n        if self.pf_input_dropout:\n            pf_mask = (self.pf_input_dropout(pf_mask) != 0).float()\n            pf_points *= pf_mask\n            pf_features *= pf_mask\n        # mod_feats = self.pf_conv(pf_features)   #* pf_mask , * pf_mask\n        return self.gnn(pf_points, pf_features, pf_mask)\n\ndef get_model(data_config, **kwargs):\n    # conv_params = [\n    #     (16, (64, 64, 64)),\n    #     (16, (128, 128, 128)),\n    #     (16, (256, 256, 256)),\n    #     ]\n    ec_k = kwargs.get('ec_k', 16)\n    ec_c1 = kwargs.get('ec_c1', 64)\n    ec_c2 = kwargs.get('ec_c2', 128)\n    ec_c3 = kwargs.get('ec_c3', 256)\n    fc_c, fc_p = kwargs.get('fc_c', 256), kwargs.get('fc_p', 0.1)\n    conv_params = [\n        (ec_k, (ec_c1, ec_c1, ec_c1)),\n        (ec_k, (ec_c2, ec_c2, ec_c2)),\n        (ec_k, (ec_c3, ec_c3, ec_c3)),\n        ]\n    fc_params = [(fc_c, fc_p)]\n    use_fusion = True\n\n    pf_features_dims = len(data_config.input_dicts['pf_features'])\n    num_classes = len(data_config.label_value)\n    model = ParticleNetTagger1Path(pf_features_dims, num_classes,\n                                   conv_params, fc_params,\n                                   use_fusion=use_fusion,\n                                   use_fts_bn=kwargs.get('use_fts_bn', False),\n                                   use_counts=kwargs.get('use_counts', True),\n                                   pf_input_dropout=kwargs.get('pf_input_dropout', None),\n                                   for_inference=kwargs.get('for_inference', False)\n                                   )\n    model_info = {\n        'input_names':list(data_config.input_names),\n        'input_shapes':{k:((1,) + s[1:]) for k, s in data_config.input_shapes.items()},\n        'output_names':['softmax'],\n        'dynamic_axes':{**{k:{0:'N', 2:'n_' + k.split('_')[0]} for k in data_config.input_names}, **{'softmax':{0:'N'}}},\n        }\n\n    return model, model_info","metadata":{"id":"apm4c_MrZw0T","execution":{"iopub.status.busy":"2024-10-16T11:36:53.264737Z","iopub.execute_input":"2024-10-16T11:36:53.265081Z","iopub.status.idle":"2024-10-16T11:36:53.316606Z","shell.execute_reply.started":"2024-10-16T11:36:53.265041Z","shell.execute_reply":"2024-10-16T11:36:53.315557Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# @title\ndef drop_nodes_prob_batch(graph, batch_size):\n\n    node_num = graph.num_nodes()\n    edge_num = graph.num_edges()\n    node_num_sin = int(graph.num_nodes()/batch_size)\n    edge_num_sin = int(graph.num_edges()/batch_size)\n    drop_num_sin = int(node_num_sin * aug_ratio)\n    drop_num = batch_size*drop_num_sin\n    node_score = graph.ndata['node_score'].reshape(batch_size, -1)\n    node_prob = node_score.float()\n    node_prob += 0.001\n    node_prob = cp.array(node_prob)\n    node_prob /= node_prob.sum(axis=1)[:, None]\n    node_prob = node_prob.get()\n\n    idx_nondrop = np.zeros((batch_size, node_num_sin-drop_num_sin), dtype=np.int64)\n    idx_drop_set = []\n    idx_nondrop_e = np.zeros((batch_size, node_num_sin-drop_num_sin), dtype=np.int64)\n    for b in range(batch_size):\n      idx_nondrop[b] = np.random.choice(node_num_sin, node_num_sin-drop_num_sin, replace=False, p=node_prob[b])\n      idx_drop_set.append(set(np.setdiff1d(np.arange(node_num_sin), idx_nondrop[b]).tolist()))\n      idx_nondrop[b].sort()\n      idx_nondrop_e[b] += idx_nondrop[b] + b*node_num_sin\n\n    idx_nondrop_e = idx_nondrop_e.reshape(-1,)\n\n    idx_drop_set_e = set(np.setdiff1d(np.arange(node_num), idx_nondrop_e).tolist())\n\n    idx_dict = np.zeros((idx_nondrop_e[-1] + 1,), dtype=np.int64)\n    idx_dict[idx_nondrop_e] = np.arange(len(idx_nondrop_e), dtype=np.int64)\n\n    # edge_index = data.edge_index.numpy()\n    edge_index = np.array([graph.edges()[0].cpu().numpy(), graph.edges()[1].cpu().numpy()])\n\n    edge_mask = []\n    for n in range(edge_num):\n        if edge_index[0, n] not in idx_drop_set_e and edge_index[1, n] not in idx_drop_set_e:\n          edge_mask.append(n)\n    edge_mask = np.asarray(edge_mask, dtype=np.int64)\n    edge_index = idx_dict[edge_index[:, edge_mask]]\n\n    ng = dgl.graph([])\n    src = graph.edges()[0]\n    dst = graph.edges()[1]\n    nsrc = edge_index[0]\n    ndst = edge_index[1]\n    ng.add_edges(nsrc, ndst)\n    ng.to(device)\n    ng.ndata['node_attr'] = graph.ndata['node_attr'].clone().reshape(batch_size,node_num_sin,-1)[torch.arange(batch_size, device=device).unsqueeze(-1), idx_nondrop].reshape(node_num-drop_num,-1)\n    ng.ndata['node_attr_irc'] = graph.ndata['node_attr_irc'].clone().reshape(batch_size,node_num_sin,-1)[torch.arange(batch_size, device=device).unsqueeze(-1), idx_nondrop].reshape(node_num-drop_num,-1)\n    ng.ndata['node_indices'] = torch.Tensor(idx_nondrop, device=device).int().reshape(-1,1)\n    ng.edata['edge_attr'] = graph.edata['edge_attr'].clone()[edge_mask]\n    ng.edata['edge_indices'] = torch.Tensor(edge_mask, device=device).int()\n\n    return ng","metadata":{"id":"poBXGx9yXlIL","cellView":"form","execution":{"iopub.status.busy":"2024-10-16T11:36:53.318095Z","iopub.execute_input":"2024-10-16T11:36:53.318797Z","iopub.status.idle":"2024-10-16T11:36:53.336004Z","shell.execute_reply.started":"2024-10-16T11:36:53.318754Z","shell.execute_reply":"2024-10-16T11:36:53.335148Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# @title\ndef drop_nodes_cp_batch(graph, batch_size):\n\n    node_num = graph.num_nodes()\n    edge_num = graph.num_edges()\n    node_num_sin = int(graph.num_nodes()/batch_size)\n    edge_num_sin = int(graph.num_edges()/batch_size)\n    drop_num_sin = int(node_num_sin * aug_ratio)\n    drop_num = batch_size*drop_num_sin\n    node_score = graph.ndata['node_score'].reshape(batch_size, -1)\n    node_prob = torch.sub(torch.max(node_score, dim=1).values.reshape(-1,1), node_score)\n    node_prob += 0.001\n    node_prob = cp.array(node_prob)\n    node_prob /= node_prob.sum(axis=1)[:, None]\n    node_prob = node_prob.get()\n\n    idx_nondrop = np.zeros((batch_size, node_num_sin-drop_num_sin), dtype=np.int64)\n    idx_drop_set = []\n    idx_nondrop_e = np.zeros((batch_size, node_num_sin-drop_num_sin), dtype=np.int64)\n    for b in range(batch_size):\n      idx_nondrop[b] = np.random.choice(node_num_sin, node_num_sin-drop_num_sin, replace=False, p=node_prob[b])\n      idx_drop_set.append(set(np.setdiff1d(np.arange(node_num_sin), idx_nondrop[b]).tolist()))\n      idx_nondrop[b].sort()\n      idx_nondrop_e[b] += idx_nondrop[b] + b*node_num_sin\n\n    idx_nondrop_e = idx_nondrop_e.reshape(-1,)\n\n    idx_drop_set_e = set(np.setdiff1d(np.arange(node_num), idx_nondrop_e).tolist())\n\n    idx_dict = np.zeros((idx_nondrop_e[-1] + 1,), dtype=np.int64)\n    idx_dict[idx_nondrop_e] = np.arange(len(idx_nondrop_e), dtype=np.int64)\n\n    # edge_index = data.edge_index.numpy()\n    edge_index = np.array([graph.edges()[0].cpu().numpy(), graph.edges()[1].cpu().numpy()])\n\n    edge_mask = []\n    for n in range(edge_num):\n        if edge_index[0, n] not in idx_drop_set_e and edge_index[1, n] not in idx_drop_set_e:\n          edge_mask.append(n)\n    edge_mask = np.asarray(edge_mask, dtype=np.int64)\n    edge_index = idx_dict[edge_index[:, edge_mask]]\n\n    ng = dgl.graph([])\n    src = graph.edges()[0]\n    dst = graph.edges()[1]\n    nsrc = edge_index[0]\n    ndst = edge_index[1]\n    ng.add_edges(nsrc, ndst)\n    ng.to(device)\n    ng.ndata['node_attr'] = graph.ndata['node_attr'].clone().reshape(batch_size,node_num_sin,-1)[torch.arange(batch_size,  device=device).unsqueeze(-1), idx_nondrop].reshape(node_num-drop_num,-1)\n    ng.ndata['node_attr_irc'] = graph.ndata['node_attr_irc'].clone().reshape(batch_size,node_num_sin,-1)[torch.arange(batch_size, device=device).unsqueeze(-1), idx_nondrop].reshape(node_num-drop_num,-1)\n    ng.ndata['node_indices'] = torch.Tensor(idx_nondrop, device=device).int().reshape(-1,1)\n    ng.edata['edge_attr'] = graph.edata['edge_attr'].clone()[edge_mask]\n    ng.edata['edge_indices'] = torch.Tensor(edge_mask, device=device).int()\n\n    return ng","metadata":{"id":"9pqevFSEXptq","cellView":"form","execution":{"iopub.status.busy":"2024-10-16T11:36:53.337439Z","iopub.execute_input":"2024-10-16T11:36:53.337815Z","iopub.status.idle":"2024-10-16T11:36:53.355760Z","shell.execute_reply.started":"2024-10-16T11:36:53.337774Z","shell.execute_reply":"2024-10-16T11:36:53.354864Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# @title\nclass graphcl(nn.Module):\n    def __init__(self, gnn, node_imp_estimator, emb_dim, out_dim):\n        super(graphcl, self).__init__()\n        self.gnn = gnn\n        self.node_imp_estimator = node_imp_estimator\n        self.pool = global_mean_pool\n        self.projection_head = nn.Sequential(nn.Linear(emb_dim, out_dim), nn.ReLU(inplace=True), nn.Linear(out_dim, out_dim))\n\n    def prepare_variables_rg(self, gr_n, g_n, n_i):\n      g_n[n_i] = gr_n\n      return g_n\n\n    def forward_cl(self, x, edge_index, edge_attr, batch, nodes_per_graph, g_batch=None, q_edge_attr=False, device='cpu', node_est='classical'):\n      if node_est == 'classical':\n          node_imp = self.node_imp_estimator(x, edge_index, edge_attr, batch)\n      if node_est == 'quantum':\n          # ############ Quantum Node Est.\n\n          g_n = g_batch.ndata['node_attr'].clone().reshape(3*batch_size, nodes_per_graph, -1)\n          n_i = g_batch.ndata['node_indices'].clone().reshape(3*batch_size, nodes_per_graph)\n          g_n_0 = torch.zeros((3*batch_size, nodes_per_graph_original, g_n.shape[2]), device=device)\n          g_n = torch.vmap(self.prepare_variables_rg)(g_n.float(), g_n_0, n_i.long())\n\n          e_n = g_batch.edata['edge_attr'].clone()\n          e_i = g_batch.edata['edge_indices'].clone()\n          e_n_0 = torch.zeros((3*batch_size*nodes_per_graph_original*(nodes_per_graph_original-1)), device=device)\n          e_n_0[e_i.long()]  = e_n\n          e_n = e_n_0.reshape(3*batch_size, nodes_per_graph_original, -1)\n\n          if q_edge_attr:\n            node_imp = self.node_imp_estimator(g_n, n_i, e_n)\n          else:\n            node_imp = self.node_imp_estimator(g_n, n_i)\n          node_imp = node_imp.reshape(-1,1)\n          ############\n\n      out = torch.max(node_imp.reshape(-1, nodes_per_graph), 1)[0]\n      out = out.reshape(-1, 1)\n      out = out[batch]\n      node_imp /= (out * 10)\n      node_imp += 0.9\n\n      pf_feats = x.reshape(3*batch_size, nodes_per_graph, -1)\n      points = pf_feats[:,:,1:3]\n\n      x = self.gnn(points.reshape(points.shape[0], points.shape[2], points.shape[1])\n                     , pf_feats.reshape(pf_feats.shape[0], pf_feats.shape[2], pf_feats.shape[1]), None)\n      x = x.reshape(x.shape[0], x.shape[2], x.shape[1])\n      x = x.reshape(x.shape[0]*x.shape[1], x.shape[2])\n\n      node_imp = node_imp.expand(-1, x.shape[1])\n      x = torch.mul(x, node_imp)\n      x = self.pool(x, batch)\n      x = self.projection_head(x.float())\n\n      return x\n\n    def loss_cl(self, x1, x2, temp):\n        T = temp\n        batch_size, _ = x1.size()\n        x1_abs = x1.norm(dim=1)\n        x2_abs = x2.norm(dim=1)\n\n        sim_matrix = torch.einsum('ik,jk->ij', x1, x2) / torch.einsum('i,j->ij', x1_abs, x2_abs)\n        sim_matrix = torch.exp(sim_matrix / T)\n        pos_sim = sim_matrix[range(batch_size), range(batch_size)]\n        loss = pos_sim / (sim_matrix.sum(dim=1) - pos_sim)\n        loss = - torch.log(loss).mean()\n        return loss\n\n    def loss_infonce(self, x1, x2, temp):\n        T = temp\n        batch_size, _ = x1.size()\n        x1_abs = x1.norm(dim=1)\n        x2_abs = x2.norm(dim=1)\n\n        sim_matrix = torch.einsum('ik,jk->ij', x1, x2) / torch.einsum('i,j->ij', x1_abs, x2_abs)\n        sim_matrix = torch.exp(sim_matrix / T)\n        pos_sim = sim_matrix[range(batch_size), range(batch_size)]\n        loss = pos_sim / sim_matrix.sum(dim=1)\n        loss = - torch.log(loss).mean()\n        return loss\n\n    def loss_ra(self, x1, x2, x3, temp, lamda):\n        batch_size, _ = x1.size()\n        x1_abs = x1.norm(dim=1)\n        x2_abs = x2.norm(dim=1)\n        x3_abs = x3.norm(dim=1)\n\n        cp_sim_matrix = torch.einsum('ik,jk->ij', x1, x3) / torch.einsum('i,j->ij', x1_abs, x3_abs)\n        cp_sim_matrix = torch.exp(cp_sim_matrix / temp)\n\n        sim_matrix = torch.einsum('ik,jk->ij', x1, x2) / torch.einsum('i,j->ij', x1_abs, x2_abs)\n        sim_matrix = torch.exp(sim_matrix / temp)\n\n        pos_sim = sim_matrix[range(batch_size), range(batch_size)]\n\n        ra_loss = pos_sim / (sim_matrix.sum(dim=1) - pos_sim)\n        ra_loss = - torch.log(ra_loss).mean()\n\n        cp_loss = pos_sim / (cp_sim_matrix.sum(dim=1) + pos_sim)\n        cp_loss = - torch.log(cp_loss).mean()\n\n        uni_loss_1 = self.lunif(torch.nn.functional.normalize(x1, dim=1))\n        uni_loss_2 = self.lunif(torch.nn.functional.normalize(x2, dim=1))\n        uni_loss = (uni_loss_1 + uni_loss_2) / 2\n        al_loss = self.lalign(torch.nn.functional.normalize(x1, dim=1), torch.nn.functional.normalize(x2, dim=1))\n\n        loss = ra_loss + lamda * cp_loss\n        # loss = 0.5*uni_loss + al_loss + lamda * cp_loss\n\n        return ra_loss, cp_loss, loss, uni_loss, al_loss\n\n    def lalign(self, x, y, alpha=2):\n      return (x - y).norm(dim=1).pow(alpha).mean()\n\n    def lunif(self, x, t=2):\n      sq_pdist = torch.pdist(x, p=2).pow(2)\n      return sq_pdist.mul(-t).exp().mean().log()\n\ndef train(epoch, model, device, dataset, optimizer, batch_size, nodes_per_graph, aug_ratio, loss_temp, lamda, irc_safety, q_edge_attr=False, loader=None, node_est='classical'):\n\n    torch.autograd.set_detect_anomaly(True)\n    dataset.aug = \"none\"\n    imp_batch_size = batch_size\n    loader = GraphDataLoader(dataset, batch_size=imp_batch_size, shuffle=False, drop_last=False)\n    model.eval()\n    torch.set_grad_enabled(False)\n    node_imp_l = []\n    # loader.set_epoch(epoch)\n    for step, (g_batch, _) in enumerate(loader):\n\n        batch = torch.arange(0, g_batch.batch_size, device=device).reshape(-1,1).expand(g_batch.batch_size, nodes_per_graph).reshape(-1,)\n        if node_est == 'classical':\n          node_imp = model.node_imp_estimator(g_batch.ndata['node_attr'], torch.stack(g_batch.edges()), g_batch.edata['edge_attr'], batch).detach()\n        else:\n          ############ Quantum Node Est.\n          g_batch.to(device)\n          g_n = g_batch.ndata['node_attr'].clone().reshape(batch_size, nodes_per_graph, -1)\n          e_n = g_batch.edata['edge_attr'].clone().reshape(batch_size, nodes_per_graph, -1)\n          n_i = g_batch.ndata['node_indices'].clone().reshape(batch_size, nodes_per_graph)\n\n          if q_edge_attr:\n            node_imp = model.node_imp_estimator(g_n, n_i, e_n)\n          else:\n            node_imp = model.node_imp_estimator(g_n, n_i)\n          node_imp = node_imp.reshape(-1,1)\n\n          ############\n\n        node_imp_l.append(node_imp.squeeze())\n\n    for i, b in enumerate(node_imp_l):\n      n = b.reshape(-1,nodes_per_graph)\n      for g in range(len(n)):\n        dataset[i*len(n)+g][0].ndata['node_score'] = torch.Tensor(n[g])\n\n    dataset.nodes_per_aug_graph = dataset.nodes_per_graph-int(aug_ratio*dataset.nodes_per_graph)\n\n    torch.set_grad_enabled(True)\n    model.train()\n\n    train_loss_accum = 0\n    ra_loss_accum = 0\n    cp_loss_accum = 0\n    uni_loss_accum = 0\n    alignment_loss_accum = 0\n\n    for step, (g_batch, _) in enumerate(loader):\n        batch1, batch2 = dataset.augment_dataset('rationale', g_batch, batch_size)\n        batch3 = dataset.augment_dataset('complement', g_batch, batch_size)\n\n        batch1 = batch1.to(device)\n        batch2 = batch2.to(device)\n        batch3 = batch3.to(device)\n\n        optimizer.zero_grad()\n        batch_1 = torch.arange(0, batch_size, device=device).reshape(-1,1).expand(batch_size, dataset.nodes_per_aug_graph).reshape(-1,)\n        batch_2 = torch.arange(0, batch_size, device=device).reshape(-1,1).expand(batch_size, dataset.nodes_per_aug_graph).reshape(-1,)\n        batch_3 = torch.arange(0, batch_size, device=device).reshape(-1,1).expand(batch_size, dataset.nodes_per_aug_graph).reshape(-1,)\n\n        node_attr_123 = torch.cat((batch1.ndata['node_attr'].float(), batch2.ndata['node_attr'].float(), batch3.ndata['node_attr'].float()), dim=0)\n        edges_123 = torch.stack(dgl.batch([batch1, batch2, batch3]).edges())\n        edge_attr_123 = torch.cat((batch1.edata['edge_attr'], batch2.edata['edge_attr'], batch3.edata['edge_attr']), dim=0)\n        overall_batch = torch.arange(0, batch_size*3).reshape(-1,1).expand(batch_size*3, dataset.nodes_per_aug_graph).reshape(-1,)\n        output = model.forward_cl(node_attr_123, edges_123, edge_attr_123, overall_batch, dataset.nodes_per_aug_graph, dgl.batch([batch1, batch2, batch3]), q_edge_attr, device=device, node_est=node_est)\n        x1, x2, x3 = torch.split(output, [batch_size, batch_size, batch_size], dim=0)\n\n        ra_loss, cp_loss, loss, uni_loss, al_loss = model.loss_ra(x1, x2, x3, loss_temp, lamda)\n\n        loss.backward()\n        optimizer.step()\n\n        train_loss_accum += float(loss.detach().cpu().item())\n        ra_loss_accum += float(ra_loss.detach().cpu().item())\n        cp_loss_accum += float(cp_loss.detach().cpu().item())\n        uni_loss_accum += float(uni_loss.detach().cpu().item())\n        alignment_loss_accum += float(al_loss.detach().cpu().item())\n\n    gc.collect()\n    return train_loss_accum/(step+1), ra_loss_accum/(step+1), cp_loss_accum/(step+1), uni_loss_accum/(step+1), alignment_loss_accum/(step+1)","metadata":{"id":"pR4PZBx2XsD8","cellView":"form","execution":{"iopub.status.busy":"2024-10-16T11:36:53.357262Z","iopub.execute_input":"2024-10-16T11:36:53.357534Z","iopub.status.idle":"2024-10-16T11:36:53.404603Z","shell.execute_reply.started":"2024-10-16T11:36:53.357489Z","shell.execute_reply":"2024-10-16T11:36:53.403725Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"### Train","metadata":{"id":"pGOPXa_D4akV"}},{"cell_type":"code","source":"# # @title\n# # Example Hyperparameter Search for Learning Rate\n\n# # Set up different learning rates to try\n# parameters = ['DisplacementEncoding']\n\n# for paramx in parameters:\n#     # Set up model\n#     device = 'cuda'\n#     num_layer_gnn = 2\n#     num_layer_gnn_est = 2\n#     qnn_layers = 3\n#     emb_dim = 128\n#     in_dim = 8\n#     inter_dim = 256\n#     out_dim = 128\n#     JK = 'last'\n#     dropout_ratio = 0.1\n#     gnn_type = 'gat'\n#     lr = 0.001\n#     decay = 0\n#     aug_ratio = 0.1\n#     batch_size = 2000\n#     loss_temp = 0.1\n#     lamda = 0.1\n#     node_est = 'quantum'\n#     entanglement_type = 'CNOT' #'CNOT'\n#     encoding_type = paramx\n\n#     # Dataset\n#     qg_dataset = QuarkGluonGraphDataset(dataset_name='Quark Gluon', raw_dir=main_dir, save_dir='/content',\n#                                         data_folder_name=jet_folder_path, datafile_name=jet_file_path, labelsfile_name=jet_file_path,\n#                                         datatype='particles', dataset_size=10000, nodes_per_graph=nodes_per_graph_original,\n#                                         spectral_augmentation=False, irc_safety_aug=True, device='cuda')\n\n#     # Model\n#     gnn = ParticleNetTagger1Path(in_dim, 2)\n#     if node_est == 'classical':\n#         node_imp_estimator = GNN_imp_estimator(num_layer=num_layer_gnn_est, emb_dim=emb_dim, in_dim=in_dim, JK=JK, drop_ratio=dropout_ratio)\n#     if node_est == 'quantum':\n#         node_imp_estimator = QGNN_node_estimator(nodes_per_graph_original, qnn_layers, in_dim, device=device,\n#                                                  entanglement_type=entanglement_type, encoding_type=encoding_type)\n\n#     model = graphcl(gnn, node_imp_estimator, emb_dim, out_dim)\n#     model.to(device)\n\n#     # Optimizer with current learning rate\n#     optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=decay)\n\n\n# ############## after training ###############\n#     epochs = 1\n#     con_loss = []\n\n#     for epoch in range(1, epochs + 1):\n#         print(\"====epoch \" + str(epoch))\n#         qg_dataset.augment = False\n#         train_loss, ra_loss, cp_loss, uni_loss, al_loss = train(epoch, model=model, device=device, dataset=qg_dataset, optimizer=optimizer, batch_size=batch_size,\n#                                           nodes_per_graph=qg_dataset.nodes_per_graph, aug_ratio=aug_ratio, loss_temp=loss_temp, lamda=lamda,\n#                                           irc_safety=True, q_edge_attr=True, node_est=node_est)\n#         con_loss.append(train_loss)\n#         print(train_loss)\n#         print(ra_loss)\n#         print(cp_loss)\n#         print('UNI : ', uni_loss)\n#         print('ALIGN : ', al_loss)\n\n#     # nodes_per_graph_original = 10\n#     test_dataset = QuarkGluonGraphDataset(dataset_name='Quark Gluon', raw_dir=main_dir, save_dir='/content',\n#                                         data_folder_name=jet_folder_path, datafile_name=jet_file_path, labelsfile_name=jet_file_path,\n#                                         datatype='particles', dataset_size=7000, nodes_per_graph=nodes_per_graph_original, spectral_augmentation=False, irc_safety_aug=True,\n#                                         device='cuda') # 7000\n\n#     test_samples = torch.tensor(np.arange(1000,7000).astype('int32'))\n#     test_sampler = SubsetRandomSampler(test_samples)\n\n#     test_dataloader = test_dataloader = GraphDataLoader(\n#         test_dataset, sampler=test_sampler, batch_size=500, drop_last=False\n#     )\n\n#     cls_embds = torch.Tensor([])\n#     cls_labels = torch.Tensor([])\n\n#     for batched_graph, labels in test_dataloader:\n#           graphs = []\n#           unbatched_graph = dgl.unbatch(batched_graph)\n#           for graph in unbatched_graph:\n#             graphs.append(dgl.add_self_loop(graph))\n#           batched_graph = dgl.batch(graphs)\n#           batch_t = torch.arange(0, batched_graph.batch_size).reshape(-1,1).expand(batched_graph.batch_size, test_dataset.nodes_per_graph).reshape(-1,)\n\n#           ## For custom GNN\n#           # cls_emb = gnn.forward(batched_graph.ndata[\"node_attr\"].float(), torch.stack(batched_graph.edges()), batched_graph.edata[\"edge_attr\"].float())\n\n#           ## For ParticleNet\n#           pf_feats = batched_graph.ndata[\"node_attr\"].reshape(len(unbatched_graph), nodes_per_graph_original, -1).float()\n#           points = pf_feats[:,:,1:3]\n#           cls_emb = gnn.forward(points.reshape(points.shape[0], points.shape[2], points.shape[1])\n#                              , pf_feats.reshape(pf_feats.shape[0], pf_feats.shape[2], pf_feats.shape[1]), None)\n#           cls_emb = cls_emb.reshape(cls_emb.shape[0], cls_emb.shape[2], cls_emb.shape[1])\n#           cls_emb = cls_emb.reshape(cls_emb.shape[0]*cls_emb.shape[1], cls_emb.shape[2])\n\n#           # cls_emb = batched_graph.ndata[\"node_attr\"].float()\n#           cls_emb = global_mean_pool(cls_emb, batch_t)\n#           cls_embds = torch.cat((cls_embds, cls_emb.detach()), 0)     #cls_emb\n#           cls_labels = torch.cat((cls_labels, labels))\n\n#     cls_epochs = 1000\n#     cls_train_data = cls_embds[ : int(0.8*len(cls_embds))]\n#     targets = cls_labels[ : int(0.8*len(cls_embds))]\n#     cls_test_data = cls_embds[int(0.8*len(cls_embds)) : ]\n#     testtargets = cls_labels[int(0.8*len(cls_embds)) : ]\n\n#     cls_loss, cls_accuracy, test_cls_loss, test_cls_accuracy, fpr, tpr, auc, eB, eS, f1_score, imtafe, _ = train_classifier(cls_epochs, classifier, cls_train_data, targets, cls_test_data, testtargets)\n\n#     # Print the performance metrics\n#     print(f'Imtafe (other metrics): {imtafe}')\n\n#     print('Accuracy : ', max(test_cls_accuracy))\n#     print('AUC : ', auc)\n#     print('F1 score : ', f1_score)\n#     # Print or log results for comparison\n#     print(f\"Finished training with parameter: {paramx}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WGwG-z_2C13t","outputId":"f04b92cb-2a2a-4b7d-ef7a-dd9a38f316e5","scrolled":true,"execution":{"iopub.status.busy":"2024-10-16T12:33:45.402699Z","iopub.execute_input":"2024-10-16T12:33:45.403101Z","iopub.status.idle":"2024-10-16T12:33:45.412434Z","shell.execute_reply.started":"2024-10-16T12:33:45.403064Z","shell.execute_reply":"2024-10-16T12:33:45.411248Z"},"trusted":true},"execution_count":159,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchquantum as tq\n\nclass BetterBetterTorchLayer(torch.nn.Module):\n    def __init__(self, nodes_per_graph, num_layers, input_dim, device, entanglement_type='CNOT', encoding_type='RY'):\n        super(BetterBetterTorchLayer, self).__init__()\n        self.device = device\n        self.num_qubits = nodes_per_graph\n        self.entanglement_type = entanglement_type\n        self.encoding_type = encoding_type  # Encoding type\n        inputs = []\n        self.node_attr_count = 0\n        self.amplitude_encoding = False\n        self.IQP_encoding = False\n        self.displacement_encoding = False\n\n        # Choose the type of encoding\n        if self.encoding_type == 'AmplitudeEncoding':\n            self.amplitude_encoding = True\n        elif self.encoding_type == 'IQPEncoding':\n            self.IQP_encoding = True\n        elif self.encoding_type == 'DisplacementEncoding':\n            self.displacement_encoding = True\n        else:\n            self.amplitude_encoding = False\n            self.IQP_encoding = False\n            self.displacement_encoding = False\n\n        # Standard gate encoding for node attributes\n        q_control = 0  # Define the control qubit as the first qubit (you can modify this as needed)\n        q2 = 1  # Define a second qubit for gates like SWAP (you can modify this as well)\n        theta, phi, lambda_ = 0.5, 0.3, 0.1  # Example values for U3 gate parameters (adjustable)\n\n        if not self.amplitude_encoding and not self.IQP_encoding and not self.displacement_encoding:\n            for q in range(self.num_qubits):\n                for d in range(input_dim):\n                    if self.encoding_type == 'H':\n                        # Hadamard gate encoding for superposition\n                        inputs.append({'input_idx': self.node_attr_count, 'func': 'h', 'wires': [q]})\n\n                    inputs.append({'input_idx': self.node_attr_count, 'func': 'rx', 'wires': [q]})\n                    self.node_attr_count += 1\n\n            # Prepare edge inputs\n            self.edge_attr_count = self.node_attr_count + 1\n            for q in range(self.num_qubits):\n                for e in range(q + 1, self.num_qubits):\n                    inputs.append({'input_idx': self.edge_attr_count, 'func': 'crz', 'wires': [q, e]})\n                    self.edge_attr_count += 1\n            self.edge_attr_count -= self.node_attr_count\n\n        self.encoder = tq.GeneralEncoder(inputs)\n        self.q_layers = tq.QuantumModuleList()\n\n        # Build quantum layers with entanglement\n        for layer in range(num_layers):\n            self.q_layers.append(\n                tq.Op1QAllLayer(op=tq.RX, n_wires=self.num_qubits, has_params=True, trainable=True)\n            )\n            self.q_layers.append(\n                tq.Op1QAllLayer(op=tq.RY, n_wires=self.num_qubits, has_params=True, trainable=True)\n            )\n            self.q_layers.append(\n                tq.Op1QAllLayer(op=tq.RZ, n_wires=self.num_qubits, has_params=True, trainable=True)\n            )\n\n            # Apply entanglement layer based on selected type\n            if self.entanglement_type == 'CNOT':\n                self.q_layers.append(\n                    tq.Op2QAllLayer(op=tq.CNOT, n_wires=self.num_qubits, jump=(layer + 1) % (self.num_qubits - 1), circular=True)\n                )\n            elif self.entanglement_type == 'CZ':\n                self.q_layers.append(\n                    tq.Op2QAllLayer(op=tq.CZ, n_wires=self.num_qubits, jump=(layer + 1) % (self.num_qubits - 1), circular=True)\n                )\n            elif self.entanglement_type == 'SWAP':\n                self.q_layers.append(\n                    tq.Op2QAllLayer(op=tq.SWAP, n_wires=self.num_qubits, jump=(layer + 1) % (self.num_qubits - 1), circular=True)\n                )\n            elif self.entanglement_type == 'CNOTbutterfly':\n                self.q_layers.append(\n                    tq.Op2QButterflyLayer(op=tq.CNOT, n_wires=self.num_qubits, has_params=False, trainable=False, wire_reverse=False)\n                )\n            elif self.entanglement_type == 'CZbutterfly':\n                self.q_layers.append(\n                    tq.Op2QButterflyLayer(op=tq.CZ, n_wires=self.num_qubits, has_params=False, trainable=False, wire_reverse=False)\n                )\n            elif self.entanglement_type == 'SWAPbutterfly':\n                self.q_layers.append(\n                    tq.Op2QButterflyLayer(op=tq.SWAP, n_wires=self.num_qubits, has_params=False, trainable=False, wire_reverse=False)\n                )\n\n\n    def forward(self, node_inputs, node_indices, edge_inputs):\n        qdev = tq.QuantumDevice(n_wires=self.num_qubits, bsz=node_inputs.shape[0], device=self.device, record_op=True)\n\n        if self.amplitude_encoding:\n            # Convert to a size that is a power of 2\n            converted_data = pad_or_truncate_to_power_of_two(node_inputs)\n            # Normalize the data\n            normalized_data = normalize_data(converted_data)\n            # Initialize the amplitude embedding layer\n            amplitude_encoder = AmplitudeEmbedding(num_qubits=self.num_qubits, normalize=False, pad_with=0.0)\n            # Apply amplitude encoding\n            amplitude_encoder(qdev, normalized_data)\n\n        elif self.IQP_encoding:\n            # Initialize the circuit\n            encoder = IQPEmbedding(wires=range(self.num_qubits), n_repeats=3)\n            # Apply the circuit to the quantum device\n            encoder(qdev, node_inputs)\n\n        elif self.displacement_encoding:\n            # Initialize the circuit\n            encoder = DisplacementEmbedding(n_features=self.num_qubits, wires=list(range(self.num_qubits)), method=\"phase\") # \"amplitude\", \"phase\"\n            # Apply the circuit to the quantum device\n            encoder(qdev, node_inputs)\n\n        else:\n            # Default to gate encoding\n            self.encoder(qdev, torch.cat((node_inputs.reshape(node_inputs.shape[0], -1), edge_inputs.reshape(edge_inputs.shape[0], -1)), dim=1))\n\n        # Apply quantum layers\n        for l in range(len(self.q_layers)):\n            self.q_layers[l](qdev)\n\n        # Return the squared amplitude of the final quantum state\n        return torch.abs(qdev.get_states_1d()) ** 2\n","metadata":{"execution":{"iopub.status.busy":"2024-10-16T11:59:39.031315Z","iopub.execute_input":"2024-10-16T11:59:39.031950Z","iopub.status.idle":"2024-10-16T11:59:39.059109Z","shell.execute_reply.started":"2024-10-16T11:59:39.031909Z","shell.execute_reply":"2024-10-16T11:59:39.058003Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"#set up model\ndevice = 'cuda'\n# nodes_per_graph_original = 10\nnum_layer_gnn = 2\nnum_layer_gnn_est = 2\nqnn_layers = 3\nemb_dim = 128\nin_dim = 8\ninter_dim = 256\nout_dim = 128\nJK = 'last' # modify\ndropout_ratio = 0.1\ngnn_type = 'gat'    #'gcn'\nlr = 0.001 # 1e-4, 1e-2, 3e-3, 5e-3\ndecay = 0\naug_ratio = 0.1\nbatch_size = 2000 # 2000\nloss_temp = 0.1\nlamda = 0.1\nnode_est = 'quantum' # 'classical'\nentanglement_type='SWAP' # Can be 'CNOT', 'CZ', 'SWAP', 'CNOTbutterfly', 'CZbutterfly', 'SWAPbutterfly'\nencoding_type='H' # Can be 'AmplitudeEncoding', 'IQPEncoding', 'DisplacementEncoding', 'RY', 'RZ', 'RX', 'H'\n\ntorch.set_default_tensor_type('torch.cuda.FloatTensor')\n\nqg_dataset = QuarkGluonGraphDataset(dataset_name='Quark Gluon', raw_dir=main_dir, save_dir='/content',\n                                    data_folder_name=jet_folder_path, datafile_name=jet_file_path, labelsfile_name=jet_file_path,\n                                    datatype='particles', dataset_size=10000, nodes_per_graph=nodes_per_graph_original, spectral_augmentation=False, irc_safety_aug=True,\n                                    device='cuda') # dataset_size=10000\n\n# gnn = GNN(num_layer=num_layer_gnn, in_dim=in_dim, emb_dim=emb_dim, inter_dim=inter_dim, JK=JK, drop_ratio=dropout_ratio, gnn_type=gnn_type)\ngnn = ParticleNetTagger1Path(in_dim, 2)\nif node_est == 'classical':\n  node_imp_estimator = GNN_imp_estimator(num_layer=num_layer_gnn_est, emb_dim=emb_dim, in_dim=in_dim, JK=JK, drop_ratio=dropout_ratio)\nif node_est == 'quantum':\n  node_imp_estimator = QGNN_node_estimator(nodes_per_graph_original, qnn_layers, in_dim, device=device,\n                                           entanglement_type=entanglement_type, encoding_type=encoding_type)\n\nmodel = graphcl(gnn, node_imp_estimator, emb_dim, out_dim)\nmodel.to(device)\n\nimport cupy as cp\n#set up optimizer\noptimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=decay)\n\ncount = 0\nfor i,param in enumerate(model.parameters()):\n    if param.dtype==torch.complex64:\n        count+=torch.view_as_real(param).flatten().shape[0]\n    else:\n        count+=param.flatten().shape[0]\n\nprint(count)","metadata":{"id":"BeXbU8V9XzWk","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b52bb08b-3abf-4942-ff97-b991694a5829","execution":{"iopub.status.busy":"2024-10-16T11:59:48.838773Z","iopub.execute_input":"2024-10-16T11:59:48.839176Z","iopub.status.idle":"2024-10-16T12:00:19.107346Z","shell.execute_reply.started":"2024-10-16T11:59:48.839137Z","shell.execute_reply":"2024-10-16T12:00:19.106347Z"},"trusted":true},"execution_count":129,"outputs":[{"name":"stdout","text":"--- Finding All Unique Particles ---\n\n--- Inserting Masses ---\n","output_type":"stream"},{"name":"stderr","text":"14it [00:00, 3713.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n--- Calculating Momenta and Energies ---\n\n--- Calculating Edge Tensors ---\n","output_type":"stream"},{"name":"stderr","text":"100%|| 10000/10000 [00:13<00:00, 752.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"--- Creating graphs ---\n","output_type":"stream"},{"name":"stderr","text":"100%|| 10000/10000 [00:04<00:00, 2017.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"126015\n","output_type":"stream"}]},{"cell_type":"code","source":"epochs = 50\ncon_loss = []\n\nfor epoch in range(1, epochs + 1):\n    print(\"====epoch \" + str(epoch))\n    qg_dataset.augment = False\n    train_loss, ra_loss, cp_loss, uni_loss, al_loss = train(epoch, model=model, device=device, dataset=qg_dataset, optimizer=optimizer, batch_size=batch_size,\n                                      nodes_per_graph=qg_dataset.nodes_per_graph, aug_ratio=aug_ratio, loss_temp=loss_temp, lamda=lamda,\n                                      irc_safety=True, q_edge_attr=True, node_est=node_est)\n    con_loss.append(train_loss)\n    print(train_loss)\n    print(ra_loss)\n    print(cp_loss)\n    print('UNI : ', uni_loss)\n    print('ALIGN : ', al_loss)","metadata":{"id":"M_gVJlaDX8RW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1d47b443-dd7b-4fca-84f8-2336be50bcd2","scrolled":true,"execution":{"iopub.status.busy":"2024-10-16T12:00:19.109288Z","iopub.execute_input":"2024-10-16T12:00:19.109608Z","iopub.status.idle":"2024-10-16T12:14:41.359387Z","shell.execute_reply.started":"2024-10-16T12:00:19.109573Z","shell.execute_reply":"2024-10-16T12:14:41.358422Z"},"trusted":true},"execution_count":130,"outputs":[{"name":"stdout","text":"====epoch 1\n4.595238828659058\n4.172805595397949\n4.224332618713379\nUNI :  -1.997514271736145\nALIGN :  0.10274989604949951\n====epoch 2\n2.2510359048843385\n2.022753357887268\n2.2828254222869875\nUNI :  -3.2824020385742188\nALIGN :  0.18077767193317412\n====epoch 3\n1.6085790157318116\n1.4235837936401368\n1.8499523639678954\nUNI :  -3.5150808811187746\nALIGN :  0.21856073439121246\n====epoch 4\n1.2153927087783813\n1.053631889820099\n1.6176083564758301\nUNI :  -3.6350307941436766\nALIGN :  0.22762183248996734\n====epoch 5\n0.9395268201828003\n0.7927840232849122\n1.4674277782440186\nUNI :  -3.6879677772521973\nALIGN :  0.228079092502594\n====epoch 6\n0.712245500087738\n0.5761590719223022\n1.3608642101287842\nUNI :  -3.7287535190582277\nALIGN :  0.22592168748378755\n====epoch 7\n0.5488174378871917\n0.419839209318161\n1.2897822856903076\nUNI :  -3.7491512298583984\nALIGN :  0.2199599713087082\n====epoch 8\n0.4116667628288269\n0.28859626352787016\n1.2307050466537475\nUNI :  -3.7684656143188477\nALIGN :  0.21257835030555725\n====epoch 9\n0.304116028547287\n0.18525260388851167\n1.1886342763900757\nUNI :  -3.782021427154541\nALIGN :  0.20624805092811585\n====epoch 10\n0.20675110816955566\n0.09150220602750778\n1.1524889945983887\nUNI :  -3.7902215003967283\nALIGN :  0.19778101444244384\n====epoch 11\n0.13504284173250197\n0.022106288792565466\n1.1293655157089233\nUNI :  -3.7963194847106934\nALIGN :  0.19350847899913787\n====epoch 12\n0.07593341246247291\n-0.035050413198769094\n1.1098382234573365\nUNI :  -3.8006236076354982\nALIGN :  0.1896209478378296\n====epoch 13\n0.01972838640213013\n-0.08921036422252655\n1.0893874883651733\nUNI :  -3.8044764518737795\nALIGN :  0.1848122626543045\n====epoch 14\n-0.03075585812330246\n-0.13804249912500383\n1.07286639213562\nUNI :  -3.8075175285339355\nALIGN :  0.18099959194660187\n====epoch 15\n-0.07169607132673264\n-0.17788791358470918\n1.0619184017181396\nUNI :  -3.8112960338592528\nALIGN :  0.17897913455963135\n====epoch 16\n-0.1200674220919609\n-0.22467045187950135\n1.0460302591323853\nUNI :  -3.8164859294891356\nALIGN :  0.17523427605628966\n====epoch 17\n-0.15994543433189393\n-0.2635452687740326\n1.035998320579529\nUNI :  -3.820140838623047\nALIGN :  0.17278383374214173\n====epoch 18\n-0.19310645759105682\n-0.2958941638469696\n1.0278770446777343\nUNI :  -3.8231685638427733\nALIGN :  0.17042305171489716\n====epoch 19\n-0.22535909712314606\n-0.3271501839160919\n1.0179108381271362\nUNI :  -3.824987602233887\nALIGN :  0.16776883900165557\n====epoch 20\n-0.2572844922542572\n-0.3581744790077209\n1.0088999032974244\nUNI :  -3.8277512073516844\nALIGN :  0.16568784713745116\n====epoch 21\n-0.28518942594528196\n-0.38541426658630373\n1.0022483587265014\nUNI :  -3.8315401554107664\nALIGN :  0.16375117003917694\n====epoch 22\n-0.3048839807510376\n-0.40455047488212587\n0.9966648936271667\nUNI :  -3.832439088821411\nALIGN :  0.16306612491607667\n====epoch 23\n-0.3292701721191406\n-0.4283310115337372\n0.9906083941459656\nUNI :  -3.832870864868164\nALIGN :  0.16053758859634398\n====epoch 24\n-0.3563597083091736\n-0.4546055793762207\n0.9824586987495423\nUNI :  -3.835717058181763\nALIGN :  0.1585589200258255\n====epoch 25\n-0.3783737778663635\n-0.47611382603645325\n0.9774003982543945\nUNI :  -3.837689685821533\nALIGN :  0.15699109435081482\n====epoch 26\n-0.39413697719573976\n-0.49167240858078004\n0.9753543019294739\nUNI :  -3.839278793334961\nALIGN :  0.15616858303546904\n====epoch 27\n-0.41467913389205935\n-0.5116789221763611\n0.969997787475586\nUNI :  -3.841301155090332\nALIGN :  0.15461468696594238\n====epoch 28\n-0.43570380806922915\n-0.5320649981498718\n0.9636118888854981\nUNI :  -3.8420873165130613\nALIGN :  0.15281147360801697\n====epoch 29\n-0.4534488499164581\n-0.5495883822441101\n0.9613953232765198\nUNI :  -3.843725252151489\nALIGN :  0.15156080722808837\n====epoch 30\n-0.4755083680152893\n-0.5712194204330444\n0.9571105480194092\nUNI :  -3.8455942153930662\nALIGN :  0.14975522756576537\n====epoch 31\n-0.48401122689247134\n-0.579521119594574\n0.9550988078117371\nUNI :  -3.845707082748413\nALIGN :  0.1496696025133133\n====epoch 32\n-0.4972996890544891\n-0.592377781867981\n0.9507809400558471\nUNI :  -3.8451138973236083\nALIGN :  0.1479958862066269\n====epoch 33\n-0.5101421117782593\n-0.6048289656639099\n0.9468685865402222\nUNI :  -3.844809722900391\nALIGN :  0.14644770920276642\n====epoch 34\n-0.5226855158805848\n-0.6173135042190552\n0.9462798595428467\nUNI :  -3.8471192359924316\nALIGN :  0.14615545868873597\n====epoch 35\n-0.5494574785232544\n-0.6432685375213623\n0.9381106972694397\nUNI :  -3.8517924308776856\nALIGN :  0.14434332847595216\n====epoch 36\n-0.5725715279579162\n-0.6659283995628357\n0.933568811416626\nUNI :  -3.8552225112915037\nALIGN :  0.14239163398742677\n====epoch 37\n-0.5825308680534362\n-0.675958001613617\n0.934271490573883\nUNI :  -3.858493995666504\nALIGN :  0.1433304190635681\n====epoch 38\n-0.6006632804870605\n-0.6936511278152466\n0.9298784613609314\nUNI :  -3.8598000526428224\nALIGN :  0.14181970059871674\n====epoch 39\n-0.616793954372406\n-0.7090959310531616\n0.9230197429656982\nUNI :  -3.8614433288574217\nALIGN :  0.14067151248455048\n====epoch 40\n-0.6254998087882996\n-0.717770767211914\n0.9227095365524292\nUNI :  -3.862789821624756\nALIGN :  0.14036219716072082\n====epoch 41\n-0.640296745300293\n-0.7323372483253479\n0.9204050779342652\nUNI :  -3.8631652355194093\nALIGN :  0.13898743391036988\n====epoch 42\n-0.6561249732971192\n-0.7477482914924621\n0.9162331223487854\nUNI :  -3.8643993854522707\nALIGN :  0.1372274339199066\n====epoch 43\n-0.6667552947998047\n-0.7583109736442566\n0.9155568242073059\nUNI :  -3.8650608539581297\nALIGN :  0.1364881455898285\n====epoch 44\n-0.6763127326965332\n-0.7676025271415711\n0.9128979682922364\nUNI :  -3.8668025493621827\nALIGN :  0.1362601101398468\n====epoch 45\n-0.6910022139549256\n-0.7819879651069641\n0.9098574995994568\nUNI :  -3.86898193359375\nALIGN :  0.13512913286685943\n====epoch 46\n-0.7066564798355103\n-0.797122061252594\n0.9046557784080506\nUNI :  -3.870356321334839\nALIGN :  0.13346677422523498\n====epoch 47\n-0.7197807192802429\n-0.8101254940032959\n0.9034477233886719\nUNI :  -3.8722161769866945\nALIGN :  0.133077535033226\n====epoch 48\n-0.7268220782279968\n-0.8174248576164246\n0.9060277700424194\nUNI :  -3.875235843658447\nALIGN :  0.13391132056713104\n====epoch 49\n-0.7465765595436096\n-0.8364364504814148\n0.8985990643501282\nUNI :  -3.8771985530853272\nALIGN :  0.13186396658420563\n====epoch 50\n-0.7541642308235168\n-0.8440279960632324\n0.8986376047134399\nUNI :  -3.8777862548828126\nALIGN :  0.13140348196029664\n","output_type":"stream"}]},{"cell_type":"code","source":"# nodes_per_graph_original = 10\ntest_dataset = QuarkGluonGraphDataset(dataset_name='Quark Gluon', raw_dir=main_dir, save_dir='/content',\n                                    data_folder_name=jet_folder_path, datafile_name=jet_file_path, labelsfile_name=jet_file_path,\n                                    datatype='particles', dataset_size=7000, nodes_per_graph=nodes_per_graph_original, spectral_augmentation=False, irc_safety_aug=True,\n                                    device='cuda')","metadata":{"id":"geSjHgy0YDwt","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3eb3c1c8-ff70-4a87-ee11-ba3f29804b3f","execution":{"iopub.status.busy":"2024-10-16T12:14:41.361496Z","iopub.execute_input":"2024-10-16T12:14:41.361946Z","iopub.status.idle":"2024-10-16T12:15:01.306457Z","shell.execute_reply.started":"2024-10-16T12:14:41.361898Z","shell.execute_reply":"2024-10-16T12:15:01.305662Z"},"trusted":true},"execution_count":131,"outputs":[{"name":"stdout","text":"--- Finding All Unique Particles ---\n\n--- Inserting Masses ---\n","output_type":"stream"},{"name":"stderr","text":"14it [00:00, 4220.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n--- Calculating Momenta and Energies ---\n\n--- Calculating Edge Tensors ---\n","output_type":"stream"},{"name":"stderr","text":"100%|| 7000/7000 [00:08<00:00, 797.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"--- Creating graphs ---\n","output_type":"stream"},{"name":"stderr","text":"100%|| 7000/7000 [00:03<00:00, 2169.06it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"test_samples = torch.tensor(np.arange(0,7000).astype('int32'))\ntest_sampler = SubsetRandomSampler(test_samples)\n\ntest_dataloader = test_dataloader = GraphDataLoader(\n    test_dataset, sampler=test_sampler, batch_size=500, drop_last=False\n)","metadata":{"id":"2NHBtA-yYGK5","execution":{"iopub.status.busy":"2024-10-16T12:27:12.202516Z","iopub.execute_input":"2024-10-16T12:27:12.203204Z","iopub.status.idle":"2024-10-16T12:27:12.209186Z","shell.execute_reply.started":"2024-10-16T12:27:12.203161Z","shell.execute_reply":"2024-10-16T12:27:12.208175Z"},"trusted":true},"execution_count":145,"outputs":[]},{"cell_type":"code","source":"cls_embds = torch.Tensor([])\ncls_labels = torch.Tensor([])\n\nfor batched_graph, labels in test_dataloader:\n  graphs = []\n  unbatched_graph = dgl.unbatch(batched_graph)\n  for graph in unbatched_graph:\n    graphs.append(dgl.add_self_loop(graph))\n  batched_graph = dgl.batch(graphs)\n  batch_t = torch.arange(0, batched_graph.batch_size).reshape(-1,1).expand(batched_graph.batch_size, test_dataset.nodes_per_graph).reshape(-1,)\n\n  ## For custom GNN\n  # cls_emb = gnn.forward(batched_graph.ndata[\"node_attr\"].float(), torch.stack(batched_graph.edges()), batched_graph.edata[\"edge_attr\"].float())\n\n  ## For ParticleNet\n  pf_feats = batched_graph.ndata[\"node_attr\"].reshape(len(unbatched_graph), nodes_per_graph_original, -1).float()\n  points = pf_feats[:,:,1:3]\n  cls_emb = gnn.forward(points.reshape(points.shape[0], points.shape[2], points.shape[1])\n                     , pf_feats.reshape(pf_feats.shape[0], pf_feats.shape[2], pf_feats.shape[1]), None)\n  cls_emb = cls_emb.reshape(cls_emb.shape[0], cls_emb.shape[2], cls_emb.shape[1])\n  cls_emb = cls_emb.reshape(cls_emb.shape[0]*cls_emb.shape[1], cls_emb.shape[2])\n\n  # cls_emb = batched_graph.ndata[\"node_attr\"].float()\n  cls_emb = global_mean_pool(cls_emb, batch_t)\n  cls_embds = torch.cat((cls_embds, cls_emb.detach()), 0)     #cls_emb\n  cls_labels = torch.cat((cls_labels, labels))","metadata":{"id":"zG95SQuHYHB3","execution":{"iopub.status.busy":"2024-10-16T12:27:12.213258Z","iopub.execute_input":"2024-10-16T12:27:12.213983Z","iopub.status.idle":"2024-10-16T12:27:26.615785Z","shell.execute_reply.started":"2024-10-16T12:27:12.213946Z","shell.execute_reply":"2024-10-16T12:27:26.614933Z"},"trusted":true},"execution_count":146,"outputs":[]},{"cell_type":"code","source":"cls_epochs = 1000\ncls_train_data = cls_embds[ : int(0.8*len(cls_embds))]\ntargets = cls_labels[ : int(0.8*len(cls_embds))]\ncls_test_data = cls_embds[int(0.8*len(cls_embds)) : ]\ntesttargets = cls_labels[int(0.8*len(cls_embds)) : ]","metadata":{"id":"bpwPGFaRYJH-","execution":{"iopub.status.busy":"2024-10-16T12:27:26.618804Z","iopub.execute_input":"2024-10-16T12:27:26.619127Z","iopub.status.idle":"2024-10-16T12:27:26.624967Z","shell.execute_reply.started":"2024-10-16T12:27:26.619092Z","shell.execute_reply":"2024-10-16T12:27:26.623860Z"},"trusted":true},"execution_count":147,"outputs":[]},{"cell_type":"code","source":"### Reference - https://github.com/sdogsq/LorentzNet-release/blob/main/scripts/QGTaggingROC/ROC.py\n\n# Function that takes the labels and score of the positive class\n# (top class) and returns a ROC curve, as well as the signal efficiency\n# and background rejection at a given targe signal efficiency, defaults\n# to 0.3\n\ndef buildROC(labels, score, targetEff=[0.3,0.5]):\n    if not isinstance(targetEff, list):\n        targetEff = [targetEff]\n    fpr, tpr, threshold = metrics.roc_curve(labels, score)\n    idx = [np.argmin(np.abs(tpr - Eff)) for Eff in targetEff]\n    eB, eS = fpr[idx], tpr[idx]\n    return fpr, tpr, threshold, eB, eS\n\n### Reference - https://github.com/bmdillon/JetCLR/blob/main/scripts/modules/perf_eval.py\n\ndef find_nearest( array, value ):\n    array = np.asarray( array )\n    idx = ( np.abs( array-value ) ).argmin()\n    return array[idx]\n\ndef get_perf_stats( labels, measures ):\n    measures = np.nan_to_num( measures )\n    auc = metrics.roc_auc_score( labels, measures )\n    fpr,tpr,thresholds = metrics.roc_curve( labels, measures )\n    fpr2 = [ fpr[i] for i in range( len( fpr ) ) if tpr[i]>=0.5]\n    tpr2 = [ tpr[i] for i in range( len( tpr ) ) if tpr[i]>=0.5]\n    try:\n        imtafe = np.nan_to_num( 1 / fpr2[ list( tpr2 ).index( find_nearest( list( tpr2 ), 0.5 ) ) ] )\n    except:\n        imtafe = 1\n    return auc, imtafe","metadata":{"id":"c9DjNmLGZHe6","execution":{"iopub.status.busy":"2024-10-16T12:27:26.626275Z","iopub.execute_input":"2024-10-16T12:27:26.626642Z","iopub.status.idle":"2024-10-16T12:27:26.638899Z","shell.execute_reply.started":"2024-10-16T12:27:26.626598Z","shell.execute_reply":"2024-10-16T12:27:26.637926Z"},"trusted":true},"execution_count":148,"outputs":[]},{"cell_type":"code","source":"classifier = torch.nn.Sequential(\n    torch.nn.Linear(128,1),\n    torch.nn.Sigmoid()\n)\n\n\ndef train_classifier(cls_epochs, classifier, cls_train_data, labels, cls_test_data, testlabels):\n  optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08)\n  cls_loss = []\n  cls_accuracy = []\n  test_cls_loss = []\n  test_cls_accuracy = []\n\n  for ce in range(cls_epochs):\n\n    correct = 0\n    total = 0\n    t_correct = 0\n    t_total = 0\n    optimizer.zero_grad()\n    outputs = classifier(cls_train_data)\n    loss = torch.nn.BCELoss()(outputs,labels.view(-1,1))\n    loss.backward()\n    optimizer.step()\n    predicted = np.round(outputs.cpu().detach().numpy())\n    total += labels.size(0)\n    correct += np.sum(torch.eq(torch.Tensor(predicted), labels.view(-1,1)).cpu().detach().numpy())\n    accuracy = 100 * correct / total\n    cls_loss.append(loss.cpu().detach().numpy())\n    cls_accuracy.append(accuracy)\n    testoutputs = classifier(cls_test_data)\n    testloss = torch.nn.BCELoss()(testoutputs, testlabels.view(-1,1))\n    testpredicted = np.round(testoutputs.cpu().detach().numpy())\n    t_total += testlabels.size(0)\n    t_correct += np.sum(torch.eq(torch.Tensor(testpredicted), testlabels.view(-1,1)).cpu().detach().numpy())\n    testaccuracy = 100 * t_correct / t_total\n    test_cls_loss.append(testloss.cpu().detach().numpy())  #np.mean(e_loss)\n    test_cls_accuracy.append(testaccuracy)\n    if epochs % 50 == 0:\n      print(f'Epochs : {ce} ; Loss : {loss.cpu().detach().numpy()} ; Accuracy : {accuracy} ; Test Loss : {testloss} ; Test accuracy : {testaccuracy}' )   #np.mean(e_loss)\n\n  testoutputs = classifier(cls_test_data)\n  # fpr, tpr, thresholds = metrics.roc_curve(testlabels.cpu(), testoutputs.cpu().detach().numpy())\n  fpr, tpr, threshold, eB, eS = buildROC(testlabels.cpu(), testoutputs.cpu().detach().numpy())\n  auc = metrics.auc(fpr, tpr)\n  f1_score = metrics.f1_score(testlabels.cpu(), np.round(testoutputs.cpu().detach().numpy()), average='macro')\n  _ , imtafe = get_perf_stats(testlabels.cpu(), testoutputs.cpu().detach().numpy())\n  return cls_loss, cls_accuracy, test_cls_loss, test_cls_accuracy, fpr, tpr, auc, eB, eS, f1_score, imtafe, outputs\n\n\ncls_loss, cls_accuracy, test_cls_loss, test_cls_accuracy, fpr, tpr, auc, eB, eS, f1_score, imtafe, predicted = train_classifier(cls_epochs, classifier, cls_train_data, targets, cls_test_data, testtargets)","metadata":{"id":"FtrCG9eSYLSx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6509f907-4751-446b-81e8-7ac7fdeaf9ed","scrolled":true,"execution":{"iopub.status.busy":"2024-10-16T12:27:26.641700Z","iopub.execute_input":"2024-10-16T12:27:26.642065Z","iopub.status.idle":"2024-10-16T12:27:33.277005Z","shell.execute_reply.started":"2024-10-16T12:27:26.642022Z","shell.execute_reply":"2024-10-16T12:27:33.275913Z"},"trusted":true},"execution_count":149,"outputs":[{"name":"stdout","text":"Epochs : 0 ; Loss : 0.7021549344062805 ; Accuracy : 50.375 ; Test Loss : 0.6975656151771545 ; Test accuracy : 49.285714285714285\nEpochs : 1 ; Loss : 0.6987563371658325 ; Accuracy : 50.607142857142854 ; Test Loss : 0.6942080855369568 ; Test accuracy : 50.285714285714285\nEpochs : 2 ; Loss : 0.6958940625190735 ; Accuracy : 51.19642857142857 ; Test Loss : 0.6913710236549377 ; Test accuracy : 51.785714285714285\nEpochs : 3 ; Loss : 0.6935407519340515 ; Accuracy : 52.142857142857146 ; Test Loss : 0.6890174150466919 ; Test accuracy : 53.357142857142854\nEpochs : 4 ; Loss : 0.6916546821594238 ; Accuracy : 53.017857142857146 ; Test Loss : 0.6871002316474915 ; Test accuracy : 54.642857142857146\nEpochs : 5 ; Loss : 0.6901810169219971 ; Accuracy : 52.714285714285715 ; Test Loss : 0.6855548620223999 ; Test accuracy : 56.857142857142854\nEpochs : 6 ; Loss : 0.6890490055084229 ; Accuracy : 53.732142857142854 ; Test Loss : 0.6843067407608032 ; Test accuracy : 58.642857142857146\nEpochs : 7 ; Loss : 0.6881784200668335 ; Accuracy : 53.982142857142854 ; Test Loss : 0.6832799315452576 ; Test accuracy : 58.714285714285715\nEpochs : 8 ; Loss : 0.687488853931427 ; Accuracy : 54.375 ; Test Loss : 0.6824047565460205 ; Test accuracy : 58.714285714285715\nEpochs : 9 ; Loss : 0.6869077086448669 ; Accuracy : 54.785714285714285 ; Test Loss : 0.6816221475601196 ; Test accuracy : 58.42857142857143\nEpochs : 10 ; Loss : 0.6863750219345093 ; Accuracy : 55.214285714285715 ; Test Loss : 0.6808853149414062 ; Test accuracy : 58.214285714285715\nEpochs : 11 ; Loss : 0.6858450770378113 ; Accuracy : 54.92857142857143 ; Test Loss : 0.6801608800888062 ; Test accuracy : 58.142857142857146\nEpochs : 12 ; Loss : 0.6852865815162659 ; Accuracy : 55.0 ; Test Loss : 0.6794273257255554 ; Test accuracy : 58.5\nEpochs : 13 ; Loss : 0.6846810579299927 ; Accuracy : 55.25 ; Test Loss : 0.6786738038063049 ; Test accuracy : 58.07142857142857\nEpochs : 14 ; Loss : 0.6840212345123291 ; Accuracy : 55.30357142857143 ; Test Loss : 0.6778973340988159 ; Test accuracy : 58.42857142857143\nEpochs : 15 ; Loss : 0.6833075881004333 ; Accuracy : 55.535714285714285 ; Test Loss : 0.6771009564399719 ; Test accuracy : 58.642857142857146\nEpochs : 16 ; Loss : 0.6825470924377441 ; Accuracy : 55.785714285714285 ; Test Loss : 0.6762911677360535 ; Test accuracy : 59.214285714285715\nEpochs : 17 ; Loss : 0.6817502975463867 ; Accuracy : 56.267857142857146 ; Test Loss : 0.6754765510559082 ; Test accuracy : 59.5\nEpochs : 18 ; Loss : 0.6809293627738953 ; Accuracy : 56.55357142857143 ; Test Loss : 0.6746656894683838 ; Test accuracy : 59.785714285714285\nEpochs : 19 ; Loss : 0.6800969243049622 ; Accuracy : 56.75 ; Test Loss : 0.6738665103912354 ; Test accuracy : 60.0\nEpochs : 20 ; Loss : 0.67926424741745 ; Accuracy : 56.910714285714285 ; Test Loss : 0.6730847358703613 ; Test accuracy : 60.285714285714285\nEpochs : 21 ; Loss : 0.6784408688545227 ; Accuracy : 57.375 ; Test Loss : 0.6723240613937378 ; Test accuracy : 60.785714285714285\nEpochs : 22 ; Loss : 0.6776337623596191 ; Accuracy : 57.875 ; Test Loss : 0.6715854406356812 ; Test accuracy : 61.07142857142857\nEpochs : 23 ; Loss : 0.6768471002578735 ; Accuracy : 58.25 ; Test Loss : 0.6708675026893616 ; Test accuracy : 61.0\nEpochs : 24 ; Loss : 0.67608243227005 ; Accuracy : 58.642857142857146 ; Test Loss : 0.6701666116714478 ; Test accuracy : 60.714285714285715\nEpochs : 25 ; Loss : 0.6753387451171875 ; Accuracy : 58.589285714285715 ; Test Loss : 0.6694777011871338 ; Test accuracy : 60.857142857142854\nEpochs : 26 ; Loss : 0.6746131777763367 ; Accuracy : 58.714285714285715 ; Test Loss : 0.6687944531440735 ; Test accuracy : 61.285714285714285\nEpochs : 27 ; Loss : 0.6739016175270081 ; Accuracy : 59.267857142857146 ; Test Loss : 0.6681106686592102 ; Test accuracy : 61.714285714285715\nEpochs : 28 ; Loss : 0.6731993556022644 ; Accuracy : 59.267857142857146 ; Test Loss : 0.6674205660820007 ; Test accuracy : 61.92857142857143\nEpochs : 29 ; Loss : 0.6725015640258789 ; Accuracy : 59.589285714285715 ; Test Loss : 0.6667191386222839 ; Test accuracy : 62.142857142857146\nEpochs : 30 ; Loss : 0.6718041300773621 ; Accuracy : 59.875 ; Test Loss : 0.6660030484199524 ; Test accuracy : 62.5\nEpochs : 31 ; Loss : 0.6711037755012512 ; Accuracy : 59.94642857142857 ; Test Loss : 0.6652705669403076 ; Test accuracy : 62.57142857142857\nEpochs : 32 ; Loss : 0.6703986525535583 ; Accuracy : 60.214285714285715 ; Test Loss : 0.6645213961601257 ; Test accuracy : 62.5\nEpochs : 33 ; Loss : 0.6696879863739014 ; Accuracy : 60.375 ; Test Loss : 0.6637569069862366 ; Test accuracy : 62.42857142857143\nEpochs : 34 ; Loss : 0.6689722537994385 ; Accuracy : 60.660714285714285 ; Test Loss : 0.6629794836044312 ; Test accuracy : 62.5\nEpochs : 35 ; Loss : 0.6682528257369995 ; Accuracy : 60.785714285714285 ; Test Loss : 0.6621925234794617 ; Test accuracy : 62.857142857142854\nEpochs : 36 ; Loss : 0.6675314903259277 ; Accuracy : 61.035714285714285 ; Test Loss : 0.6613997220993042 ; Test accuracy : 62.857142857142854\nEpochs : 37 ; Loss : 0.6668104529380798 ; Accuracy : 61.214285714285715 ; Test Loss : 0.6606048345565796 ; Test accuracy : 63.142857142857146\nEpochs : 38 ; Loss : 0.6660919189453125 ; Accuracy : 61.285714285714285 ; Test Loss : 0.6598111987113953 ; Test accuracy : 63.42857142857143\nEpochs : 39 ; Loss : 0.6653776168823242 ; Accuracy : 61.57142857142857 ; Test Loss : 0.6590219736099243 ; Test accuracy : 63.785714285714285\nEpochs : 40 ; Loss : 0.6646689176559448 ; Accuracy : 61.857142857142854 ; Test Loss : 0.6582393646240234 ; Test accuracy : 63.92857142857143\nEpochs : 41 ; Loss : 0.6639665961265564 ; Accuracy : 62.017857142857146 ; Test Loss : 0.6574652194976807 ; Test accuracy : 63.92857142857143\nEpochs : 42 ; Loss : 0.663270890712738 ; Accuracy : 62.17857142857143 ; Test Loss : 0.6567004919052124 ; Test accuracy : 64.28571428571429\nEpochs : 43 ; Loss : 0.6625814437866211 ; Accuracy : 62.357142857142854 ; Test Loss : 0.6559456586837769 ; Test accuracy : 64.35714285714286\nEpochs : 44 ; Loss : 0.6618977785110474 ; Accuracy : 62.55357142857143 ; Test Loss : 0.6552008390426636 ; Test accuracy : 64.64285714285714\nEpochs : 45 ; Loss : 0.66121906042099 ; Accuracy : 62.642857142857146 ; Test Loss : 0.6544657945632935 ; Test accuracy : 64.64285714285714\nEpochs : 46 ; Loss : 0.6605444550514221 ; Accuracy : 62.80357142857143 ; Test Loss : 0.6537401676177979 ; Test accuracy : 64.85714285714286\nEpochs : 47 ; Loss : 0.6598730683326721 ; Accuracy : 62.94642857142857 ; Test Loss : 0.6530235409736633 ; Test accuracy : 65.14285714285714\nEpochs : 48 ; Loss : 0.6592045426368713 ; Accuracy : 62.964285714285715 ; Test Loss : 0.6523154973983765 ; Test accuracy : 65.21428571428571\nEpochs : 49 ; Loss : 0.658538281917572 ; Accuracy : 63.07142857142857 ; Test Loss : 0.6516156792640686 ; Test accuracy : 65.35714285714286\nEpochs : 50 ; Loss : 0.6578744649887085 ; Accuracy : 63.160714285714285 ; Test Loss : 0.6509239077568054 ; Test accuracy : 65.5\nEpochs : 51 ; Loss : 0.6572130918502808 ; Accuracy : 63.232142857142854 ; Test Loss : 0.6502397060394287 ; Test accuracy : 65.57142857142857\nEpochs : 52 ; Loss : 0.6565544605255127 ; Accuracy : 63.339285714285715 ; Test Loss : 0.6495628952980042 ; Test accuracy : 65.78571428571429\nEpochs : 53 ; Loss : 0.6558990478515625 ; Accuracy : 63.5 ; Test Loss : 0.6488930583000183 ; Test accuracy : 66.14285714285714\nEpochs : 54 ; Loss : 0.6552472710609436 ; Accuracy : 63.660714285714285 ; Test Loss : 0.6482298970222473 ; Test accuracy : 66.71428571428571\nEpochs : 55 ; Loss : 0.6545995473861694 ; Accuracy : 63.910714285714285 ; Test Loss : 0.6475726962089539 ; Test accuracy : 67.14285714285714\nEpochs : 56 ; Loss : 0.6539561152458191 ; Accuracy : 64.01785714285714 ; Test Loss : 0.646920919418335 ; Test accuracy : 67.57142857142857\nEpochs : 57 ; Loss : 0.6533172726631165 ; Accuracy : 63.964285714285715 ; Test Loss : 0.6462739706039429 ; Test accuracy : 67.92857142857143\nEpochs : 58 ; Loss : 0.652682900428772 ; Accuracy : 63.94642857142857 ; Test Loss : 0.645630955696106 ; Test accuracy : 68.21428571428571\nEpochs : 59 ; Loss : 0.6520531177520752 ; Accuracy : 64.125 ; Test Loss : 0.6449912786483765 ; Test accuracy : 68.28571428571429\nEpochs : 60 ; Loss : 0.651427686214447 ; Accuracy : 64.14285714285714 ; Test Loss : 0.6443542242050171 ; Test accuracy : 68.42857142857143\nEpochs : 61 ; Loss : 0.6508064270019531 ; Accuracy : 64.26785714285714 ; Test Loss : 0.6437193751335144 ; Test accuracy : 68.35714285714286\nEpochs : 62 ; Loss : 0.650189220905304 ; Accuracy : 64.39285714285714 ; Test Loss : 0.6430862545967102 ; Test accuracy : 68.57142857142857\nEpochs : 63 ; Loss : 0.6495758891105652 ; Accuracy : 64.57142857142857 ; Test Loss : 0.6424548029899597 ; Test accuracy : 68.85714285714286\nEpochs : 64 ; Loss : 0.6489662528038025 ; Accuracy : 64.64285714285714 ; Test Loss : 0.6418249011039734 ; Test accuracy : 68.78571428571429\nEpochs : 65 ; Loss : 0.6483602523803711 ; Accuracy : 64.82142857142857 ; Test Loss : 0.6411967277526855 ; Test accuracy : 68.85714285714286\nEpochs : 66 ; Loss : 0.647757887840271 ; Accuracy : 64.96428571428571 ; Test Loss : 0.6405705213546753 ; Test accuracy : 69.0\nEpochs : 67 ; Loss : 0.6471592783927917 ; Accuracy : 65.07142857142857 ; Test Loss : 0.6399468183517456 ; Test accuracy : 69.07142857142857\nEpochs : 68 ; Loss : 0.6465643048286438 ; Accuracy : 65.14285714285714 ; Test Loss : 0.6393259167671204 ; Test accuracy : 69.07142857142857\nEpochs : 69 ; Loss : 0.6459733247756958 ; Accuracy : 65.14285714285714 ; Test Loss : 0.6387084126472473 ; Test accuracy : 69.07142857142857\nEpochs : 70 ; Loss : 0.6453862190246582 ; Accuracy : 65.19642857142857 ; Test Loss : 0.6380947828292847 ; Test accuracy : 69.0\nEpochs : 71 ; Loss : 0.6448031067848206 ; Accuracy : 65.21428571428571 ; Test Loss : 0.6374854445457458 ; Test accuracy : 69.0\nEpochs : 72 ; Loss : 0.6442240476608276 ; Accuracy : 65.32142857142857 ; Test Loss : 0.6368809342384338 ; Test accuracy : 69.21428571428571\nEpochs : 73 ; Loss : 0.6436491012573242 ; Accuracy : 65.33928571428571 ; Test Loss : 0.6362814903259277 ; Test accuracy : 69.21428571428571\nEpochs : 74 ; Loss : 0.6430781483650208 ; Accuracy : 65.48214285714286 ; Test Loss : 0.6356873512268066 ; Test accuracy : 69.28571428571429\nEpochs : 75 ; Loss : 0.6425113081932068 ; Accuracy : 65.48214285714286 ; Test Loss : 0.6350988149642944 ; Test accuracy : 69.35714285714286\nEpochs : 76 ; Loss : 0.641948401927948 ; Accuracy : 65.625 ; Test Loss : 0.6345159411430359 ; Test accuracy : 69.57142857142857\nEpochs : 77 ; Loss : 0.6413893103599548 ; Accuracy : 65.69642857142857 ; Test Loss : 0.6339387893676758 ; Test accuracy : 69.64285714285714\nEpochs : 78 ; Loss : 0.6408342719078064 ; Accuracy : 65.69642857142857 ; Test Loss : 0.6333674192428589 ; Test accuracy : 69.64285714285714\nEpochs : 79 ; Loss : 0.640282928943634 ; Accuracy : 65.78571428571429 ; Test Loss : 0.6328016519546509 ; Test accuracy : 69.57142857142857\nEpochs : 80 ; Loss : 0.6397354602813721 ; Accuracy : 65.85714285714286 ; Test Loss : 0.6322414875030518 ; Test accuracy : 69.64285714285714\nEpochs : 81 ; Loss : 0.6391916871070862 ; Accuracy : 65.89285714285714 ; Test Loss : 0.6316866278648376 ; Test accuracy : 69.5\nEpochs : 82 ; Loss : 0.6386517882347107 ; Accuracy : 65.94642857142857 ; Test Loss : 0.6311371922492981 ; Test accuracy : 69.5\nEpochs : 83 ; Loss : 0.638115644454956 ; Accuracy : 66.125 ; Test Loss : 0.6305927038192749 ; Test accuracy : 69.57142857142857\nEpochs : 84 ; Loss : 0.6375833749771118 ; Accuracy : 66.17857142857143 ; Test Loss : 0.6300531029701233 ; Test accuracy : 69.57142857142857\nEpochs : 85 ; Loss : 0.6370548009872437 ; Accuracy : 66.19642857142857 ; Test Loss : 0.6295180916786194 ; Test accuracy : 69.5\nEpochs : 86 ; Loss : 0.6365299820899963 ; Accuracy : 66.23214285714286 ; Test Loss : 0.6289874315261841 ; Test accuracy : 69.71428571428571\nEpochs : 87 ; Loss : 0.6360089778900146 ; Accuracy : 66.32142857142857 ; Test Loss : 0.6284609436988831 ; Test accuracy : 69.71428571428571\nEpochs : 88 ; Loss : 0.6354917883872986 ; Accuracy : 66.41071428571429 ; Test Loss : 0.6279383897781372 ; Test accuracy : 69.71428571428571\nEpochs : 89 ; Loss : 0.6349783539772034 ; Accuracy : 66.5 ; Test Loss : 0.6274197101593018 ; Test accuracy : 69.71428571428571\nEpochs : 90 ; Loss : 0.6344686150550842 ; Accuracy : 66.60714285714286 ; Test Loss : 0.6269046068191528 ; Test accuracy : 69.78571428571429\nEpochs : 91 ; Loss : 0.6339625716209412 ; Accuracy : 66.67857142857143 ; Test Loss : 0.6263930797576904 ; Test accuracy : 69.71428571428571\nEpochs : 92 ; Loss : 0.6334602236747742 ; Accuracy : 66.73214285714286 ; Test Loss : 0.6258849501609802 ; Test accuracy : 69.71428571428571\nEpochs : 93 ; Loss : 0.6329614520072937 ; Accuracy : 66.875 ; Test Loss : 0.6253803372383118 ; Test accuracy : 69.71428571428571\nEpochs : 94 ; Loss : 0.6324663162231445 ; Accuracy : 66.92857142857143 ; Test Loss : 0.6248791217803955 ; Test accuracy : 69.71428571428571\nEpochs : 95 ; Loss : 0.6319747567176819 ; Accuracy : 67.07142857142857 ; Test Loss : 0.6243813633918762 ; Test accuracy : 69.78571428571429\nEpochs : 96 ; Loss : 0.6314868330955505 ; Accuracy : 67.16071428571429 ; Test Loss : 0.6238871216773987 ; Test accuracy : 69.85714285714286\nEpochs : 97 ; Loss : 0.6310024261474609 ; Accuracy : 67.25 ; Test Loss : 0.6233965754508972 ; Test accuracy : 69.85714285714286\nEpochs : 98 ; Loss : 0.6305215358734131 ; Accuracy : 67.21428571428571 ; Test Loss : 0.622909665107727 ; Test accuracy : 69.85714285714286\nEpochs : 99 ; Loss : 0.6300442218780518 ; Accuracy : 67.21428571428571 ; Test Loss : 0.6224265694618225 ; Test accuracy : 69.85714285714286\nEpochs : 100 ; Loss : 0.6295703649520874 ; Accuracy : 67.25 ; Test Loss : 0.6219473481178284 ; Test accuracy : 69.85714285714286\nEpochs : 101 ; Loss : 0.6291000247001648 ; Accuracy : 67.32142857142857 ; Test Loss : 0.621472179889679 ; Test accuracy : 69.92857142857143\nEpochs : 102 ; Loss : 0.6286331415176392 ; Accuracy : 67.39285714285714 ; Test Loss : 0.6210009455680847 ; Test accuracy : 69.85714285714286\nEpochs : 103 ; Loss : 0.6281697154045105 ; Accuracy : 67.39285714285714 ; Test Loss : 0.6205338835716248 ; Test accuracy : 69.78571428571429\nEpochs : 104 ; Loss : 0.6277097463607788 ; Accuracy : 67.44642857142857 ; Test Loss : 0.6200709342956543 ; Test accuracy : 69.92857142857143\nEpochs : 105 ; Loss : 0.6272531747817993 ; Accuracy : 67.46428571428571 ; Test Loss : 0.6196120977401733 ; Test accuracy : 69.78571428571429\nEpochs : 106 ; Loss : 0.6267999410629272 ; Accuracy : 67.46428571428571 ; Test Loss : 0.6191573739051819 ; Test accuracy : 69.85714285714286\nEpochs : 107 ; Loss : 0.6263501048088074 ; Accuracy : 67.55357142857143 ; Test Loss : 0.6187068223953247 ; Test accuracy : 70.07142857142857\nEpochs : 108 ; Loss : 0.6259036064147949 ; Accuracy : 67.625 ; Test Loss : 0.6182603240013123 ; Test accuracy : 70.0\nEpochs : 109 ; Loss : 0.6254604458808899 ; Accuracy : 67.69642857142857 ; Test Loss : 0.6178178191184998 ; Test accuracy : 70.07142857142857\nEpochs : 110 ; Loss : 0.6250205636024475 ; Accuracy : 67.78571428571429 ; Test Loss : 0.6173791885375977 ; Test accuracy : 70.14285714285714\nEpochs : 111 ; Loss : 0.6245839595794678 ; Accuracy : 67.76785714285714 ; Test Loss : 0.6169444918632507 ; Test accuracy : 70.21428571428571\nEpochs : 112 ; Loss : 0.6241505742073059 ; Accuracy : 67.80357142857143 ; Test Loss : 0.6165135502815247 ; Test accuracy : 70.21428571428571\nEpochs : 113 ; Loss : 0.6237204074859619 ; Accuracy : 67.83928571428571 ; Test Loss : 0.6160863041877747 ; Test accuracy : 70.21428571428571\nEpochs : 114 ; Loss : 0.6232935190200806 ; Accuracy : 67.83928571428571 ; Test Loss : 0.6156626343727112 ; Test accuracy : 70.14285714285714\nEpochs : 115 ; Loss : 0.6228697896003723 ; Accuracy : 67.875 ; Test Loss : 0.6152424812316895 ; Test accuracy : 70.14285714285714\nEpochs : 116 ; Loss : 0.6224492192268372 ; Accuracy : 67.92857142857143 ; Test Loss : 0.6148258447647095 ; Test accuracy : 70.14285714285714\nEpochs : 117 ; Loss : 0.6220318078994751 ; Accuracy : 67.94642857142857 ; Test Loss : 0.6144125461578369 ; Test accuracy : 70.14285714285714\nEpochs : 118 ; Loss : 0.6216174960136414 ; Accuracy : 67.96428571428571 ; Test Loss : 0.6140027046203613 ; Test accuracy : 70.0\nEpochs : 119 ; Loss : 0.6212062835693359 ; Accuracy : 67.94642857142857 ; Test Loss : 0.6135960221290588 ; Test accuracy : 70.0\nEpochs : 120 ; Loss : 0.6207982301712036 ; Accuracy : 68.03571428571429 ; Test Loss : 0.6131925582885742 ; Test accuracy : 69.78571428571429\nEpochs : 121 ; Loss : 0.6203931570053101 ; Accuracy : 68.10714285714286 ; Test Loss : 0.6127923727035522 ; Test accuracy : 70.07142857142857\nEpochs : 122 ; Loss : 0.6199911236763 ; Accuracy : 68.125 ; Test Loss : 0.6123954653739929 ; Test accuracy : 70.07142857142857\nEpochs : 123 ; Loss : 0.6195921301841736 ; Accuracy : 68.23214285714286 ; Test Loss : 0.6120017170906067 ; Test accuracy : 70.07142857142857\nEpochs : 124 ; Loss : 0.6191961169242859 ; Accuracy : 68.26785714285714 ; Test Loss : 0.6116112470626831 ; Test accuracy : 70.28571428571429\nEpochs : 125 ; Loss : 0.618803083896637 ; Accuracy : 68.21428571428571 ; Test Loss : 0.6112239360809326 ; Test accuracy : 70.21428571428571\nEpochs : 126 ; Loss : 0.618412971496582 ; Accuracy : 68.21428571428571 ; Test Loss : 0.6108397841453552 ; Test accuracy : 70.28571428571429\nEpochs : 127 ; Loss : 0.6180258393287659 ; Accuracy : 68.26785714285714 ; Test Loss : 0.6104589700698853 ; Test accuracy : 70.42857142857143\nEpochs : 128 ; Loss : 0.6176415681838989 ; Accuracy : 68.25 ; Test Loss : 0.6100813150405884 ; Test accuracy : 70.5\nEpochs : 129 ; Loss : 0.617260217666626 ; Accuracy : 68.26785714285714 ; Test Loss : 0.6097069382667542 ; Test accuracy : 70.5\nEpochs : 130 ; Loss : 0.6168817281723022 ; Accuracy : 68.35714285714286 ; Test Loss : 0.6093358397483826 ; Test accuracy : 70.5\nEpochs : 131 ; Loss : 0.616506040096283 ; Accuracy : 68.35714285714286 ; Test Loss : 0.6089679002761841 ; Test accuracy : 70.5\nEpochs : 132 ; Loss : 0.6161332130432129 ; Accuracy : 68.39285714285714 ; Test Loss : 0.6086031794548035 ; Test accuracy : 70.57142857142857\nEpochs : 133 ; Loss : 0.6157631278038025 ; Accuracy : 68.42857142857143 ; Test Loss : 0.6082416772842407 ; Test accuracy : 70.5\nEpochs : 134 ; Loss : 0.6153959035873413 ; Accuracy : 68.42857142857143 ; Test Loss : 0.6078833341598511 ; Test accuracy : 70.5\nEpochs : 135 ; Loss : 0.615031361579895 ; Accuracy : 68.41071428571429 ; Test Loss : 0.6075280904769897 ; Test accuracy : 70.57142857142857\nEpochs : 136 ; Loss : 0.6146696209907532 ; Accuracy : 68.42857142857143 ; Test Loss : 0.6071760654449463 ; Test accuracy : 70.64285714285714\nEpochs : 137 ; Loss : 0.6143105626106262 ; Accuracy : 68.44642857142857 ; Test Loss : 0.6068270206451416 ; Test accuracy : 70.64285714285714\nEpochs : 138 ; Loss : 0.6139541864395142 ; Accuracy : 68.48214285714286 ; Test Loss : 0.6064810156822205 ; Test accuracy : 70.5\nEpochs : 139 ; Loss : 0.6136005520820618 ; Accuracy : 68.57142857142857 ; Test Loss : 0.6061380505561829 ; Test accuracy : 70.5\nEpochs : 140 ; Loss : 0.6132494807243347 ; Accuracy : 68.60714285714286 ; Test Loss : 0.6057979464530945 ; Test accuracy : 70.64285714285714\nEpochs : 141 ; Loss : 0.6129011511802673 ; Accuracy : 68.64285714285714 ; Test Loss : 0.6054608225822449 ; Test accuracy : 70.71428571428571\nEpochs : 142 ; Loss : 0.6125553250312805 ; Accuracy : 68.625 ; Test Loss : 0.6051265001296997 ; Test accuracy : 70.71428571428571\nEpochs : 143 ; Loss : 0.6122121810913086 ; Accuracy : 68.625 ; Test Loss : 0.6047950983047485 ; Test accuracy : 70.64285714285714\nEpochs : 144 ; Loss : 0.6118714809417725 ; Accuracy : 68.60714285714286 ; Test Loss : 0.604466438293457 ; Test accuracy : 70.64285714285714\nEpochs : 145 ; Loss : 0.6115334630012512 ; Accuracy : 68.66071428571429 ; Test Loss : 0.60414057970047 ; Test accuracy : 70.64285714285714\nEpochs : 146 ; Loss : 0.6111979484558105 ; Accuracy : 68.66071428571429 ; Test Loss : 0.6038174629211426 ; Test accuracy : 70.64285714285714\nEpochs : 147 ; Loss : 0.6108648777008057 ; Accuracy : 68.67857142857143 ; Test Loss : 0.6034970283508301 ; Test accuracy : 70.64285714285714\nEpochs : 148 ; Loss : 0.6105344295501709 ; Accuracy : 68.73214285714286 ; Test Loss : 0.6031793355941772 ; Test accuracy : 70.64285714285714\nEpochs : 149 ; Loss : 0.6102063655853271 ; Accuracy : 68.78571428571429 ; Test Loss : 0.6028642654418945 ; Test accuracy : 70.64285714285714\nEpochs : 150 ; Loss : 0.609880805015564 ; Accuracy : 68.80357142857143 ; Test Loss : 0.6025519371032715 ; Test accuracy : 70.64285714285714\nEpochs : 151 ; Loss : 0.609557569026947 ; Accuracy : 68.85714285714286 ; Test Loss : 0.6022422313690186 ; Test accuracy : 70.71428571428571\nEpochs : 152 ; Loss : 0.6092368364334106 ; Accuracy : 68.85714285714286 ; Test Loss : 0.6019351482391357 ; Test accuracy : 70.78571428571429\nEpochs : 153 ; Loss : 0.6089184880256653 ; Accuracy : 68.82142857142857 ; Test Loss : 0.6016307473182678 ; Test accuracy : 70.78571428571429\nEpochs : 154 ; Loss : 0.6086025238037109 ; Accuracy : 68.91071428571429 ; Test Loss : 0.60132896900177 ; Test accuracy : 70.78571428571429\nEpochs : 155 ; Loss : 0.6082889437675476 ; Accuracy : 68.91071428571429 ; Test Loss : 0.601029634475708 ; Test accuracy : 70.78571428571429\nEpochs : 156 ; Loss : 0.6079776287078857 ; Accuracy : 68.85714285714286 ; Test Loss : 0.6007330417633057 ; Test accuracy : 70.85714285714286\nEpochs : 157 ; Loss : 0.6076686382293701 ; Accuracy : 68.875 ; Test Loss : 0.6004389524459839 ; Test accuracy : 70.85714285714286\nEpochs : 158 ; Loss : 0.6073619723320007 ; Accuracy : 68.96428571428571 ; Test Loss : 0.6001473665237427 ; Test accuracy : 70.92857142857143\nEpochs : 159 ; Loss : 0.6070575714111328 ; Accuracy : 69.0 ; Test Loss : 0.5998584032058716 ; Test accuracy : 70.92857142857143\nEpochs : 160 ; Loss : 0.6067554354667664 ; Accuracy : 69.01785714285714 ; Test Loss : 0.5995718836784363 ; Test accuracy : 71.0\nEpochs : 161 ; Loss : 0.6064555644989014 ; Accuracy : 69.03571428571429 ; Test Loss : 0.5992878675460815 ; Test accuracy : 71.0\nEpochs : 162 ; Loss : 0.6061578989028931 ; Accuracy : 69.03571428571429 ; Test Loss : 0.5990062952041626 ; Test accuracy : 71.07142857142857\nEpochs : 163 ; Loss : 0.6058624386787415 ; Accuracy : 69.05357142857143 ; Test Loss : 0.5987271666526794 ; Test accuracy : 71.07142857142857\nEpochs : 164 ; Loss : 0.6055691242218018 ; Accuracy : 69.05357142857143 ; Test Loss : 0.5984504222869873 ; Test accuracy : 71.0\nEpochs : 165 ; Loss : 0.6052780747413635 ; Accuracy : 69.07142857142857 ; Test Loss : 0.598176121711731 ; Test accuracy : 71.0\nEpochs : 166 ; Loss : 0.6049891114234924 ; Accuracy : 69.07142857142857 ; Test Loss : 0.5979041457176208 ; Test accuracy : 70.92857142857143\nEpochs : 167 ; Loss : 0.6047022938728333 ; Accuracy : 69.10714285714286 ; Test Loss : 0.597634494304657 ; Test accuracy : 70.92857142857143\nEpochs : 168 ; Loss : 0.604417622089386 ; Accuracy : 69.08928571428571 ; Test Loss : 0.5973672270774841 ; Test accuracy : 70.92857142857143\nEpochs : 169 ; Loss : 0.6041350364685059 ; Accuracy : 69.07142857142857 ; Test Loss : 0.5971021056175232 ; Test accuracy : 70.92857142857143\nEpochs : 170 ; Loss : 0.6038545370101929 ; Accuracy : 69.07142857142857 ; Test Loss : 0.5968393087387085 ; Test accuracy : 70.78571428571429\nEpochs : 171 ; Loss : 0.603576123714447 ; Accuracy : 69.01785714285714 ; Test Loss : 0.5965787768363953 ; Test accuracy : 70.78571428571429\nEpochs : 172 ; Loss : 0.6032997369766235 ; Accuracy : 69.05357142857143 ; Test Loss : 0.5963205099105835 ; Test accuracy : 70.71428571428571\nEpochs : 173 ; Loss : 0.6030253171920776 ; Accuracy : 69.01785714285714 ; Test Loss : 0.5960643887519836 ; Test accuracy : 70.71428571428571\nEpochs : 174 ; Loss : 0.6027529835700989 ; Accuracy : 69.01785714285714 ; Test Loss : 0.5958104729652405 ; Test accuracy : 70.71428571428571\nEpochs : 175 ; Loss : 0.6024826169013977 ; Accuracy : 69.01785714285714 ; Test Loss : 0.5955586433410645 ; Test accuracy : 70.71428571428571\nEpochs : 176 ; Loss : 0.6022142767906189 ; Accuracy : 68.98214285714286 ; Test Loss : 0.5953090786933899 ; Test accuracy : 70.71428571428571\nEpochs : 177 ; Loss : 0.6019478440284729 ; Accuracy : 69.01785714285714 ; Test Loss : 0.5950616598129272 ; Test accuracy : 70.71428571428571\nEpochs : 178 ; Loss : 0.6016833186149597 ; Accuracy : 69.07142857142857 ; Test Loss : 0.5948162078857422 ; Test accuracy : 70.71428571428571\nEpochs : 179 ; Loss : 0.6014208197593689 ; Accuracy : 69.07142857142857 ; Test Loss : 0.5945730209350586 ; Test accuracy : 70.71428571428571\nEpochs : 180 ; Loss : 0.6011602282524109 ; Accuracy : 69.08928571428571 ; Test Loss : 0.5943318605422974 ; Test accuracy : 70.64285714285714\nEpochs : 181 ; Loss : 0.6009014844894409 ; Accuracy : 69.16071428571429 ; Test Loss : 0.5940927267074585 ; Test accuracy : 70.64285714285714\nEpochs : 182 ; Loss : 0.6006446480751038 ; Accuracy : 69.14285714285714 ; Test Loss : 0.5938556790351868 ; Test accuracy : 70.64285714285714\nEpochs : 183 ; Loss : 0.6003897190093994 ; Accuracy : 69.16071428571429 ; Test Loss : 0.5936206579208374 ; Test accuracy : 70.64285714285714\nEpochs : 184 ; Loss : 0.6001365780830383 ; Accuracy : 69.14285714285714 ; Test Loss : 0.5933877229690552 ; Test accuracy : 70.64285714285714\nEpochs : 185 ; Loss : 0.5998852849006653 ; Accuracy : 69.14285714285714 ; Test Loss : 0.5931566953659058 ; Test accuracy : 70.64285714285714\nEpochs : 186 ; Loss : 0.5996357798576355 ; Accuracy : 69.14285714285714 ; Test Loss : 0.5929276943206787 ; Test accuracy : 70.64285714285714\nEpochs : 187 ; Loss : 0.5993881821632385 ; Accuracy : 69.19642857142857 ; Test Loss : 0.5927006602287292 ; Test accuracy : 70.64285714285714\nEpochs : 188 ; Loss : 0.5991422533988953 ; Accuracy : 69.19642857142857 ; Test Loss : 0.5924755930900574 ; Test accuracy : 70.64285714285714\nEpochs : 189 ; Loss : 0.59889817237854 ; Accuracy : 69.17857142857143 ; Test Loss : 0.5922523736953735 ; Test accuracy : 70.71428571428571\nEpochs : 190 ; Loss : 0.5986558198928833 ; Accuracy : 69.14285714285714 ; Test Loss : 0.5920311808586121 ; Test accuracy : 70.71428571428571\nEpochs : 191 ; Loss : 0.5984152555465698 ; Accuracy : 69.14285714285714 ; Test Loss : 0.5918117761611938 ; Test accuracy : 70.71428571428571\nEpochs : 192 ; Loss : 0.5981764197349548 ; Accuracy : 69.16071428571429 ; Test Loss : 0.5915943384170532 ; Test accuracy : 70.64285714285714\nEpochs : 193 ; Loss : 0.5979392528533936 ; Accuracy : 69.16071428571429 ; Test Loss : 0.5913786888122559 ; Test accuracy : 70.64285714285714\nEpochs : 194 ; Loss : 0.5977038145065308 ; Accuracy : 69.125 ; Test Loss : 0.5911648869514465 ; Test accuracy : 70.64285714285714\nEpochs : 195 ; Loss : 0.5974699854850769 ; Accuracy : 69.14285714285714 ; Test Loss : 0.5909529328346252 ; Test accuracy : 70.5\nEpochs : 196 ; Loss : 0.5972378849983215 ; Accuracy : 69.16071428571429 ; Test Loss : 0.5907427668571472 ; Test accuracy : 70.57142857142857\nEpochs : 197 ; Loss : 0.5970075130462646 ; Accuracy : 69.16071428571429 ; Test Loss : 0.5905343294143677 ; Test accuracy : 70.64285714285714\nEpochs : 198 ; Loss : 0.5967786908149719 ; Accuracy : 69.19642857142857 ; Test Loss : 0.5903277397155762 ; Test accuracy : 70.64285714285714\nEpochs : 199 ; Loss : 0.5965514779090881 ; Accuracy : 69.19642857142857 ; Test Loss : 0.5901229381561279 ; Test accuracy : 70.64285714285714\nEpochs : 200 ; Loss : 0.5963259935379028 ; Accuracy : 69.19642857142857 ; Test Loss : 0.5899198055267334 ; Test accuracy : 70.57142857142857\nEpochs : 201 ; Loss : 0.5961019992828369 ; Accuracy : 69.26785714285714 ; Test Loss : 0.5897184014320374 ; Test accuracy : 70.57142857142857\nEpochs : 202 ; Loss : 0.5958796739578247 ; Accuracy : 69.26785714285714 ; Test Loss : 0.5895187854766846 ; Test accuracy : 70.5\nEpochs : 203 ; Loss : 0.5956588387489319 ; Accuracy : 69.26785714285714 ; Test Loss : 0.5893207788467407 ; Test accuracy : 70.5\nEpochs : 204 ; Loss : 0.595439612865448 ; Accuracy : 69.30357142857143 ; Test Loss : 0.5891245007514954 ; Test accuracy : 70.57142857142857\nEpochs : 205 ; Loss : 0.5952219367027283 ; Accuracy : 69.30357142857143 ; Test Loss : 0.5889298915863037 ; Test accuracy : 70.57142857142857\nEpochs : 206 ; Loss : 0.5950058102607727 ; Accuracy : 69.30357142857143 ; Test Loss : 0.588736891746521 ; Test accuracy : 70.5\nEpochs : 207 ; Loss : 0.5947911739349365 ; Accuracy : 69.26785714285714 ; Test Loss : 0.5885456204414368 ; Test accuracy : 70.57142857142857\nEpochs : 208 ; Loss : 0.5945780873298645 ; Accuracy : 69.26785714285714 ; Test Loss : 0.5883558988571167 ; Test accuracy : 70.57142857142857\nEpochs : 209 ; Loss : 0.5943664312362671 ; Accuracy : 69.32142857142857 ; Test Loss : 0.5881677865982056 ; Test accuracy : 70.5\nEpochs : 210 ; Loss : 0.5941563248634338 ; Accuracy : 69.32142857142857 ; Test Loss : 0.5879813432693481 ; Test accuracy : 70.64285714285714\nEpochs : 211 ; Loss : 0.5939475893974304 ; Accuracy : 69.28571428571429 ; Test Loss : 0.5877964496612549 ; Test accuracy : 70.57142857142857\nEpochs : 212 ; Loss : 0.5937404036521912 ; Accuracy : 69.30357142857143 ; Test Loss : 0.5876131057739258 ; Test accuracy : 70.57142857142857\nEpochs : 213 ; Loss : 0.5935346484184265 ; Accuracy : 69.33928571428571 ; Test Loss : 0.5874313116073608 ; Test accuracy : 70.57142857142857\nEpochs : 214 ; Loss : 0.5933302640914917 ; Accuracy : 69.375 ; Test Loss : 0.5872510671615601 ; Test accuracy : 70.71428571428571\nEpochs : 215 ; Loss : 0.5931273698806763 ; Accuracy : 69.375 ; Test Loss : 0.5870723724365234 ; Test accuracy : 70.71428571428571\nEpochs : 216 ; Loss : 0.5929258465766907 ; Accuracy : 69.33928571428571 ; Test Loss : 0.5868951082229614 ; Test accuracy : 70.78571428571429\nEpochs : 217 ; Loss : 0.5927257537841797 ; Accuracy : 69.375 ; Test Loss : 0.5867194533348083 ; Test accuracy : 70.71428571428571\nEpochs : 218 ; Loss : 0.5925270318984985 ; Accuracy : 69.33928571428571 ; Test Loss : 0.5865452289581299 ; Test accuracy : 70.64285714285714\nEpochs : 219 ; Loss : 0.5923296809196472 ; Accuracy : 69.32142857142857 ; Test Loss : 0.586372435092926 ; Test accuracy : 70.64285714285714\nEpochs : 220 ; Loss : 0.5921337008476257 ; Accuracy : 69.32142857142857 ; Test Loss : 0.5862011909484863 ; Test accuracy : 70.78571428571429\nEpochs : 221 ; Loss : 0.5919390320777893 ; Accuracy : 69.30357142857143 ; Test Loss : 0.5860313177108765 ; Test accuracy : 70.85714285714286\nEpochs : 222 ; Loss : 0.5917457342147827 ; Accuracy : 69.28571428571429 ; Test Loss : 0.5858628749847412 ; Test accuracy : 71.0\nEpochs : 223 ; Loss : 0.5915537476539612 ; Accuracy : 69.33928571428571 ; Test Loss : 0.5856958627700806 ; Test accuracy : 71.07142857142857\nEpochs : 224 ; Loss : 0.5913630723953247 ; Accuracy : 69.375 ; Test Loss : 0.5855302810668945 ; Test accuracy : 71.07142857142857\nEpochs : 225 ; Loss : 0.5911737084388733 ; Accuracy : 69.375 ; Test Loss : 0.5853660106658936 ; Test accuracy : 71.0\nEpochs : 226 ; Loss : 0.5909855961799622 ; Accuracy : 69.39285714285714 ; Test Loss : 0.585203230381012 ; Test accuracy : 71.14285714285714\nEpochs : 227 ; Loss : 0.5907988548278809 ; Accuracy : 69.41071428571429 ; Test Loss : 0.5850417613983154 ; Test accuracy : 71.28571428571429\nEpochs : 228 ; Loss : 0.5906133055686951 ; Accuracy : 69.44642857142857 ; Test Loss : 0.5848816633224487 ; Test accuracy : 71.21428571428571\nEpochs : 229 ; Loss : 0.5904290676116943 ; Accuracy : 69.48214285714286 ; Test Loss : 0.5847228765487671 ; Test accuracy : 71.21428571428571\nEpochs : 230 ; Loss : 0.5902460813522339 ; Accuracy : 69.5 ; Test Loss : 0.5845655202865601 ; Test accuracy : 71.07142857142857\nEpochs : 231 ; Loss : 0.590064287185669 ; Accuracy : 69.5 ; Test Loss : 0.5844094157218933 ; Test accuracy : 70.92857142857143\nEpochs : 232 ; Loss : 0.5898837447166443 ; Accuracy : 69.53571428571429 ; Test Loss : 0.5842545628547668 ; Test accuracy : 71.0\nEpochs : 233 ; Loss : 0.5897043943405151 ; Accuracy : 69.53571428571429 ; Test Loss : 0.5841010808944702 ; Test accuracy : 71.0\nEpochs : 234 ; Loss : 0.5895262956619263 ; Accuracy : 69.53571428571429 ; Test Loss : 0.5839489102363586 ; Test accuracy : 71.0\nEpochs : 235 ; Loss : 0.5893493294715881 ; Accuracy : 69.5 ; Test Loss : 0.5837979316711426 ; Test accuracy : 71.0\nEpochs : 236 ; Loss : 0.5891736745834351 ; Accuracy : 69.51785714285714 ; Test Loss : 0.5836482644081116 ; Test accuracy : 71.0\nEpochs : 237 ; Loss : 0.5889990925788879 ; Accuracy : 69.5 ; Test Loss : 0.5834998488426208 ; Test accuracy : 71.0\nEpochs : 238 ; Loss : 0.5888257026672363 ; Accuracy : 69.57142857142857 ; Test Loss : 0.5833526253700256 ; Test accuracy : 71.07142857142857\nEpochs : 239 ; Loss : 0.5886534452438354 ; Accuracy : 69.55357142857143 ; Test Loss : 0.5832067131996155 ; Test accuracy : 71.14285714285714\nEpochs : 240 ; Loss : 0.5884823799133301 ; Accuracy : 69.60714285714286 ; Test Loss : 0.583061933517456 ; Test accuracy : 71.21428571428571\nEpochs : 241 ; Loss : 0.5883124470710754 ; Accuracy : 69.64285714285714 ; Test Loss : 0.5829184055328369 ; Test accuracy : 71.21428571428571\nEpochs : 242 ; Loss : 0.5881435871124268 ; Accuracy : 69.64285714285714 ; Test Loss : 0.5827760696411133 ; Test accuracy : 71.21428571428571\nEpochs : 243 ; Loss : 0.5879759192466736 ; Accuracy : 69.66071428571429 ; Test Loss : 0.5826349854469299 ; Test accuracy : 71.21428571428571\nEpochs : 244 ; Loss : 0.5878093838691711 ; Accuracy : 69.66071428571429 ; Test Loss : 0.5824949741363525 ; Test accuracy : 71.21428571428571\nEpochs : 245 ; Loss : 0.5876438617706299 ; Accuracy : 69.60714285714286 ; Test Loss : 0.5823561549186707 ; Test accuracy : 71.28571428571429\nEpochs : 246 ; Loss : 0.5874794721603394 ; Accuracy : 69.60714285714286 ; Test Loss : 0.5822184681892395 ; Test accuracy : 71.35714285714286\nEpochs : 247 ; Loss : 0.5873161554336548 ; Accuracy : 69.58928571428571 ; Test Loss : 0.5820819735527039 ; Test accuracy : 71.35714285714286\nEpochs : 248 ; Loss : 0.5871539115905762 ; Accuracy : 69.625 ; Test Loss : 0.5819465517997742 ; Test accuracy : 71.35714285714286\nEpochs : 249 ; Loss : 0.5869926810264587 ; Accuracy : 69.625 ; Test Loss : 0.58181232213974 ; Test accuracy : 71.35714285714286\nEpochs : 250 ; Loss : 0.5868326425552368 ; Accuracy : 69.60714285714286 ; Test Loss : 0.5816791653633118 ; Test accuracy : 71.35714285714286\nEpochs : 251 ; Loss : 0.5866735577583313 ; Accuracy : 69.58928571428571 ; Test Loss : 0.5815470814704895 ; Test accuracy : 71.28571428571429\nEpochs : 252 ; Loss : 0.586515486240387 ; Accuracy : 69.58928571428571 ; Test Loss : 0.5814161896705627 ; Test accuracy : 71.28571428571429\nEpochs : 253 ; Loss : 0.5863584876060486 ; Accuracy : 69.60714285714286 ; Test Loss : 0.5812862515449524 ; Test accuracy : 71.28571428571429\nEpochs : 254 ; Loss : 0.5862025022506714 ; Accuracy : 69.625 ; Test Loss : 0.5811575055122375 ; Test accuracy : 71.28571428571429\nEpochs : 255 ; Loss : 0.5860475301742554 ; Accuracy : 69.625 ; Test Loss : 0.5810297727584839 ; Test accuracy : 71.28571428571429\nEpochs : 256 ; Loss : 0.5858935713768005 ; Accuracy : 69.66071428571429 ; Test Loss : 0.5809031128883362 ; Test accuracy : 71.28571428571429\nEpochs : 257 ; Loss : 0.5857405066490173 ; Accuracy : 69.67857142857143 ; Test Loss : 0.5807774662971497 ; Test accuracy : 71.28571428571429\nEpochs : 258 ; Loss : 0.5855885744094849 ; Accuracy : 69.69642857142857 ; Test Loss : 0.5806528329849243 ; Test accuracy : 71.21428571428571\nEpochs : 259 ; Loss : 0.5854375958442688 ; Accuracy : 69.69642857142857 ; Test Loss : 0.5805292725563049 ; Test accuracy : 71.21428571428571\nEpochs : 260 ; Loss : 0.5852875113487244 ; Accuracy : 69.69642857142857 ; Test Loss : 0.5804067254066467 ; Test accuracy : 71.28571428571429\nEpochs : 261 ; Loss : 0.5851384401321411 ; Accuracy : 69.66071428571429 ; Test Loss : 0.5802851915359497 ; Test accuracy : 71.35714285714286\nEpochs : 262 ; Loss : 0.5849903225898743 ; Accuracy : 69.66071428571429 ; Test Loss : 0.5801646709442139 ; Test accuracy : 71.42857142857143\nEpochs : 263 ; Loss : 0.5848431587219238 ; Accuracy : 69.69642857142857 ; Test Loss : 0.5800450444221497 ; Test accuracy : 71.42857142857143\nEpochs : 264 ; Loss : 0.5846968293190002 ; Accuracy : 69.71428571428571 ; Test Loss : 0.5799264907836914 ; Test accuracy : 71.42857142857143\nEpochs : 265 ; Loss : 0.5845515727996826 ; Accuracy : 69.71428571428571 ; Test Loss : 0.5798088908195496 ; Test accuracy : 71.42857142857143\nEpochs : 266 ; Loss : 0.5844071507453918 ; Accuracy : 69.76785714285714 ; Test Loss : 0.5796923041343689 ; Test accuracy : 71.35714285714286\nEpochs : 267 ; Loss : 0.5842636227607727 ; Accuracy : 69.80357142857143 ; Test Loss : 0.5795766115188599 ; Test accuracy : 71.42857142857143\nEpochs : 268 ; Loss : 0.5841211080551147 ; Accuracy : 69.80357142857143 ; Test Loss : 0.5794618129730225 ; Test accuracy : 71.5\nEpochs : 269 ; Loss : 0.5839794874191284 ; Accuracy : 69.80357142857143 ; Test Loss : 0.5793480277061462 ; Test accuracy : 71.5\nEpochs : 270 ; Loss : 0.5838386416435242 ; Accuracy : 69.80357142857143 ; Test Loss : 0.5792351961135864 ; Test accuracy : 71.5\nEpochs : 271 ; Loss : 0.5836988091468811 ; Accuracy : 69.80357142857143 ; Test Loss : 0.5791232585906982 ; Test accuracy : 71.5\nEpochs : 272 ; Loss : 0.5835598111152649 ; Accuracy : 69.80357142857143 ; Test Loss : 0.5790122151374817 ; Test accuracy : 71.42857142857143\nEpochs : 273 ; Loss : 0.5834216475486755 ; Accuracy : 69.82142857142857 ; Test Loss : 0.5789021253585815 ; Test accuracy : 71.5\nEpochs : 274 ; Loss : 0.5832843780517578 ; Accuracy : 69.85714285714286 ; Test Loss : 0.5787928700447083 ; Test accuracy : 71.5\nEpochs : 275 ; Loss : 0.5831479430198669 ; Accuracy : 69.89285714285714 ; Test Loss : 0.5786845684051514 ; Test accuracy : 71.42857142857143\nEpochs : 276 ; Loss : 0.5830124020576477 ; Accuracy : 69.94642857142857 ; Test Loss : 0.5785771012306213 ; Test accuracy : 71.35714285714286\nEpochs : 277 ; Loss : 0.5828776955604553 ; Accuracy : 69.94642857142857 ; Test Loss : 0.5784705281257629 ; Test accuracy : 71.28571428571429\nEpochs : 278 ; Loss : 0.582743763923645 ; Accuracy : 69.94642857142857 ; Test Loss : 0.5783647894859314 ; Test accuracy : 71.28571428571429\nEpochs : 279 ; Loss : 0.5826107263565063 ; Accuracy : 69.98214285714286 ; Test Loss : 0.5782599449157715 ; Test accuracy : 71.28571428571429\nEpochs : 280 ; Loss : 0.5824785232543945 ; Accuracy : 70.0 ; Test Loss : 0.5781559348106384 ; Test accuracy : 71.28571428571429\nEpochs : 281 ; Loss : 0.58234703540802 ; Accuracy : 70.03571428571429 ; Test Loss : 0.578052818775177 ; Test accuracy : 71.28571428571429\nEpochs : 282 ; Loss : 0.5822165012359619 ; Accuracy : 70.03571428571429 ; Test Loss : 0.5779504776000977 ; Test accuracy : 71.28571428571429\nEpochs : 283 ; Loss : 0.5820866823196411 ; Accuracy : 70.05357142857143 ; Test Loss : 0.5778490304946899 ; Test accuracy : 71.35714285714286\nEpochs : 284 ; Loss : 0.5819576382637024 ; Accuracy : 70.03571428571429 ; Test Loss : 0.5777482986450195 ; Test accuracy : 71.35714285714286\nEpochs : 285 ; Loss : 0.5818294286727905 ; Accuracy : 70.10714285714286 ; Test Loss : 0.5776484608650208 ; Test accuracy : 71.42857142857143\nEpochs : 286 ; Loss : 0.5817019939422607 ; Accuracy : 70.16071428571429 ; Test Loss : 0.577549397945404 ; Test accuracy : 71.42857142857143\nEpochs : 287 ; Loss : 0.581575334072113 ; Accuracy : 70.21428571428571 ; Test Loss : 0.577451229095459 ; Test accuracy : 71.42857142857143\nEpochs : 288 ; Loss : 0.5814495086669922 ; Accuracy : 70.23214285714286 ; Test Loss : 0.5773537158966064 ; Test accuracy : 71.35714285714286\nEpochs : 289 ; Loss : 0.5813243985176086 ; Accuracy : 70.23214285714286 ; Test Loss : 0.5772570967674255 ; Test accuracy : 71.35714285714286\nEpochs : 290 ; Loss : 0.5812000036239624 ; Accuracy : 70.21428571428571 ; Test Loss : 0.5771611332893372 ; Test accuracy : 71.42857142857143\nEpochs : 291 ; Loss : 0.5810763835906982 ; Accuracy : 70.26785714285714 ; Test Loss : 0.5770660638809204 ; Test accuracy : 71.42857142857143\nEpochs : 292 ; Loss : 0.5809535384178162 ; Accuracy : 70.25 ; Test Loss : 0.576971709728241 ; Test accuracy : 71.35714285714286\nEpochs : 293 ; Loss : 0.5808314085006714 ; Accuracy : 70.28571428571429 ; Test Loss : 0.5768781304359436 ; Test accuracy : 71.35714285714286\nEpochs : 294 ; Loss : 0.5807099938392639 ; Accuracy : 70.26785714285714 ; Test Loss : 0.5767852663993835 ; Test accuracy : 71.35714285714286\nEpochs : 295 ; Loss : 0.5805893540382385 ; Accuracy : 70.26785714285714 ; Test Loss : 0.5766931772232056 ; Test accuracy : 71.35714285714286\nEpochs : 296 ; Loss : 0.5804694294929504 ; Accuracy : 70.30357142857143 ; Test Loss : 0.5766018629074097 ; Test accuracy : 71.35714285714286\nEpochs : 297 ; Loss : 0.5803502202033997 ; Accuracy : 70.28571428571429 ; Test Loss : 0.5765112042427063 ; Test accuracy : 71.35714285714286\nEpochs : 298 ; Loss : 0.5802317261695862 ; Accuracy : 70.32142857142857 ; Test Loss : 0.5764213800430298 ; Test accuracy : 71.35714285714286\nEpochs : 299 ; Loss : 0.58011394739151 ; Accuracy : 70.35714285714286 ; Test Loss : 0.5763322114944458 ; Test accuracy : 71.35714285714286\nEpochs : 300 ; Loss : 0.5799968838691711 ; Accuracy : 70.35714285714286 ; Test Loss : 0.5762436985969543 ; Test accuracy : 71.28571428571429\nEpochs : 301 ; Loss : 0.5798804759979248 ; Accuracy : 70.33928571428571 ; Test Loss : 0.5761560201644897 ; Test accuracy : 71.28571428571429\nEpochs : 302 ; Loss : 0.579764723777771 ; Accuracy : 70.35714285714286 ; Test Loss : 0.5760689973831177 ; Test accuracy : 71.28571428571429\nEpochs : 303 ; Loss : 0.5796497464179993 ; Accuracy : 70.35714285714286 ; Test Loss : 0.5759825706481934 ; Test accuracy : 71.28571428571429\nEpochs : 304 ; Loss : 0.5795353651046753 ; Accuracy : 70.375 ; Test Loss : 0.5758969783782959 ; Test accuracy : 71.28571428571429\nEpochs : 305 ; Loss : 0.5794216990470886 ; Accuracy : 70.375 ; Test Loss : 0.5758119821548462 ; Test accuracy : 71.28571428571429\nEpochs : 306 ; Loss : 0.5793087482452393 ; Accuracy : 70.375 ; Test Loss : 0.575727641582489 ; Test accuracy : 71.28571428571429\nEpochs : 307 ; Loss : 0.5791963934898376 ; Accuracy : 70.39285714285714 ; Test Loss : 0.5756440162658691 ; Test accuracy : 71.28571428571429\nEpochs : 308 ; Loss : 0.5790847539901733 ; Accuracy : 70.41071428571429 ; Test Loss : 0.5755611062049866 ; Test accuracy : 71.28571428571429\nEpochs : 309 ; Loss : 0.578973650932312 ; Accuracy : 70.41071428571429 ; Test Loss : 0.5754787921905518 ; Test accuracy : 71.21428571428571\nEpochs : 310 ; Loss : 0.5788633227348328 ; Accuracy : 70.41071428571429 ; Test Loss : 0.5753971338272095 ; Test accuracy : 71.21428571428571\nEpochs : 311 ; Loss : 0.5787535905838013 ; Accuracy : 70.42857142857143 ; Test Loss : 0.5753161311149597 ; Test accuracy : 71.14285714285714\nEpochs : 312 ; Loss : 0.5786444544792175 ; Accuracy : 70.42857142857143 ; Test Loss : 0.5752357840538025 ; Test accuracy : 71.14285714285714\nEpochs : 313 ; Loss : 0.5785360336303711 ; Accuracy : 70.41071428571429 ; Test Loss : 0.5751560926437378 ; Test accuracy : 71.14285714285714\nEpochs : 314 ; Loss : 0.5784281492233276 ; Accuracy : 70.42857142857143 ; Test Loss : 0.5750769972801208 ; Test accuracy : 71.14285714285714\nEpochs : 315 ; Loss : 0.5783209800720215 ; Accuracy : 70.42857142857143 ; Test Loss : 0.5749985575675964 ; Test accuracy : 71.14285714285714\nEpochs : 316 ; Loss : 0.5782143473625183 ; Accuracy : 70.42857142857143 ; Test Loss : 0.5749207139015198 ; Test accuracy : 71.14285714285714\nEpochs : 317 ; Loss : 0.5781083703041077 ; Accuracy : 70.44642857142857 ; Test Loss : 0.5748435258865356 ; Test accuracy : 71.14285714285714\nEpochs : 318 ; Loss : 0.5780029892921448 ; Accuracy : 70.46428571428571 ; Test Loss : 0.5747669339179993 ; Test accuracy : 71.21428571428571\nEpochs : 319 ; Loss : 0.5778982639312744 ; Accuracy : 70.48214285714286 ; Test Loss : 0.5746908783912659 ; Test accuracy : 71.14285714285714\nEpochs : 320 ; Loss : 0.577794075012207 ; Accuracy : 70.5 ; Test Loss : 0.5746155381202698 ; Test accuracy : 71.14285714285714\nEpochs : 321 ; Loss : 0.5776905417442322 ; Accuracy : 70.48214285714286 ; Test Loss : 0.5745407342910767 ; Test accuracy : 71.21428571428571\nEpochs : 322 ; Loss : 0.5775875449180603 ; Accuracy : 70.44642857142857 ; Test Loss : 0.5744665265083313 ; Test accuracy : 71.21428571428571\nEpochs : 323 ; Loss : 0.5774851441383362 ; Accuracy : 70.5 ; Test Loss : 0.5743928551673889 ; Test accuracy : 71.21428571428571\nEpochs : 324 ; Loss : 0.5773833394050598 ; Accuracy : 70.51785714285714 ; Test Loss : 0.5743198394775391 ; Test accuracy : 71.14285714285714\nEpochs : 325 ; Loss : 0.5772820711135864 ; Accuracy : 70.55357142857143 ; Test Loss : 0.5742473602294922 ; Test accuracy : 71.14285714285714\nEpochs : 326 ; Loss : 0.5771814584732056 ; Accuracy : 70.55357142857143 ; Test Loss : 0.5741754770278931 ; Test accuracy : 71.14285714285714\nEpochs : 327 ; Loss : 0.5770812630653381 ; Accuracy : 70.58928571428571 ; Test Loss : 0.5741041898727417 ; Test accuracy : 71.21428571428571\nEpochs : 328 ; Loss : 0.576981782913208 ; Accuracy : 70.60714285714286 ; Test Loss : 0.5740333795547485 ; Test accuracy : 71.28571428571429\nEpochs : 329 ; Loss : 0.5768828392028809 ; Accuracy : 70.58928571428571 ; Test Loss : 0.5739631652832031 ; Test accuracy : 71.28571428571429\nEpochs : 330 ; Loss : 0.5767844319343567 ; Accuracy : 70.57142857142857 ; Test Loss : 0.5738934874534607 ; Test accuracy : 71.21428571428571\nEpochs : 331 ; Loss : 0.5766865611076355 ; Accuracy : 70.57142857142857 ; Test Loss : 0.5738243460655212 ; Test accuracy : 71.21428571428571\nEpochs : 332 ; Loss : 0.5765892863273621 ; Accuracy : 70.58928571428571 ; Test Loss : 0.5737558007240295 ; Test accuracy : 71.21428571428571\nEpochs : 333 ; Loss : 0.5764924883842468 ; Accuracy : 70.57142857142857 ; Test Loss : 0.573687732219696 ; Test accuracy : 71.21428571428571\nEpochs : 334 ; Loss : 0.5763962864875793 ; Accuracy : 70.57142857142857 ; Test Loss : 0.5736202597618103 ; Test accuracy : 71.28571428571429\nEpochs : 335 ; Loss : 0.5763005018234253 ; Accuracy : 70.57142857142857 ; Test Loss : 0.5735532641410828 ; Test accuracy : 71.28571428571429\nEpochs : 336 ; Loss : 0.5762053728103638 ; Accuracy : 70.55357142857143 ; Test Loss : 0.573486864566803 ; Test accuracy : 71.28571428571429\nEpochs : 337 ; Loss : 0.5761107206344604 ; Accuracy : 70.57142857142857 ; Test Loss : 0.5734208822250366 ; Test accuracy : 71.28571428571429\nEpochs : 338 ; Loss : 0.5760166049003601 ; Accuracy : 70.55357142857143 ; Test Loss : 0.573355495929718 ; Test accuracy : 71.28571428571429\nEpochs : 339 ; Loss : 0.5759230256080627 ; Accuracy : 70.55357142857143 ; Test Loss : 0.5732906460762024 ; Test accuracy : 71.28571428571429\nEpochs : 340 ; Loss : 0.5758299827575684 ; Accuracy : 70.53571428571429 ; Test Loss : 0.5732262134552002 ; Test accuracy : 71.35714285714286\nEpochs : 341 ; Loss : 0.5757373571395874 ; Accuracy : 70.55357142857143 ; Test Loss : 0.573162317276001 ; Test accuracy : 71.35714285714286\nEpochs : 342 ; Loss : 0.5756453275680542 ; Accuracy : 70.58928571428571 ; Test Loss : 0.57309889793396 ; Test accuracy : 71.35714285714286\nEpochs : 343 ; Loss : 0.5755537748336792 ; Accuracy : 70.58928571428571 ; Test Loss : 0.5730360150337219 ; Test accuracy : 71.28571428571429\nEpochs : 344 ; Loss : 0.5754626989364624 ; Accuracy : 70.58928571428571 ; Test Loss : 0.5729736089706421 ; Test accuracy : 71.21428571428571\nEpochs : 345 ; Loss : 0.5753721594810486 ; Accuracy : 70.625 ; Test Loss : 0.5729116797447205 ; Test accuracy : 71.21428571428571\nEpochs : 346 ; Loss : 0.5752820372581482 ; Accuracy : 70.64285714285714 ; Test Loss : 0.572850227355957 ; Test accuracy : 71.21428571428571\nEpochs : 347 ; Loss : 0.5751925110816956 ; Accuracy : 70.67857142857143 ; Test Loss : 0.5727892518043518 ; Test accuracy : 71.21428571428571\nEpochs : 348 ; Loss : 0.5751034021377563 ; Accuracy : 70.66071428571429 ; Test Loss : 0.5727288126945496 ; Test accuracy : 71.21428571428571\nEpochs : 349 ; Loss : 0.5750148296356201 ; Accuracy : 70.625 ; Test Loss : 0.5726687908172607 ; Test accuracy : 71.14285714285714\nEpochs : 350 ; Loss : 0.5749266743659973 ; Accuracy : 70.625 ; Test Loss : 0.5726091861724854 ; Test accuracy : 71.14285714285714\nEpochs : 351 ; Loss : 0.5748390555381775 ; Accuracy : 70.625 ; Test Loss : 0.5725501179695129 ; Test accuracy : 71.14285714285714\nEpochs : 352 ; Loss : 0.5747518539428711 ; Accuracy : 70.64285714285714 ; Test Loss : 0.572491466999054 ; Test accuracy : 71.14285714285714\nEpochs : 353 ; Loss : 0.5746651291847229 ; Accuracy : 70.66071428571429 ; Test Loss : 0.5724332928657532 ; Test accuracy : 71.14285714285714\nEpochs : 354 ; Loss : 0.5745788812637329 ; Accuracy : 70.625 ; Test Loss : 0.5723755955696106 ; Test accuracy : 71.21428571428571\nEpochs : 355 ; Loss : 0.5744931101799011 ; Accuracy : 70.625 ; Test Loss : 0.5723182559013367 ; Test accuracy : 71.21428571428571\nEpochs : 356 ; Loss : 0.5744077563285828 ; Accuracy : 70.64285714285714 ; Test Loss : 0.5722614526748657 ; Test accuracy : 71.21428571428571\nEpochs : 357 ; Loss : 0.5743229389190674 ; Accuracy : 70.625 ; Test Loss : 0.5722050666809082 ; Test accuracy : 71.14285714285714\nEpochs : 358 ; Loss : 0.5742384791374207 ; Accuracy : 70.64285714285714 ; Test Loss : 0.5721491575241089 ; Test accuracy : 71.14285714285714\nEpochs : 359 ; Loss : 0.5741544961929321 ; Accuracy : 70.66071428571429 ; Test Loss : 0.5720936059951782 ; Test accuracy : 71.14285714285714\nEpochs : 360 ; Loss : 0.5740710496902466 ; Accuracy : 70.67857142857143 ; Test Loss : 0.572038471698761 ; Test accuracy : 71.14285714285714\nEpochs : 361 ; Loss : 0.5739879012107849 ; Accuracy : 70.69642857142857 ; Test Loss : 0.571983814239502 ; Test accuracy : 71.21428571428571\nEpochs : 362 ; Loss : 0.5739052295684814 ; Accuracy : 70.71428571428571 ; Test Loss : 0.5719295740127563 ; Test accuracy : 71.28571428571429\nEpochs : 363 ; Loss : 0.5738230347633362 ; Accuracy : 70.71428571428571 ; Test Loss : 0.5718756914138794 ; Test accuracy : 71.28571428571429\nEpochs : 364 ; Loss : 0.5737412571907043 ; Accuracy : 70.73214285714286 ; Test Loss : 0.5718222856521606 ; Test accuracy : 71.28571428571429\nEpochs : 365 ; Loss : 0.5736598968505859 ; Accuracy : 70.76785714285714 ; Test Loss : 0.5717692971229553 ; Test accuracy : 71.28571428571429\nEpochs : 366 ; Loss : 0.5735790133476257 ; Accuracy : 70.75 ; Test Loss : 0.5717167258262634 ; Test accuracy : 71.21428571428571\nEpochs : 367 ; Loss : 0.573498547077179 ; Accuracy : 70.78571428571429 ; Test Loss : 0.5716645121574402 ; Test accuracy : 71.21428571428571\nEpochs : 368 ; Loss : 0.5734184384346008 ; Accuracy : 70.82142857142857 ; Test Loss : 0.5716127157211304 ; Test accuracy : 71.28571428571429\nEpochs : 369 ; Loss : 0.5733388066291809 ; Accuracy : 70.85714285714286 ; Test Loss : 0.571561336517334 ; Test accuracy : 71.28571428571429\nEpochs : 370 ; Loss : 0.5732595324516296 ; Accuracy : 70.83928571428571 ; Test Loss : 0.571510374546051 ; Test accuracy : 71.28571428571429\nEpochs : 371 ; Loss : 0.5731807351112366 ; Accuracy : 70.83928571428571 ; Test Loss : 0.5714597105979919 ; Test accuracy : 71.28571428571429\nEpochs : 372 ; Loss : 0.5731022953987122 ; Accuracy : 70.82142857142857 ; Test Loss : 0.5714095234870911 ; Test accuracy : 71.28571428571429\nEpochs : 373 ; Loss : 0.5730242729187012 ; Accuracy : 70.82142857142857 ; Test Loss : 0.5713596940040588 ; Test accuracy : 71.14285714285714\nEpochs : 374 ; Loss : 0.5729466676712036 ; Accuracy : 70.82142857142857 ; Test Loss : 0.5713102221488953 ; Test accuracy : 71.21428571428571\nEpochs : 375 ; Loss : 0.5728694200515747 ; Accuracy : 70.82142857142857 ; Test Loss : 0.5712611675262451 ; Test accuracy : 71.21428571428571\nEpochs : 376 ; Loss : 0.5727927088737488 ; Accuracy : 70.83928571428571 ; Test Loss : 0.5712125301361084 ; Test accuracy : 71.28571428571429\nEpochs : 377 ; Loss : 0.5727162957191467 ; Accuracy : 70.85714285714286 ; Test Loss : 0.5711641907691956 ; Test accuracy : 71.28571428571429\nEpochs : 378 ; Loss : 0.5726402401924133 ; Accuracy : 70.83928571428571 ; Test Loss : 0.5711162686347961 ; Test accuracy : 71.28571428571429\nEpochs : 379 ; Loss : 0.5725646018981934 ; Accuracy : 70.875 ; Test Loss : 0.5710686445236206 ; Test accuracy : 71.28571428571429\nEpochs : 380 ; Loss : 0.5724893808364868 ; Accuracy : 70.85714285714286 ; Test Loss : 0.5710214376449585 ; Test accuracy : 71.28571428571429\nEpochs : 381 ; Loss : 0.5724144577980042 ; Accuracy : 70.85714285714286 ; Test Loss : 0.570974588394165 ; Test accuracy : 71.28571428571429\nEpochs : 382 ; Loss : 0.5723400115966797 ; Accuracy : 70.85714285714286 ; Test Loss : 0.5709280967712402 ; Test accuracy : 71.28571428571429\nEpochs : 383 ; Loss : 0.5722658634185791 ; Accuracy : 70.85714285714286 ; Test Loss : 0.5708819627761841 ; Test accuracy : 71.28571428571429\nEpochs : 384 ; Loss : 0.5721921324729919 ; Accuracy : 70.875 ; Test Loss : 0.5708361864089966 ; Test accuracy : 71.21428571428571\nEpochs : 385 ; Loss : 0.5721188187599182 ; Accuracy : 70.875 ; Test Loss : 0.5707907676696777 ; Test accuracy : 71.21428571428571\nEpochs : 386 ; Loss : 0.5720458030700684 ; Accuracy : 70.91071428571429 ; Test Loss : 0.5707456469535828 ; Test accuracy : 71.21428571428571\nEpochs : 387 ; Loss : 0.5719732046127319 ; Accuracy : 70.91071428571429 ; Test Loss : 0.5707009434700012 ; Test accuracy : 71.21428571428571\nEpochs : 388 ; Loss : 0.5719009637832642 ; Accuracy : 70.91071428571429 ; Test Loss : 0.5706565380096436 ; Test accuracy : 71.21428571428571\nEpochs : 389 ; Loss : 0.571829080581665 ; Accuracy : 70.94642857142857 ; Test Loss : 0.5706124305725098 ; Test accuracy : 71.21428571428571\nEpochs : 390 ; Loss : 0.5717575550079346 ; Accuracy : 70.92857142857143 ; Test Loss : 0.5705687403678894 ; Test accuracy : 71.21428571428571\nEpochs : 391 ; Loss : 0.5716863870620728 ; Accuracy : 70.91071428571429 ; Test Loss : 0.5705253481864929 ; Test accuracy : 71.21428571428571\nEpochs : 392 ; Loss : 0.5716155767440796 ; Accuracy : 70.89285714285714 ; Test Loss : 0.5704822540283203 ; Test accuracy : 71.21428571428571\nEpochs : 393 ; Loss : 0.5715451240539551 ; Accuracy : 70.91071428571429 ; Test Loss : 0.5704395174980164 ; Test accuracy : 71.21428571428571\nEpochs : 394 ; Loss : 0.5714750289916992 ; Accuracy : 70.91071428571429 ; Test Loss : 0.570397138595581 ; Test accuracy : 71.21428571428571\nEpochs : 395 ; Loss : 0.571405291557312 ; Accuracy : 70.89285714285714 ; Test Loss : 0.5703550577163696 ; Test accuracy : 71.21428571428571\nEpochs : 396 ; Loss : 0.5713358521461487 ; Accuracy : 70.89285714285714 ; Test Loss : 0.5703132748603821 ; Test accuracy : 71.21428571428571\nEpochs : 397 ; Loss : 0.5712668299674988 ; Accuracy : 70.89285714285714 ; Test Loss : 0.5702718496322632 ; Test accuracy : 71.14285714285714\nEpochs : 398 ; Loss : 0.5711981058120728 ; Accuracy : 70.89285714285714 ; Test Loss : 0.5702307224273682 ; Test accuracy : 71.14285714285714\nEpochs : 399 ; Loss : 0.5711296796798706 ; Accuracy : 70.89285714285714 ; Test Loss : 0.570189893245697 ; Test accuracy : 71.14285714285714\nEpochs : 400 ; Loss : 0.5710616707801819 ; Accuracy : 70.89285714285714 ; Test Loss : 0.5701494216918945 ; Test accuracy : 71.07142857142857\nEpochs : 401 ; Loss : 0.570993959903717 ; Accuracy : 70.91071428571429 ; Test Loss : 0.5701091885566711 ; Test accuracy : 71.07142857142857\nEpochs : 402 ; Loss : 0.5709266066551208 ; Accuracy : 70.91071428571429 ; Test Loss : 0.5700693130493164 ; Test accuracy : 71.0\nEpochs : 403 ; Loss : 0.5708595514297485 ; Accuracy : 70.91071428571429 ; Test Loss : 0.5700297355651855 ; Test accuracy : 71.0\nEpochs : 404 ; Loss : 0.5707928538322449 ; Accuracy : 70.91071428571429 ; Test Loss : 0.5699904561042786 ; Test accuracy : 71.0\nEpochs : 405 ; Loss : 0.5707263946533203 ; Accuracy : 70.91071428571429 ; Test Loss : 0.5699515342712402 ; Test accuracy : 71.0\nEpochs : 406 ; Loss : 0.5706603527069092 ; Accuracy : 70.92857142857143 ; Test Loss : 0.5699127912521362 ; Test accuracy : 71.0\nEpochs : 407 ; Loss : 0.5705945491790771 ; Accuracy : 70.92857142857143 ; Test Loss : 0.5698744058609009 ; Test accuracy : 71.0\nEpochs : 408 ; Loss : 0.5705291628837585 ; Accuracy : 70.92857142857143 ; Test Loss : 0.5698363184928894 ; Test accuracy : 71.0\nEpochs : 409 ; Loss : 0.5704640746116638 ; Accuracy : 70.92857142857143 ; Test Loss : 0.569798469543457 ; Test accuracy : 71.0\nEpochs : 410 ; Loss : 0.570399284362793 ; Accuracy : 70.94642857142857 ; Test Loss : 0.5697609782218933 ; Test accuracy : 71.14285714285714\nEpochs : 411 ; Loss : 0.570334792137146 ; Accuracy : 70.98214285714286 ; Test Loss : 0.5697236657142639 ; Test accuracy : 71.14285714285714\nEpochs : 412 ; Loss : 0.5702706575393677 ; Accuracy : 70.91071428571429 ; Test Loss : 0.5696867108345032 ; Test accuracy : 71.14285714285714\nEpochs : 413 ; Loss : 0.5702068209648132 ; Accuracy : 70.91071428571429 ; Test Loss : 0.5696501135826111 ; Test accuracy : 71.07142857142857\nEpochs : 414 ; Loss : 0.5701432228088379 ; Accuracy : 70.89285714285714 ; Test Loss : 0.5696136951446533 ; Test accuracy : 71.07142857142857\nEpochs : 415 ; Loss : 0.5700799822807312 ; Accuracy : 70.91071428571429 ; Test Loss : 0.5695775151252747 ; Test accuracy : 71.07142857142857\nEpochs : 416 ; Loss : 0.5700170397758484 ; Accuracy : 70.94642857142857 ; Test Loss : 0.5695416927337646 ; Test accuracy : 71.07142857142857\nEpochs : 417 ; Loss : 0.5699543952941895 ; Accuracy : 70.94642857142857 ; Test Loss : 0.5695061087608337 ; Test accuracy : 71.07142857142857\nEpochs : 418 ; Loss : 0.5698921084403992 ; Accuracy : 70.94642857142857 ; Test Loss : 0.5694708824157715 ; Test accuracy : 71.07142857142857\nEpochs : 419 ; Loss : 0.569830060005188 ; Accuracy : 70.91071428571429 ; Test Loss : 0.5694358348846436 ; Test accuracy : 71.0\nEpochs : 420 ; Loss : 0.5697683095932007 ; Accuracy : 70.91071428571429 ; Test Loss : 0.5694010853767395 ; Test accuracy : 71.0\nEpochs : 421 ; Loss : 0.5697068572044373 ; Accuracy : 70.91071428571429 ; Test Loss : 0.5693665146827698 ; Test accuracy : 71.0\nEpochs : 422 ; Loss : 0.5696457028388977 ; Accuracy : 70.89285714285714 ; Test Loss : 0.5693322420120239 ; Test accuracy : 71.0\nEpochs : 423 ; Loss : 0.569584846496582 ; Accuracy : 70.89285714285714 ; Test Loss : 0.5692983269691467 ; Test accuracy : 71.0\nEpochs : 424 ; Loss : 0.5695242881774902 ; Accuracy : 70.91071428571429 ; Test Loss : 0.5692645907402039 ; Test accuracy : 71.0\nEpochs : 425 ; Loss : 0.5694639682769775 ; Accuracy : 70.92857142857143 ; Test Loss : 0.5692310929298401 ; Test accuracy : 71.0\nEpochs : 426 ; Loss : 0.5694040060043335 ; Accuracy : 70.94642857142857 ; Test Loss : 0.5691978931427002 ; Test accuracy : 71.0\nEpochs : 427 ; Loss : 0.5693442821502686 ; Accuracy : 70.94642857142857 ; Test Loss : 0.5691649317741394 ; Test accuracy : 71.07142857142857\nEpochs : 428 ; Loss : 0.5692847967147827 ; Accuracy : 70.96428571428571 ; Test Loss : 0.5691322088241577 ; Test accuracy : 71.14285714285714\nEpochs : 429 ; Loss : 0.5692256093025208 ; Accuracy : 71.0 ; Test Loss : 0.5690997242927551 ; Test accuracy : 71.14285714285714\nEpochs : 430 ; Loss : 0.5691667199134827 ; Accuracy : 71.03571428571429 ; Test Loss : 0.5690675377845764 ; Test accuracy : 71.14285714285714\nEpochs : 431 ; Loss : 0.5691081285476685 ; Accuracy : 71.03571428571429 ; Test Loss : 0.569035530090332 ; Test accuracy : 71.14285714285714\nEpochs : 432 ; Loss : 0.5690497756004333 ; Accuracy : 71.05357142857143 ; Test Loss : 0.5690038204193115 ; Test accuracy : 71.14285714285714\nEpochs : 433 ; Loss : 0.5689917206764221 ; Accuracy : 71.05357142857143 ; Test Loss : 0.5689723491668701 ; Test accuracy : 71.14285714285714\nEpochs : 434 ; Loss : 0.5689339637756348 ; Accuracy : 71.08928571428571 ; Test Loss : 0.568941056728363 ; Test accuracy : 71.14285714285714\nEpochs : 435 ; Loss : 0.5688764452934265 ; Accuracy : 71.08928571428571 ; Test Loss : 0.5689100623130798 ; Test accuracy : 71.14285714285714\nEpochs : 436 ; Loss : 0.5688191652297974 ; Accuracy : 71.08928571428571 ; Test Loss : 0.5688793063163757 ; Test accuracy : 71.14285714285714\nEpochs : 437 ; Loss : 0.5687621235847473 ; Accuracy : 71.08928571428571 ; Test Loss : 0.5688486695289612 ; Test accuracy : 71.14285714285714\nEpochs : 438 ; Loss : 0.5687054395675659 ; Accuracy : 71.08928571428571 ; Test Loss : 0.5688183903694153 ; Test accuracy : 71.14285714285714\nEpochs : 439 ; Loss : 0.5686489939689636 ; Accuracy : 71.08928571428571 ; Test Loss : 0.5687883496284485 ; Test accuracy : 71.14285714285714\nEpochs : 440 ; Loss : 0.5685927867889404 ; Accuracy : 71.08928571428571 ; Test Loss : 0.5687584280967712 ; Test accuracy : 71.14285714285714\nEpochs : 441 ; Loss : 0.5685368180274963 ; Accuracy : 71.08928571428571 ; Test Loss : 0.5687288641929626 ; Test accuracy : 71.14285714285714\nEpochs : 442 ; Loss : 0.5684811472892761 ; Accuracy : 71.08928571428571 ; Test Loss : 0.5686995387077332 ; Test accuracy : 71.14285714285714\nEpochs : 443 ; Loss : 0.568425714969635 ; Accuracy : 71.08928571428571 ; Test Loss : 0.5686702728271484 ; Test accuracy : 71.14285714285714\nEpochs : 444 ; Loss : 0.568370521068573 ; Accuracy : 71.08928571428571 ; Test Loss : 0.5686412453651428 ; Test accuracy : 71.07142857142857\nEpochs : 445 ; Loss : 0.5683156251907349 ; Accuracy : 71.05357142857143 ; Test Loss : 0.5686125755310059 ; Test accuracy : 71.07142857142857\nEpochs : 446 ; Loss : 0.568260908126831 ; Accuracy : 71.05357142857143 ; Test Loss : 0.5685840845108032 ; Test accuracy : 71.07142857142857\nEpochs : 447 ; Loss : 0.5682064890861511 ; Accuracy : 71.01785714285714 ; Test Loss : 0.5685557126998901 ; Test accuracy : 71.07142857142857\nEpochs : 448 ; Loss : 0.5681523084640503 ; Accuracy : 71.0 ; Test Loss : 0.5685276389122009 ; Test accuracy : 71.07142857142857\nEpochs : 449 ; Loss : 0.5680983662605286 ; Accuracy : 71.01785714285714 ; Test Loss : 0.568499743938446 ; Test accuracy : 71.07142857142857\nEpochs : 450 ; Loss : 0.5680446624755859 ; Accuracy : 71.01785714285714 ; Test Loss : 0.5684720873832703 ; Test accuracy : 71.07142857142857\nEpochs : 451 ; Loss : 0.5679911971092224 ; Accuracy : 71.03571428571429 ; Test Loss : 0.5684446692466736 ; Test accuracy : 71.07142857142857\nEpochs : 452 ; Loss : 0.5679380297660828 ; Accuracy : 71.03571428571429 ; Test Loss : 0.5684173703193665 ; Test accuracy : 71.0\nEpochs : 453 ; Loss : 0.5678851008415222 ; Accuracy : 71.01785714285714 ; Test Loss : 0.5683903694152832 ; Test accuracy : 71.0\nEpochs : 454 ; Loss : 0.567832350730896 ; Accuracy : 71.0 ; Test Loss : 0.5683635473251343 ; Test accuracy : 71.0\nEpochs : 455 ; Loss : 0.5677798390388489 ; Accuracy : 71.0 ; Test Loss : 0.5683369040489197 ; Test accuracy : 70.85714285714286\nEpochs : 456 ; Loss : 0.5677276253700256 ; Accuracy : 71.01785714285714 ; Test Loss : 0.5683104991912842 ; Test accuracy : 70.85714285714286\nEpochs : 457 ; Loss : 0.5676755905151367 ; Accuracy : 71.01785714285714 ; Test Loss : 0.568284273147583 ; Test accuracy : 70.85714285714286\nEpochs : 458 ; Loss : 0.5676237940788269 ; Accuracy : 71.0 ; Test Loss : 0.5682582259178162 ; Test accuracy : 70.85714285714286\nEpochs : 459 ; Loss : 0.5675722360610962 ; Accuracy : 71.0 ; Test Loss : 0.5682324171066284 ; Test accuracy : 70.85714285714286\nEpochs : 460 ; Loss : 0.5675209164619446 ; Accuracy : 71.0 ; Test Loss : 0.568206787109375 ; Test accuracy : 70.85714285714286\nEpochs : 461 ; Loss : 0.5674698352813721 ; Accuracy : 71.01785714285714 ; Test Loss : 0.5681813359260559 ; Test accuracy : 70.85714285714286\nEpochs : 462 ; Loss : 0.5674189925193787 ; Accuracy : 71.0 ; Test Loss : 0.5681561231613159 ; Test accuracy : 70.85714285714286\nEpochs : 463 ; Loss : 0.5673683881759644 ; Accuracy : 71.0 ; Test Loss : 0.5681310296058655 ; Test accuracy : 70.85714285714286\nEpochs : 464 ; Loss : 0.5673179626464844 ; Accuracy : 71.0 ; Test Loss : 0.5681061744689941 ; Test accuracy : 70.92857142857143\nEpochs : 465 ; Loss : 0.5672677755355835 ; Accuracy : 70.96428571428571 ; Test Loss : 0.5680815577507019 ; Test accuracy : 70.92857142857143\nEpochs : 466 ; Loss : 0.5672177672386169 ; Accuracy : 70.96428571428571 ; Test Loss : 0.5680570602416992 ; Test accuracy : 70.78571428571429\nEpochs : 467 ; Loss : 0.5671680569648743 ; Accuracy : 70.96428571428571 ; Test Loss : 0.5680327415466309 ; Test accuracy : 70.78571428571429\nEpochs : 468 ; Loss : 0.5671185255050659 ; Accuracy : 71.0 ; Test Loss : 0.5680086612701416 ; Test accuracy : 70.78571428571429\nEpochs : 469 ; Loss : 0.5670692324638367 ; Accuracy : 71.0 ; Test Loss : 0.5679847598075867 ; Test accuracy : 70.78571428571429\nEpochs : 470 ; Loss : 0.567020058631897 ; Accuracy : 70.98214285714286 ; Test Loss : 0.5679610371589661 ; Test accuracy : 70.78571428571429\nEpochs : 471 ; Loss : 0.5669712424278259 ; Accuracy : 70.96428571428571 ; Test Loss : 0.567937433719635 ; Test accuracy : 70.78571428571429\nEpochs : 472 ; Loss : 0.5669226050376892 ; Accuracy : 70.96428571428571 ; Test Loss : 0.5679140686988831 ; Test accuracy : 70.85714285714286\nEpochs : 473 ; Loss : 0.5668741464614868 ; Accuracy : 70.94642857142857 ; Test Loss : 0.5678908824920654 ; Test accuracy : 70.85714285714286\nEpochs : 474 ; Loss : 0.5668259263038635 ; Accuracy : 70.94642857142857 ; Test Loss : 0.5678678750991821 ; Test accuracy : 70.85714285714286\nEpochs : 475 ; Loss : 0.5667778849601746 ; Accuracy : 70.96428571428571 ; Test Loss : 0.5678450465202332 ; Test accuracy : 70.85714285714286\nEpochs : 476 ; Loss : 0.5667300224304199 ; Accuracy : 70.94642857142857 ; Test Loss : 0.5678223371505737 ; Test accuracy : 70.85714285714286\nEpochs : 477 ; Loss : 0.5666824579238892 ; Accuracy : 70.96428571428571 ; Test Loss : 0.5677998661994934 ; Test accuracy : 70.85714285714286\nEpochs : 478 ; Loss : 0.566635012626648 ; Accuracy : 70.98214285714286 ; Test Loss : 0.5677775144577026 ; Test accuracy : 70.85714285714286\nEpochs : 479 ; Loss : 0.5665878653526306 ; Accuracy : 70.98214285714286 ; Test Loss : 0.567755401134491 ; Test accuracy : 70.85714285714286\nEpochs : 480 ; Loss : 0.5665408968925476 ; Accuracy : 70.98214285714286 ; Test Loss : 0.5677334070205688 ; Test accuracy : 70.71428571428571\nEpochs : 481 ; Loss : 0.5664941072463989 ; Accuracy : 70.98214285714286 ; Test Loss : 0.567711591720581 ; Test accuracy : 70.64285714285714\nEpochs : 482 ; Loss : 0.5664475560188293 ; Accuracy : 71.0 ; Test Loss : 0.5676900148391724 ; Test accuracy : 70.64285714285714\nEpochs : 483 ; Loss : 0.5664011240005493 ; Accuracy : 71.0 ; Test Loss : 0.5676684379577637 ; Test accuracy : 70.64285714285714\nEpochs : 484 ; Loss : 0.5663549900054932 ; Accuracy : 71.01785714285714 ; Test Loss : 0.5676471590995789 ; Test accuracy : 70.64285714285714\nEpochs : 485 ; Loss : 0.5663089156150818 ; Accuracy : 71.0 ; Test Loss : 0.5676259994506836 ; Test accuracy : 70.64285714285714\nEpochs : 486 ; Loss : 0.5662631392478943 ; Accuracy : 71.0 ; Test Loss : 0.5676050186157227 ; Test accuracy : 70.64285714285714\nEpochs : 487 ; Loss : 0.5662176609039307 ; Accuracy : 71.0 ; Test Loss : 0.567584216594696 ; Test accuracy : 70.57142857142857\nEpochs : 488 ; Loss : 0.566172182559967 ; Accuracy : 71.0 ; Test Loss : 0.567563533782959 ; Test accuracy : 70.57142857142857\nEpochs : 489 ; Loss : 0.5661269426345825 ; Accuracy : 71.0 ; Test Loss : 0.567543089389801 ; Test accuracy : 70.57142857142857\nEpochs : 490 ; Loss : 0.5660820007324219 ; Accuracy : 71.0 ; Test Loss : 0.5675226449966431 ; Test accuracy : 70.57142857142857\nEpochs : 491 ; Loss : 0.5660371780395508 ; Accuracy : 71.01785714285714 ; Test Loss : 0.567502498626709 ; Test accuracy : 70.57142857142857\nEpochs : 492 ; Loss : 0.565992534160614 ; Accuracy : 71.01785714285714 ; Test Loss : 0.5674824714660645 ; Test accuracy : 70.57142857142857\nEpochs : 493 ; Loss : 0.5659481287002563 ; Accuracy : 71.01785714285714 ; Test Loss : 0.5674625635147095 ; Test accuracy : 70.57142857142857\nEpochs : 494 ; Loss : 0.565903902053833 ; Accuracy : 71.01785714285714 ; Test Loss : 0.5674428939819336 ; Test accuracy : 70.57142857142857\nEpochs : 495 ; Loss : 0.5658597946166992 ; Accuracy : 71.05357142857143 ; Test Loss : 0.5674232840538025 ; Test accuracy : 70.57142857142857\nEpochs : 496 ; Loss : 0.5658159255981445 ; Accuracy : 71.05357142857143 ; Test Loss : 0.5674038529396057 ; Test accuracy : 70.57142857142857\nEpochs : 497 ; Loss : 0.5657722353935242 ; Accuracy : 71.08928571428571 ; Test Loss : 0.567384660243988 ; Test accuracy : 70.57142857142857\nEpochs : 498 ; Loss : 0.5657287240028381 ; Accuracy : 71.08928571428571 ; Test Loss : 0.5673655271530151 ; Test accuracy : 70.5\nEpochs : 499 ; Loss : 0.5656854510307312 ; Accuracy : 71.08928571428571 ; Test Loss : 0.5673465132713318 ; Test accuracy : 70.5\nEpochs : 500 ; Loss : 0.5656422972679138 ; Accuracy : 71.07142857142857 ; Test Loss : 0.5673276782035828 ; Test accuracy : 70.5\nEpochs : 501 ; Loss : 0.5655993819236755 ; Accuracy : 71.07142857142857 ; Test Loss : 0.5673090219497681 ; Test accuracy : 70.5\nEpochs : 502 ; Loss : 0.5655566453933716 ; Accuracy : 71.07142857142857 ; Test Loss : 0.5672904849052429 ; Test accuracy : 70.57142857142857\nEpochs : 503 ; Loss : 0.5655139684677124 ; Accuracy : 71.07142857142857 ; Test Loss : 0.5672721862792969 ; Test accuracy : 70.57142857142857\nEpochs : 504 ; Loss : 0.5654716491699219 ; Accuracy : 71.08928571428571 ; Test Loss : 0.567253828048706 ; Test accuracy : 70.57142857142857\nEpochs : 505 ; Loss : 0.5654293298721313 ; Accuracy : 71.10714285714286 ; Test Loss : 0.5672357678413391 ; Test accuracy : 70.57142857142857\nEpochs : 506 ; Loss : 0.5653873085975647 ; Accuracy : 71.125 ; Test Loss : 0.5672178268432617 ; Test accuracy : 70.57142857142857\nEpochs : 507 ; Loss : 0.5653454065322876 ; Accuracy : 71.14285714285714 ; Test Loss : 0.5672000050544739 ; Test accuracy : 70.64285714285714\nEpochs : 508 ; Loss : 0.5653036832809448 ; Accuracy : 71.19642857142857 ; Test Loss : 0.5671823024749756 ; Test accuracy : 70.71428571428571\nEpochs : 509 ; Loss : 0.5652621388435364 ; Accuracy : 71.17857142857143 ; Test Loss : 0.5671647787094116 ; Test accuracy : 70.71428571428571\nEpochs : 510 ; Loss : 0.565220832824707 ; Accuracy : 71.19642857142857 ; Test Loss : 0.5671473741531372 ; Test accuracy : 70.71428571428571\nEpochs : 511 ; Loss : 0.5651795864105225 ; Accuracy : 71.19642857142857 ; Test Loss : 0.5671301484107971 ; Test accuracy : 70.71428571428571\nEpochs : 512 ; Loss : 0.565138578414917 ; Accuracy : 71.19642857142857 ; Test Loss : 0.5671129822731018 ; Test accuracy : 70.71428571428571\nEpochs : 513 ; Loss : 0.5650977492332458 ; Accuracy : 71.21428571428571 ; Test Loss : 0.567095935344696 ; Test accuracy : 70.71428571428571\nEpochs : 514 ; Loss : 0.565057098865509 ; Accuracy : 71.21428571428571 ; Test Loss : 0.5670791268348694 ; Test accuracy : 70.71428571428571\nEpochs : 515 ; Loss : 0.5650165677070618 ; Accuracy : 71.23214285714286 ; Test Loss : 0.5670623779296875 ; Test accuracy : 70.64285714285714\nEpochs : 516 ; Loss : 0.5649762153625488 ; Accuracy : 71.25 ; Test Loss : 0.5670457482337952 ; Test accuracy : 70.64285714285714\nEpochs : 517 ; Loss : 0.5649359822273254 ; Accuracy : 71.28571428571429 ; Test Loss : 0.5670292973518372 ; Test accuracy : 70.64285714285714\nEpochs : 518 ; Loss : 0.5648959875106812 ; Accuracy : 71.28571428571429 ; Test Loss : 0.5670129656791687 ; Test accuracy : 70.64285714285714\nEpochs : 519 ; Loss : 0.5648561120033264 ; Accuracy : 71.28571428571429 ; Test Loss : 0.5669968128204346 ; Test accuracy : 70.64285714285714\nEpochs : 520 ; Loss : 0.5648164749145508 ; Accuracy : 71.26785714285714 ; Test Loss : 0.5669806599617004 ; Test accuracy : 70.57142857142857\nEpochs : 521 ; Loss : 0.5647768974304199 ; Accuracy : 71.26785714285714 ; Test Loss : 0.5669646859169006 ; Test accuracy : 70.57142857142857\nEpochs : 522 ; Loss : 0.5647375583648682 ; Accuracy : 71.26785714285714 ; Test Loss : 0.5669489502906799 ; Test accuracy : 70.57142857142857\nEpochs : 523 ; Loss : 0.5646983981132507 ; Accuracy : 71.26785714285714 ; Test Loss : 0.5669332146644592 ; Test accuracy : 70.57142857142857\nEpochs : 524 ; Loss : 0.5646593570709229 ; Accuracy : 71.25 ; Test Loss : 0.5669176578521729 ; Test accuracy : 70.64285714285714\nEpochs : 525 ; Loss : 0.5646204352378845 ; Accuracy : 71.23214285714286 ; Test Loss : 0.566902220249176 ; Test accuracy : 70.64285714285714\nEpochs : 526 ; Loss : 0.5645817518234253 ; Accuracy : 71.25 ; Test Loss : 0.566886842250824 ; Test accuracy : 70.64285714285714\nEpochs : 527 ; Loss : 0.5645431280136108 ; Accuracy : 71.25 ; Test Loss : 0.566871702671051 ; Test accuracy : 70.64285714285714\nEpochs : 528 ; Loss : 0.5645047426223755 ; Accuracy : 71.26785714285714 ; Test Loss : 0.5668566226959229 ; Test accuracy : 70.64285714285714\nEpochs : 529 ; Loss : 0.5644664764404297 ; Accuracy : 71.30357142857143 ; Test Loss : 0.5668416023254395 ; Test accuracy : 70.64285714285714\nEpochs : 530 ; Loss : 0.5644283294677734 ; Accuracy : 71.30357142857143 ; Test Loss : 0.5668267607688904 ; Test accuracy : 70.64285714285714\nEpochs : 531 ; Loss : 0.5643904209136963 ; Accuracy : 71.30357142857143 ; Test Loss : 0.5668119788169861 ; Test accuracy : 70.64285714285714\nEpochs : 532 ; Loss : 0.5643525719642639 ; Accuracy : 71.30357142857143 ; Test Loss : 0.5667973756790161 ; Test accuracy : 70.64285714285714\nEpochs : 533 ; Loss : 0.5643149018287659 ; Accuracy : 71.32142857142857 ; Test Loss : 0.5667828917503357 ; Test accuracy : 70.64285714285714\nEpochs : 534 ; Loss : 0.5642774701118469 ; Accuracy : 71.32142857142857 ; Test Loss : 0.5667685866355896 ; Test accuracy : 70.64285714285714\nEpochs : 535 ; Loss : 0.5642401576042175 ; Accuracy : 71.32142857142857 ; Test Loss : 0.5667542815208435 ; Test accuracy : 70.64285714285714\nEpochs : 536 ; Loss : 0.5642029047012329 ; Accuracy : 71.32142857142857 ; Test Loss : 0.566740095615387 ; Test accuracy : 70.64285714285714\nEpochs : 537 ; Loss : 0.5641658902168274 ; Accuracy : 71.32142857142857 ; Test Loss : 0.5667260885238647 ; Test accuracy : 70.64285714285714\nEpochs : 538 ; Loss : 0.5641289949417114 ; Accuracy : 71.32142857142857 ; Test Loss : 0.5667122006416321 ; Test accuracy : 70.71428571428571\nEpochs : 539 ; Loss : 0.564092218875885 ; Accuracy : 71.32142857142857 ; Test Loss : 0.566698431968689 ; Test accuracy : 70.71428571428571\nEpochs : 540 ; Loss : 0.5640556216239929 ; Accuracy : 71.32142857142857 ; Test Loss : 0.5666846632957458 ; Test accuracy : 70.71428571428571\nEpochs : 541 ; Loss : 0.5640192031860352 ; Accuracy : 71.32142857142857 ; Test Loss : 0.5666711330413818 ; Test accuracy : 70.78571428571429\nEpochs : 542 ; Loss : 0.5639829039573669 ; Accuracy : 71.32142857142857 ; Test Loss : 0.5666576027870178 ; Test accuracy : 70.78571428571429\nEpochs : 543 ; Loss : 0.5639467239379883 ; Accuracy : 71.32142857142857 ; Test Loss : 0.5666442513465881 ; Test accuracy : 70.78571428571429\nEpochs : 544 ; Loss : 0.5639106631278992 ; Accuracy : 71.32142857142857 ; Test Loss : 0.566631019115448 ; Test accuracy : 70.78571428571429\nEpochs : 545 ; Loss : 0.5638748407363892 ; Accuracy : 71.32142857142857 ; Test Loss : 0.5666178464889526 ; Test accuracy : 70.78571428571429\nEpochs : 546 ; Loss : 0.5638390779495239 ; Accuracy : 71.32142857142857 ; Test Loss : 0.5666048526763916 ; Test accuracy : 70.71428571428571\nEpochs : 547 ; Loss : 0.563803493976593 ; Accuracy : 71.30357142857143 ; Test Loss : 0.5665918588638306 ; Test accuracy : 70.71428571428571\nEpochs : 548 ; Loss : 0.5637680292129517 ; Accuracy : 71.30357142857143 ; Test Loss : 0.5665790438652039 ; Test accuracy : 70.71428571428571\nEpochs : 549 ; Loss : 0.5637326836585999 ; Accuracy : 71.30357142857143 ; Test Loss : 0.5665663480758667 ; Test accuracy : 70.78571428571429\nEpochs : 550 ; Loss : 0.5636975765228271 ; Accuracy : 71.32142857142857 ; Test Loss : 0.5665537714958191 ; Test accuracy : 70.78571428571429\nEpochs : 551 ; Loss : 0.5636624693870544 ; Accuracy : 71.32142857142857 ; Test Loss : 0.5665411949157715 ; Test accuracy : 70.78571428571429\nEpochs : 552 ; Loss : 0.5636276006698608 ; Accuracy : 71.30357142857143 ; Test Loss : 0.566528856754303 ; Test accuracy : 70.78571428571429\nEpochs : 553 ; Loss : 0.5635928511619568 ; Accuracy : 71.30357142857143 ; Test Loss : 0.5665165185928345 ; Test accuracy : 70.85714285714286\nEpochs : 554 ; Loss : 0.5635582208633423 ; Accuracy : 71.30357142857143 ; Test Loss : 0.5665043592453003 ; Test accuracy : 70.78571428571429\nEpochs : 555 ; Loss : 0.5635237097740173 ; Accuracy : 71.28571428571429 ; Test Loss : 0.5664921998977661 ; Test accuracy : 70.78571428571429\nEpochs : 556 ; Loss : 0.5634893774986267 ; Accuracy : 71.28571428571429 ; Test Loss : 0.5664801597595215 ; Test accuracy : 70.78571428571429\nEpochs : 557 ; Loss : 0.5634551644325256 ; Accuracy : 71.26785714285714 ; Test Loss : 0.5664682984352112 ; Test accuracy : 70.78571428571429\nEpochs : 558 ; Loss : 0.5634210109710693 ; Accuracy : 71.26785714285714 ; Test Loss : 0.5664564967155457 ; Test accuracy : 70.78571428571429\nEpochs : 559 ; Loss : 0.5633870959281921 ; Accuracy : 71.26785714285714 ; Test Loss : 0.5664448142051697 ; Test accuracy : 70.85714285714286\nEpochs : 560 ; Loss : 0.5633532404899597 ; Accuracy : 71.25 ; Test Loss : 0.5664331912994385 ; Test accuracy : 70.85714285714286\nEpochs : 561 ; Loss : 0.5633196234703064 ; Accuracy : 71.26785714285714 ; Test Loss : 0.5664216876029968 ; Test accuracy : 70.85714285714286\nEpochs : 562 ; Loss : 0.5632860660552979 ; Accuracy : 71.26785714285714 ; Test Loss : 0.5664102435112 ; Test accuracy : 70.85714285714286\nEpochs : 563 ; Loss : 0.5632525682449341 ; Accuracy : 71.25 ; Test Loss : 0.5663989186286926 ; Test accuracy : 70.85714285714286\nEpochs : 564 ; Loss : 0.5632192492485046 ; Accuracy : 71.26785714285714 ; Test Loss : 0.5663877725601196 ; Test accuracy : 70.85714285714286\nEpochs : 565 ; Loss : 0.5631861090660095 ; Accuracy : 71.26785714285714 ; Test Loss : 0.5663766264915466 ; Test accuracy : 70.85714285714286\nEpochs : 566 ; Loss : 0.563153088092804 ; Accuracy : 71.28571428571429 ; Test Loss : 0.5663655400276184 ; Test accuracy : 70.85714285714286\nEpochs : 567 ; Loss : 0.5631201267242432 ; Accuracy : 71.32142857142857 ; Test Loss : 0.5663546323776245 ; Test accuracy : 70.85714285714286\nEpochs : 568 ; Loss : 0.5630873441696167 ; Accuracy : 71.32142857142857 ; Test Loss : 0.5663437843322754 ; Test accuracy : 70.85714285714286\nEpochs : 569 ; Loss : 0.5630547404289246 ; Accuracy : 71.32142857142857 ; Test Loss : 0.566332995891571 ; Test accuracy : 70.85714285714286\nEpochs : 570 ; Loss : 0.5630221366882324 ; Accuracy : 71.33928571428571 ; Test Loss : 0.566322386264801 ; Test accuracy : 70.85714285714286\nEpochs : 571 ; Loss : 0.5629897713661194 ; Accuracy : 71.32142857142857 ; Test Loss : 0.5663117170333862 ; Test accuracy : 70.85714285714286\nEpochs : 572 ; Loss : 0.5629575252532959 ; Accuracy : 71.30357142857143 ; Test Loss : 0.5663012862205505 ; Test accuracy : 70.92857142857143\nEpochs : 573 ; Loss : 0.5629252791404724 ; Accuracy : 71.32142857142857 ; Test Loss : 0.5662909150123596 ; Test accuracy : 70.92857142857143\nEpochs : 574 ; Loss : 0.5628932118415833 ; Accuracy : 71.32142857142857 ; Test Loss : 0.5662806034088135 ; Test accuracy : 70.92857142857143\nEpochs : 575 ; Loss : 0.5628613233566284 ; Accuracy : 71.30357142857143 ; Test Loss : 0.5662704110145569 ; Test accuracy : 70.92857142857143\nEpochs : 576 ; Loss : 0.5628295540809631 ; Accuracy : 71.32142857142857 ; Test Loss : 0.5662602186203003 ; Test accuracy : 70.92857142857143\nEpochs : 577 ; Loss : 0.5627978444099426 ; Accuracy : 71.30357142857143 ; Test Loss : 0.566250205039978 ; Test accuracy : 70.92857142857143\nEpochs : 578 ; Loss : 0.5627662539482117 ; Accuracy : 71.30357142857143 ; Test Loss : 0.5662402510643005 ; Test accuracy : 71.0\nEpochs : 579 ; Loss : 0.5627349019050598 ; Accuracy : 71.28571428571429 ; Test Loss : 0.5662303566932678 ; Test accuracy : 71.0\nEpochs : 580 ; Loss : 0.562703549861908 ; Accuracy : 71.30357142857143 ; Test Loss : 0.5662205815315247 ; Test accuracy : 71.0\nEpochs : 581 ; Loss : 0.5626723170280457 ; Accuracy : 71.30357142857143 ; Test Loss : 0.5662108659744263 ; Test accuracy : 71.0\nEpochs : 582 ; Loss : 0.5626412630081177 ; Accuracy : 71.30357142857143 ; Test Loss : 0.5662012696266174 ; Test accuracy : 71.0\nEpochs : 583 ; Loss : 0.5626102685928345 ; Accuracy : 71.28571428571429 ; Test Loss : 0.5661917328834534 ; Test accuracy : 71.0\nEpochs : 584 ; Loss : 0.5625794529914856 ; Accuracy : 71.28571428571429 ; Test Loss : 0.5661822557449341 ; Test accuracy : 71.0\nEpochs : 585 ; Loss : 0.5625487565994263 ; Accuracy : 71.26785714285714 ; Test Loss : 0.5661728978157043 ; Test accuracy : 71.0\nEpochs : 586 ; Loss : 0.5625181198120117 ; Accuracy : 71.28571428571429 ; Test Loss : 0.5661635994911194 ; Test accuracy : 71.0\nEpochs : 587 ; Loss : 0.5624876022338867 ; Accuracy : 71.30357142857143 ; Test Loss : 0.5661543607711792 ; Test accuracy : 71.0\nEpochs : 588 ; Loss : 0.5624572038650513 ; Accuracy : 71.32142857142857 ; Test Loss : 0.5661453008651733 ; Test accuracy : 71.0\nEpochs : 589 ; Loss : 0.5624269843101501 ; Accuracy : 71.33928571428571 ; Test Loss : 0.5661363005638123 ; Test accuracy : 71.0\nEpochs : 590 ; Loss : 0.5623968243598938 ; Accuracy : 71.35714285714286 ; Test Loss : 0.5661273002624512 ; Test accuracy : 71.0\nEpochs : 591 ; Loss : 0.562366783618927 ; Accuracy : 71.375 ; Test Loss : 0.5661184191703796 ; Test accuracy : 71.0\nEpochs : 592 ; Loss : 0.5623368620872498 ; Accuracy : 71.35714285714286 ; Test Loss : 0.5661095976829529 ; Test accuracy : 71.0\nEpochs : 593 ; Loss : 0.5623070597648621 ; Accuracy : 71.35714285714286 ; Test Loss : 0.5661008954048157 ; Test accuracy : 71.0\nEpochs : 594 ; Loss : 0.5622773170471191 ; Accuracy : 71.35714285714286 ; Test Loss : 0.5660922527313232 ; Test accuracy : 71.0\nEpochs : 595 ; Loss : 0.5622477531433105 ; Accuracy : 71.375 ; Test Loss : 0.5660836696624756 ; Test accuracy : 71.0\nEpochs : 596 ; Loss : 0.5622182488441467 ; Accuracy : 71.375 ; Test Loss : 0.5660751461982727 ; Test accuracy : 71.0\nEpochs : 597 ; Loss : 0.5621888637542725 ; Accuracy : 71.41071428571429 ; Test Loss : 0.5660667419433594 ; Test accuracy : 71.0\nEpochs : 598 ; Loss : 0.5621595978736877 ; Accuracy : 71.41071428571429 ; Test Loss : 0.5660584568977356 ; Test accuracy : 71.0\nEpochs : 599 ; Loss : 0.5621304512023926 ; Accuracy : 71.41071428571429 ; Test Loss : 0.5660501718521118 ; Test accuracy : 71.0\nEpochs : 600 ; Loss : 0.562101423740387 ; Accuracy : 71.41071428571429 ; Test Loss : 0.5660419464111328 ; Test accuracy : 71.0\nEpochs : 601 ; Loss : 0.5620725154876709 ; Accuracy : 71.39285714285714 ; Test Loss : 0.5660338401794434 ; Test accuracy : 71.0\nEpochs : 602 ; Loss : 0.5620436072349548 ; Accuracy : 71.41071428571429 ; Test Loss : 0.5660257935523987 ; Test accuracy : 71.07142857142857\nEpochs : 603 ; Loss : 0.5620149374008179 ; Accuracy : 71.41071428571429 ; Test Loss : 0.5660178661346436 ; Test accuracy : 71.07142857142857\nEpochs : 604 ; Loss : 0.5619862675666809 ; Accuracy : 71.41071428571429 ; Test Loss : 0.5660099983215332 ; Test accuracy : 71.07142857142857\nEpochs : 605 ; Loss : 0.5619577765464783 ; Accuracy : 71.41071428571429 ; Test Loss : 0.5660021305084229 ; Test accuracy : 71.07142857142857\nEpochs : 606 ; Loss : 0.5619293451309204 ; Accuracy : 71.41071428571429 ; Test Loss : 0.565994381904602 ; Test accuracy : 71.07142857142857\nEpochs : 607 ; Loss : 0.5619010925292969 ; Accuracy : 71.39285714285714 ; Test Loss : 0.565986692905426 ; Test accuracy : 71.07142857142857\nEpochs : 608 ; Loss : 0.5618728399276733 ; Accuracy : 71.39285714285714 ; Test Loss : 0.5659790635108948 ; Test accuracy : 71.07142857142857\nEpochs : 609 ; Loss : 0.5618447661399841 ; Accuracy : 71.39285714285714 ; Test Loss : 0.5659716129302979 ; Test accuracy : 71.07142857142857\nEpochs : 610 ; Loss : 0.5618167519569397 ; Accuracy : 71.41071428571429 ; Test Loss : 0.5659641027450562 ; Test accuracy : 71.07142857142857\nEpochs : 611 ; Loss : 0.5617889165878296 ; Accuracy : 71.41071428571429 ; Test Loss : 0.5659566521644592 ; Test accuracy : 71.07142857142857\nEpochs : 612 ; Loss : 0.5617611408233643 ; Accuracy : 71.41071428571429 ; Test Loss : 0.5659493803977966 ; Test accuracy : 71.07142857142857\nEpochs : 613 ; Loss : 0.5617334246635437 ; Accuracy : 71.42857142857143 ; Test Loss : 0.565942108631134 ; Test accuracy : 71.07142857142857\nEpochs : 614 ; Loss : 0.5617058277130127 ; Accuracy : 71.42857142857143 ; Test Loss : 0.565934956073761 ; Test accuracy : 71.07142857142857\nEpochs : 615 ; Loss : 0.5616783499717712 ; Accuracy : 71.41071428571429 ; Test Loss : 0.5659278035163879 ; Test accuracy : 71.07142857142857\nEpochs : 616 ; Loss : 0.5616509914398193 ; Accuracy : 71.41071428571429 ; Test Loss : 0.5659207701683044 ; Test accuracy : 71.07142857142857\nEpochs : 617 ; Loss : 0.5616236329078674 ; Accuracy : 71.41071428571429 ; Test Loss : 0.5659137964248657 ; Test accuracy : 71.07142857142857\nEpochs : 618 ; Loss : 0.5615965127944946 ; Accuracy : 71.41071428571429 ; Test Loss : 0.5659068822860718 ; Test accuracy : 71.0\nEpochs : 619 ; Loss : 0.5615694522857666 ; Accuracy : 71.39285714285714 ; Test Loss : 0.5659000277519226 ; Test accuracy : 71.0\nEpochs : 620 ; Loss : 0.5615424513816833 ; Accuracy : 71.39285714285714 ; Test Loss : 0.565893292427063 ; Test accuracy : 71.0\nEpochs : 621 ; Loss : 0.5615155696868896 ; Accuracy : 71.375 ; Test Loss : 0.5658864974975586 ; Test accuracy : 71.0\nEpochs : 622 ; Loss : 0.5614887475967407 ; Accuracy : 71.35714285714286 ; Test Loss : 0.5658798813819885 ; Test accuracy : 71.0\nEpochs : 623 ; Loss : 0.5614620447158813 ; Accuracy : 71.35714285714286 ; Test Loss : 0.5658732056617737 ; Test accuracy : 71.0\nEpochs : 624 ; Loss : 0.5614354610443115 ; Accuracy : 71.35714285714286 ; Test Loss : 0.5658667087554932 ; Test accuracy : 71.0\nEpochs : 625 ; Loss : 0.5614089965820312 ; Accuracy : 71.35714285714286 ; Test Loss : 0.5658602118492126 ; Test accuracy : 71.0\nEpochs : 626 ; Loss : 0.561382532119751 ; Accuracy : 71.35714285714286 ; Test Loss : 0.5658538937568665 ; Test accuracy : 70.92857142857143\nEpochs : 627 ; Loss : 0.5613563060760498 ; Accuracy : 71.33928571428571 ; Test Loss : 0.5658475160598755 ; Test accuracy : 71.0\nEpochs : 628 ; Loss : 0.5613300204277039 ; Accuracy : 71.32142857142857 ; Test Loss : 0.5658413171768188 ; Test accuracy : 71.0\nEpochs : 629 ; Loss : 0.5613038539886475 ; Accuracy : 71.30357142857143 ; Test Loss : 0.5658350586891174 ; Test accuracy : 71.0\nEpochs : 630 ; Loss : 0.5612778663635254 ; Accuracy : 71.30357142857143 ; Test Loss : 0.5658289194107056 ; Test accuracy : 71.0\nEpochs : 631 ; Loss : 0.5612519383430481 ; Accuracy : 71.30357142857143 ; Test Loss : 0.5658228397369385 ; Test accuracy : 71.0\nEpochs : 632 ; Loss : 0.5612261295318604 ; Accuracy : 71.28571428571429 ; Test Loss : 0.5658168196678162 ; Test accuracy : 71.0\nEpochs : 633 ; Loss : 0.5612003803253174 ; Accuracy : 71.28571428571429 ; Test Loss : 0.5658107995986938 ; Test accuracy : 71.0\nEpochs : 634 ; Loss : 0.5611746907234192 ; Accuracy : 71.30357142857143 ; Test Loss : 0.5658048987388611 ; Test accuracy : 71.0\nEpochs : 635 ; Loss : 0.5611491203308105 ; Accuracy : 71.30357142857143 ; Test Loss : 0.5657990574836731 ; Test accuracy : 71.0\nEpochs : 636 ; Loss : 0.5611236691474915 ; Accuracy : 71.30357142857143 ; Test Loss : 0.5657932758331299 ; Test accuracy : 71.0\nEpochs : 637 ; Loss : 0.5610982775688171 ; Accuracy : 71.30357142857143 ; Test Loss : 0.5657875537872314 ; Test accuracy : 71.0\nEpochs : 638 ; Loss : 0.5610730051994324 ; Accuracy : 71.32142857142857 ; Test Loss : 0.5657818913459778 ; Test accuracy : 71.0\nEpochs : 639 ; Loss : 0.5610477924346924 ; Accuracy : 71.32142857142857 ; Test Loss : 0.5657762885093689 ; Test accuracy : 71.0\nEpochs : 640 ; Loss : 0.5610226988792419 ; Accuracy : 71.32142857142857 ; Test Loss : 0.56577068567276 ; Test accuracy : 71.0\nEpochs : 641 ; Loss : 0.5609976649284363 ; Accuracy : 71.32142857142857 ; Test Loss : 0.5657652020454407 ; Test accuracy : 71.0\nEpochs : 642 ; Loss : 0.5609726905822754 ; Accuracy : 71.30357142857143 ; Test Loss : 0.5657597780227661 ; Test accuracy : 71.0\nEpochs : 643 ; Loss : 0.5609478950500488 ; Accuracy : 71.30357142857143 ; Test Loss : 0.5657544136047363 ; Test accuracy : 71.0\nEpochs : 644 ; Loss : 0.5609230995178223 ; Accuracy : 71.28571428571429 ; Test Loss : 0.5657490491867065 ; Test accuracy : 71.0\nEpochs : 645 ; Loss : 0.5608984231948853 ; Accuracy : 71.28571428571429 ; Test Loss : 0.5657438635826111 ; Test accuracy : 71.0\nEpochs : 646 ; Loss : 0.5608738660812378 ; Accuracy : 71.28571428571429 ; Test Loss : 0.5657386183738708 ; Test accuracy : 71.0\nEpochs : 647 ; Loss : 0.5608493685722351 ; Accuracy : 71.28571428571429 ; Test Loss : 0.5657334327697754 ; Test accuracy : 71.0\nEpochs : 648 ; Loss : 0.560824990272522 ; Accuracy : 71.28571428571429 ; Test Loss : 0.5657283067703247 ; Test accuracy : 71.0\nEpochs : 649 ; Loss : 0.5608006715774536 ; Accuracy : 71.26785714285714 ; Test Loss : 0.5657232999801636 ; Test accuracy : 71.0\nEpochs : 650 ; Loss : 0.56077641248703 ; Accuracy : 71.26785714285714 ; Test Loss : 0.5657182931900024 ; Test accuracy : 71.0\nEpochs : 651 ; Loss : 0.5607522130012512 ; Accuracy : 71.26785714285714 ; Test Loss : 0.5657133460044861 ; Test accuracy : 71.0\nEpochs : 652 ; Loss : 0.560728132724762 ; Accuracy : 71.28571428571429 ; Test Loss : 0.5657084584236145 ; Test accuracy : 71.0\nEpochs : 653 ; Loss : 0.560704231262207 ; Accuracy : 71.28571428571429 ; Test Loss : 0.5657036304473877 ; Test accuracy : 71.0\nEpochs : 654 ; Loss : 0.5606803297996521 ; Accuracy : 71.30357142857143 ; Test Loss : 0.5656988620758057 ; Test accuracy : 71.0\nEpochs : 655 ; Loss : 0.5606564879417419 ; Accuracy : 71.30357142857143 ; Test Loss : 0.5656941533088684 ; Test accuracy : 71.0\nEpochs : 656 ; Loss : 0.5606327652931213 ; Accuracy : 71.28571428571429 ; Test Loss : 0.5656894445419312 ; Test accuracy : 71.0\nEpochs : 657 ; Loss : 0.5606091022491455 ; Accuracy : 71.28571428571429 ; Test Loss : 0.5656847953796387 ; Test accuracy : 71.0\nEpochs : 658 ; Loss : 0.5605855584144592 ; Accuracy : 71.33928571428571 ; Test Loss : 0.5656802654266357 ; Test accuracy : 71.0\nEpochs : 659 ; Loss : 0.560562014579773 ; Accuracy : 71.33928571428571 ; Test Loss : 0.5656757354736328 ; Test accuracy : 71.0\nEpochs : 660 ; Loss : 0.560538649559021 ; Accuracy : 71.33928571428571 ; Test Loss : 0.5656712651252747 ; Test accuracy : 71.0\nEpochs : 661 ; Loss : 0.5605153441429138 ; Accuracy : 71.35714285714286 ; Test Loss : 0.5656668543815613 ; Test accuracy : 71.0\nEpochs : 662 ; Loss : 0.5604920983314514 ; Accuracy : 71.35714285714286 ; Test Loss : 0.5656625032424927 ; Test accuracy : 71.0\nEpochs : 663 ; Loss : 0.5604689121246338 ; Accuracy : 71.39285714285714 ; Test Loss : 0.5656581521034241 ; Test accuracy : 71.0\nEpochs : 664 ; Loss : 0.5604459047317505 ; Accuracy : 71.41071428571429 ; Test Loss : 0.565653920173645 ; Test accuracy : 71.0\nEpochs : 665 ; Loss : 0.5604228973388672 ; Accuracy : 71.41071428571429 ; Test Loss : 0.565649688243866 ; Test accuracy : 71.0\nEpochs : 666 ; Loss : 0.5603999495506287 ; Accuracy : 71.42857142857143 ; Test Loss : 0.5656454563140869 ; Test accuracy : 71.07142857142857\nEpochs : 667 ; Loss : 0.5603771209716797 ; Accuracy : 71.42857142857143 ; Test Loss : 0.5656414031982422 ; Test accuracy : 71.0\nEpochs : 668 ; Loss : 0.5603543519973755 ; Accuracy : 71.46428571428571 ; Test Loss : 0.5656372904777527 ; Test accuracy : 71.0\nEpochs : 669 ; Loss : 0.5603317022323608 ; Accuracy : 71.48214285714286 ; Test Loss : 0.5656332969665527 ; Test accuracy : 71.0\nEpochs : 670 ; Loss : 0.560309112071991 ; Accuracy : 71.48214285714286 ; Test Loss : 0.5656293034553528 ; Test accuracy : 71.0\nEpochs : 671 ; Loss : 0.5602865815162659 ; Accuracy : 71.48214285714286 ; Test Loss : 0.5656254291534424 ; Test accuracy : 71.0\nEpochs : 672 ; Loss : 0.5602641105651855 ; Accuracy : 71.48214285714286 ; Test Loss : 0.5656214952468872 ; Test accuracy : 71.0\nEpochs : 673 ; Loss : 0.5602417588233948 ; Accuracy : 71.48214285714286 ; Test Loss : 0.5656176805496216 ; Test accuracy : 71.0\nEpochs : 674 ; Loss : 0.5602194666862488 ; Accuracy : 71.51785714285714 ; Test Loss : 0.565613865852356 ; Test accuracy : 71.0\nEpochs : 675 ; Loss : 0.5601972341537476 ; Accuracy : 71.5 ; Test Loss : 0.5656101703643799 ; Test accuracy : 71.0\nEpochs : 676 ; Loss : 0.5601750612258911 ; Accuracy : 71.5 ; Test Loss : 0.565606415271759 ; Test accuracy : 71.0\nEpochs : 677 ; Loss : 0.560153067111969 ; Accuracy : 71.51785714285714 ; Test Loss : 0.5656027793884277 ; Test accuracy : 71.0\nEpochs : 678 ; Loss : 0.5601310729980469 ; Accuracy : 71.51785714285714 ; Test Loss : 0.5655992031097412 ; Test accuracy : 71.0\nEpochs : 679 ; Loss : 0.5601091384887695 ; Accuracy : 71.53571428571429 ; Test Loss : 0.5655956268310547 ; Test accuracy : 71.07142857142857\nEpochs : 680 ; Loss : 0.560087263584137 ; Accuracy : 71.53571428571429 ; Test Loss : 0.5655921101570129 ; Test accuracy : 71.07142857142857\nEpochs : 681 ; Loss : 0.5600655674934387 ; Accuracy : 71.53571428571429 ; Test Loss : 0.565588653087616 ; Test accuracy : 71.07142857142857\nEpochs : 682 ; Loss : 0.5600438714027405 ; Accuracy : 71.53571428571429 ; Test Loss : 0.5655852556228638 ; Test accuracy : 71.07142857142857\nEpochs : 683 ; Loss : 0.560022234916687 ; Accuracy : 71.53571428571429 ; Test Loss : 0.5655818581581116 ; Test accuracy : 71.07142857142857\nEpochs : 684 ; Loss : 0.5600007176399231 ; Accuracy : 71.53571428571429 ; Test Loss : 0.5655785202980042 ; Test accuracy : 71.07142857142857\nEpochs : 685 ; Loss : 0.559979259967804 ; Accuracy : 71.53571428571429 ; Test Loss : 0.5655751824378967 ; Test accuracy : 71.07142857142857\nEpochs : 686 ; Loss : 0.5599578619003296 ; Accuracy : 71.53571428571429 ; Test Loss : 0.5655719637870789 ; Test accuracy : 71.07142857142857\nEpochs : 687 ; Loss : 0.5599365234375 ; Accuracy : 71.53571428571429 ; Test Loss : 0.565568745136261 ; Test accuracy : 71.07142857142857\nEpochs : 688 ; Loss : 0.55991530418396 ; Accuracy : 71.53571428571429 ; Test Loss : 0.5655655860900879 ; Test accuracy : 71.07142857142857\nEpochs : 689 ; Loss : 0.5598940849304199 ; Accuracy : 71.55357142857143 ; Test Loss : 0.5655624866485596 ; Test accuracy : 71.07142857142857\nEpochs : 690 ; Loss : 0.5598729848861694 ; Accuracy : 71.57142857142857 ; Test Loss : 0.565559446811676 ; Test accuracy : 71.07142857142857\nEpochs : 691 ; Loss : 0.5598520040512085 ; Accuracy : 71.55357142857143 ; Test Loss : 0.5655563473701477 ; Test accuracy : 71.07142857142857\nEpochs : 692 ; Loss : 0.5598310232162476 ; Accuracy : 71.55357142857143 ; Test Loss : 0.5655533075332642 ; Test accuracy : 71.07142857142857\nEpochs : 693 ; Loss : 0.5598101019859314 ; Accuracy : 71.55357142857143 ; Test Loss : 0.5655503869056702 ; Test accuracy : 71.07142857142857\nEpochs : 694 ; Loss : 0.5597892999649048 ; Accuracy : 71.57142857142857 ; Test Loss : 0.5655474662780762 ; Test accuracy : 71.07142857142857\nEpochs : 695 ; Loss : 0.559768557548523 ; Accuracy : 71.57142857142857 ; Test Loss : 0.565544605255127 ; Test accuracy : 71.07142857142857\nEpochs : 696 ; Loss : 0.5597479343414307 ; Accuracy : 71.55357142857143 ; Test Loss : 0.5655417442321777 ; Test accuracy : 71.07142857142857\nEpochs : 697 ; Loss : 0.5597272515296936 ; Accuracy : 71.55357142857143 ; Test Loss : 0.5655389428138733 ; Test accuracy : 71.07142857142857\nEpochs : 698 ; Loss : 0.5597066879272461 ; Accuracy : 71.55357142857143 ; Test Loss : 0.5655362606048584 ; Test accuracy : 71.07142857142857\nEpochs : 699 ; Loss : 0.5596862435340881 ; Accuracy : 71.57142857142857 ; Test Loss : 0.5655335187911987 ; Test accuracy : 71.07142857142857\nEpochs : 700 ; Loss : 0.559665858745575 ; Accuracy : 71.57142857142857 ; Test Loss : 0.5655308365821838 ; Test accuracy : 71.07142857142857\nEpochs : 701 ; Loss : 0.5596455335617065 ; Accuracy : 71.57142857142857 ; Test Loss : 0.5655282139778137 ; Test accuracy : 71.07142857142857\nEpochs : 702 ; Loss : 0.5596252083778381 ; Accuracy : 71.57142857142857 ; Test Loss : 0.5655256509780884 ; Test accuracy : 71.07142857142857\nEpochs : 703 ; Loss : 0.559605062007904 ; Accuracy : 71.58928571428571 ; Test Loss : 0.565523087978363 ; Test accuracy : 71.07142857142857\nEpochs : 704 ; Loss : 0.5595849752426147 ; Accuracy : 71.60714285714286 ; Test Loss : 0.5655205249786377 ; Test accuracy : 71.07142857142857\nEpochs : 705 ; Loss : 0.5595648884773254 ; Accuracy : 71.60714285714286 ; Test Loss : 0.5655180811882019 ; Test accuracy : 71.07142857142857\nEpochs : 706 ; Loss : 0.5595448613166809 ; Accuracy : 71.60714285714286 ; Test Loss : 0.5655156373977661 ; Test accuracy : 71.07142857142857\nEpochs : 707 ; Loss : 0.5595249533653259 ; Accuracy : 71.60714285714286 ; Test Loss : 0.5655131936073303 ; Test accuracy : 71.0\nEpochs : 708 ; Loss : 0.5595051050186157 ; Accuracy : 71.64285714285714 ; Test Loss : 0.5655108690261841 ; Test accuracy : 71.0\nEpochs : 709 ; Loss : 0.5594853162765503 ; Accuracy : 71.66071428571429 ; Test Loss : 0.5655085444450378 ; Test accuracy : 71.0\nEpochs : 710 ; Loss : 0.5594655275344849 ; Accuracy : 71.67857142857143 ; Test Loss : 0.5655062198638916 ; Test accuracy : 71.0\nEpochs : 711 ; Loss : 0.559445858001709 ; Accuracy : 71.67857142857143 ; Test Loss : 0.5655039548873901 ; Test accuracy : 71.0\nEpochs : 712 ; Loss : 0.5594263076782227 ; Accuracy : 71.67857142857143 ; Test Loss : 0.5655017495155334 ; Test accuracy : 71.07142857142857\nEpochs : 713 ; Loss : 0.5594067573547363 ; Accuracy : 71.69642857142857 ; Test Loss : 0.5654995441436768 ; Test accuracy : 71.07142857142857\nEpochs : 714 ; Loss : 0.5593872666358948 ; Accuracy : 71.71428571428571 ; Test Loss : 0.5654974579811096 ; Test accuracy : 71.07142857142857\nEpochs : 715 ; Loss : 0.5593678951263428 ; Accuracy : 71.73214285714286 ; Test Loss : 0.5654953122138977 ; Test accuracy : 71.07142857142857\nEpochs : 716 ; Loss : 0.5593485832214355 ; Accuracy : 71.76785714285714 ; Test Loss : 0.5654932260513306 ; Test accuracy : 71.07142857142857\nEpochs : 717 ; Loss : 0.5593293309211731 ; Accuracy : 71.76785714285714 ; Test Loss : 0.565491259098053 ; Test accuracy : 71.07142857142857\nEpochs : 718 ; Loss : 0.5593100190162659 ; Accuracy : 71.76785714285714 ; Test Loss : 0.5654892325401306 ; Test accuracy : 71.07142857142857\nEpochs : 719 ; Loss : 0.559290885925293 ; Accuracy : 71.76785714285714 ; Test Loss : 0.5654872059822083 ; Test accuracy : 71.07142857142857\nEpochs : 720 ; Loss : 0.5592718720436096 ; Accuracy : 71.78571428571429 ; Test Loss : 0.5654852986335754 ; Test accuracy : 71.07142857142857\nEpochs : 721 ; Loss : 0.5592527985572815 ; Accuracy : 71.78571428571429 ; Test Loss : 0.5654834508895874 ; Test accuracy : 71.07142857142857\nEpochs : 722 ; Loss : 0.5592338442802429 ; Accuracy : 71.76785714285714 ; Test Loss : 0.5654815435409546 ; Test accuracy : 71.07142857142857\nEpochs : 723 ; Loss : 0.5592149496078491 ; Accuracy : 71.76785714285714 ; Test Loss : 0.5654797554016113 ; Test accuracy : 71.0\nEpochs : 724 ; Loss : 0.5591961145401001 ; Accuracy : 71.78571428571429 ; Test Loss : 0.5654779076576233 ; Test accuracy : 71.0\nEpochs : 725 ; Loss : 0.5591773390769958 ; Accuracy : 71.78571428571429 ; Test Loss : 0.5654761791229248 ; Test accuracy : 71.0\nEpochs : 726 ; Loss : 0.5591586232185364 ; Accuracy : 71.80357142857143 ; Test Loss : 0.5654744505882263 ; Test accuracy : 71.0\nEpochs : 727 ; Loss : 0.5591400265693665 ; Accuracy : 71.80357142857143 ; Test Loss : 0.5654727816581726 ; Test accuracy : 71.0\nEpochs : 728 ; Loss : 0.5591214299201965 ; Accuracy : 71.80357142857143 ; Test Loss : 0.5654710531234741 ; Test accuracy : 70.92857142857143\nEpochs : 729 ; Loss : 0.5591028928756714 ; Accuracy : 71.80357142857143 ; Test Loss : 0.5654694437980652 ; Test accuracy : 70.92857142857143\nEpochs : 730 ; Loss : 0.559084415435791 ; Accuracy : 71.82142857142857 ; Test Loss : 0.565467894077301 ; Test accuracy : 70.92857142857143\nEpochs : 731 ; Loss : 0.5590659976005554 ; Accuracy : 71.80357142857143 ; Test Loss : 0.5654662847518921 ; Test accuracy : 70.92857142857143\nEpochs : 732 ; Loss : 0.5590476393699646 ; Accuracy : 71.80357142857143 ; Test Loss : 0.5654647350311279 ; Test accuracy : 70.92857142857143\nEpochs : 733 ; Loss : 0.5590293407440186 ; Accuracy : 71.78571428571429 ; Test Loss : 0.5654632449150085 ; Test accuracy : 70.85714285714286\nEpochs : 734 ; Loss : 0.5590111613273621 ; Accuracy : 71.83928571428571 ; Test Loss : 0.5654617547988892 ; Test accuracy : 70.85714285714286\nEpochs : 735 ; Loss : 0.5589929819107056 ; Accuracy : 71.83928571428571 ; Test Loss : 0.5654603838920593 ; Test accuracy : 70.85714285714286\nEpochs : 736 ; Loss : 0.5589748620986938 ; Accuracy : 71.83928571428571 ; Test Loss : 0.5654589533805847 ; Test accuracy : 70.85714285714286\nEpochs : 737 ; Loss : 0.5589568018913269 ; Accuracy : 71.83928571428571 ; Test Loss : 0.5654575824737549 ; Test accuracy : 70.92857142857143\nEpochs : 738 ; Loss : 0.5589388608932495 ; Accuracy : 71.85714285714286 ; Test Loss : 0.565456211566925 ; Test accuracy : 70.92857142857143\nEpochs : 739 ; Loss : 0.5589209198951721 ; Accuracy : 71.85714285714286 ; Test Loss : 0.56545490026474 ; Test accuracy : 70.92857142857143\nEpochs : 740 ; Loss : 0.5589030385017395 ; Accuracy : 71.85714285714286 ; Test Loss : 0.5654536485671997 ; Test accuracy : 70.85714285714286\nEpochs : 741 ; Loss : 0.5588851571083069 ; Accuracy : 71.85714285714286 ; Test Loss : 0.5654523968696594 ; Test accuracy : 70.85714285714286\nEpochs : 742 ; Loss : 0.5588674545288086 ; Accuracy : 71.875 ; Test Loss : 0.5654511451721191 ; Test accuracy : 70.78571428571429\nEpochs : 743 ; Loss : 0.5588497519493103 ; Accuracy : 71.89285714285714 ; Test Loss : 0.5654500126838684 ; Test accuracy : 70.78571428571429\nEpochs : 744 ; Loss : 0.5588321089744568 ; Accuracy : 71.89285714285714 ; Test Loss : 0.5654488801956177 ; Test accuracy : 70.78571428571429\nEpochs : 745 ; Loss : 0.558814525604248 ; Accuracy : 71.89285714285714 ; Test Loss : 0.5654477477073669 ; Test accuracy : 70.78571428571429\nEpochs : 746 ; Loss : 0.5587970018386841 ; Accuracy : 71.91071428571429 ; Test Loss : 0.5654466152191162 ; Test accuracy : 70.78571428571429\nEpochs : 747 ; Loss : 0.5587795376777649 ; Accuracy : 71.92857142857143 ; Test Loss : 0.5654455423355103 ; Test accuracy : 70.78571428571429\nEpochs : 748 ; Loss : 0.5587621331214905 ; Accuracy : 71.91071428571429 ; Test Loss : 0.5654445290565491 ; Test accuracy : 70.78571428571429\nEpochs : 749 ; Loss : 0.5587447881698608 ; Accuracy : 71.91071428571429 ; Test Loss : 0.5654434561729431 ; Test accuracy : 70.78571428571429\nEpochs : 750 ; Loss : 0.5587274432182312 ; Accuracy : 71.89285714285714 ; Test Loss : 0.5654424428939819 ; Test accuracy : 70.78571428571429\nEpochs : 751 ; Loss : 0.5587102174758911 ; Accuracy : 71.89285714285714 ; Test Loss : 0.5654415488243103 ; Test accuracy : 70.78571428571429\nEpochs : 752 ; Loss : 0.558692991733551 ; Accuracy : 71.89285714285714 ; Test Loss : 0.5654405951499939 ; Test accuracy : 70.78571428571429\nEpochs : 753 ; Loss : 0.5586758852005005 ; Accuracy : 71.91071428571429 ; Test Loss : 0.5654397010803223 ; Test accuracy : 70.78571428571429\nEpochs : 754 ; Loss : 0.55865877866745 ; Accuracy : 71.91071428571429 ; Test Loss : 0.5654388070106506 ; Test accuracy : 70.78571428571429\nEpochs : 755 ; Loss : 0.558641791343689 ; Accuracy : 71.91071428571429 ; Test Loss : 0.5654379725456238 ; Test accuracy : 70.78571428571429\nEpochs : 756 ; Loss : 0.558624804019928 ; Accuracy : 71.91071428571429 ; Test Loss : 0.5654371976852417 ; Test accuracy : 70.78571428571429\nEpochs : 757 ; Loss : 0.5586078763008118 ; Accuracy : 71.91071428571429 ; Test Loss : 0.5654363632202148 ; Test accuracy : 70.78571428571429\nEpochs : 758 ; Loss : 0.5585910677909851 ; Accuracy : 71.91071428571429 ; Test Loss : 0.5654355883598328 ; Test accuracy : 70.78571428571429\nEpochs : 759 ; Loss : 0.5585741996765137 ; Accuracy : 71.91071428571429 ; Test Loss : 0.5654348134994507 ; Test accuracy : 70.78571428571429\nEpochs : 760 ; Loss : 0.5585574507713318 ; Accuracy : 71.91071428571429 ; Test Loss : 0.5654341578483582 ; Test accuracy : 70.78571428571429\nEpochs : 761 ; Loss : 0.5585407018661499 ; Accuracy : 71.91071428571429 ; Test Loss : 0.5654335021972656 ; Test accuracy : 70.78571428571429\nEpochs : 762 ; Loss : 0.5585240721702576 ; Accuracy : 71.91071428571429 ; Test Loss : 0.5654328465461731 ; Test accuracy : 70.78571428571429\nEpochs : 763 ; Loss : 0.55850750207901 ; Accuracy : 71.91071428571429 ; Test Loss : 0.5654321908950806 ; Test accuracy : 70.78571428571429\nEpochs : 764 ; Loss : 0.5584909319877625 ; Accuracy : 71.91071428571429 ; Test Loss : 0.5654315948486328 ; Test accuracy : 70.78571428571429\nEpochs : 765 ; Loss : 0.5584744811058044 ; Accuracy : 71.91071428571429 ; Test Loss : 0.5654310584068298 ; Test accuracy : 70.78571428571429\nEpochs : 766 ; Loss : 0.5584580898284912 ; Accuracy : 71.91071428571429 ; Test Loss : 0.5654304623603821 ; Test accuracy : 70.78571428571429\nEpochs : 767 ; Loss : 0.5584416389465332 ; Accuracy : 71.91071428571429 ; Test Loss : 0.5654299259185791 ; Test accuracy : 70.78571428571429\nEpochs : 768 ; Loss : 0.5584253072738647 ; Accuracy : 71.91071428571429 ; Test Loss : 0.5654294490814209 ; Test accuracy : 70.78571428571429\nEpochs : 769 ; Loss : 0.5584090352058411 ; Accuracy : 71.89285714285714 ; Test Loss : 0.5654289722442627 ; Test accuracy : 70.78571428571429\nEpochs : 770 ; Loss : 0.5583928227424622 ; Accuracy : 71.89285714285714 ; Test Loss : 0.5654285550117493 ; Test accuracy : 70.78571428571429\nEpochs : 771 ; Loss : 0.5583766102790833 ; Accuracy : 71.85714285714286 ; Test Loss : 0.5654281377792358 ; Test accuracy : 70.78571428571429\nEpochs : 772 ; Loss : 0.5583605170249939 ; Accuracy : 71.85714285714286 ; Test Loss : 0.5654277205467224 ; Test accuracy : 70.78571428571429\nEpochs : 773 ; Loss : 0.5583444237709045 ; Accuracy : 71.85714285714286 ; Test Loss : 0.565427303314209 ; Test accuracy : 70.78571428571429\nEpochs : 774 ; Loss : 0.55832839012146 ; Accuracy : 71.875 ; Test Loss : 0.5654270052909851 ; Test accuracy : 70.78571428571429\nEpochs : 775 ; Loss : 0.5583124160766602 ; Accuracy : 71.83928571428571 ; Test Loss : 0.5654266476631165 ; Test accuracy : 70.78571428571429\nEpochs : 776 ; Loss : 0.5582965016365051 ; Accuracy : 71.85714285714286 ; Test Loss : 0.5654263496398926 ; Test accuracy : 70.78571428571429\nEpochs : 777 ; Loss : 0.5582806468009949 ; Accuracy : 71.85714285714286 ; Test Loss : 0.5654261112213135 ; Test accuracy : 70.78571428571429\nEpochs : 778 ; Loss : 0.5582647919654846 ; Accuracy : 71.875 ; Test Loss : 0.5654258728027344 ; Test accuracy : 70.78571428571429\nEpochs : 779 ; Loss : 0.5582489967346191 ; Accuracy : 71.875 ; Test Loss : 0.5654255747795105 ; Test accuracy : 70.78571428571429\nEpochs : 780 ; Loss : 0.5582333207130432 ; Accuracy : 71.89285714285714 ; Test Loss : 0.5654253959655762 ; Test accuracy : 70.78571428571429\nEpochs : 781 ; Loss : 0.5582176446914673 ; Accuracy : 71.89285714285714 ; Test Loss : 0.5654252171516418 ; Test accuracy : 70.78571428571429\nEpochs : 782 ; Loss : 0.5582020282745361 ; Accuracy : 71.89285714285714 ; Test Loss : 0.5654250383377075 ; Test accuracy : 70.78571428571429\nEpochs : 783 ; Loss : 0.5581864714622498 ; Accuracy : 71.89285714285714 ; Test Loss : 0.565424919128418 ; Test accuracy : 70.78571428571429\nEpochs : 784 ; Loss : 0.5581709742546082 ; Accuracy : 71.91071428571429 ; Test Loss : 0.5654248595237732 ; Test accuracy : 70.78571428571429\nEpochs : 785 ; Loss : 0.5581554174423218 ; Accuracy : 71.92857142857143 ; Test Loss : 0.5654247403144836 ; Test accuracy : 70.78571428571429\nEpochs : 786 ; Loss : 0.558139979839325 ; Accuracy : 71.92857142857143 ; Test Loss : 0.5654246807098389 ; Test accuracy : 70.78571428571429\nEpochs : 787 ; Loss : 0.5581246614456177 ; Accuracy : 71.92857142857143 ; Test Loss : 0.5654246211051941 ; Test accuracy : 70.78571428571429\nEpochs : 788 ; Loss : 0.5581092834472656 ; Accuracy : 71.94642857142857 ; Test Loss : 0.5654246211051941 ; Test accuracy : 70.78571428571429\nEpochs : 789 ; Loss : 0.5580940246582031 ; Accuracy : 71.94642857142857 ; Test Loss : 0.5654246211051941 ; Test accuracy : 70.78571428571429\nEpochs : 790 ; Loss : 0.5580787658691406 ; Accuracy : 71.92857142857143 ; Test Loss : 0.5654246211051941 ; Test accuracy : 70.78571428571429\nEpochs : 791 ; Loss : 0.5580635666847229 ; Accuracy : 71.92857142857143 ; Test Loss : 0.5654247403144836 ; Test accuracy : 70.78571428571429\nEpochs : 792 ; Loss : 0.55804842710495 ; Accuracy : 71.92857142857143 ; Test Loss : 0.5654247999191284 ; Test accuracy : 70.78571428571429\nEpochs : 793 ; Loss : 0.5580333471298218 ; Accuracy : 71.92857142857143 ; Test Loss : 0.5654248595237732 ; Test accuracy : 70.78571428571429\nEpochs : 794 ; Loss : 0.5580183267593384 ; Accuracy : 71.92857142857143 ; Test Loss : 0.5654249787330627 ; Test accuracy : 70.78571428571429\nEpochs : 795 ; Loss : 0.558003306388855 ; Accuracy : 71.92857142857143 ; Test Loss : 0.5654250979423523 ; Test accuracy : 70.78571428571429\nEpochs : 796 ; Loss : 0.5579883456230164 ; Accuracy : 71.92857142857143 ; Test Loss : 0.5654252171516418 ; Test accuracy : 70.78571428571429\nEpochs : 797 ; Loss : 0.5579734444618225 ; Accuracy : 71.94642857142857 ; Test Loss : 0.5654253959655762 ; Test accuracy : 70.71428571428571\nEpochs : 798 ; Loss : 0.5579585433006287 ; Accuracy : 71.94642857142857 ; Test Loss : 0.5654256343841553 ; Test accuracy : 70.71428571428571\nEpochs : 799 ; Loss : 0.5579437613487244 ; Accuracy : 71.96428571428571 ; Test Loss : 0.5654258728027344 ; Test accuracy : 70.71428571428571\nEpochs : 800 ; Loss : 0.5579289793968201 ; Accuracy : 71.96428571428571 ; Test Loss : 0.5654261112213135 ; Test accuracy : 70.71428571428571\nEpochs : 801 ; Loss : 0.5579142570495605 ; Accuracy : 71.96428571428571 ; Test Loss : 0.5654263496398926 ; Test accuracy : 70.71428571428571\nEpochs : 802 ; Loss : 0.5578995943069458 ; Accuracy : 71.96428571428571 ; Test Loss : 0.5654266476631165 ; Test accuracy : 70.64285714285714\nEpochs : 803 ; Loss : 0.557884931564331 ; Accuracy : 71.96428571428571 ; Test Loss : 0.5654268860816956 ; Test accuracy : 70.64285714285714\nEpochs : 804 ; Loss : 0.5578703880310059 ; Accuracy : 71.98214285714286 ; Test Loss : 0.5654272437095642 ; Test accuracy : 70.64285714285714\nEpochs : 805 ; Loss : 0.5578558444976807 ; Accuracy : 72.0 ; Test Loss : 0.5654275417327881 ; Test accuracy : 70.64285714285714\nEpochs : 806 ; Loss : 0.5578413605690002 ; Accuracy : 72.01785714285714 ; Test Loss : 0.5654279589653015 ; Test accuracy : 70.64285714285714\nEpochs : 807 ; Loss : 0.5578268766403198 ; Accuracy : 72.01785714285714 ; Test Loss : 0.5654282569885254 ; Test accuracy : 70.64285714285714\nEpochs : 808 ; Loss : 0.557812511920929 ; Accuracy : 72.03571428571429 ; Test Loss : 0.5654286742210388 ; Test accuracy : 70.57142857142857\nEpochs : 809 ; Loss : 0.5577980875968933 ; Accuracy : 72.03571428571429 ; Test Loss : 0.565429151058197 ; Test accuracy : 70.57142857142857\nEpochs : 810 ; Loss : 0.5577837824821472 ; Accuracy : 72.03571428571429 ; Test Loss : 0.5654295682907104 ; Test accuracy : 70.57142857142857\nEpochs : 811 ; Loss : 0.5577695369720459 ; Accuracy : 72.03571428571429 ; Test Loss : 0.5654300451278687 ; Test accuracy : 70.57142857142857\nEpochs : 812 ; Loss : 0.5577552914619446 ; Accuracy : 72.01785714285714 ; Test Loss : 0.5654305219650269 ; Test accuracy : 70.5\nEpochs : 813 ; Loss : 0.557741105556488 ; Accuracy : 72.0 ; Test Loss : 0.5654309988021851 ; Test accuracy : 70.5\nEpochs : 814 ; Loss : 0.5577269792556763 ; Accuracy : 72.01785714285714 ; Test Loss : 0.565431535243988 ; Test accuracy : 70.5\nEpochs : 815 ; Loss : 0.5577128529548645 ; Accuracy : 72.03571428571429 ; Test Loss : 0.5654320120811462 ; Test accuracy : 70.5\nEpochs : 816 ; Loss : 0.5576988458633423 ; Accuracy : 72.03571428571429 ; Test Loss : 0.565432608127594 ; Test accuracy : 70.5\nEpochs : 817 ; Loss : 0.5576848387718201 ; Accuracy : 72.03571428571429 ; Test Loss : 0.565433144569397 ; Test accuracy : 70.5\nEpochs : 818 ; Loss : 0.5576708316802979 ; Accuracy : 72.05357142857143 ; Test Loss : 0.5654338002204895 ; Test accuracy : 70.5\nEpochs : 819 ; Loss : 0.5576569437980652 ; Accuracy : 72.05357142857143 ; Test Loss : 0.5654343366622925 ; Test accuracy : 70.5\nEpochs : 820 ; Loss : 0.5576430559158325 ; Accuracy : 72.05357142857143 ; Test Loss : 0.565434992313385 ; Test accuracy : 70.5\nEpochs : 821 ; Loss : 0.5576292276382446 ; Accuracy : 72.05357142857143 ; Test Loss : 0.5654355883598328 ; Test accuracy : 70.5\nEpochs : 822 ; Loss : 0.557615339756012 ; Accuracy : 72.05357142857143 ; Test Loss : 0.5654363036155701 ; Test accuracy : 70.5\nEpochs : 823 ; Loss : 0.5576016902923584 ; Accuracy : 72.05357142857143 ; Test Loss : 0.5654368996620178 ; Test accuracy : 70.5\nEpochs : 824 ; Loss : 0.5575879812240601 ; Accuracy : 72.05357142857143 ; Test Loss : 0.5654376745223999 ; Test accuracy : 70.5\nEpochs : 825 ; Loss : 0.5575742721557617 ; Accuracy : 72.05357142857143 ; Test Loss : 0.5654383897781372 ; Test accuracy : 70.5\nEpochs : 826 ; Loss : 0.5575606226921082 ; Accuracy : 72.03571428571429 ; Test Loss : 0.5654391050338745 ; Test accuracy : 70.5\nEpochs : 827 ; Loss : 0.5575469732284546 ; Accuracy : 72.03571428571429 ; Test Loss : 0.5654398798942566 ; Test accuracy : 70.5\nEpochs : 828 ; Loss : 0.5575335025787354 ; Accuracy : 72.03571428571429 ; Test Loss : 0.5654405951499939 ; Test accuracy : 70.5\nEpochs : 829 ; Loss : 0.5575199723243713 ; Accuracy : 72.03571428571429 ; Test Loss : 0.5654414296150208 ; Test accuracy : 70.5\nEpochs : 830 ; Loss : 0.5575065612792969 ; Accuracy : 72.03571428571429 ; Test Loss : 0.5654422044754028 ; Test accuracy : 70.5\nEpochs : 831 ; Loss : 0.5574930906295776 ; Accuracy : 72.03571428571429 ; Test Loss : 0.5654430389404297 ; Test accuracy : 70.5\nEpochs : 832 ; Loss : 0.5574796795845032 ; Accuracy : 72.03571428571429 ; Test Loss : 0.5654438734054565 ; Test accuracy : 70.5\nEpochs : 833 ; Loss : 0.5574663281440735 ; Accuracy : 72.03571428571429 ; Test Loss : 0.5654447078704834 ; Test accuracy : 70.5\nEpochs : 834 ; Loss : 0.5574530959129333 ; Accuracy : 72.05357142857143 ; Test Loss : 0.565445601940155 ; Test accuracy : 70.5\nEpochs : 835 ; Loss : 0.5574398040771484 ; Accuracy : 72.05357142857143 ; Test Loss : 0.5654464960098267 ; Test accuracy : 70.5\nEpochs : 836 ; Loss : 0.5574265718460083 ; Accuracy : 72.07142857142857 ; Test Loss : 0.5654473900794983 ; Test accuracy : 70.5\nEpochs : 837 ; Loss : 0.5574133396148682 ; Accuracy : 72.07142857142857 ; Test Loss : 0.5654482841491699 ; Test accuracy : 70.5\nEpochs : 838 ; Loss : 0.5574002265930176 ; Accuracy : 72.07142857142857 ; Test Loss : 0.5654492378234863 ; Test accuracy : 70.5\nEpochs : 839 ; Loss : 0.5573871731758118 ; Accuracy : 72.05357142857143 ; Test Loss : 0.5654501914978027 ; Test accuracy : 70.5\nEpochs : 840 ; Loss : 0.5573740601539612 ; Accuracy : 72.05357142857143 ; Test Loss : 0.5654510855674744 ; Test accuracy : 70.5\nEpochs : 841 ; Loss : 0.5573610663414001 ; Accuracy : 72.03571428571429 ; Test Loss : 0.5654520988464355 ; Test accuracy : 70.5\nEpochs : 842 ; Loss : 0.5573480725288391 ; Accuracy : 72.03571428571429 ; Test Loss : 0.5654531121253967 ; Test accuracy : 70.5\nEpochs : 843 ; Loss : 0.5573351383209229 ; Accuracy : 72.03571428571429 ; Test Loss : 0.5654540657997131 ; Test accuracy : 70.5\nEpochs : 844 ; Loss : 0.5573222041130066 ; Accuracy : 72.03571428571429 ; Test Loss : 0.5654551386833191 ; Test accuracy : 70.5\nEpochs : 845 ; Loss : 0.5573093295097351 ; Accuracy : 72.03571428571429 ; Test Loss : 0.5654561519622803 ; Test accuracy : 70.5\nEpochs : 846 ; Loss : 0.5572965145111084 ; Accuracy : 72.03571428571429 ; Test Loss : 0.5654572248458862 ; Test accuracy : 70.5\nEpochs : 847 ; Loss : 0.5572837591171265 ; Accuracy : 72.03571428571429 ; Test Loss : 0.5654582977294922 ; Test accuracy : 70.35714285714286\nEpochs : 848 ; Loss : 0.5572710037231445 ; Accuracy : 72.03571428571429 ; Test Loss : 0.5654594302177429 ; Test accuracy : 70.35714285714286\nEpochs : 849 ; Loss : 0.5572583079338074 ; Accuracy : 72.03571428571429 ; Test Loss : 0.5654605627059937 ; Test accuracy : 70.35714285714286\nEpochs : 850 ; Loss : 0.5572456121444702 ; Accuracy : 72.03571428571429 ; Test Loss : 0.5654615759849548 ; Test accuracy : 70.35714285714286\nEpochs : 851 ; Loss : 0.5572330355644226 ; Accuracy : 72.03571428571429 ; Test Loss : 0.5654627084732056 ; Test accuracy : 70.35714285714286\nEpochs : 852 ; Loss : 0.5572203993797302 ; Accuracy : 72.03571428571429 ; Test Loss : 0.5654638409614563 ; Test accuracy : 70.42857142857143\nEpochs : 853 ; Loss : 0.5572078227996826 ; Accuracy : 72.03571428571429 ; Test Loss : 0.565464973449707 ; Test accuracy : 70.42857142857143\nEpochs : 854 ; Loss : 0.5571953058242798 ; Accuracy : 72.03571428571429 ; Test Loss : 0.5654662251472473 ; Test accuracy : 70.5\nEpochs : 855 ; Loss : 0.557182788848877 ; Accuracy : 72.03571428571429 ; Test Loss : 0.5654674172401428 ; Test accuracy : 70.5\nEpochs : 856 ; Loss : 0.5571703910827637 ; Accuracy : 72.01785714285714 ; Test Loss : 0.5654686093330383 ; Test accuracy : 70.5\nEpochs : 857 ; Loss : 0.5571579337120056 ; Accuracy : 72.03571428571429 ; Test Loss : 0.5654698014259338 ; Test accuracy : 70.57142857142857\nEpochs : 858 ; Loss : 0.5571455359458923 ; Accuracy : 72.01785714285714 ; Test Loss : 0.5654711127281189 ; Test accuracy : 70.57142857142857\nEpochs : 859 ; Loss : 0.5571332573890686 ; Accuracy : 72.01785714285714 ; Test Loss : 0.5654723048210144 ; Test accuracy : 70.5\nEpochs : 860 ; Loss : 0.5571209788322449 ; Accuracy : 72.0 ; Test Loss : 0.5654735565185547 ; Test accuracy : 70.5\nEpochs : 861 ; Loss : 0.5571087002754211 ; Accuracy : 72.0 ; Test Loss : 0.5654748678207397 ; Test accuracy : 70.57142857142857\nEpochs : 862 ; Loss : 0.5570964813232422 ; Accuracy : 72.01785714285714 ; Test Loss : 0.5654761791229248 ; Test accuracy : 70.57142857142857\nEpochs : 863 ; Loss : 0.557084321975708 ; Accuracy : 72.01785714285714 ; Test Loss : 0.5654774308204651 ; Test accuracy : 70.57142857142857\nEpochs : 864 ; Loss : 0.5570721626281738 ; Accuracy : 72.03571428571429 ; Test Loss : 0.5654787421226501 ; Test accuracy : 70.57142857142857\nEpochs : 865 ; Loss : 0.5570600032806396 ; Accuracy : 72.05357142857143 ; Test Loss : 0.5654800534248352 ; Test accuracy : 70.57142857142857\nEpochs : 866 ; Loss : 0.5570479035377502 ; Accuracy : 72.07142857142857 ; Test Loss : 0.5654813647270203 ; Test accuracy : 70.57142857142857\nEpochs : 867 ; Loss : 0.5570358633995056 ; Accuracy : 72.07142857142857 ; Test Loss : 0.5654827356338501 ; Test accuracy : 70.57142857142857\nEpochs : 868 ; Loss : 0.557023823261261 ; Accuracy : 72.07142857142857 ; Test Loss : 0.5654841065406799 ; Test accuracy : 70.57142857142857\nEpochs : 869 ; Loss : 0.5570119023323059 ; Accuracy : 72.07142857142857 ; Test Loss : 0.5654854774475098 ; Test accuracy : 70.57142857142857\nEpochs : 870 ; Loss : 0.5569999814033508 ; Accuracy : 72.05357142857143 ; Test Loss : 0.5654869079589844 ; Test accuracy : 70.57142857142857\nEpochs : 871 ; Loss : 0.5569880604743958 ; Accuracy : 72.05357142857143 ; Test Loss : 0.5654882788658142 ; Test accuracy : 70.57142857142857\nEpochs : 872 ; Loss : 0.5569761395454407 ; Accuracy : 72.05357142857143 ; Test Loss : 0.565489649772644 ; Test accuracy : 70.5\nEpochs : 873 ; Loss : 0.5569643378257751 ; Accuracy : 72.05357142857143 ; Test Loss : 0.5654911398887634 ; Test accuracy : 70.5\nEpochs : 874 ; Loss : 0.5569525361061096 ; Accuracy : 72.08928571428571 ; Test Loss : 0.565492570400238 ; Test accuracy : 70.5\nEpochs : 875 ; Loss : 0.5569408535957336 ; Accuracy : 72.08928571428571 ; Test Loss : 0.5654940009117126 ; Test accuracy : 70.5\nEpochs : 876 ; Loss : 0.5569290518760681 ; Accuracy : 72.10714285714286 ; Test Loss : 0.565495491027832 ; Test accuracy : 70.5\nEpochs : 877 ; Loss : 0.5569173693656921 ; Accuracy : 72.10714285714286 ; Test Loss : 0.5654969215393066 ; Test accuracy : 70.5\nEpochs : 878 ; Loss : 0.5569057464599609 ; Accuracy : 72.10714285714286 ; Test Loss : 0.5654984712600708 ; Test accuracy : 70.5\nEpochs : 879 ; Loss : 0.556894063949585 ; Accuracy : 72.10714285714286 ; Test Loss : 0.5654999613761902 ; Test accuracy : 70.5\nEpochs : 880 ; Loss : 0.5568825006484985 ; Accuracy : 72.10714285714286 ; Test Loss : 0.5655015110969543 ; Test accuracy : 70.5\nEpochs : 881 ; Loss : 0.5568709969520569 ; Accuracy : 72.10714285714286 ; Test Loss : 0.5655030012130737 ; Test accuracy : 70.5\nEpochs : 882 ; Loss : 0.5568594932556152 ; Accuracy : 72.10714285714286 ; Test Loss : 0.5655045509338379 ; Test accuracy : 70.5\nEpochs : 883 ; Loss : 0.5568479895591736 ; Accuracy : 72.10714285714286 ; Test Loss : 0.565506100654602 ; Test accuracy : 70.5\nEpochs : 884 ; Loss : 0.5568365454673767 ; Accuracy : 72.10714285714286 ; Test Loss : 0.5655076503753662 ; Test accuracy : 70.5\nEpochs : 885 ; Loss : 0.5568251013755798 ; Accuracy : 72.10714285714286 ; Test Loss : 0.5655092000961304 ; Test accuracy : 70.5\nEpochs : 886 ; Loss : 0.5568137168884277 ; Accuracy : 72.10714285714286 ; Test Loss : 0.5655108094215393 ; Test accuracy : 70.5\nEpochs : 887 ; Loss : 0.5568023324012756 ; Accuracy : 72.08928571428571 ; Test Loss : 0.5655124187469482 ; Test accuracy : 70.5\nEpochs : 888 ; Loss : 0.5567910075187683 ; Accuracy : 72.08928571428571 ; Test Loss : 0.5655139684677124 ; Test accuracy : 70.42857142857143\nEpochs : 889 ; Loss : 0.5567797422409058 ; Accuracy : 72.10714285714286 ; Test Loss : 0.5655156373977661 ; Test accuracy : 70.42857142857143\nEpochs : 890 ; Loss : 0.556768536567688 ; Accuracy : 72.125 ; Test Loss : 0.565517246723175 ; Test accuracy : 70.42857142857143\nEpochs : 891 ; Loss : 0.5567572712898254 ; Accuracy : 72.125 ; Test Loss : 0.565518856048584 ; Test accuracy : 70.42857142857143\nEpochs : 892 ; Loss : 0.5567460656166077 ; Accuracy : 72.14285714285714 ; Test Loss : 0.5655205249786377 ; Test accuracy : 70.42857142857143\nEpochs : 893 ; Loss : 0.5567349195480347 ; Accuracy : 72.14285714285714 ; Test Loss : 0.5655221939086914 ; Test accuracy : 70.42857142857143\nEpochs : 894 ; Loss : 0.5567237734794617 ; Accuracy : 72.14285714285714 ; Test Loss : 0.5655239224433899 ; Test accuracy : 70.42857142857143\nEpochs : 895 ; Loss : 0.5567127466201782 ; Accuracy : 72.14285714285714 ; Test Loss : 0.5655255913734436 ; Test accuracy : 70.42857142857143\nEpochs : 896 ; Loss : 0.55670166015625 ; Accuracy : 72.14285714285714 ; Test Loss : 0.5655273199081421 ; Test accuracy : 70.42857142857143\nEpochs : 897 ; Loss : 0.5566906929016113 ; Accuracy : 72.14285714285714 ; Test Loss : 0.565528929233551 ; Test accuracy : 70.42857142857143\nEpochs : 898 ; Loss : 0.5566796660423279 ; Accuracy : 72.125 ; Test Loss : 0.5655307173728943 ; Test accuracy : 70.42857142857143\nEpochs : 899 ; Loss : 0.5566686987876892 ; Accuracy : 72.10714285714286 ; Test Loss : 0.565532386302948 ; Test accuracy : 70.42857142857143\nEpochs : 900 ; Loss : 0.5566577911376953 ; Accuracy : 72.125 ; Test Loss : 0.5655341148376465 ; Test accuracy : 70.42857142857143\nEpochs : 901 ; Loss : 0.5566468834877014 ; Accuracy : 72.125 ; Test Loss : 0.5655359029769897 ; Test accuracy : 70.42857142857143\nEpochs : 902 ; Loss : 0.5566359758377075 ; Accuracy : 72.125 ; Test Loss : 0.565537691116333 ; Test accuracy : 70.42857142857143\nEpochs : 903 ; Loss : 0.5566251873970032 ; Accuracy : 72.14285714285714 ; Test Loss : 0.5655394196510315 ; Test accuracy : 70.42857142857143\nEpochs : 904 ; Loss : 0.5566143989562988 ; Accuracy : 72.14285714285714 ; Test Loss : 0.5655412077903748 ; Test accuracy : 70.42857142857143\nEpochs : 905 ; Loss : 0.5566036105155945 ; Accuracy : 72.16071428571429 ; Test Loss : 0.5655429363250732 ; Test accuracy : 70.42857142857143\nEpochs : 906 ; Loss : 0.5565929412841797 ; Accuracy : 72.17857142857143 ; Test Loss : 0.5655447840690613 ; Test accuracy : 70.42857142857143\nEpochs : 907 ; Loss : 0.5565822124481201 ; Accuracy : 72.17857142857143 ; Test Loss : 0.5655466318130493 ; Test accuracy : 70.42857142857143\nEpochs : 908 ; Loss : 0.5565715432167053 ; Accuracy : 72.17857142857143 ; Test Loss : 0.5655484199523926 ; Test accuracy : 70.42857142857143\nEpochs : 909 ; Loss : 0.5565608143806458 ; Accuracy : 72.19642857142857 ; Test Loss : 0.5655502080917358 ; Test accuracy : 70.42857142857143\nEpochs : 910 ; Loss : 0.5565502643585205 ; Accuracy : 72.19642857142857 ; Test Loss : 0.5655521154403687 ; Test accuracy : 70.42857142857143\nEpochs : 911 ; Loss : 0.5565396547317505 ; Accuracy : 72.17857142857143 ; Test Loss : 0.5655539035797119 ; Test accuracy : 70.42857142857143\nEpochs : 912 ; Loss : 0.5565291047096252 ; Accuracy : 72.17857142857143 ; Test Loss : 0.5655557513237 ; Test accuracy : 70.42857142857143\nEpochs : 913 ; Loss : 0.5565186142921448 ; Accuracy : 72.17857142857143 ; Test Loss : 0.565557599067688 ; Test accuracy : 70.42857142857143\nEpochs : 914 ; Loss : 0.5565080642700195 ; Accuracy : 72.16071428571429 ; Test Loss : 0.5655595064163208 ; Test accuracy : 70.42857142857143\nEpochs : 915 ; Loss : 0.5564976334571838 ; Accuracy : 72.16071428571429 ; Test Loss : 0.5655614137649536 ; Test accuracy : 70.42857142857143\nEpochs : 916 ; Loss : 0.5564872026443481 ; Accuracy : 72.125 ; Test Loss : 0.5655632615089417 ; Test accuracy : 70.42857142857143\nEpochs : 917 ; Loss : 0.5564767718315125 ; Accuracy : 72.125 ; Test Loss : 0.5655651688575745 ; Test accuracy : 70.42857142857143\nEpochs : 918 ; Loss : 0.5564665198326111 ; Accuracy : 72.125 ; Test Loss : 0.5655670762062073 ; Test accuracy : 70.42857142857143\nEpochs : 919 ; Loss : 0.5564560890197754 ; Accuracy : 72.125 ; Test Loss : 0.5655690431594849 ; Test accuracy : 70.42857142857143\nEpochs : 920 ; Loss : 0.556445837020874 ; Accuracy : 72.125 ; Test Loss : 0.5655708909034729 ; Test accuracy : 70.42857142857143\nEpochs : 921 ; Loss : 0.5564355254173279 ; Accuracy : 72.14285714285714 ; Test Loss : 0.5655729174613953 ; Test accuracy : 70.42857142857143\nEpochs : 922 ; Loss : 0.5564252734184265 ; Accuracy : 72.14285714285714 ; Test Loss : 0.5655748248100281 ; Test accuracy : 70.42857142857143\nEpochs : 923 ; Loss : 0.5564150214195251 ; Accuracy : 72.14285714285714 ; Test Loss : 0.5655767917633057 ; Test accuracy : 70.42857142857143\nEpochs : 924 ; Loss : 0.5564048290252686 ; Accuracy : 72.14285714285714 ; Test Loss : 0.5655787587165833 ; Test accuracy : 70.42857142857143\nEpochs : 925 ; Loss : 0.5563946962356567 ; Accuracy : 72.14285714285714 ; Test Loss : 0.5655807256698608 ; Test accuracy : 70.42857142857143\nEpochs : 926 ; Loss : 0.5563845634460449 ; Accuracy : 72.16071428571429 ; Test Loss : 0.5655826926231384 ; Test accuracy : 70.42857142857143\nEpochs : 927 ; Loss : 0.5563744902610779 ; Accuracy : 72.16071428571429 ; Test Loss : 0.565584659576416 ; Test accuracy : 70.42857142857143\nEpochs : 928 ; Loss : 0.5563644170761108 ; Accuracy : 72.16071428571429 ; Test Loss : 0.5655866861343384 ; Test accuracy : 70.42857142857143\nEpochs : 929 ; Loss : 0.5563543438911438 ; Accuracy : 72.17857142857143 ; Test Loss : 0.565588653087616 ; Test accuracy : 70.42857142857143\nEpochs : 930 ; Loss : 0.5563443303108215 ; Accuracy : 72.17857142857143 ; Test Loss : 0.5655906796455383 ; Test accuracy : 70.42857142857143\nEpochs : 931 ; Loss : 0.556334376335144 ; Accuracy : 72.21428571428571 ; Test Loss : 0.5655927062034607 ; Test accuracy : 70.42857142857143\nEpochs : 932 ; Loss : 0.5563243627548218 ; Accuracy : 72.23214285714286 ; Test Loss : 0.5655947327613831 ; Test accuracy : 70.42857142857143\nEpochs : 933 ; Loss : 0.5563144683837891 ; Accuracy : 72.23214285714286 ; Test Loss : 0.5655967593193054 ; Test accuracy : 70.42857142857143\nEpochs : 934 ; Loss : 0.5563045740127563 ; Accuracy : 72.23214285714286 ; Test Loss : 0.5655987858772278 ; Test accuracy : 70.42857142857143\nEpochs : 935 ; Loss : 0.5562947392463684 ; Accuracy : 72.25 ; Test Loss : 0.5656008124351501 ; Test accuracy : 70.42857142857143\nEpochs : 936 ; Loss : 0.5562848448753357 ; Accuracy : 72.26785714285714 ; Test Loss : 0.5656029582023621 ; Test accuracy : 70.42857142857143\nEpochs : 937 ; Loss : 0.5562750101089478 ; Accuracy : 72.26785714285714 ; Test Loss : 0.5656049847602844 ; Test accuracy : 70.42857142857143\nEpochs : 938 ; Loss : 0.5562652349472046 ; Accuracy : 72.26785714285714 ; Test Loss : 0.5656070113182068 ; Test accuracy : 70.42857142857143\nEpochs : 939 ; Loss : 0.5562554597854614 ; Accuracy : 72.25 ; Test Loss : 0.5656090974807739 ; Test accuracy : 70.42857142857143\nEpochs : 940 ; Loss : 0.556245744228363 ; Accuracy : 72.25 ; Test Loss : 0.5656112432479858 ; Test accuracy : 70.42857142857143\nEpochs : 941 ; Loss : 0.5562360286712646 ; Accuracy : 72.25 ; Test Loss : 0.565613329410553 ; Test accuracy : 70.42857142857143\nEpochs : 942 ; Loss : 0.556226372718811 ; Accuracy : 72.25 ; Test Loss : 0.5656154751777649 ; Test accuracy : 70.42857142857143\nEpochs : 943 ; Loss : 0.5562167167663574 ; Accuracy : 72.25 ; Test Loss : 0.5656175017356873 ; Test accuracy : 70.42857142857143\nEpochs : 944 ; Loss : 0.5562071204185486 ; Accuracy : 72.25 ; Test Loss : 0.5656196475028992 ; Test accuracy : 70.42857142857143\nEpochs : 945 ; Loss : 0.5561975240707397 ; Accuracy : 72.25 ; Test Loss : 0.5656217932701111 ; Test accuracy : 70.42857142857143\nEpochs : 946 ; Loss : 0.5561879277229309 ; Accuracy : 72.25 ; Test Loss : 0.565623939037323 ; Test accuracy : 70.42857142857143\nEpochs : 947 ; Loss : 0.5561783909797668 ; Accuracy : 72.25 ; Test Loss : 0.5656260251998901 ; Test accuracy : 70.42857142857143\nEpochs : 948 ; Loss : 0.5561689734458923 ; Accuracy : 72.25 ; Test Loss : 0.5656282305717468 ; Test accuracy : 70.42857142857143\nEpochs : 949 ; Loss : 0.5561594367027283 ; Accuracy : 72.25 ; Test Loss : 0.5656303763389587 ; Test accuracy : 70.42857142857143\nEpochs : 950 ; Loss : 0.556149959564209 ; Accuracy : 72.26785714285714 ; Test Loss : 0.5656325221061707 ; Test accuracy : 70.42857142857143\nEpochs : 951 ; Loss : 0.5561405420303345 ; Accuracy : 72.26785714285714 ; Test Loss : 0.5656346678733826 ; Test accuracy : 70.42857142857143\nEpochs : 952 ; Loss : 0.55613112449646 ; Accuracy : 72.26785714285714 ; Test Loss : 0.5656368732452393 ; Test accuracy : 70.42857142857143\nEpochs : 953 ; Loss : 0.5561217069625854 ; Accuracy : 72.26785714285714 ; Test Loss : 0.5656390190124512 ; Test accuracy : 70.42857142857143\nEpochs : 954 ; Loss : 0.5561124086380005 ; Accuracy : 72.26785714285714 ; Test Loss : 0.5656412243843079 ; Test accuracy : 70.42857142857143\nEpochs : 955 ; Loss : 0.5561030507087708 ; Accuracy : 72.26785714285714 ; Test Loss : 0.5656434297561646 ; Test accuracy : 70.42857142857143\nEpochs : 956 ; Loss : 0.5560938119888306 ; Accuracy : 72.26785714285714 ; Test Loss : 0.5656456351280212 ; Test accuracy : 70.42857142857143\nEpochs : 957 ; Loss : 0.5560845732688904 ; Accuracy : 72.26785714285714 ; Test Loss : 0.5656478404998779 ; Test accuracy : 70.42857142857143\nEpochs : 958 ; Loss : 0.5560752749443054 ; Accuracy : 72.26785714285714 ; Test Loss : 0.5656501054763794 ; Test accuracy : 70.42857142857143\nEpochs : 959 ; Loss : 0.55606609582901 ; Accuracy : 72.28571428571429 ; Test Loss : 0.5656523108482361 ; Test accuracy : 70.42857142857143\nEpochs : 960 ; Loss : 0.5560569167137146 ; Accuracy : 72.28571428571429 ; Test Loss : 0.5656545162200928 ; Test accuracy : 70.42857142857143\nEpochs : 961 ; Loss : 0.5560476779937744 ; Accuracy : 72.26785714285714 ; Test Loss : 0.5656567215919495 ; Test accuracy : 70.42857142857143\nEpochs : 962 ; Loss : 0.5560386180877686 ; Accuracy : 72.26785714285714 ; Test Loss : 0.5656589865684509 ; Test accuracy : 70.42857142857143\nEpochs : 963 ; Loss : 0.5560294985771179 ; Accuracy : 72.26785714285714 ; Test Loss : 0.5656612515449524 ; Test accuracy : 70.42857142857143\nEpochs : 964 ; Loss : 0.5560204386711121 ; Accuracy : 72.26785714285714 ; Test Loss : 0.5656635165214539 ; Test accuracy : 70.42857142857143\nEpochs : 965 ; Loss : 0.5560113191604614 ; Accuracy : 72.28571428571429 ; Test Loss : 0.5656657814979553 ; Test accuracy : 70.42857142857143\nEpochs : 966 ; Loss : 0.5560022592544556 ; Accuracy : 72.30357142857143 ; Test Loss : 0.565667986869812 ; Test accuracy : 70.5\nEpochs : 967 ; Loss : 0.5559933185577393 ; Accuracy : 72.28571428571429 ; Test Loss : 0.5656703114509583 ; Test accuracy : 70.5\nEpochs : 968 ; Loss : 0.5559843182563782 ; Accuracy : 72.28571428571429 ; Test Loss : 0.5656725764274597 ; Test accuracy : 70.5\nEpochs : 969 ; Loss : 0.5559753179550171 ; Accuracy : 72.28571428571429 ; Test Loss : 0.5656748414039612 ; Test accuracy : 70.5\nEpochs : 970 ; Loss : 0.5559664368629456 ; Accuracy : 72.28571428571429 ; Test Loss : 0.5656771063804626 ; Test accuracy : 70.5\nEpochs : 971 ; Loss : 0.5559574961662292 ; Accuracy : 72.28571428571429 ; Test Loss : 0.5656794309616089 ; Test accuracy : 70.5\nEpochs : 972 ; Loss : 0.5559486746788025 ; Accuracy : 72.28571428571429 ; Test Loss : 0.5656817555427551 ; Test accuracy : 70.5\nEpochs : 973 ; Loss : 0.5559397339820862 ; Accuracy : 72.30357142857143 ; Test Loss : 0.5656840801239014 ; Test accuracy : 70.5\nEpochs : 974 ; Loss : 0.5559309720993042 ; Accuracy : 72.30357142857143 ; Test Loss : 0.5656864047050476 ; Test accuracy : 70.5\nEpochs : 975 ; Loss : 0.5559221506118774 ; Accuracy : 72.28571428571429 ; Test Loss : 0.5656887292861938 ; Test accuracy : 70.5\nEpochs : 976 ; Loss : 0.5559133291244507 ; Accuracy : 72.28571428571429 ; Test Loss : 0.5656909942626953 ; Test accuracy : 70.5\nEpochs : 977 ; Loss : 0.5559046268463135 ; Accuracy : 72.28571428571429 ; Test Loss : 0.5656933188438416 ; Test accuracy : 70.5\nEpochs : 978 ; Loss : 0.5558958649635315 ; Accuracy : 72.28571428571429 ; Test Loss : 0.5656956434249878 ; Test accuracy : 70.5\nEpochs : 979 ; Loss : 0.5558871626853943 ; Accuracy : 72.28571428571429 ; Test Loss : 0.5656980276107788 ; Test accuracy : 70.5\nEpochs : 980 ; Loss : 0.5558784604072571 ; Accuracy : 72.28571428571429 ; Test Loss : 0.565700352191925 ; Test accuracy : 70.5\nEpochs : 981 ; Loss : 0.5558698177337646 ; Accuracy : 72.28571428571429 ; Test Loss : 0.5657027363777161 ; Test accuracy : 70.5\nEpochs : 982 ; Loss : 0.5558611750602722 ; Accuracy : 72.28571428571429 ; Test Loss : 0.5657050609588623 ; Test accuracy : 70.5\nEpochs : 983 ; Loss : 0.5558525919914246 ; Accuracy : 72.28571428571429 ; Test Loss : 0.5657074451446533 ; Test accuracy : 70.5\nEpochs : 984 ; Loss : 0.5558439493179321 ; Accuracy : 72.28571428571429 ; Test Loss : 0.5657097697257996 ; Test accuracy : 70.5\nEpochs : 985 ; Loss : 0.5558354258537292 ; Accuracy : 72.28571428571429 ; Test Loss : 0.5657122135162354 ; Test accuracy : 70.5\nEpochs : 986 ; Loss : 0.5558269023895264 ; Accuracy : 72.28571428571429 ; Test Loss : 0.5657145380973816 ; Test accuracy : 70.5\nEpochs : 987 ; Loss : 0.5558183193206787 ; Accuracy : 72.30357142857143 ; Test Loss : 0.5657169222831726 ; Test accuracy : 70.42857142857143\nEpochs : 988 ; Loss : 0.5558098554611206 ; Accuracy : 72.28571428571429 ; Test Loss : 0.5657193660736084 ; Test accuracy : 70.42857142857143\nEpochs : 989 ; Loss : 0.5558013916015625 ; Accuracy : 72.28571428571429 ; Test Loss : 0.5657217502593994 ; Test accuracy : 70.42857142857143\nEpochs : 990 ; Loss : 0.5557929277420044 ; Accuracy : 72.28571428571429 ; Test Loss : 0.5657241344451904 ; Test accuracy : 70.42857142857143\nEpochs : 991 ; Loss : 0.5557845830917358 ; Accuracy : 72.28571428571429 ; Test Loss : 0.5657264590263367 ; Test accuracy : 70.42857142857143\nEpochs : 992 ; Loss : 0.5557761192321777 ; Accuracy : 72.28571428571429 ; Test Loss : 0.5657289028167725 ; Test accuracy : 70.42857142857143\nEpochs : 993 ; Loss : 0.5557677745819092 ; Accuracy : 72.28571428571429 ; Test Loss : 0.5657313466072083 ; Test accuracy : 70.42857142857143\nEpochs : 994 ; Loss : 0.5557594299316406 ; Accuracy : 72.26785714285714 ; Test Loss : 0.5657337307929993 ; Test accuracy : 70.42857142857143\nEpochs : 995 ; Loss : 0.5557510852813721 ; Accuracy : 72.26785714285714 ; Test Loss : 0.5657361745834351 ; Test accuracy : 70.42857142857143\nEpochs : 996 ; Loss : 0.5557428002357483 ; Accuracy : 72.26785714285714 ; Test Loss : 0.5657386183738708 ; Test accuracy : 70.35714285714286\nEpochs : 997 ; Loss : 0.5557345747947693 ; Accuracy : 72.28571428571429 ; Test Loss : 0.5657410621643066 ; Test accuracy : 70.35714285714286\nEpochs : 998 ; Loss : 0.5557262301445007 ; Accuracy : 72.30357142857143 ; Test Loss : 0.5657434463500977 ; Test accuracy : 70.35714285714286\nEpochs : 999 ; Loss : 0.5557180047035217 ; Accuracy : 72.32142857142857 ; Test Loss : 0.5657459497451782 ; Test accuracy : 70.35714285714286\n","output_type":"stream"}]},{"cell_type":"code","source":"# prompt: how to unlist 'predicted'\n\npredicted = predicted.cpu().detach().numpy().flatten().tolist()","metadata":{"id":"Hmg7VqO_Ry7q","execution":{"iopub.status.busy":"2024-10-16T12:27:33.278836Z","iopub.execute_input":"2024-10-16T12:27:33.279157Z","iopub.status.idle":"2024-10-16T12:27:33.284705Z","shell.execute_reply.started":"2024-10-16T12:27:33.279123Z","shell.execute_reply":"2024-10-16T12:27:33.283750Z"},"trusted":true},"execution_count":150,"outputs":[]},{"cell_type":"code","source":"import csv\n\n# Save first 4 variables to CSV (train_loss, val_loss, train_acc, val_acc)\nwith open('qgcl_model_history.csv', 'w', newline='') as file1:\n    writer = csv.writer(file1)\n    # Writing the headers\n    writer.writerow(['train_loss', 'val_loss', 'train_acc', 'val_acc'])\n    # Writing the data\n    for i in range(len(cls_loss)):\n        writer.writerow([\n            cls_loss[i],\n            test_cls_loss[i],\n            cls_accuracy[i],\n            test_cls_accuracy[i]\n        ])\n\n# Save last 4 variables to another CSV (fpr_eqgnn, tpr_eqgnn, labels_all, y_score_eqgnn)\nwith open('qgcl_roc_data.csv', 'w', newline='') as file2:\n    writer = csv.writer(file2)\n    # Writing the headers\n    writer.writerow(['fpr_eqgnn', 'tpr_eqgnn', 'labels_all', 'y_score_eqgnn'])\n    # Writing the data\n    for i in range(len(fpr)):\n        writer.writerow([\n            fpr[i],\n            tpr[i],\n            targets[i].int().cpu().numpy(),\n            predicted[i]\n        ])\n","metadata":{"id":"vSvkCyzHO1oW","execution":{"iopub.status.busy":"2024-10-16T12:27:33.285944Z","iopub.execute_input":"2024-10-16T12:27:33.286308Z","iopub.status.idle":"2024-10-16T12:27:33.339958Z","shell.execute_reply.started":"2024-10-16T12:27:33.286273Z","shell.execute_reply":"2024-10-16T12:27:33.339065Z"},"trusted":true},"execution_count":151,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import metrics\n\ndef plot_loss_accuracy(cls_loss, cls_accuracy, test_cls_loss, test_cls_accuracy, epochs):\n    plt.figure(figsize=(14, 6))\n\n    # Plot Loss\n    plt.subplot(1, 2, 1)\n    plt.plot(range(1, epochs + 1), cls_loss, label='Train Loss', color='blue')\n    plt.plot(range(1, epochs + 1), test_cls_loss, label='Test Loss', color='red')\n    plt.title('Training and Testing Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid()\n\n    # Plot Accuracy\n    plt.subplot(1, 2, 2)\n    plt.plot(range(1, epochs + 1), cls_accuracy, label='Train Accuracy', color='blue')\n    plt.plot(range(1, epochs + 1), test_cls_accuracy, label='Test Accuracy', color='red')\n    plt.title('Training and Testing Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy (%)')\n    plt.legend()\n    plt.grid()\n\n    plt.tight_layout()\n    plt.show()\n\ndef plot_roc_curve(fpr, tpr, auc):\n    plt.figure(figsize=(8, 6))\n    plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {auc:.2f})')\n    plt.plot([0, 1], [0, 1], color='red', linestyle='--')  # Diagonal line\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.0])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.grid()\n    plt.show()\n\n# Assuming your classifier training is done and you've collected all metrics\nepochs = cls_epochs  # Total number of epochs used for training\nplot_loss_accuracy(cls_loss, cls_accuracy, test_cls_loss, test_cls_accuracy, epochs)\nplot_roc_curve(fpr, tpr, auc)\n\n# Print the performance metrics\nprint(f'AUC: {auc:.2f}')\nprint(f'F1 Score: {f1_score:.2f}')\nprint(f'Imtafe (other metrics): {imtafe}')\n","metadata":{"id":"90PD3BcGZqTE","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"db6c5594-7833-4a0a-96df-15ec00dead44","execution":{"iopub.status.busy":"2024-10-16T12:27:33.341102Z","iopub.execute_input":"2024-10-16T12:27:33.341397Z","iopub.status.idle":"2024-10-16T12:27:34.263887Z","shell.execute_reply.started":"2024-10-16T12:27:33.341365Z","shell.execute_reply":"2024-10-16T12:27:34.262991Z"},"trusted":true},"execution_count":152,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1400x600 with 2 Axes>","image/png":"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"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"AUC: 0.78\nF1 Score: 0.70\nImtafe (other metrics): 7.127659574468085\n","output_type":"stream"}]},{"cell_type":"code","source":"plt.plot(cls_loss, label='Train Loss')\nplt.plot(test_cls_loss, label='Val Loss')\nplt.legend()","metadata":{"id":"RPawpog4YODT","colab":{"base_uri":"https://localhost:8080/","height":447},"outputId":"4b665ebe-8704-46f9-f7e4-d9decb94ed2c","execution":{"iopub.status.busy":"2024-10-16T12:27:34.265103Z","iopub.execute_input":"2024-10-16T12:27:34.265404Z","iopub.status.idle":"2024-10-16T12:27:34.506494Z","shell.execute_reply.started":"2024-10-16T12:27:34.265370Z","shell.execute_reply":"2024-10-16T12:27:34.505516Z"},"trusted":true},"execution_count":153,"outputs":[{"execution_count":153,"output_type":"execute_result","data":{"text/plain":"<matplotlib.legend.Legend at 0x78088c1f1540>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"plt.plot(cls_accuracy, label='Train Accuracy')\nplt.plot(test_cls_accuracy, label='Val Accuracy')\nplt.legend()","metadata":{"id":"3Xxf7zLSZQfa","colab":{"base_uri":"https://localhost:8080/","height":447},"outputId":"3f1e4b4c-f586-4f8a-c59f-d03ac2ce3688","execution":{"iopub.status.busy":"2024-10-16T12:27:34.507592Z","iopub.execute_input":"2024-10-16T12:27:34.507876Z","iopub.status.idle":"2024-10-16T12:27:34.784478Z","shell.execute_reply.started":"2024-10-16T12:27:34.507844Z","shell.execute_reply":"2024-10-16T12:27:34.783588Z"},"trusted":true},"execution_count":154,"outputs":[{"execution_count":154,"output_type":"execute_result","data":{"text/plain":"<matplotlib.legend.Legend at 0x78088d15a590>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"import matplotlib.patches as mpl_patches\n\nfont = {'family': 'serif',\n        'color':  'darkblue',\n        'weight': 'normal',\n        'size': 12,\n        }\n\nplt.plot(fpr, tpr)\nplt.xlabel('FPR', fontsize=14)\nplt.ylabel('TPR', fontsize=14)\n# plt.text(0.9, 0.9, 'AUC = '+str(auc.round(6)), fontdict=font, wrap=True)\n# create a list with two empty handles (or more if needed)\nhandles = [mpl_patches.Rectangle((0, 0), 1, 1, fc=\"white\", ec=\"white\",\n                                 lw=0, alpha=0)]\n\n# create the corresponding number of labels (= the text you want to display)\nlabels = []\nlabels.append(\"AUC = \"+str(auc.round(6)))\n\n# create the legend, supressing the blank space of the empty line symbol and the\n# padding between symbol and label by setting handlelenght and handletextpad\nplt.legend(handles, labels, loc='best', fontsize='large',\n          fancybox=True, framealpha=0.7,\n          handlelength=0, handletextpad=0)","metadata":{"id":"1d5JA8Q0ZSRM","colab":{"base_uri":"https://localhost:8080/","height":471},"outputId":"15612ff4-3885-4718-feb2-4799615ebb3b","execution":{"iopub.status.busy":"2024-10-16T12:27:34.787886Z","iopub.execute_input":"2024-10-16T12:27:34.788275Z","iopub.status.idle":"2024-10-16T12:27:34.998191Z","shell.execute_reply.started":"2024-10-16T12:27:34.788242Z","shell.execute_reply":"2024-10-16T12:27:34.997373Z"},"trusted":true},"execution_count":155,"outputs":[{"execution_count":155,"output_type":"execute_result","data":{"text/plain":"<matplotlib.legend.Legend at 0x7809a819d360>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"print('Accuracy : ', max(test_cls_accuracy))\nprint('AUC : ', auc)\nprint('F1 score : ', f1_score)","metadata":{"id":"dxQgZz78ZU0c","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5655c706-99f5-43ae-9a35-b90acdf7e05b","execution":{"iopub.status.busy":"2024-10-16T12:27:34.999272Z","iopub.execute_input":"2024-10-16T12:27:34.999572Z","iopub.status.idle":"2024-10-16T12:27:35.004581Z","shell.execute_reply.started":"2024-10-16T12:27:34.999539Z","shell.execute_reply":"2024-10-16T12:27:35.003478Z"},"trusted":true},"execution_count":156,"outputs":[{"name":"stdout","text":"Accuracy :  71.5\nAUC :  0.7752872623185443\nF1 score :  0.7034768740031898\n","output_type":"stream"}]},{"cell_type":"code","source":"gc.collect()","metadata":{"id":"8l7_IN9UZXPt","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0041cc71-d9e9-4c45-bf10-1030ec88b98d","execution":{"iopub.status.busy":"2024-10-16T12:27:35.005838Z","iopub.execute_input":"2024-10-16T12:27:35.006162Z","iopub.status.idle":"2024-10-16T12:27:35.535576Z","shell.execute_reply.started":"2024-10-16T12:27:35.006127Z","shell.execute_reply":"2024-10-16T12:27:35.534211Z"},"trusted":true},"execution_count":157,"outputs":[{"execution_count":157,"output_type":"execute_result","data":{"text/plain":"7499"},"metadata":{}}]},{"cell_type":"code","source":"# # augmentation ratio\n\n# parameters = [7,8,9,10]\n\n# for paramx in parameters:\n#     # Set up model\n#     nodes_per_graph_original = paramx\n#     device = 'cuda'\n#     num_layer_gnn = 2\n#     num_layer_gnn_est = 2\n#     qnn_layers = 3\n#     emb_dim = 128\n#     in_dim = 8\n#     inter_dim = 256\n#     out_dim = 128\n#     JK = 'last'\n#     dropout_ratio = 0.1\n#     gnn_type = 'gat'\n#     lr = 0.001\n#     decay = 0\n#     aug_ratio = 0.1\n#     batch_size = 2000\n#     loss_temp = 0.1\n#     lamda = 0.1\n#     node_est = 'classical'\n#     entanglement_type = 'CNOT'\n#     encoding_type = 'RY'\n\n#     # Dataset\n#     qg_dataset = QuarkGluonGraphDataset(dataset_name='Quark Gluon', raw_dir=main_dir, save_dir='/content',\n#                                         data_folder_name=jet_folder_path, datafile_name=jet_file_path, labelsfile_name=jet_file_path,\n#                                         datatype='particles', dataset_size=10000, nodes_per_graph=nodes_per_graph_original,\n#                                         spectral_augmentation=False, irc_safety_aug=True, device='cuda')\n\n#     # Model\n#     gnn = ParticleNetTagger1Path(in_dim, 2)\n#     if node_est == 'classical':\n#         node_imp_estimator = GNN_imp_estimator(num_layer=num_layer_gnn_est, emb_dim=emb_dim, in_dim=in_dim, JK=JK, drop_ratio=dropout_ratio)\n#     if node_est == 'quantum':\n#         node_imp_estimator = QGNN_node_estimator(nodes_per_graph_original, qnn_layers, in_dim, device=device,\n#                                                  entanglement_type=entanglement_type, encoding_type=encoding_type)\n\n#     model = graphcl(gnn, node_imp_estimator, emb_dim, out_dim)\n#     model.to(device)\n\n#     # Optimizer with current learning rate\n#     optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=decay)\n\n\n# ############## after training ###############\n#     epochs = 50\n#     con_loss = []\n\n#     for epoch in range(1, epochs + 1):\n#         print(\"====epoch \" + str(epoch))\n#         qg_dataset.augment = False\n#         train_loss, ra_loss, cp_loss, uni_loss, al_loss = train(epoch, model=model, device=device, dataset=qg_dataset, optimizer=optimizer, batch_size=batch_size,\n#                                           nodes_per_graph=qg_dataset.nodes_per_graph, aug_ratio=aug_ratio, loss_temp=loss_temp, lamda=lamda,\n#                                           irc_safety=True, q_edge_attr=True, node_est=node_est)\n#         con_loss.append(train_loss)\n#         print(train_loss)\n#         print(ra_loss)\n#         print(cp_loss)\n#         print('UNI : ', uni_loss)\n#         print('ALIGN : ', al_loss)\n\n#     # nodes_per_graph_original = 10\n#     test_dataset = QuarkGluonGraphDataset(dataset_name='Quark Gluon', raw_dir=main_dir, save_dir='/content',\n#                                         data_folder_name=jet_folder_path, datafile_name=jet_file_path, labelsfile_name=jet_file_path,\n#                                         datatype='particles', dataset_size=7000, nodes_per_graph=nodes_per_graph_original, spectral_augmentation=False, irc_safety_aug=True,\n#                                         device='cuda')\n\n#     test_samples = torch.tensor(np.arange(2000,7000).astype('int32'))\n#     test_sampler = SubsetRandomSampler(test_samples)\n\n#     test_dataloader = test_dataloader = GraphDataLoader(\n#         test_dataset, sampler=test_sampler, batch_size=500, drop_last=False\n#     )\n\n#     cls_embds = torch.Tensor([])\n#     cls_labels = torch.Tensor([])\n\n#     for batched_graph, labels in test_dataloader:\n#           graphs = []\n#           unbatched_graph = dgl.unbatch(batched_graph)\n#           for graph in unbatched_graph:\n#             graphs.append(dgl.add_self_loop(graph))\n#           batched_graph = dgl.batch(graphs)\n#           batch_t = torch.arange(0, batched_graph.batch_size).reshape(-1,1).expand(batched_graph.batch_size, test_dataset.nodes_per_graph).reshape(-1,)\n\n#           ## For custom GNN\n#           # cls_emb = gnn.forward(batched_graph.ndata[\"node_attr\"].float(), torch.stack(batched_graph.edges()), batched_graph.edata[\"edge_attr\"].float())\n\n#           ## For ParticleNet\n#           pf_feats = batched_graph.ndata[\"node_attr\"].reshape(len(unbatched_graph), nodes_per_graph_original, -1).float()\n#           points = pf_feats[:,:,1:3]\n#           cls_emb = gnn.forward(points.reshape(points.shape[0], points.shape[2], points.shape[1])\n#                              , pf_feats.reshape(pf_feats.shape[0], pf_feats.shape[2], pf_feats.shape[1]), None)\n#           cls_emb = cls_emb.reshape(cls_emb.shape[0], cls_emb.shape[2], cls_emb.shape[1])\n#           cls_emb = cls_emb.reshape(cls_emb.shape[0]*cls_emb.shape[1], cls_emb.shape[2])\n\n#           # cls_emb = batched_graph.ndata[\"node_attr\"].float()\n#           cls_emb = global_mean_pool(cls_emb, batch_t)\n#           cls_embds = torch.cat((cls_embds, cls_emb.detach()), 0)     #cls_emb\n#           cls_labels = torch.cat((cls_labels, labels))\n\n#     cls_epochs = 1000\n#     cls_train_data = cls_embds[ : int(0.8*len(cls_embds))]\n#     targets = cls_labels[ : int(0.8*len(cls_embds))]\n#     cls_test_data = cls_embds[int(0.8*len(cls_embds)) : ]\n#     testtargets = cls_labels[int(0.8*len(cls_embds)) : ]\n\n#     cls_loss, cls_accuracy, test_cls_loss, test_cls_accuracy, fpr, tpr, auc, eB, eS, f1_score, imtafe = train_classifier(cls_epochs, classifier, cls_train_data, targets, cls_test_data, testtargets)\n\n#     # Print the performance metrics\n#     print(f'Imtafe (other metrics): {imtafe}')\n\n#     print('Accuracy : ', max(test_cls_accuracy))\n#     print('AUC : ', auc)\n#     print('F1 score : ', f1_score)\n#     # Print or log results for comparison\n#     print(f\"Finished training with parameter: {paramx}\")","metadata":{"id":"D0N6wVg9O_0h","execution":{"iopub.status.busy":"2024-10-16T12:27:35.537532Z","iopub.execute_input":"2024-10-16T12:27:35.537967Z","iopub.status.idle":"2024-10-16T12:27:35.556773Z","shell.execute_reply.started":"2024-10-16T12:27:35.537919Z","shell.execute_reply":"2024-10-16T12:27:35.555734Z"},"trusted":true},"execution_count":158,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"3Airz8bgO_6b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"DKDW5XPGO_9k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"62n6dx5nPAAh"},"execution_count":null,"outputs":[]}]}